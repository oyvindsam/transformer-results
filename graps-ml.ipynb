{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "diagnostic-seating",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.use(\"pgf\")\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from dataset import *\n",
    "\n",
    "# This is a hack to be able to import modules in parent directory\n",
    "module_path = os.path.abspath(os.path.join('.'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "plt.rcParams.update({\n",
    "    \"font.family\": \"serif\",  # use serif/main font for text elements\n",
    "    \"text.usetex\": True,     # use inline math for ticks\n",
    "    \"pgf.rcfonts\": False,     # don't setup fonts from rc parameters\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "magnetic-accessory",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "            0: deepmatcher_structured_amazon_google,\n",
    "            4: deepmatcher_structured_walmart_amazon,\n",
    "            5: deepmatcher_textual_abt_buy,\n",
    "            1: deepmatcher_structured_dblp_acm,\n",
    "            2: deepmatcher_structured_dblp_google_scholar,\n",
    "            #3: deepmatcher_structured_itunes_amazon,\n",
    "}\n",
    "\n",
    "def save_plots(models=['.'], specific=None, x='labeled_instances', y='test_f1', experiments=[0,1,3,5,6, 'ml'], include={'max':False}, \n",
    "               min_labeled=200, max_labeled=1000, file='results'):\n",
    "    \"\"\"\n",
    "    Main function for saving plots based on test results\n",
    "    params:\n",
    "    models: list of folder names you want to plot\n",
    "    specific: specify dataset by key in datasets,\n",
    "    x: value to use on x-axis\n",
    "    y: list of values to use on y-axis\n",
    "    plots: list of predefined experiments to be included\n",
    "    f1_all: True if you want a red line of maximum f1 score in graph\n",
    "    \"\"\"\n",
    "    exps = [f'exp{nr}' for nr in experiments]\n",
    "    \n",
    "    if specific is not None:\n",
    "        d = datasets[specific]()\n",
    "        plot_results(models, d, x, y, exps, include, min_labeled, file)\n",
    "       \n",
    "    else:\n",
    "        for dataset in datasets.values():\n",
    "            d = dataset()\n",
    "            plot_results(models, d, x, y, exps, include, min_labeled, max_labeled, file)\n",
    "\n",
    "def plot_results(models, dataset, x, y, experiments, include, min_labeled, max_labeled, file):\n",
    "    scores = {}\n",
    "    max_val = None\n",
    "    \n",
    "    for model in models:\n",
    "        for filename in sorted(glob(f'{model}/out/{dataset.name}/*.csv')):\n",
    "            if file in filename or model == 'ml':\n",
    "                for exp in experiments:\n",
    "                    if exp == 'exp0' and exp in filename:\n",
    "                        df = pd.read_csv(filename)\n",
    "                        scores[f'{model}_{exp}'] = df.loc[(df['labeled_instances'] >= min_labeled) & (df['labeled_instances'] <= max_labeled), :]\n",
    "                        \n",
    "                        total_values = df.loc[:, 'labeled_instances'].iloc[-1]\n",
    "                        scores[f'{model}_{exp}_Max#{total_values}'] = df.loc[:, y].iloc[-1] \n",
    "                        scores[f'{model}_{exp}_1/2#{total_values//2}'] = df.loc[:, y].iloc[-2]\n",
    "                        scores[f'{model}_{exp}_1/4#{total_values//4}'] = df.loc[:, y].iloc[-3]\n",
    "\n",
    "                    elif exp in ['exp4', 'exp6', 'exp55'] and exp in filename:\n",
    "                        df = pd.read_csv(filename)\n",
    "                        scores[f'{model}_{exp}'] = df.loc[(df['orakle_instances'] >= min_labeled) & (df['orakle_instances'] <= max_labeled), :]\n",
    "                    elif exp == 'expml' and '_data' in filename:\n",
    "                        df = pd.read_csv(filename)\n",
    "                        df = df.rename({'f1': 'test_f1', 'precision': 'test_prec', 'recall': 'test_recall'}, axis=1)\n",
    "                        df['labeled_instances'] = df.index.values\n",
    "                        scores[f'{model}_{exp}'] = df.iloc[min_labeled:max_labeled]\n",
    "                    elif exp in filename:\n",
    "                        df = pd.read_csv(filename)\n",
    "                        scores[f'{model}_{exp}'] = df.loc[(df['labeled_instances'] >= min_labeled) & (df['labeled_instances'] <= max_labeled), :]\n",
    "\n",
    "                        \n",
    "    make_plot(scores, x, y, dataset, models, experiments, max_val, include=include, file=file)\n",
    "    \n",
    "def make_plot(scores, x, y, dataset, models, experiments, max_val, include, file):\n",
    "    plt.figure(num=None, figsize=(10, 4), facecolor='w', edgecolor='k', dpi=200) # set size of plot\n",
    "    titles = []\n",
    "    \n",
    "    title_mapping = {\n",
    "            'exp0': 'Baseline',\n",
    "            'exp1': 'Partition-4',\n",
    "            'exp3': 'Hybrid',\n",
    "            'exp4': 'Hybrid-Partition-2',\n",
    "            'exp5': 'Uncertainity',\n",
    "            'exp6': 'Partition-2',\n",
    "            'exp55': 'Balanced-Uncertainity',\n",
    "            'expml': 'ML-RF'\n",
    "        }\n",
    "    def get_title(exp):\n",
    "        title = title_mapping[exp]\n",
    "        return title\n",
    "            \n",
    "    y_mapping = {\n",
    "        'test_f1': 'F1-score',\n",
    "        'iteration_time': 'Iteration time',\n",
    "        'test_recall': 'Recall',\n",
    "        'test_prec': 'Precision',\n",
    "        'train_positive_rate': 'Train Positive Rate',\n",
    "        'pool_positive_rate': 'Pool Positive Rate',\n",
    "\n",
    "    }\n",
    "    def get_y_label(y):\n",
    "        label = y_mapping[y]\n",
    "        if file == 'std':\n",
    "            label = label + ' (std)'\n",
    "        return label\n",
    "    \n",
    "    x_mapping = {\n",
    "        'labeled_instances': 'Labeled examples'\n",
    "    }\n",
    "    \n",
    "    include_model = len(models) > 1\n",
    "    \n",
    "    for key,score in scores.items():\n",
    "        exp = key.split('_')[-1]\n",
    "        model = key.split('_')[0].split('-')[0]\n",
    "        model_str = model+'_' if include_model else ''\n",
    "        key_exp = key.split('_')[-1]\n",
    "        if key_exp in ['exp4', 'exp6', 'exp55']:\n",
    "            plt.plot(score['orakle_instances'], score[y])\n",
    "            titles.append(f'{model_str}{get_title(exp)}')\n",
    "        elif 'exp' in exp:  \n",
    "            plt.plot(score[x], score[y])\n",
    "            titles.append(f'{model_str}{get_title(exp)}')\n",
    "        else:\n",
    "            for metric,show in include.items():\n",
    "                if metric in key:\n",
    "                    if show:\n",
    "                        plt.axhline(y=score, color='r', linestyle='--') # plt.axhline(y=score, color='lightgray', linestyle='--')\n",
    "                        titles.append(f\"{model_str}Baseline-{metric} ({key.split('#')[1]})\")\n",
    "\n",
    "    #plt.xticks(scores[list(scores.keys())[-1]][x])  # set values of points on x axis\n",
    "    plt.margins(0.01) # set margins to 0.01\n",
    "    plt.legend(titles, loc=4) # add titles of plots, 4 = lower right, 2 = upper left\n",
    "    title = dataset.name.split('/')[-1]\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_mapping[x])\n",
    "    plt.ylabel(get_y_label(y))\n",
    "\n",
    "    try:\n",
    "        path = os.path.join('graps', f'{\"_\".join(models)}', f'{\"_\".join(experiments)}')\n",
    "        os.makedirs(path)\n",
    "    except OSError as e:\n",
    "        pass\n",
    "    \n",
    "    plt.savefig(f'{path}/{title}_{y}.pdf', format='pdf', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fc7070-5392-4908-b3f1-4bd8b50ad404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduction\n",
    "save_plots(models=['roberta-2504'], x='labeled_instances', y='test_f1', experiments=[0,4,6], \n",
    "           include={'Max':True, '1/2':True, '1/4':False}, \n",
    "           min_labeled=200, max_labeled=1000, \n",
    "           file='results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6fed7db8-f62c-4517-b5c4-5ec5d31f8e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extended\n",
    "save_plots(models=['roberta-2504', 'ml'], x='labeled_instances', y='test_f1', experiments=[0,4,6, 'ml'], \n",
    "           include={'Max':True, '1/2':True, '1/4':True}, \n",
    "           min_labeled=1, max_labeled=1000, \n",
    "           file='results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "simplified-clarity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1\n",
    "save_plots(models=['roberta-2504'], x='labeled_instances', y='test_f1', experiments=[0,1,3,4,5,6], \n",
    "           include={'Max':True, '1/2':False, '1/4':False}, \n",
    "           min_labeled=200, max_labeled=1000, \n",
    "           file='results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "sacred-pantyhose",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STD\n",
    "save_plots(models=['roberta-2504'], x='labeled_instances', y='test_f1', experiments=[0,1,3,4,5,6], include={}, min_labeled=200, max_labeled=1000, file='std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "modified-melbourne",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration time\n",
    "save_plots(models=['roberta-2504'], x='labeled_instances', y='iteration_time', experiments=[0,1,3,4,5,6], min_labeled=200, max_labeled=1000, file='results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "integrated-turning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train positive rate\n",
    "save_plots(models=['roberta-2504'], x='labeled_instances', y='train_positive_rate', experiments=[0,4,6], specific=None, min_labeled=200, max_labeled=1000, file='results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "capable-lyric",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pool positive rate\n",
    "save_plots(models=['roberta-2504'], x='labeled_instances', y='pool_positive_rate', experiments=[0,4,6], specific=None, min_labeled=200, max_labeled=1000, file='results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d1d2444-bdde-421c-b42b-741903c4c6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall\n",
    "save_plots(models=['roberta-2504'], x='labeled_instances', y='test_recall', experiments=[0,4,6], specific=None, min_labeled=200, max_labeled=1000, file='results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8166a46-c69e-42e1-87c1-dcd7299a4fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision\n",
    "save_plots(models=['roberta-2504'], x='labeled_instances', y='test_prec', experiments=[0,4,6], specific=None, min_labeled=200, max_labeled=1000, file='results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a027ecf4-9efd-45d0-ad2a-25673181244d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7494a53c-5b8f-46ba-9a79-458aafe27bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DistilBERT vs RoBERTa\n",
    "save_plots(models=['roberta-2504','distilbert-0305'], x='labeled_instances', y='test_f1', experiments=[0,6], specific=None, min_labeled=1, max_labeled=1000, file='results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a84f5a-8bb9-461c-a0a2-aea6b26b0a79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
