We are running from this directory: /cluster/work/oyvinsam
The name of the job is: alt-0
The job ID is 152329
The job was run on these nodes: idun-05-08
Number of nodes: 1
We are using 1 cores
We are using 1 cores per node
Total of 1 cores
Sat Apr  3 15:36:28 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.27.04    Driver Version: 460.27.04    CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-PCIE...  Off  | 00000000:3B:00.0 Off |                    0 |
| N/A   29C    P0    33W / 250W |      0MiB / 16160MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
Launch Python
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
Could not create dir out, File exists
[60, 80, 100, 120, 140, 160, 180, 200, 240, 280, 320, 360, 400, 440, 480, 520, 560, 600, 640, 680, 720, 760, 800, 840, 880, 920, 960, 1000]




    ###########  New Dataset: <function deepmatcher_structured_amazon_google at 0x14cca5abf5e0>
New cross validation 0, for  <function deepmatcher_structured_amazon_google at 0x14cca5abf5e0>

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 200
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 6874
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
[{'test_loss': 0.3791249990463257, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.08333333333333333, 'pool_positive_rate': 0.10184913413560318, 'iteration_time': 122.6709668636322}, {'test_loss': 0.3071334958076477, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 80, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.1017073888725346, 'iteration_time': 108.43698811531067}, {'test_loss': 0.49024248123168945, 'test_f1': 0.20547945205479448, 'test_prec': 0.5172413793103449, 'test_recall': 0.1282051282051282, 'labeled_instances': 100, 'train_positive_rate': 0.11, 'pool_positive_rate': 0.1015648066135223, 'iteration_time': 113.04394197463989}, {'test_loss': 0.4420240819454193, 'test_f1': 0.1267605633802817, 'test_prec': 0.36, 'test_recall': 0.07692307692307693, 'labeled_instances': 120, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10171750074030204, 'iteration_time': 116.4954526424408}, {'test_loss': 0.30896317958831787, 'test_f1': 0.4722222222222222, 'test_prec': 0.5151515151515151, 'test_recall': 0.4358974358974359, 'labeled_instances': 140, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10172260172260172, 'iteration_time': 121.96452140808105}, {'test_loss': 0.4364992678165436, 'test_f1': 0.39179954441913445, 'test_prec': 0.4195121951219512, 'test_recall': 0.36752136752136755, 'labeled_instances': 160, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.10187667560321716, 'iteration_time': 122.0938048362732}, {'test_loss': 0.3897577226161957, 'test_f1': 0.4064665127020785, 'test_prec': 0.44221105527638194, 'test_recall': 0.37606837606837606, 'labeled_instances': 180, 'train_positive_rate': 0.09444444444444444, 'pool_positive_rate': 0.1018822826411712, 'iteration_time': 126.81936621665955}, {'test_loss': 0.23243491351604462, 'test_f1': 0.42077922077922075, 'test_prec': 0.5364238410596026, 'test_recall': 0.34615384615384615, 'labeled_instances': 200, 'train_positive_rate': 0.085, 'pool_positive_rate': 0.10218759364698832, 'iteration_time': 128.41889572143555}, {'test_loss': 0.4521315097808838, 'test_f1': 0.5255474452554745, 'test_prec': 0.4585987261146497, 'test_recall': 0.6153846153846154, 'labeled_instances': 240, 'train_positive_rate': 0.09583333333333334, 'pool_positive_rate': 0.10189930660235152, 'iteration_time': 132.28658962249756}, {'test_loss': 0.47376227378845215, 'test_f1': 0.4376470588235294, 'test_prec': 0.4869109947643979, 'test_recall': 0.3974358974358974, 'labeled_instances': 280, 'train_positive_rate': 0.10714285714285714, 'pool_positive_rate': 0.10145586897179254, 'iteration_time': 133.79018831253052}, {'test_loss': 0.3863884508609772, 'test_f1': 0.4510869565217392, 'test_prec': 0.6194029850746269, 'test_recall': 0.3547008547008547, 'labeled_instances': 320, 'train_positive_rate': 0.109375, 'pool_positive_rate': 0.10131217577052182, 'iteration_time': 137.72755026817322}, {'test_loss': 0.3821813464164734, 'test_f1': 0.4766146993318485, 'test_prec': 0.49767441860465117, 'test_recall': 0.45726495726495725, 'labeled_instances': 360, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10178077985876574, 'iteration_time': 138.53357863426208}, {'test_loss': 0.4137853682041168, 'test_f1': 0.5386064030131826, 'test_prec': 0.48148148148148145, 'test_recall': 0.6111111111111112, 'labeled_instances': 400, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10179178251467408, 'iteration_time': 142.58175587654114}, {'test_loss': 0.3582777976989746, 'test_f1': 0.588709677419355, 'test_prec': 0.5572519083969466, 'test_recall': 0.6239316239316239, 'labeled_instances': 440, 'train_positive_rate': 0.09545454545454546, 'pool_positive_rate': 0.10211377059372086, 'iteration_time': 145.34396886825562}, {'test_loss': 0.522704005241394, 'test_f1': 0.25301204819277107, 'test_prec': 0.42857142857142855, 'test_recall': 0.1794871794871795, 'labeled_instances': 480, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.10228339067876134, 'iteration_time': 142.90372800827026}, {'test_loss': 0.43272891640663147, 'test_f1': 0.5407925407925408, 'test_prec': 0.5948717948717949, 'test_recall': 0.49572649572649574, 'labeled_instances': 520, 'train_positive_rate': 0.09038461538461538, 'pool_positive_rate': 0.10261252754170601, 'iteration_time': 151.43355917930603}, {'test_loss': 0.43768310546875, 'test_f1': 0.5219638242894056, 'test_prec': 0.6601307189542484, 'test_recall': 0.43162393162393164, 'labeled_instances': 560, 'train_positive_rate': 0.0875, 'pool_positive_rate': 0.10294583465315173, 'iteration_time': 157.15951943397522}, {'test_loss': 0.4379901587963104, 'test_f1': 0.4468085106382979, 'test_prec': 0.5915492957746479, 'test_recall': 0.358974358974359, 'labeled_instances': 600, 'train_positive_rate': 0.08666666666666667, 'pool_positive_rate': 0.10312400382531081, 'iteration_time': 157.633930683136}, {'test_loss': 0.4682965874671936, 'test_f1': 0.4207920792079208, 'test_prec': 0.5, 'test_recall': 0.36324786324786323, 'labeled_instances': 640, 'train_positive_rate': 0.0859375, 'pool_positive_rate': 0.10330445941610523, 'iteration_time': 162.57909107208252}, {'test_loss': 0.3634989857673645, 'test_f1': 0.49187935034802777, 'test_prec': 0.5380710659898477, 'test_recall': 0.452991452991453, 'labeled_instances': 680, 'train_positive_rate': 0.08676470588235294, 'pool_positive_rate': 0.10332579916047788, 'iteration_time': 159.55700659751892}, {'test_loss': 0.3985046446323395, 'test_f1': 0.45177664974619286, 'test_prec': 0.55625, 'test_recall': 0.3803418803418803, 'labeled_instances': 720, 'train_positive_rate': 0.09166666666666666, 'pool_positive_rate': 0.10285992850178746, 'iteration_time': 161.76103711128235}, {'test_loss': 0.453679621219635, 'test_f1': 0.5397590361445783, 'test_prec': 0.6187845303867403, 'test_recall': 0.47863247863247865, 'labeled_instances': 760, 'train_positive_rate': 0.09210526315789473, 'pool_positive_rate': 0.10287863918874714, 'iteration_time': 170.48561477661133}, {'test_loss': 0.349854439496994, 'test_f1': 0.5978021978021978, 'test_prec': 0.6153846153846154, 'test_recall': 0.5811965811965812, 'labeled_instances': 800, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.10273296015805071, 'iteration_time': 170.55064702033997}, {'test_loss': 0.3924081325531006, 'test_f1': 0.6174496644295302, 'test_prec': 0.647887323943662, 'test_recall': 0.5897435897435898, 'labeled_instances': 840, 'train_positive_rate': 0.09285714285714286, 'pool_positive_rate': 0.10291680477295327, 'iteration_time': 167.22840571403503}, {'test_loss': 0.3881375193595886, 'test_f1': 0.6, 'test_prec': 0.5853658536585366, 'test_recall': 0.6153846153846154, 'labeled_instances': 880, 'train_positive_rate': 0.09431818181818181, 'pool_positive_rate': 0.10276943610276944, 'iteration_time': 177.33712577819824}, {'test_loss': 0.3488548994064331, 'test_f1': 0.5688487584650113, 'test_prec': 0.6028708133971292, 'test_recall': 0.5384615384615384, 'labeled_instances': 920, 'train_positive_rate': 0.09565217391304348, 'pool_positive_rate': 0.10262008733624454, 'iteration_time': 170.19081044197083}, {'test_loss': 0.35551244020462036, 'test_f1': 0.5672371638141809, 'test_prec': 0.6628571428571428, 'test_recall': 0.49572649572649574, 'labeled_instances': 960, 'train_positive_rate': 0.09479166666666666, 'pool_positive_rate': 0.10280689888400406, 'iteration_time': 180.71359205245972}, {'test_loss': 0.37657785415649414, 'test_f1': 0.5887850467289719, 'test_prec': 0.6494845360824743, 'test_recall': 0.5384615384615384, 'labeled_instances': 1000, 'train_positive_rate': 0.094, 'pool_positive_rate': 0.10299625468164794, 'iteration_time': 187.15468740463257}, {'test_loss': 0.23811988532543182, 'test_f1': 0.7297297297297296, 'test_prec': 0.7714285714285715, 'test_recall': 0.6923076923076923, 'labeled_instances': 6874, 'train_positive_rate': 0.1016875181844632, 'pool_positive_rate': 0.1016875181844632, 'iteration_time': 409.2015869617462}]
New cross validation 1, for  <function deepmatcher_structured_amazon_google at 0x14cca5abf5e0>

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 200
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 6874
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
[{'test_loss': 0.27436935901641846, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.13333333333333333, 'pool_positive_rate': 0.1014088641033167, 'iteration_time': 136.93471002578735}, {'test_loss': 0.24882300198078156, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 80, 'train_positive_rate': 0.15, 'pool_positive_rate': 0.10111863408890197, 'iteration_time': 149.55087065696716}, {'test_loss': 0.3437240719795227, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 100, 'train_positive_rate': 0.13, 'pool_positive_rate': 0.10126956008266903, 'iteration_time': 147.14727544784546}, {'test_loss': 0.2886030375957489, 'test_f1': 0.272108843537415, 'test_prec': 0.6666666666666666, 'test_recall': 0.17094017094017094, 'labeled_instances': 120, 'train_positive_rate': 0.11666666666666667, 'pool_positive_rate': 0.10142137992300859, 'iteration_time': 147.16154170036316}, {'test_loss': 0.41060686111450195, 'test_f1': 0.42696629213483145, 'test_prec': 0.6229508196721312, 'test_recall': 0.3247863247863248, 'labeled_instances': 140, 'train_positive_rate': 0.10714285714285714, 'pool_positive_rate': 0.10157410157410157, 'iteration_time': 151.30720901489258}, {'test_loss': 0.35227787494659424, 'test_f1': 0.45224171539961017, 'test_prec': 0.4157706093189964, 'test_recall': 0.49572649572649574, 'labeled_instances': 160, 'train_positive_rate': 0.1125, 'pool_positive_rate': 0.10142984807864164, 'iteration_time': 150.83645844459534}, {'test_loss': 0.45971551537513733, 'test_f1': 0.379746835443038, 'test_prec': 0.4658385093167702, 'test_recall': 0.32051282051282054, 'labeled_instances': 180, 'train_positive_rate': 0.1111111111111111, 'pool_positive_rate': 0.101434120107559, 'iteration_time': 153.66169691085815}, {'test_loss': 0.3313113749027252, 'test_f1': 0.4471057884231538, 'test_prec': 0.41947565543071164, 'test_recall': 0.47863247863247865, 'labeled_instances': 200, 'train_positive_rate': 0.115, 'pool_positive_rate': 0.1012885825591849, 'iteration_time': 152.32281708717346}, {'test_loss': 0.672760009765625, 'test_f1': 0.3542435424354244, 'test_prec': 0.3116883116883117, 'test_recall': 0.41025641025641024, 'labeled_instances': 240, 'train_positive_rate': 0.125, 'pool_positive_rate': 0.10084413626771178, 'iteration_time': 156.76395106315613}, {'test_loss': 0.42087993025779724, 'test_f1': 0.4484304932735426, 'test_prec': 0.4716981132075472, 'test_recall': 0.42735042735042733, 'labeled_instances': 280, 'train_positive_rate': 0.11428571428571428, 'pool_positive_rate': 0.10115256293600243, 'iteration_time': 156.0014569759369}, {'test_loss': 0.4609827399253845, 'test_f1': 0.46950092421441775, 'test_prec': 0.41368078175895767, 'test_recall': 0.5427350427350427, 'labeled_instances': 320, 'train_positive_rate': 0.10625, 'pool_positive_rate': 0.10146475434848948, 'iteration_time': 158.97457909584045}, {'test_loss': 0.46604517102241516, 'test_f1': 0.4898876404494382, 'test_prec': 0.5165876777251185, 'test_recall': 0.4658119658119658, 'labeled_instances': 360, 'train_positive_rate': 0.09722222222222222, 'pool_positive_rate': 0.10193429536383175, 'iteration_time': 160.6222791671753}, {'test_loss': 0.39541763067245483, 'test_f1': 0.5210918114143921, 'test_prec': 0.621301775147929, 'test_recall': 0.44871794871794873, 'labeled_instances': 400, 'train_positive_rate': 0.105, 'pool_positive_rate': 0.10148285449490269, 'iteration_time': 166.1554172039032}, {'test_loss': 0.4282478988170624, 'test_f1': 0.5065963060686016, 'test_prec': 0.6620689655172414, 'test_recall': 0.41025641025641024, 'labeled_instances': 440, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.1018029219769972, 'iteration_time': 153.0316460132599}, {'test_loss': 0.33148276805877686, 'test_f1': 0.5405405405405405, 'test_prec': 0.6358381502890174, 'test_recall': 0.4700854700854701, 'labeled_instances': 480, 'train_positive_rate': 0.09583333333333334, 'pool_positive_rate': 0.10212699405692836, 'iteration_time': 170.54260301589966}, {'test_loss': 0.34530502557754517, 'test_f1': 0.5441176470588236, 'test_prec': 0.6379310344827587, 'test_recall': 0.47435897435897434, 'labeled_instances': 520, 'train_positive_rate': 0.09423076923076923, 'pool_positive_rate': 0.1022977651872836, 'iteration_time': 172.18396186828613}, {'test_loss': 0.4708520174026489, 'test_f1': 0.35779816513761464, 'test_prec': 0.38613861386138615, 'test_recall': 0.3333333333333333, 'labeled_instances': 560, 'train_positive_rate': 0.09464285714285714, 'pool_positive_rate': 0.10231232182451695, 'iteration_time': 167.3621027469635}, {'test_loss': 0.3521563410758972, 'test_f1': 0.5573033707865168, 'test_prec': 0.5876777251184834, 'test_recall': 0.5299145299145299, 'labeled_instances': 600, 'train_positive_rate': 0.095, 'pool_positive_rate': 0.102327064073956, 'iteration_time': 174.35543155670166}, {'test_loss': 0.4138576090335846, 'test_f1': 0.4563106796116505, 'test_prec': 0.5280898876404494, 'test_recall': 0.4017094017094017, 'labeled_instances': 640, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.10250240615976901, 'iteration_time': 177.01961588859558}, {'test_loss': 0.35769951343536377, 'test_f1': 0.5488126649076517, 'test_prec': 0.7172413793103448, 'test_recall': 0.4444444444444444, 'labeled_instances': 680, 'train_positive_rate': 0.09264705882352942, 'pool_positive_rate': 0.1026800129157249, 'iteration_time': 177.01250529289246}, {'test_loss': 0.4081607460975647, 'test_f1': 0.5, 'test_prec': 0.47674418604651164, 'test_recall': 0.5256410256410257, 'labeled_instances': 720, 'train_positive_rate': 0.09305555555555556, 'pool_positive_rate': 0.1026974325641859, 'iteration_time': 183.26923751831055}, {'test_loss': 0.46233314275741577, 'test_f1': 0.47549019607843135, 'test_prec': 0.5574712643678161, 'test_recall': 0.41452991452991456, 'labeled_instances': 760, 'train_positive_rate': 0.09210526315789473, 'pool_positive_rate': 0.10287863918874714, 'iteration_time': 180.84272074699402}, {'test_loss': 0.4198109805583954, 'test_f1': 0.5510688836104513, 'test_prec': 0.6203208556149733, 'test_recall': 0.49572649572649574, 'labeled_instances': 800, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.10273296015805071, 'iteration_time': 178.65976810455322}, {'test_loss': 0.36847373843193054, 'test_f1': 0.5507246376811593, 'test_prec': 0.6333333333333333, 'test_recall': 0.48717948717948717, 'labeled_instances': 840, 'train_positive_rate': 0.09642857142857143, 'pool_positive_rate': 0.10241962214119987, 'iteration_time': 180.44776940345764}, {'test_loss': 0.408107727766037, 'test_f1': 0.5422993492407809, 'test_prec': 0.5506607929515418, 'test_recall': 0.5341880341880342, 'labeled_instances': 880, 'train_positive_rate': 0.09659090909090909, 'pool_positive_rate': 0.10243576910243576, 'iteration_time': 185.79735207557678}, {'test_loss': 0.4116363823413849, 'test_f1': 0.5314685314685315, 'test_prec': 0.5846153846153846, 'test_recall': 0.48717948717948717, 'labeled_instances': 920, 'train_positive_rate': 0.09565217391304348, 'pool_positive_rate': 0.10262008733624454, 'iteration_time': 191.26486468315125}, {'test_loss': 0.4659099578857422, 'test_f1': 0.5201072386058981, 'test_prec': 0.697841726618705, 'test_recall': 0.41452991452991456, 'labeled_instances': 960, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.10297598917822116, 'iteration_time': 200.32649111747742}, {'test_loss': 0.3595931828022003, 'test_f1': 0.5741626794258373, 'test_prec': 0.6521739130434783, 'test_recall': 0.5128205128205128, 'labeled_instances': 1000, 'train_positive_rate': 0.096, 'pool_positive_rate': 0.10265577119509704, 'iteration_time': 185.43362379074097}, {'test_loss': 0.2672756314277649, 'test_f1': 0.7126436781609196, 'test_prec': 0.7711442786069652, 'test_recall': 0.6623931623931624, 'labeled_instances': 6874, 'train_positive_rate': 0.1016875181844632, 'pool_positive_rate': 0.1016875181844632, 'iteration_time': 437.8609268665314}]
New cross validation 2, for  <function deepmatcher_structured_amazon_google at 0x14cca5abf5e0>

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 160
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 200
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 1000
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 6874
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
[{'test_loss': 0.4939475953578949, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.03333333333333333, 'pool_positive_rate': 0.10228940416788963, 'iteration_time': 148.98734521865845}, {'test_loss': 0.5802435278892517, 'test_f1': 0.15436241610738255, 'test_prec': 0.359375, 'test_recall': 0.09829059829059829, 'labeled_instances': 80, 'train_positive_rate': 0.0375, 'pool_positive_rate': 0.10244333235207537, 'iteration_time': 163.8282973766327}, {'test_loss': 0.6010261178016663, 'test_f1': 0.0390625, 'test_prec': 0.22727272727272727, 'test_recall': 0.021367521367521368, 'labeled_instances': 100, 'train_positive_rate': 0.04, 'pool_positive_rate': 0.10259816947150871, 'iteration_time': 172.2641739845276}, {'test_loss': 0.5014572739601135, 'test_f1': 0.08727272727272727, 'test_prec': 0.2926829268292683, 'test_recall': 0.05128205128205128, 'labeled_instances': 120, 'train_positive_rate': 0.05, 'pool_positive_rate': 0.10260586319218241, 'iteration_time': 163.37206959724426}, {'test_loss': 0.3885788917541504, 'test_f1': 0.39487179487179486, 'test_prec': 0.4935897435897436, 'test_recall': 0.32905982905982906, 'labeled_instances': 140, 'train_positive_rate': 0.07142857142857142, 'pool_positive_rate': 0.10231660231660232, 'iteration_time': 168.53832507133484}, {'test_loss': 0.5555430054664612, 'test_f1': 0.13680781758957652, 'test_prec': 0.2876712328767123, 'test_recall': 0.08974358974358974, 'labeled_instances': 160, 'train_positive_rate': 0.06875, 'pool_positive_rate': 0.10247244563598451, 'iteration_time': 163.08598685264587}, {'test_loss': 0.5189993977546692, 'test_f1': 0.37037037037037035, 'test_prec': 0.40404040404040403, 'test_recall': 0.3418803418803419, 'labeled_instances': 180, 'train_positive_rate': 0.07222222222222222, 'pool_positive_rate': 0.10247983268598745, 'iteration_time': 168.44190120697021}, {'test_loss': 0.42317140102386475, 'test_f1': 0.41176470588235287, 'test_prec': 0.4049586776859504, 'test_recall': 0.4188034188034188, 'labeled_instances': 200, 'train_positive_rate': 0.08, 'pool_positive_rate': 0.10233742882828888, 'iteration_time': 166.18462562561035}, {'test_loss': 0.4031312167644501, 'test_f1': 0.35294117647058826, 'test_prec': 0.41379310344827586, 'test_recall': 0.3076923076923077, 'labeled_instances': 240, 'train_positive_rate': 0.07916666666666666, 'pool_positive_rate': 0.10250226107928852, 'iteration_time': 173.9784746170044}, {'test_loss': 0.38179293274879456, 'test_f1': 0.47404063205417607, 'test_prec': 0.5023923444976076, 'test_recall': 0.44871794871794873, 'labeled_instances': 280, 'train_positive_rate': 0.08928571428571429, 'pool_positive_rate': 0.10221413406126782, 'iteration_time': 171.61529064178467}, {'test_loss': 0.33304938673973083, 'test_f1': 0.5887445887445888, 'test_prec': 0.5964912280701754, 'test_recall': 0.5811965811965812, 'labeled_instances': 320, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.10207506866036009, 'iteration_time': 180.38528966903687}, {'test_loss': 0.41769617795944214, 'test_f1': 0.5472061657032756, 'test_prec': 0.4982456140350877, 'test_recall': 0.6068376068376068, 'labeled_instances': 360, 'train_positive_rate': 0.09166666666666666, 'pool_positive_rate': 0.10224132637396377, 'iteration_time': 176.28981137275696}, {'test_loss': 0.3797335624694824, 'test_f1': 0.4895104895104895, 'test_prec': 0.5384615384615384, 'test_recall': 0.44871794871794873, 'labeled_instances': 400, 'train_positive_rate': 0.0875, 'pool_positive_rate': 0.10256410256410256, 'iteration_time': 181.36766076087952}, {'test_loss': 0.40156763792037964, 'test_f1': 0.4405940594059406, 'test_prec': 0.5235294117647059, 'test_recall': 0.3803418803418803, 'labeled_instances': 440, 'train_positive_rate': 0.08863636363636364, 'pool_positive_rate': 0.10258004351880634, 'iteration_time': 182.52614498138428}, {'test_loss': 0.47161611914634705, 'test_f1': 0.4912280701754386, 'test_prec': 0.593939393939394, 'test_recall': 0.4188034188034188, 'labeled_instances': 480, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.10228339067876134, 'iteration_time': 172.50275349617004}, {'test_loss': 0.436093807220459, 'test_f1': 0.4120603015075377, 'test_prec': 0.5, 'test_recall': 0.3504273504273504, 'labeled_instances': 520, 'train_positive_rate': 0.09423076923076923, 'pool_positive_rate': 0.1022977651872836, 'iteration_time': 193.98488068580627}, {'test_loss': 0.3850313723087311, 'test_f1': 0.5150812064965198, 'test_prec': 0.5634517766497462, 'test_recall': 0.47435897435897434, 'labeled_instances': 560, 'train_positive_rate': 0.09285714285714286, 'pool_positive_rate': 0.10247070003167565, 'iteration_time': 184.76557993888855}, {'test_loss': 0.40897446870803833, 'test_f1': 0.48899755501222486, 'test_prec': 0.5714285714285714, 'test_recall': 0.42735042735042733, 'labeled_instances': 600, 'train_positive_rate': 0.09166666666666666, 'pool_positive_rate': 0.10264583997449793, 'iteration_time': 185.8528916835785}, {'test_loss': 0.490640789270401, 'test_f1': 0.5252525252525252, 'test_prec': 0.6419753086419753, 'test_recall': 0.4444444444444444, 'labeled_instances': 640, 'train_positive_rate': 0.0890625, 'pool_positive_rate': 0.10298363811357074, 'iteration_time': 186.03490614891052}, {'test_loss': 0.4811479449272156, 'test_f1': 0.456140350877193, 'test_prec': 0.5515151515151515, 'test_recall': 0.3888888888888889, 'labeled_instances': 680, 'train_positive_rate': 0.09264705882352942, 'pool_positive_rate': 0.1026800129157249, 'iteration_time': 183.88206315040588}, {'test_loss': 0.46722617745399475, 'test_f1': 0.5107398568019093, 'test_prec': 0.5783783783783784, 'test_recall': 0.45726495726495725, 'labeled_instances': 720, 'train_positive_rate': 0.09444444444444444, 'pool_positive_rate': 0.10253493662658433, 'iteration_time': 184.91850304603577}, {'test_loss': 0.2847003638744354, 'test_f1': 0.519650655021834, 'test_prec': 0.53125, 'test_recall': 0.5085470085470085, 'labeled_instances': 760, 'train_positive_rate': 0.09868421052631579, 'pool_positive_rate': 0.10206084396467124, 'iteration_time': 186.28952360153198}, {'test_loss': 0.44084784388542175, 'test_f1': 0.4988662131519274, 'test_prec': 0.5314009661835749, 'test_recall': 0.4700854700854701, 'labeled_instances': 800, 'train_positive_rate': 0.0975, 'pool_positive_rate': 0.10223905169575238, 'iteration_time': 189.95526266098022}, {'test_loss': 0.46535322070121765, 'test_f1': 0.49307479224376727, 'test_prec': 0.7007874015748031, 'test_recall': 0.3803418803418803, 'labeled_instances': 840, 'train_positive_rate': 0.0988095238095238, 'pool_positive_rate': 0.10208816705336426, 'iteration_time': 190.96385288238525}, {'test_loss': 0.44073882699012756, 'test_f1': 0.5141388174807199, 'test_prec': 0.6451612903225806, 'test_recall': 0.42735042735042733, 'labeled_instances': 880, 'train_positive_rate': 0.09886363636363636, 'pool_positive_rate': 0.1021021021021021, 'iteration_time': 198.45414352416992}, {'test_loss': 0.39513224363327026, 'test_f1': 0.5673758865248226, 'test_prec': 0.6349206349206349, 'test_recall': 0.5128205128205128, 'labeled_instances': 920, 'train_positive_rate': 0.09782608695652174, 'pool_positive_rate': 0.10228417870339268, 'iteration_time': 198.45638227462769}, {'test_loss': 0.45169949531555176, 'test_f1': 0.5289672544080605, 'test_prec': 0.6441717791411042, 'test_recall': 0.44871794871794873, 'labeled_instances': 960, 'train_positive_rate': 0.09479166666666666, 'pool_positive_rate': 0.10280689888400406, 'iteration_time': 205.8980634212494}, {'test_loss': 0.43807411193847656, 'test_f1': 0.5286783042394015, 'test_prec': 0.6347305389221557, 'test_recall': 0.452991452991453, 'labeled_instances': 1000, 'train_positive_rate': 0.094, 'pool_positive_rate': 0.10299625468164794, 'iteration_time': 211.76080703735352}, {'test_loss': 0.24773310124874115, 'test_f1': 0.730512249443207, 'test_prec': 0.7627906976744186, 'test_recall': 0.7008547008547008, 'labeled_instances': 6874, 'train_positive_rate': 0.1016875181844632, 'pool_positive_rate': 0.1016875181844632, 'iteration_time': 458.7065896987915}]
New cross validation 3, for  <function deepmatcher_structured_amazon_google at 0x14cca5abf5e0>

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 100
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 200
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 560
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 6874
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
[{'test_loss': 0.2933925688266754, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.11666666666666667, 'pool_positive_rate': 0.10155562078074552, 'iteration_time': 183.0238528251648}, {'test_loss': 0.3823033571243286, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 80, 'train_positive_rate': 0.0875, 'pool_positive_rate': 0.10185457756844274, 'iteration_time': 180.82886409759521}, {'test_loss': 0.5340797305107117, 'test_f1': 0.12734082397003746, 'test_prec': 0.5151515151515151, 'test_recall': 0.07264957264957266, 'labeled_instances': 100, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10171242987894892, 'iteration_time': 193.67196083068848}, {'test_loss': 0.5136470198631287, 'test_f1': 0.1288135593220339, 'test_prec': 0.3114754098360656, 'test_recall': 0.0811965811965812, 'labeled_instances': 120, 'train_positive_rate': 0.09166666666666666, 'pool_positive_rate': 0.10186556114894878, 'iteration_time': 169.71352124214172}, {'test_loss': 0.46387308835983276, 'test_f1': 0.27184466019417475, 'test_prec': 0.56, 'test_recall': 0.1794871794871795, 'labeled_instances': 140, 'train_positive_rate': 0.08571428571428572, 'pool_positive_rate': 0.10201960201960202, 'iteration_time': 187.47459626197815}, {'test_loss': 0.47934582829475403, 'test_f1': 0.20567375886524822, 'test_prec': 0.6041666666666666, 'test_recall': 0.12393162393162394, 'labeled_instances': 160, 'train_positive_rate': 0.0875, 'pool_positive_rate': 0.10202561811140899, 'iteration_time': 184.41390299797058}, {'test_loss': 0.44930893182754517, 'test_f1': 0.40326975476839233, 'test_prec': 0.556390977443609, 'test_recall': 0.3162393162393162, 'labeled_instances': 180, 'train_positive_rate': 0.08888888888888889, 'pool_positive_rate': 0.10203167015237526, 'iteration_time': 180.37964630126953}, {'test_loss': 0.47781887650489807, 'test_f1': 0.2727272727272727, 'test_prec': 0.5675675675675675, 'test_recall': 0.1794871794871795, 'labeled_instances': 200, 'train_positive_rate': 0.085, 'pool_positive_rate': 0.10218759364698832, 'iteration_time': 184.2931580543518}, {'test_loss': 0.39096933603286743, 'test_f1': 0.47345132743362833, 'test_prec': 0.4908256880733945, 'test_recall': 0.45726495726495725, 'labeled_instances': 240, 'train_positive_rate': 0.07916666666666666, 'pool_positive_rate': 0.10250226107928852, 'iteration_time': 174.4284327030182}, {'test_loss': 0.3684849739074707, 'test_f1': 0.42165242165242167, 'test_prec': 0.6324786324786325, 'test_recall': 0.3162393162393162, 'labeled_instances': 280, 'train_positive_rate': 0.075, 'pool_positive_rate': 0.10282074613284804, 'iteration_time': 179.76769280433655}, {'test_loss': 0.3799881935119629, 'test_f1': 0.4879227053140097, 'test_prec': 0.5611111111111111, 'test_recall': 0.43162393162393164, 'labeled_instances': 320, 'train_positive_rate': 0.078125, 'pool_positive_rate': 0.10283796155019835, 'iteration_time': 179.11020398139954}, {'test_loss': 0.41802677512168884, 'test_f1': 0.14569536423841062, 'test_prec': 0.3235294117647059, 'test_recall': 0.09401709401709402, 'labeled_instances': 360, 'train_positive_rate': 0.09166666666666666, 'pool_positive_rate': 0.10224132637396377, 'iteration_time': 191.11034178733826}, {'test_loss': 0.47715553641319275, 'test_f1': 0.4630541871921182, 'test_prec': 0.5465116279069767, 'test_recall': 0.4017094017094017, 'labeled_instances': 400, 'train_positive_rate': 0.085, 'pool_positive_rate': 0.10271856657398826, 'iteration_time': 184.24483633041382}, {'test_loss': 0.4693334698677063, 'test_f1': 0.4963503649635037, 'test_prec': 0.576271186440678, 'test_recall': 0.4358974358974359, 'labeled_instances': 440, 'train_positive_rate': 0.08863636363636364, 'pool_positive_rate': 0.10258004351880634, 'iteration_time': 188.1947898864746}, {'test_loss': 0.37412431836128235, 'test_f1': 0.47088607594936704, 'test_prec': 0.577639751552795, 'test_recall': 0.3974358974358974, 'labeled_instances': 480, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10181420081326244, 'iteration_time': 193.44362688064575}, {'test_loss': 0.3174949884414673, 'test_f1': 0.49871465295629824, 'test_prec': 0.6258064516129033, 'test_recall': 0.41452991452991456, 'labeled_instances': 520, 'train_positive_rate': 0.09807692307692308, 'pool_positive_rate': 0.10198300283286119, 'iteration_time': 199.12244987487793}, {'test_loss': 0.39259856939315796, 'test_f1': 0.5188679245283019, 'test_prec': 0.5789473684210527, 'test_recall': 0.4700854700854701, 'labeled_instances': 560, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10183718720304086, 'iteration_time': 204.26191639900208}, {'test_loss': 0.4193727672100067, 'test_f1': 0.5413870246085012, 'test_prec': 0.568075117370892, 'test_recall': 0.5170940170940171, 'labeled_instances': 600, 'train_positive_rate': 0.09833333333333333, 'pool_positive_rate': 0.10200828817341409, 'iteration_time': 211.06242632865906}, {'test_loss': 0.43125513195991516, 'test_f1': 0.3542234332425068, 'test_prec': 0.48872180451127817, 'test_recall': 0.2777777777777778, 'labeled_instances': 640, 'train_positive_rate': 0.096875, 'pool_positive_rate': 0.10218158485723453, 'iteration_time': 211.70828127861023}, {'test_loss': 0.4332379698753357, 'test_f1': 0.47858942065491183, 'test_prec': 0.5828220858895705, 'test_recall': 0.405982905982906, 'labeled_instances': 680, 'train_positive_rate': 0.09852941176470588, 'pool_positive_rate': 0.10203422667097191, 'iteration_time': 224.34714341163635}, {'test_loss': 0.38627365231513977, 'test_f1': 0.5738758029978587, 'test_prec': 0.575107296137339, 'test_recall': 0.5726495726495726, 'labeled_instances': 720, 'train_positive_rate': 0.09861111111111111, 'pool_positive_rate': 0.10204744881377965, 'iteration_time': 219.78166007995605}, {'test_loss': 0.33782780170440674, 'test_f1': 0.5794392523364487, 'test_prec': 0.6391752577319587, 'test_recall': 0.5299145299145299, 'labeled_instances': 760, 'train_positive_rate': 0.09342105263157895, 'pool_positive_rate': 0.10271508014393196, 'iteration_time': 224.26724338531494}, {'test_loss': 0.3656686842441559, 'test_f1': 0.59375, 'test_prec': 0.6214953271028038, 'test_recall': 0.5683760683760684, 'labeled_instances': 800, 'train_positive_rate': 0.095, 'pool_positive_rate': 0.10256832400395127, 'iteration_time': 203.90145754814148}, {'test_loss': 0.3644871115684509, 'test_f1': 0.5856832971800433, 'test_prec': 0.5947136563876652, 'test_recall': 0.5769230769230769, 'labeled_instances': 840, 'train_positive_rate': 0.09166666666666666, 'pool_positive_rate': 0.10308253231687106, 'iteration_time': 233.60968446731567}, {'test_loss': 0.48300865292549133, 'test_f1': 0.3439153439153439, 'test_prec': 0.4513888888888889, 'test_recall': 0.2777777777777778, 'labeled_instances': 880, 'train_positive_rate': 0.09431818181818181, 'pool_positive_rate': 0.10276943610276944, 'iteration_time': 234.7580635547638}, {'test_loss': 0.3356768488883972, 'test_f1': 0.5547445255474452, 'test_prec': 0.6440677966101694, 'test_recall': 0.48717948717948717, 'labeled_instances': 920, 'train_positive_rate': 0.09891304347826087, 'pool_positive_rate': 0.10211622438696674, 'iteration_time': 224.6974802017212}, {'test_loss': 0.3783408999443054, 'test_f1': 0.22287390029325513, 'test_prec': 0.35514018691588783, 'test_recall': 0.1623931623931624, 'labeled_instances': 960, 'train_positive_rate': 0.09895833333333333, 'pool_positive_rate': 0.10213053770713561, 'iteration_time': 221.04731822013855}, {'test_loss': 0.3505653738975525, 'test_f1': 0.5787037037037036, 'test_prec': 0.6313131313131313, 'test_recall': 0.5341880341880342, 'labeled_instances': 1000, 'train_positive_rate': 0.105, 'pool_positive_rate': 0.10112359550561797, 'iteration_time': 229.11905097961426}, {'test_loss': 0.2707332670688629, 'test_f1': 0.6823529411764705, 'test_prec': 0.7591623036649214, 'test_recall': 0.6196581196581197, 'labeled_instances': 6874, 'train_positive_rate': 0.1016875181844632, 'pool_positive_rate': 0.1016875181844632, 'iteration_time': 523.680212020874}]
New cross validation 4, for  <function deepmatcher_structured_amazon_google at 0x14cca5abf5e0>

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 200
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 480
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 6874
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
[{'test_loss': 0.2785826623439789, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.15, 'pool_positive_rate': 0.10126210742588788, 'iteration_time': 179.34965133666992}, {'test_loss': 0.267952561378479, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 80, 'train_positive_rate': 0.15, 'pool_positive_rate': 0.10111863408890197, 'iteration_time': 189.40980505943298}, {'test_loss': 0.22968842089176178, 'test_f1': 0.5195876288659794, 'test_prec': 0.50199203187251, 'test_recall': 0.5384615384615384, 'labeled_instances': 100, 'train_positive_rate': 0.14, 'pool_positive_rate': 0.1011219368172424, 'iteration_time': 217.09229612350464}, {'test_loss': 0.2686937153339386, 'test_f1': 0.46436781609195404, 'test_prec': 0.5024875621890548, 'test_recall': 0.43162393162393164, 'labeled_instances': 120, 'train_positive_rate': 0.14166666666666666, 'pool_positive_rate': 0.10097719869706841, 'iteration_time': 212.63189673423767}, {'test_loss': 0.2915519177913666, 'test_f1': 0.5396145610278372, 'test_prec': 0.5407725321888412, 'test_recall': 0.5384615384615384, 'labeled_instances': 140, 'train_positive_rate': 0.12142857142857143, 'pool_positive_rate': 0.10127710127710128, 'iteration_time': 214.35938596725464}, {'test_loss': 0.42784684896469116, 'test_f1': 0.1933085501858736, 'test_prec': 0.7428571428571429, 'test_recall': 0.1111111111111111, 'labeled_instances': 160, 'train_positive_rate': 0.10625, 'pool_positive_rate': 0.10157879058683349, 'iteration_time': 214.46642971038818}, {'test_loss': 0.3629744350910187, 'test_f1': 0.5391969407265774, 'test_prec': 0.48788927335640137, 'test_recall': 0.6025641025641025, 'labeled_instances': 180, 'train_positive_rate': 0.09444444444444444, 'pool_positive_rate': 0.1018822826411712, 'iteration_time': 211.83705806732178}, {'test_loss': 0.31911370158195496, 'test_f1': 0.3507692307692308, 'test_prec': 0.6263736263736264, 'test_recall': 0.24358974358974358, 'labeled_instances': 200, 'train_positive_rate': 0.09, 'pool_positive_rate': 0.10203775846568774, 'iteration_time': 211.95135593414307}, {'test_loss': 0.3905051648616791, 'test_f1': 0.43701799485861176, 'test_prec': 0.5483870967741935, 'test_recall': 0.36324786324786323, 'labeled_instances': 240, 'train_positive_rate': 0.07916666666666666, 'pool_positive_rate': 0.10250226107928852, 'iteration_time': 217.40155482292175}, {'test_loss': 0.40131714940071106, 'test_f1': 0.4, 'test_prec': 0.6875, 'test_recall': 0.28205128205128205, 'labeled_instances': 280, 'train_positive_rate': 0.08928571428571429, 'pool_positive_rate': 0.10221413406126782, 'iteration_time': 220.42656707763672}, {'test_loss': 0.46820735931396484, 'test_f1': 0.35114503816793896, 'test_prec': 0.4339622641509434, 'test_recall': 0.2948717948717949, 'labeled_instances': 320, 'train_positive_rate': 0.090625, 'pool_positive_rate': 0.10222764723832774, 'iteration_time': 231.44873571395874}, {'test_loss': 0.293174684047699, 'test_f1': 0.5669291338582678, 'test_prec': 0.7346938775510204, 'test_recall': 0.46153846153846156, 'labeled_instances': 360, 'train_positive_rate': 0.08888888888888889, 'pool_positive_rate': 0.10239484187902978, 'iteration_time': 202.4667797088623}, {'test_loss': 0.3755534291267395, 'test_f1': 0.5235602094240838, 'test_prec': 0.6756756756756757, 'test_recall': 0.42735042735042733, 'labeled_instances': 400, 'train_positive_rate': 0.095, 'pool_positive_rate': 0.10210071053444547, 'iteration_time': 230.99847960472107}, {'test_loss': 0.3438507616519928, 'test_f1': 0.4768211920529801, 'test_prec': 0.4931506849315068, 'test_recall': 0.46153846153846156, 'labeled_instances': 440, 'train_positive_rate': 0.09545454545454546, 'pool_positive_rate': 0.10211377059372086, 'iteration_time': 238.48349475860596}, {'test_loss': 0.4091413617134094, 'test_f1': 0.4519774011299435, 'test_prec': 0.6666666666666666, 'test_recall': 0.3418803418803419, 'labeled_instances': 480, 'train_positive_rate': 0.09583333333333334, 'pool_positive_rate': 0.10212699405692836, 'iteration_time': 218.71040272712708}, {'test_loss': 0.2856200933456421, 'test_f1': 0.579185520361991, 'test_prec': 0.6153846153846154, 'test_recall': 0.5470085470085471, 'labeled_instances': 520, 'train_positive_rate': 0.09423076923076923, 'pool_positive_rate': 0.1022977651872836, 'iteration_time': 223.42137360572815}, {'test_loss': 0.477974534034729, 'test_f1': 0.5605700712589075, 'test_prec': 0.6310160427807486, 'test_recall': 0.5042735042735043, 'labeled_instances': 560, 'train_positive_rate': 0.09642857142857143, 'pool_positive_rate': 0.10215394361735824, 'iteration_time': 224.6707592010498}, {'test_loss': 0.36725208163261414, 'test_f1': 0.5628140703517588, 'test_prec': 0.6829268292682927, 'test_recall': 0.47863247863247865, 'labeled_instances': 600, 'train_positive_rate': 0.09666666666666666, 'pool_positive_rate': 0.10216767612368505, 'iteration_time': 225.4727509021759}, {'test_loss': 0.41968104243278503, 'test_f1': 0.2222222222222222, 'test_prec': 0.3037037037037037, 'test_recall': 0.1752136752136752, 'labeled_instances': 640, 'train_positive_rate': 0.103125, 'pool_positive_rate': 0.10153994225216555, 'iteration_time': 229.35481023788452}, {'test_loss': 0.3899994194507599, 'test_f1': 0.579185520361991, 'test_prec': 0.6153846153846154, 'test_recall': 0.5470085470085471, 'labeled_instances': 680, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10187278010978366, 'iteration_time': 253.54796719551086}, {'test_loss': 0.37311071157455444, 'test_f1': 0.5900900900900901, 'test_prec': 0.6238095238095238, 'test_recall': 0.5598290598290598, 'labeled_instances': 720, 'train_positive_rate': 0.10416666666666667, 'pool_positive_rate': 0.10139746506337341, 'iteration_time': 263.43936109542847}, {'test_loss': 0.33561593294143677, 'test_f1': 0.5892473118279571, 'test_prec': 0.5930735930735931, 'test_recall': 0.5854700854700855, 'labeled_instances': 760, 'train_positive_rate': 0.10394736842105264, 'pool_positive_rate': 0.10140660778541054, 'iteration_time': 269.88999676704407}, {'test_loss': 0.3675234913825989, 'test_f1': 0.6187363834422658, 'test_prec': 0.6311111111111111, 'test_recall': 0.6068376068376068, 'labeled_instances': 800, 'train_positive_rate': 0.105, 'pool_positive_rate': 0.10125123477115575, 'iteration_time': 241.10674285888672}, {'test_loss': 0.3129766285419464, 'test_f1': 0.5230769230769231, 'test_prec': 0.5384615384615384, 'test_recall': 0.5085470085470085, 'labeled_instances': 840, 'train_positive_rate': 0.10595238095238095, 'pool_positive_rate': 0.10109380178985747, 'iteration_time': 279.1341960430145}, {'test_loss': 0.4049142301082611, 'test_f1': 0.6150442477876107, 'test_prec': 0.6376146788990825, 'test_recall': 0.594017094017094, 'labeled_instances': 880, 'train_positive_rate': 0.10568181818181818, 'pool_positive_rate': 0.1011011011011011, 'iteration_time': 276.3441798686981}, {'test_loss': 0.356105774641037, 'test_f1': 0.6185101580135439, 'test_prec': 0.6555023923444976, 'test_recall': 0.5854700854700855, 'labeled_instances': 920, 'train_positive_rate': 0.10869565217391304, 'pool_positive_rate': 0.10060463553913336, 'iteration_time': 264.02068400382996}, {'test_loss': 0.3117325007915497, 'test_f1': 0.6315789473684211, 'test_prec': 0.6224066390041494, 'test_recall': 0.6410256410256411, 'labeled_instances': 960, 'train_positive_rate': 0.10520833333333333, 'pool_positive_rate': 0.10111599594183295, 'iteration_time': 289.9400951862335}, {'test_loss': 0.3647712767124176, 'test_f1': 0.6167400881057269, 'test_prec': 0.6363636363636364, 'test_recall': 0.5982905982905983, 'labeled_instances': 1000, 'train_positive_rate': 0.105, 'pool_positive_rate': 0.10112359550561797, 'iteration_time': 275.30117177963257}, {'test_loss': 0.2546791434288025, 'test_f1': 0.7006960556844548, 'test_prec': 0.766497461928934, 'test_recall': 0.6452991452991453, 'labeled_instances': 6874, 'train_positive_rate': 0.1016875181844632, 'pool_positive_rate': 0.1016875181844632, 'iteration_time': 579.2673599720001}]
Could not create dir out, File exists




    ###########  New Dataset: <function deepmatcher_structured_dblp_acm at 0x14cc376e10d0>
New cross validation 0, for  <function deepmatcher_structured_dblp_acm at 0x14cc376e10d0>

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 200
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 240
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 360
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 7417
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
[{'test_loss': 0.11529754847288132, 'test_f1': 0.8884381338742394, 'test_prec': 0.8081180811808119, 'test_recall': 0.9864864864864865, 'labeled_instances': 60, 'train_positive_rate': 0.21666666666666667, 'pool_positive_rate': 0.1792850346608672, 'iteration_time': 298.1946415901184}, {'test_loss': 0.2072502225637436, 'test_f1': 0.8741328047571851, 'test_prec': 0.7805309734513274, 'test_recall': 0.9932432432432432, 'labeled_instances': 80, 'train_positive_rate': 0.1875, 'pool_positive_rate': 0.17950115851165327, 'iteration_time': 298.8016242980957}, {'test_loss': 0.06366977095603943, 'test_f1': 0.9353448275862069, 'test_prec': 0.8966942148760331, 'test_recall': 0.9774774774774775, 'labeled_instances': 100, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.1793084597512642, 'iteration_time': 304.3375492095947}, {'test_loss': 0.10411783307790756, 'test_f1': 0.9066666666666667, 'test_prec': 0.832391713747646, 'test_recall': 0.9954954954954955, 'labeled_instances': 120, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.17925174729340826, 'iteration_time': 303.5549900531769}, {'test_loss': 0.17515897750854492, 'test_f1': 0.8683693516699411, 'test_prec': 0.7700348432055749, 'test_recall': 0.9954954954954955, 'labeled_instances': 140, 'train_positive_rate': 0.2357142857142857, 'pool_positive_rate': 0.17850762676927306, 'iteration_time': 308.6117925643921}, {'test_loss': 0.10507500916719437, 'test_f1': 0.8837675350701403, 'test_prec': 0.796028880866426, 'test_recall': 0.9932432432432432, 'labeled_instances': 160, 'train_positive_rate': 0.225, 'pool_positive_rate': 0.17858619264158743, 'iteration_time': 301.6906657218933}, {'test_loss': 0.09794606268405914, 'test_f1': 0.9225941422594143, 'test_prec': 0.861328125, 'test_recall': 0.9932432432432432, 'labeled_instances': 180, 'train_positive_rate': 0.2222222222222222, 'pool_positive_rate': 0.17852701395605913, 'iteration_time': 307.5909307003021}, {'test_loss': 0.106660857796669, 'test_f1': 0.8992878942014242, 'test_prec': 0.8200371057513914, 'test_recall': 0.9954954954954955, 'labeled_instances': 200, 'train_positive_rate': 0.23, 'pool_positive_rate': 0.17819038381599003, 'iteration_time': 306.2682614326477}, {'test_loss': 0.09159880131483078, 'test_f1': 0.914344685242518, 'test_prec': 0.8438095238095238, 'test_recall': 0.9977477477477478, 'labeled_instances': 240, 'train_positive_rate': 0.2125, 'pool_positive_rate': 0.17848683293855372, 'iteration_time': 315.61333417892456}, {'test_loss': 0.10477818548679352, 'test_f1': 0.9430719656283566, 'test_prec': 0.9014373716632443, 'test_recall': 0.9887387387387387, 'labeled_instances': 280, 'train_positive_rate': 0.21071428571428572, 'pool_positive_rate': 0.17836626033347344, 'iteration_time': 316.67282819747925}, {'test_loss': 0.09964212775230408, 'test_f1': 0.9420600858369099, 'test_prec': 0.8995901639344263, 'test_recall': 0.9887387387387387, 'labeled_instances': 320, 'train_positive_rate': 0.203125, 'pool_positive_rate': 0.17852613780470622, 'iteration_time': 330.12434792518616}, {'test_loss': 0.09378119558095932, 'test_f1': 0.9484978540772531, 'test_prec': 0.9057377049180327, 'test_recall': 0.9954954954954955, 'labeled_instances': 360, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.178546124415474, 'iteration_time': 330.21412539482117}, {'test_loss': 0.04938123747706413, 'test_f1': 0.9566160520607375, 'test_prec': 0.9225941422594143, 'test_recall': 0.9932432432432432, 'labeled_instances': 400, 'train_positive_rate': 0.1925, 'pool_positive_rate': 0.178851360980476, 'iteration_time': 331.2660057544708}, {'test_loss': 0.0338396281003952, 'test_f1': 0.9701657458563535, 'test_prec': 0.9522776572668112, 'test_recall': 0.9887387387387387, 'labeled_instances': 440, 'train_positive_rate': 0.19545454545454546, 'pool_positive_rate': 0.17858678515121112, 'iteration_time': 315.11279344558716}, {'test_loss': 0.024150826036930084, 'test_f1': 0.9851428571428571, 'test_prec': 1.0, 'test_recall': 0.9707207207207207, 'labeled_instances': 480, 'train_positive_rate': 0.19375, 'pool_positive_rate': 0.17860746720484358, 'iteration_time': 332.517626285553}, {'test_loss': 0.05822363868355751, 'test_f1': 0.9554831704668838, 'test_prec': 0.9224318658280922, 'test_recall': 0.990990990990991, 'labeled_instances': 520, 'train_positive_rate': 0.18269230769230768, 'pool_positive_rate': 0.17935334203276787, 'iteration_time': 323.80053782463074}, {'test_loss': 0.028593480587005615, 'test_f1': 0.9754464285714286, 'test_prec': 0.9668141592920354, 'test_recall': 0.9842342342342343, 'labeled_instances': 560, 'train_positive_rate': 0.18928571428571428, 'pool_positive_rate': 0.1787953915706577, 'iteration_time': 324.6516263484955}, {'test_loss': 0.024478916078805923, 'test_f1': 0.9808773903262092, 'test_prec': 0.9797752808988764, 'test_recall': 0.9819819819819819, 'labeled_instances': 600, 'train_positive_rate': 0.19166666666666668, 'pool_positive_rate': 0.1785242775414405, 'iteration_time': 337.5024342536926}, {'test_loss': 0.022325629368424416, 'test_f1': 0.9819004524886877, 'test_prec': 0.9863636363636363, 'test_recall': 0.9774774774774775, 'labeled_instances': 640, 'train_positive_rate': 0.1953125, 'pool_positive_rate': 0.17810240519403867, 'iteration_time': 336.3900089263916}, {'test_loss': 0.03308241441845894, 'test_f1': 0.9775280898876404, 'test_prec': 0.9753363228699552, 'test_recall': 0.9797297297297297, 'labeled_instances': 680, 'train_positive_rate': 0.19117647058823528, 'pool_positive_rate': 0.17841769333531246, 'iteration_time': 339.0700511932373}, {'test_loss': 0.04112616926431656, 'test_f1': 0.9754464285714286, 'test_prec': 0.9668141592920354, 'test_recall': 0.9842342342342343, 'labeled_instances': 720, 'train_positive_rate': 0.19444444444444445, 'pool_positive_rate': 0.17799014484097356, 'iteration_time': 338.1679449081421}, {'test_loss': 0.029129207134246826, 'test_f1': 0.9783352337514253, 'test_prec': 0.9907621247113164, 'test_recall': 0.9662162162162162, 'labeled_instances': 760, 'train_positive_rate': 0.19342105263157894, 'pool_positive_rate': 0.17800811176205497, 'iteration_time': 350.6070017814636}, {'test_loss': 0.05532419681549072, 'test_f1': 0.9658213891951488, 'test_prec': 0.9460043196544277, 'test_recall': 0.9864864864864865, 'labeled_instances': 800, 'train_positive_rate': 0.18875, 'pool_positive_rate': 0.17847967356808223, 'iteration_time': 366.414160490036}, {'test_loss': 0.026054758578538895, 'test_f1': 0.9799107142857142, 'test_prec': 0.9712389380530974, 'test_recall': 0.9887387387387387, 'labeled_instances': 840, 'train_positive_rate': 0.18333333333333332, 'pool_positive_rate': 0.17910901626881556, 'iteration_time': 339.847553730011}, {'test_loss': 0.06259183585643768, 'test_f1': 0.9642058165548099, 'test_prec': 0.9577777777777777, 'test_recall': 0.9707207207207207, 'labeled_instances': 880, 'train_positive_rate': 0.18295454545454545, 'pool_positive_rate': 0.17913415940033656, 'iteration_time': 366.15682458877563}, {'test_loss': 0.05683258920907974, 'test_f1': 0.9660633484162895, 'test_prec': 0.9704545454545455, 'test_recall': 0.9617117117117117, 'labeled_instances': 920, 'train_positive_rate': 0.18043478260869567, 'pool_positive_rate': 0.17946744651377558, 'iteration_time': 374.7429847717285}, {'test_loss': 0.029337799176573753, 'test_f1': 0.9764837625979844, 'test_prec': 0.9710467706013363, 'test_recall': 0.9819819819819819, 'labeled_instances': 960, 'train_positive_rate': 0.17916666666666667, 'pool_positive_rate': 0.17964999225646586, 'iteration_time': 366.28311944007874}, {'test_loss': 0.020694803446531296, 'test_f1': 0.9898074745186863, 'test_prec': 0.9954441913439636, 'test_recall': 0.9842342342342343, 'labeled_instances': 1000, 'train_positive_rate': 0.183, 'pool_positive_rate': 0.1790556334735858, 'iteration_time': 370.83144187927246}, {'test_loss': 0.03174011409282684, 'test_f1': 0.9817351598173515, 'test_prec': 0.9953703703703703, 'test_recall': 0.9684684684684685, 'labeled_instances': 7417, 'train_positive_rate': 0.17958743427261697, 'pool_positive_rate': 0.17958743427261697, 'iteration_time': 768.6515550613403}]
New cross validation 1, for  <function deepmatcher_structured_dblp_acm at 0x14cc376e10d0>

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 160
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 200
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 7417
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
[{'test_loss': 0.11989666521549225, 'test_f1': 0.8695652173913043, 'test_prec': 0.7746478873239436, 'test_recall': 0.990990990990991, 'labeled_instances': 60, 'train_positive_rate': 0.23333333333333334, 'pool_positive_rate': 0.17914910969145031, 'iteration_time': 319.5422043800354}, {'test_loss': 0.16680918633937836, 'test_f1': 0.8912354804646251, 'test_prec': 0.8389662027833003, 'test_recall': 0.9504504504504504, 'labeled_instances': 80, 'train_positive_rate': 0.25, 'pool_positive_rate': 0.17881968106855664, 'iteration_time': 313.7374186515808}, {'test_loss': 0.06507977843284607, 'test_f1': 0.9286474973375931, 'test_prec': 0.8808080808080808, 'test_recall': 0.9819819819819819, 'labeled_instances': 100, 'train_positive_rate': 0.24, 'pool_positive_rate': 0.17876178761787617, 'iteration_time': 316.74830412864685}, {'test_loss': 0.048721201717853546, 'test_f1': 0.9624573378839592, 'test_prec': 0.9724137931034482, 'test_recall': 0.9527027027027027, 'labeled_instances': 120, 'train_positive_rate': 0.225, 'pool_positive_rate': 0.17884061943264354, 'iteration_time': 322.2408993244171}, {'test_loss': 0.05909129977226257, 'test_f1': 0.9551569506726457, 'test_prec': 0.9508928571428571, 'test_recall': 0.9594594594594594, 'labeled_instances': 140, 'train_positive_rate': 0.20714285714285716, 'pool_positive_rate': 0.17905730383399754, 'iteration_time': 325.6093862056732}, {'test_loss': 0.042358480393886566, 'test_f1': 0.9685393258426966, 'test_prec': 0.9663677130044843, 'test_recall': 0.9707207207207207, 'labeled_instances': 160, 'train_positive_rate': 0.20625, 'pool_positive_rate': 0.17899958660603554, 'iteration_time': 325.6786003112793}, {'test_loss': 0.04999035596847534, 'test_f1': 0.9652076318742986, 'test_prec': 0.9619686800894854, 'test_recall': 0.9684684684684685, 'labeled_instances': 180, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.1790797291695454, 'iteration_time': 325.77515625953674}, {'test_loss': 0.060731831938028336, 'test_f1': 0.9526952695269527, 'test_prec': 0.9311827956989247, 'test_recall': 0.9752252252252253, 'labeled_instances': 200, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.1790217541914923, 'iteration_time': 330.66681146621704}, {'test_loss': 0.05292213335633278, 'test_f1': 0.9694915254237287, 'test_prec': 0.9727891156462585, 'test_recall': 0.9662162162162162, 'labeled_instances': 240, 'train_positive_rate': 0.18333333333333332, 'pool_positive_rate': 0.17946217082346383, 'iteration_time': 330.6909911632538}, {'test_loss': 0.06404466927051544, 'test_f1': 0.9617977528089887, 'test_prec': 0.9596412556053812, 'test_recall': 0.963963963963964, 'labeled_instances': 280, 'train_positive_rate': 0.18214285714285713, 'pool_positive_rate': 0.1794871794871795, 'iteration_time': 324.36957359313965}, {'test_loss': 0.04582212492823601, 'test_f1': 0.9718785151856018, 'test_prec': 0.9707865168539326, 'test_recall': 0.972972972972973, 'labeled_instances': 320, 'train_positive_rate': 0.18125, 'pool_positive_rate': 0.17951247005777088, 'iteration_time': 342.2313303947449}, {'test_loss': 0.05219321697950363, 'test_f1': 0.9737742303306728, 'test_prec': 0.9861431870669746, 'test_recall': 0.9617117117117117, 'labeled_instances': 360, 'train_positive_rate': 0.175, 'pool_positive_rate': 0.1798214538755845, 'iteration_time': 336.49931502342224}, {'test_loss': 0.06734057515859604, 'test_f1': 0.967741935483871, 'test_prec': 0.9560439560439561, 'test_recall': 0.9797297297297297, 'labeled_instances': 400, 'train_positive_rate': 0.1775, 'pool_positive_rate': 0.17970642724811173, 'iteration_time': 328.1262583732605}, {'test_loss': 0.06985774636268616, 'test_f1': 0.963882618510158, 'test_prec': 0.9660633484162896, 'test_recall': 0.9617117117117117, 'labeled_instances': 440, 'train_positive_rate': 0.17954545454545454, 'pool_positive_rate': 0.17959008169700444, 'iteration_time': 353.8572995662689}, {'test_loss': 0.039667945355176926, 'test_f1': 0.9841628959276018, 'test_prec': 0.9886363636363636, 'test_recall': 0.9797297297297297, 'labeled_instances': 480, 'train_positive_rate': 0.18541666666666667, 'pool_positive_rate': 0.17918408533948393, 'iteration_time': 337.0997726917267}, {'test_loss': 0.0495520755648613, 'test_f1': 0.9660633484162895, 'test_prec': 0.9704545454545455, 'test_recall': 0.9617117117117117, 'labeled_instances': 520, 'train_positive_rate': 0.18653846153846154, 'pool_positive_rate': 0.1790633608815427, 'iteration_time': 342.79122042655945}, {'test_loss': 0.04231898486614227, 'test_f1': 0.984090909090909, 'test_prec': 0.9931192660550459, 'test_recall': 0.9752252252252253, 'labeled_instances': 560, 'train_positive_rate': 0.19285714285714287, 'pool_positive_rate': 0.17850371882747557, 'iteration_time': 366.6962671279907}, {'test_loss': 0.040153346955776215, 'test_f1': 0.9786276715410572, 'test_prec': 0.9775280898876404, 'test_recall': 0.9797297297297297, 'labeled_instances': 600, 'train_positive_rate': 0.19333333333333333, 'pool_positive_rate': 0.17837758544814433, 'iteration_time': 351.7943398952484}, {'test_loss': 0.044668085873126984, 'test_f1': 0.9738339021615473, 'test_prec': 0.9839080459770115, 'test_recall': 0.963963963963964, 'labeled_instances': 640, 'train_positive_rate': 0.196875, 'pool_positive_rate': 0.17795484727755645, 'iteration_time': 352.450382232666}, {'test_loss': 0.039246998727321625, 'test_f1': 0.9775280898876404, 'test_prec': 0.9753363228699552, 'test_recall': 0.9797297297297297, 'labeled_instances': 680, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.17752708920884666, 'iteration_time': 356.03768849372864}, {'test_loss': 0.041948556900024414, 'test_f1': 0.9775784753363228, 'test_prec': 0.9732142857142857, 'test_recall': 0.9819819819819819, 'labeled_instances': 720, 'train_positive_rate': 0.20694444444444443, 'pool_positive_rate': 0.1766462595191877, 'iteration_time': 356.7591574192047}, {'test_loss': 0.03750915825366974, 'test_f1': 0.9829738933030647, 'test_prec': 0.9908466819221968, 'test_recall': 0.9752252252252253, 'labeled_instances': 760, 'train_positive_rate': 0.20789473684210527, 'pool_positive_rate': 0.17635571578789244, 'iteration_time': 361.15959787368774}, {'test_loss': 0.03943577781319618, 'test_f1': 0.967670011148272, 'test_prec': 0.9580573951434879, 'test_recall': 0.9774774774774775, 'labeled_instances': 800, 'train_positive_rate': 0.20875, 'pool_positive_rate': 0.17606165936224874, 'iteration_time': 371.8963189125061}, {'test_loss': 0.03354044631123543, 'test_f1': 0.980963045912654, 'test_prec': 0.9755011135857461, 'test_recall': 0.9864864864864865, 'labeled_instances': 840, 'train_positive_rate': 0.2119047619047619, 'pool_positive_rate': 0.17545993614109776, 'iteration_time': 359.07799458503723}, {'test_loss': 0.024956265464425087, 'test_f1': 0.9785310734463276, 'test_prec': 0.981859410430839, 'test_recall': 0.9752252252252253, 'labeled_instances': 880, 'train_positive_rate': 0.20681818181818182, 'pool_positive_rate': 0.17592167661006577, 'iteration_time': 379.64921379089355}, {'test_loss': 0.03422337397933006, 'test_f1': 0.9854096520763187, 'test_prec': 0.9821029082774049, 'test_recall': 0.9887387387387387, 'labeled_instances': 920, 'train_positive_rate': 0.20869565217391303, 'pool_positive_rate': 0.175465599507465, 'iteration_time': 393.8766613006592}, {'test_loss': 0.030783722177147865, 'test_f1': 0.978675645342312, 'test_prec': 0.9753914988814317, 'test_recall': 0.9819819819819819, 'labeled_instances': 960, 'train_positive_rate': 0.2125, 'pool_positive_rate': 0.17469413040111506, 'iteration_time': 377.50331449508667}, {'test_loss': 0.037180233746767044, 'test_f1': 0.9741863075196409, 'test_prec': 0.970917225950783, 'test_recall': 0.9774774774774775, 'labeled_instances': 1000, 'train_positive_rate': 0.207, 'pool_positive_rate': 0.1753155680224404, 'iteration_time': 380.29882764816284}, {'test_loss': 0.013848874717950821, 'test_f1': 0.9887133182844244, 'test_prec': 0.9909502262443439, 'test_recall': 0.9864864864864865, 'labeled_instances': 7417, 'train_positive_rate': 0.17958743427261697, 'pool_positive_rate': 0.17958743427261697, 'iteration_time': 811.3210089206696}]
New cross validation 2, for  <function deepmatcher_structured_dblp_acm at 0x14cc376e10d0>

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 200
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 600
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 760
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 800
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 880
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 7417
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
[{'test_loss': 0.07305105030536652, 'test_f1': 0.9262032085561498, 'test_prec': 0.8818737270875764, 'test_recall': 0.9752252252252253, 'labeled_instances': 60, 'train_positive_rate': 0.21666666666666667, 'pool_positive_rate': 0.1792850346608672, 'iteration_time': 306.91362619400024}, {'test_loss': 0.13012991845607758, 'test_f1': 0.8938775510204081, 'test_prec': 0.8171641791044776, 'test_recall': 0.9864864864864865, 'labeled_instances': 80, 'train_positive_rate': 0.175, 'pool_positive_rate': 0.1796374540002726, 'iteration_time': 321.02594923973083}, {'test_loss': 0.08587304502725601, 'test_f1': 0.9392624728850326, 'test_prec': 0.9058577405857741, 'test_recall': 0.9752252252252253, 'labeled_instances': 100, 'train_positive_rate': 0.16, 'pool_positive_rate': 0.1798551318846522, 'iteration_time': 330.03480792045593}, {'test_loss': 0.14118845760822296, 'test_f1': 0.9124324324324324, 'test_prec': 0.8773388773388774, 'test_recall': 0.9504504504504504, 'labeled_instances': 120, 'train_positive_rate': 0.14166666666666666, 'pool_positive_rate': 0.18021104563519255, 'iteration_time': 319.14309334754944}, {'test_loss': 0.088333360850811, 'test_f1': 0.9192139737991266, 'test_prec': 0.8919491525423728, 'test_recall': 0.9481981981981982, 'labeled_instances': 140, 'train_positive_rate': 0.15, 'pool_positive_rate': 0.1801566579634465, 'iteration_time': 328.36105155944824}, {'test_loss': 0.12212305516004562, 'test_f1': 0.9309576837416481, 'test_prec': 0.920704845814978, 'test_recall': 0.9414414414414415, 'labeled_instances': 160, 'train_positive_rate': 0.14375, 'pool_positive_rate': 0.18037756648752928, 'iteration_time': 333.29138827323914}, {'test_loss': 0.08314423263072968, 'test_f1': 0.9421841541755889, 'test_prec': 0.8979591836734694, 'test_recall': 0.990990990990991, 'labeled_instances': 180, 'train_positive_rate': 0.16111111111111112, 'pool_positive_rate': 0.18004698079314632, 'iteration_time': 332.68053150177}, {'test_loss': 0.06852638721466064, 'test_f1': 0.9573033707865168, 'test_prec': 0.9551569506726457, 'test_recall': 0.9594594594594594, 'labeled_instances': 200, 'train_positive_rate': 0.155, 'pool_positive_rate': 0.18026880975474574, 'iteration_time': 332.9597496986389}, {'test_loss': 0.11648279428482056, 'test_f1': 0.9413067552602437, 'test_prec': 0.9259259259259259, 'test_recall': 0.9572072072072072, 'labeled_instances': 240, 'train_positive_rate': 0.1625, 'pool_positive_rate': 0.1801588407412568, 'iteration_time': 335.61532640457153}, {'test_loss': 0.11185702681541443, 'test_f1': 0.9453734671125975, 'test_prec': 0.9359823399558499, 'test_recall': 0.954954954954955, 'labeled_instances': 280, 'train_positive_rate': 0.15714285714285714, 'pool_positive_rate': 0.18046798374667228, 'iteration_time': 335.7742438316345}, {'test_loss': 0.07650706171989441, 'test_f1': 0.9523809523809524, 'test_prec': 0.9368191721132898, 'test_recall': 0.9684684684684685, 'labeled_instances': 320, 'train_positive_rate': 0.16875, 'pool_positive_rate': 0.18007608848809356, 'iteration_time': 328.09653401374817}, {'test_loss': 0.0732462927699089, 'test_f1': 0.9588431590656283, 'test_prec': 0.9472527472527472, 'test_recall': 0.9707207207207207, 'labeled_instances': 360, 'train_positive_rate': 0.1638888888888889, 'pool_positive_rate': 0.18038826696896698, 'iteration_time': 352.85023403167725}, {'test_loss': 0.0684112012386322, 'test_f1': 0.9584736251402918, 'test_prec': 0.9552572706935123, 'test_recall': 0.9617117117117117, 'labeled_instances': 400, 'train_positive_rate': 0.155, 'pool_positive_rate': 0.18098902664956534, 'iteration_time': 342.5144085884094}, {'test_loss': 0.1181233674287796, 'test_f1': 0.9480662983425415, 'test_prec': 0.93058568329718, 'test_recall': 0.9662162162162162, 'labeled_instances': 440, 'train_positive_rate': 0.1590909090909091, 'pool_positive_rate': 0.1808800343987387, 'iteration_time': 340.9371852874756}, {'test_loss': 0.07901417464017868, 'test_f1': 0.9580973952434882, 'test_prec': 0.9635535307517085, 'test_recall': 0.9527027027027027, 'labeled_instances': 480, 'train_positive_rate': 0.1625, 'pool_positive_rate': 0.18076978520974485, 'iteration_time': 348.56721448898315}, {'test_loss': 0.09612233191728592, 'test_f1': 0.9565217391304347, 'test_prec': 0.9470198675496688, 'test_recall': 0.9662162162162162, 'labeled_instances': 520, 'train_positive_rate': 0.16346153846153846, 'pool_positive_rate': 0.18080324778889373, 'iteration_time': 342.4356338977814}, {'test_loss': 0.06234511733055115, 'test_f1': 0.967452300785634, 'test_prec': 0.9642058165548099, 'test_recall': 0.9707207207207207, 'labeled_instances': 560, 'train_positive_rate': 0.16785714285714284, 'pool_positive_rate': 0.18054542802975063, 'iteration_time': 346.5089771747589}, {'test_loss': 0.09039206057786942, 'test_f1': 0.9582863585118377, 'test_prec': 0.9593679458239278, 'test_recall': 0.9572072072072072, 'labeled_instances': 600, 'train_positive_rate': 0.16666666666666666, 'pool_positive_rate': 0.18072465894088308, 'iteration_time': 353.0228912830353}, {'test_loss': 0.05175929516553879, 'test_f1': 0.9683257918552037, 'test_prec': 0.9727272727272728, 'test_recall': 0.963963963963964, 'labeled_instances': 640, 'train_positive_rate': 0.175, 'pool_positive_rate': 0.1800206581083075, 'iteration_time': 356.1329562664032}, {'test_loss': 0.04071487858891487, 'test_f1': 0.975, 'test_prec': 0.9839449541284404, 'test_recall': 0.9662162162162162, 'labeled_instances': 680, 'train_positive_rate': 0.175, 'pool_positive_rate': 0.1800504675671664, 'iteration_time': 356.63100028038025}, {'test_loss': 0.05310338735580444, 'test_f1': 0.9683972911963882, 'test_prec': 0.9705882352941176, 'test_recall': 0.9662162162162162, 'labeled_instances': 720, 'train_positive_rate': 0.1763888888888889, 'pool_positive_rate': 0.1799313125279976, 'iteration_time': 355.8592674732208}, {'test_loss': 0.04912867769598961, 'test_f1': 0.9688195991091313, 'test_prec': 0.9581497797356828, 'test_recall': 0.9797297297297297, 'labeled_instances': 760, 'train_positive_rate': 0.1763157894736842, 'pool_positive_rate': 0.17996094336788343, 'iteration_time': 362.7027311325073}, {'test_loss': 0.04217434301972389, 'test_f1': 0.9730941704035874, 'test_prec': 0.96875, 'test_recall': 0.9774774774774775, 'labeled_instances': 800, 'train_positive_rate': 0.1775, 'pool_positive_rate': 0.17983980655886353, 'iteration_time': 369.45417737960815}, {'test_loss': 0.042214006185531616, 'test_f1': 0.9754464285714286, 'test_prec': 0.9668141592920354, 'test_recall': 0.9842342342342343, 'labeled_instances': 840, 'train_positive_rate': 0.17261904761904762, 'pool_positive_rate': 0.18047742131670974, 'iteration_time': 372.41273522377014}, {'test_loss': 0.029878048226237297, 'test_f1': 0.9765886287625419, 'test_prec': 0.9668874172185431, 'test_recall': 0.9864864864864865, 'labeled_instances': 880, 'train_positive_rate': 0.17272727272727273, 'pool_positive_rate': 0.18051093773902402, 'iteration_time': 374.81911730766296}, {'test_loss': 0.04394615814089775, 'test_f1': 0.9700996677740864, 'test_prec': 0.954248366013072, 'test_recall': 0.9864864864864865, 'labeled_instances': 920, 'train_positive_rate': 0.16956521739130434, 'pool_positive_rate': 0.18100661843927968, 'iteration_time': 391.70415472984314}, {'test_loss': 0.043995846062898636, 'test_f1': 0.9701657458563535, 'test_prec': 0.9522776572668112, 'test_recall': 0.9887387387387387, 'labeled_instances': 960, 'train_positive_rate': 0.17291666666666666, 'pool_positive_rate': 0.18057921635434412, 'iteration_time': 362.98589396476746}, {'test_loss': 0.05443255603313446, 'test_f1': 0.968609865470852, 'test_prec': 0.9642857142857143, 'test_recall': 0.972972972972973, 'labeled_instances': 1000, 'train_positive_rate': 0.174, 'pool_positive_rate': 0.18045815801776532, 'iteration_time': 379.3039333820343}, {'test_loss': 0.01958128996193409, 'test_f1': 0.9853107344632768, 'test_prec': 0.9886621315192744, 'test_recall': 0.9819819819819819, 'labeled_instances': 7417, 'train_positive_rate': 0.17958743427261697, 'pool_positive_rate': 0.17958743427261697, 'iteration_time': 783.8639132976532}]
New cross validation 3, for  <function deepmatcher_structured_dblp_acm at 0x14cc376e10d0>

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 200
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 720
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 920
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 7417
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
[{'test_loss': 0.1862248331308365, 'test_f1': 0.8388683886838869, 'test_prec': 0.924119241192412, 'test_recall': 0.7680180180180181, 'labeled_instances': 60, 'train_positive_rate': 0.15, 'pool_positive_rate': 0.17982873453853473, 'iteration_time': 330.1528151035309}, {'test_loss': 0.14634430408477783, 'test_f1': 0.9086809470124014, 'test_prec': 0.909706546275395, 'test_recall': 0.9076576576576577, 'labeled_instances': 80, 'train_positive_rate': 0.15, 'pool_positive_rate': 0.17991004497751126, 'iteration_time': 332.68082904815674}, {'test_loss': 0.1911715269088745, 'test_f1': 0.8799076212471133, 'test_prec': 0.9028436018957346, 'test_recall': 0.8581081081081081, 'labeled_instances': 100, 'train_positive_rate': 0.13, 'pool_positive_rate': 0.18026513598469318, 'iteration_time': 328.82742047309875}, {'test_loss': 0.06618006527423859, 'test_f1': 0.9478357380688125, 'test_prec': 0.9343544857768052, 'test_recall': 0.9617117117117117, 'labeled_instances': 120, 'train_positive_rate': 0.15, 'pool_positive_rate': 0.18007400301493764, 'iteration_time': 332.36761927604675}, {'test_loss': 0.07587869465351105, 'test_f1': 0.945770065075922, 'test_prec': 0.9121338912133892, 'test_recall': 0.9819819819819819, 'labeled_instances': 140, 'train_positive_rate': 0.17857142857142858, 'pool_positive_rate': 0.179606980898722, 'iteration_time': 341.5331971645355}, {'test_loss': 0.07841861248016357, 'test_f1': 0.9381107491856677, 'test_prec': 0.9056603773584906, 'test_recall': 0.972972972972973, 'labeled_instances': 160, 'train_positive_rate': 0.175, 'pool_positive_rate': 0.1796885765467824, 'iteration_time': 335.90672492980957}, {'test_loss': 0.08950689435005188, 'test_f1': 0.9511400651465798, 'test_prec': 0.9182389937106918, 'test_recall': 0.9864864864864865, 'labeled_instances': 180, 'train_positive_rate': 0.18333333333333332, 'pool_positive_rate': 0.17949426557966008, 'iteration_time': 343.26911640167236}, {'test_loss': 0.061201076954603195, 'test_f1': 0.961883408071749, 'test_prec': 0.9575892857142857, 'test_recall': 0.9662162162162162, 'labeled_instances': 200, 'train_positive_rate': 0.175, 'pool_positive_rate': 0.1797145628377442, 'iteration_time': 332.2818410396576}, {'test_loss': 0.07753296941518784, 'test_f1': 0.9623717217787913, 'test_prec': 0.9745958429561201, 'test_recall': 0.9504504504504504, 'labeled_instances': 240, 'train_positive_rate': 0.17916666666666667, 'pool_positive_rate': 0.17960150480702244, 'iteration_time': 346.806987285614}, {'test_loss': 0.08565288782119751, 'test_f1': 0.944206008583691, 'test_prec': 0.9016393442622951, 'test_recall': 0.990990990990991, 'labeled_instances': 280, 'train_positive_rate': 0.16785714285714284, 'pool_positive_rate': 0.1800476390640325, 'iteration_time': 348.3320336341858}, {'test_loss': 0.03802613541483879, 'test_f1': 0.96875, 'test_prec': 0.9601769911504425, 'test_recall': 0.9774774774774775, 'labeled_instances': 320, 'train_positive_rate': 0.171875, 'pool_positive_rate': 0.17993518388051288, 'iteration_time': 331.44966888427734}, {'test_loss': 0.09339151531457901, 'test_f1': 0.9555555555555556, 'test_prec': 0.9429824561403509, 'test_recall': 0.9684684684684685, 'labeled_instances': 360, 'train_positive_rate': 0.175, 'pool_positive_rate': 0.1798214538755845, 'iteration_time': 369.6985788345337}, {'test_loss': 0.055463459342718124, 'test_f1': 0.9713024282560706, 'test_prec': 0.9523809523809523, 'test_recall': 0.990990990990991, 'labeled_instances': 400, 'train_positive_rate': 0.1725, 'pool_positive_rate': 0.17999144933732364, 'iteration_time': 363.96653509140015}, {'test_loss': 0.07079115509986877, 'test_f1': 0.9665178571428571, 'test_prec': 0.9579646017699115, 'test_recall': 0.9752252252252253, 'labeled_instances': 440, 'train_positive_rate': 0.17727272727272728, 'pool_positive_rate': 0.17973340977497493, 'iteration_time': 342.79714822769165}, {'test_loss': 0.045271728187799454, 'test_f1': 0.9706546275395034, 'test_prec': 0.9728506787330317, 'test_recall': 0.9684684684684685, 'labeled_instances': 480, 'train_positive_rate': 0.17708333333333334, 'pool_positive_rate': 0.17976070347412426, 'iteration_time': 369.3206331729889}, {'test_loss': 0.04764380678534508, 'test_f1': 0.9730941704035874, 'test_prec': 0.96875, 'test_recall': 0.9774774774774775, 'labeled_instances': 520, 'train_positive_rate': 0.17692307692307693, 'pool_positive_rate': 0.17978831375960563, 'iteration_time': 366.29353761672974}, {'test_loss': 0.03860093653202057, 'test_f1': 0.983050847457627, 'test_prec': 0.9863945578231292, 'test_recall': 0.9797297297297297, 'labeled_instances': 560, 'train_positive_rate': 0.17857142857142858, 'pool_positive_rate': 0.17967040980020418, 'iteration_time': 360.09773087501526}, {'test_loss': 0.06856744736433029, 'test_f1': 0.9596412556053813, 'test_prec': 0.9553571428571429, 'test_recall': 0.963963963963964, 'labeled_instances': 600, 'train_positive_rate': 0.17833333333333334, 'pool_positive_rate': 0.1796978142878099, 'iteration_time': 362.2647023200989}, {'test_loss': 0.06772864609956741, 'test_f1': 0.961883408071749, 'test_prec': 0.9575892857142857, 'test_recall': 0.9662162162162162, 'labeled_instances': 640, 'train_positive_rate': 0.184375, 'pool_positive_rate': 0.1791353106094142, 'iteration_time': 363.53287982940674}, {'test_loss': 0.03916848450899124, 'test_f1': 0.9797297297297298, 'test_prec': 0.9797297297297297, 'test_recall': 0.9797297297297297, 'labeled_instances': 680, 'train_positive_rate': 0.18088235294117647, 'pool_positive_rate': 0.17945673148285587, 'iteration_time': 364.5901052951813}, {'test_loss': 0.04361651837825775, 'test_f1': 0.9775784753363228, 'test_prec': 0.9732142857142857, 'test_recall': 0.9819819819819819, 'labeled_instances': 720, 'train_positive_rate': 0.1763888888888889, 'pool_positive_rate': 0.1799313125279976, 'iteration_time': 372.895968914032}, {'test_loss': 0.06972312927246094, 'test_f1': 0.9648127128263336, 'test_prec': 0.9725400457665904, 'test_recall': 0.9572072072072072, 'labeled_instances': 760, 'train_positive_rate': 0.175, 'pool_positive_rate': 0.1801111611837164, 'iteration_time': 378.0560038089752}, {'test_loss': 0.0581246092915535, 'test_f1': 0.9761634506242906, 'test_prec': 0.9839816933638444, 'test_recall': 0.9684684684684685, 'labeled_instances': 800, 'train_positive_rate': 0.17625, 'pool_positive_rate': 0.17999093244672812, 'iteration_time': 394.1119315624237}, {'test_loss': 0.03979267552495003, 'test_f1': 0.9786276715410572, 'test_prec': 0.9775280898876404, 'test_recall': 0.9797297297297297, 'labeled_instances': 840, 'train_positive_rate': 0.17261904761904762, 'pool_positive_rate': 0.18047742131670974, 'iteration_time': 399.01300501823425}, {'test_loss': 0.04815579950809479, 'test_f1': 0.9678135405105438, 'test_prec': 0.9540481400437637, 'test_recall': 0.9819819819819819, 'labeled_instances': 880, 'train_positive_rate': 0.17272727272727273, 'pool_positive_rate': 0.18051093773902402, 'iteration_time': 376.9630856513977}, {'test_loss': 0.05342564359307289, 'test_f1': 0.9796380090497738, 'test_prec': 0.9840909090909091, 'test_recall': 0.9752252252252253, 'labeled_instances': 920, 'train_positive_rate': 0.17282608695652174, 'pool_positive_rate': 0.18054486686162843, 'iteration_time': 411.9692063331604}, {'test_loss': 0.040712274610996246, 'test_f1': 0.9755011135857461, 'test_prec': 0.9647577092511013, 'test_recall': 0.9864864864864865, 'labeled_instances': 960, 'train_positive_rate': 0.171875, 'pool_positive_rate': 0.18073408703732383, 'iteration_time': 396.4233777523041}, {'test_loss': 0.04361751675605774, 'test_f1': 0.9819413092550789, 'test_prec': 0.9841628959276018, 'test_recall': 0.9797297297297297, 'labeled_instances': 1000, 'train_positive_rate': 0.175, 'pool_positive_rate': 0.18030232195730092, 'iteration_time': 403.6092746257782}, {'test_loss': 0.01952500268816948, 'test_f1': 0.9810479375696767, 'test_prec': 0.9713024282560706, 'test_recall': 0.990990990990991, 'labeled_instances': 7417, 'train_positive_rate': 0.17958743427261697, 'pool_positive_rate': 0.17958743427261697, 'iteration_time': 824.8358995914459}]
New cross validation 4, for  <function deepmatcher_structured_dblp_acm at 0x14cc376e10d0>

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 140
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 200
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 240
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 360
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 800
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 7417
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
[{'test_loss': 0.18138539791107178, 'test_f1': 0.8825541619156214, 'test_prec': 0.8937644341801386, 'test_recall': 0.8716216216216216, 'labeled_instances': 60, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.1794209596302841, 'iteration_time': 319.40934228897095}, {'test_loss': 0.10617281496524811, 'test_f1': 0.9094736842105263, 'test_prec': 0.8537549407114624, 'test_recall': 0.972972972972973, 'labeled_instances': 80, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.17936486302303395, 'iteration_time': 349.89361453056335}, {'test_loss': 0.13923314213752747, 'test_f1': 0.8959999999999999, 'test_prec': 0.9095127610208816, 'test_recall': 0.8828828828828829, 'labeled_instances': 100, 'train_positive_rate': 0.18, 'pool_positive_rate': 0.1795817958179582, 'iteration_time': 344.3048927783966}, {'test_loss': 0.07122492790222168, 'test_f1': 0.9479512735326688, 'test_prec': 0.9324618736383442, 'test_recall': 0.963963963963964, 'labeled_instances': 120, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.17925174729340826, 'iteration_time': 355.71093010902405}, {'test_loss': 0.13236333429813385, 'test_f1': 0.9198312236286921, 'test_prec': 0.8650793650793651, 'test_recall': 0.9819819819819819, 'labeled_instances': 140, 'train_positive_rate': 0.21428571428571427, 'pool_positive_rate': 0.1789198845678164, 'iteration_time': 347.8179986476898}, {'test_loss': 0.08764283359050751, 'test_f1': 0.9308855291576674, 'test_prec': 0.8941908713692946, 'test_recall': 0.9707207207207207, 'labeled_instances': 160, 'train_positive_rate': 0.21875, 'pool_positive_rate': 0.17872399062973682, 'iteration_time': 344.0183582305908}, {'test_loss': 0.12942248582839966, 'test_f1': 0.9250814332247558, 'test_prec': 0.8930817610062893, 'test_recall': 0.9594594594594594, 'labeled_instances': 180, 'train_positive_rate': 0.2111111111111111, 'pool_positive_rate': 0.17880337156280227, 'iteration_time': 343.87926745414734}, {'test_loss': 0.13787902891635895, 'test_f1': 0.9051094890510948, 'test_prec': 0.8427184466019417, 'test_recall': 0.9774774774774775, 'labeled_instances': 200, 'train_positive_rate': 0.21, 'pool_positive_rate': 0.17874463073299154, 'iteration_time': 342.8912396430969}, {'test_loss': 0.10514990240335464, 'test_f1': 0.9352051835853132, 'test_prec': 0.8983402489626556, 'test_recall': 0.9752252252252253, 'labeled_instances': 240, 'train_positive_rate': 0.20416666666666666, 'pool_positive_rate': 0.1787655009056709, 'iteration_time': 353.75712275505066}, {'test_loss': 0.10576076805591583, 'test_f1': 0.9488574537540805, 'test_prec': 0.9178947368421052, 'test_recall': 0.9819819819819819, 'labeled_instances': 280, 'train_positive_rate': 0.20357142857142857, 'pool_positive_rate': 0.17864649012189995, 'iteration_time': 353.3838143348694}, {'test_loss': 0.06790128350257874, 'test_f1': 0.9600886917960089, 'test_prec': 0.9454148471615721, 'test_recall': 0.9752252252252253, 'labeled_instances': 320, 'train_positive_rate': 0.19375, 'pool_positive_rate': 0.17894885162744822, 'iteration_time': 337.5906569957733}, {'test_loss': 0.07704929262399673, 'test_f1': 0.9642857142857144, 'test_prec': 0.9557522123893806, 'test_recall': 0.972972972972973, 'labeled_instances': 360, 'train_positive_rate': 0.19444444444444445, 'pool_positive_rate': 0.17882953096216522, 'iteration_time': 353.8068857192993}, {'test_loss': 0.07105788588523865, 'test_f1': 0.9655172413793103, 'test_prec': 0.9538461538461539, 'test_recall': 0.9774774774774775, 'labeled_instances': 400, 'train_positive_rate': 0.1925, 'pool_positive_rate': 0.178851360980476, 'iteration_time': 357.90795254707336}, {'test_loss': 0.03741392493247986, 'test_f1': 0.9748858447488584, 'test_prec': 0.9884259259259259, 'test_recall': 0.9617117117117117, 'labeled_instances': 440, 'train_positive_rate': 0.19318181818181818, 'pool_positive_rate': 0.1787301132291816, 'iteration_time': 352.25298261642456}, {'test_loss': 0.029042702168226242, 'test_f1': 0.9807909604519773, 'test_prec': 0.9841269841269841, 'test_recall': 0.9774774774774775, 'labeled_instances': 480, 'train_positive_rate': 0.19791666666666666, 'pool_positive_rate': 0.17831915813752341, 'iteration_time': 370.5473129749298}, {'test_loss': 0.030328450724482536, 'test_f1': 0.9831649831649831, 'test_prec': 0.9798657718120806, 'test_recall': 0.9864864864864865, 'labeled_instances': 520, 'train_positive_rate': 0.20384615384615384, 'pool_positive_rate': 0.17775844570102944, 'iteration_time': 364.42863488197327}, {'test_loss': 0.040307480841875076, 'test_f1': 0.9808342728297633, 'test_prec': 0.981941309255079, 'test_recall': 0.9797297297297297, 'labeled_instances': 560, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.17792037334111127, 'iteration_time': 364.3670823574066}, {'test_loss': 0.02787712961435318, 'test_f1': 0.9774774774774775, 'test_prec': 0.9774774774774775, 'test_recall': 0.9774774774774775, 'labeled_instances': 600, 'train_positive_rate': 0.19833333333333333, 'pool_positive_rate': 0.17793750916825582, 'iteration_time': 381.10345363616943}, {'test_loss': 0.033709850162267685, 'test_f1': 0.9806598407281, 'test_prec': 0.9908045977011494, 'test_recall': 0.9707207207207207, 'labeled_instances': 640, 'train_positive_rate': 0.190625, 'pool_positive_rate': 0.1785450789434853, 'iteration_time': 373.24188232421875}, {'test_loss': 0.023766079917550087, 'test_f1': 0.9853438556933484, 'test_prec': 0.9864559819413092, 'test_recall': 0.9842342342342343, 'labeled_instances': 680, 'train_positive_rate': 0.18970588235294117, 'pool_positive_rate': 0.17856612735639008, 'iteration_time': 372.3358871936798}, {'test_loss': 0.030632508918642998, 'test_f1': 0.9819819819819819, 'test_prec': 0.9819819819819819, 'test_recall': 0.9819819819819819, 'labeled_instances': 720, 'train_positive_rate': 0.19444444444444445, 'pool_positive_rate': 0.17799014484097356, 'iteration_time': 380.8046545982361}, {'test_loss': 0.027100324630737305, 'test_f1': 0.9798206278026906, 'test_prec': 0.9754464285714286, 'test_recall': 0.9842342342342343, 'labeled_instances': 760, 'train_positive_rate': 0.19078947368421054, 'pool_positive_rate': 0.1783085473937209, 'iteration_time': 373.4032175540924}, {'test_loss': 0.029720265418291092, 'test_f1': 0.9830124575311437, 'test_prec': 0.9886104783599089, 'test_recall': 0.9774774774774775, 'labeled_instances': 800, 'train_positive_rate': 0.19125, 'pool_positive_rate': 0.17817742179235302, 'iteration_time': 376.9796333312988}, {'test_loss': 0.04068997502326965, 'test_f1': 0.9776785714285714, 'test_prec': 0.9690265486725663, 'test_recall': 0.9864864864864865, 'labeled_instances': 840, 'train_positive_rate': 0.19166666666666668, 'pool_positive_rate': 0.17804470123156454, 'iteration_time': 389.88217663764954}, {'test_loss': 0.023625509813427925, 'test_f1': 0.9865470852017937, 'test_prec': 0.9821428571428571, 'test_recall': 0.990990990990991, 'labeled_instances': 880, 'train_positive_rate': 0.19090909090909092, 'pool_positive_rate': 0.1780633318035796, 'iteration_time': 385.68699526786804}, {'test_loss': 0.02572471648454666, 'test_f1': 0.9807474518686297, 'test_prec': 0.9863325740318907, 'test_recall': 0.9752252252252253, 'labeled_instances': 920, 'train_positive_rate': 0.19021739130434784, 'pool_positive_rate': 0.1780821917808219, 'iteration_time': 377.8915696144104}, {'test_loss': 0.031073343008756638, 'test_f1': 0.9797752808988766, 'test_prec': 0.9775784753363229, 'test_recall': 0.9819819819819819, 'labeled_instances': 960, 'train_positive_rate': 0.190625, 'pool_positive_rate': 0.17794641474368902, 'iteration_time': 390.5623404979706}, {'test_loss': 0.026007631793618202, 'test_f1': 0.9817351598173515, 'test_prec': 0.9953703703703703, 'test_recall': 0.9684684684684685, 'labeled_instances': 1000, 'train_positive_rate': 0.191, 'pool_positive_rate': 0.17780894498987065, 'iteration_time': 387.9306905269623}, {'test_loss': 0.011938274838030338, 'test_f1': 0.9898074745186863, 'test_prec': 0.9954441913439636, 'test_recall': 0.9842342342342343, 'labeled_instances': 7417, 'train_positive_rate': 0.17958743427261697, 'pool_positive_rate': 0.17958743427261697, 'iteration_time': 831.2119710445404}]
Could not create dir out, File exists




    ###########  New Dataset: <function deepmatcher_structured_dblp_google_scholar at 0x14cc376e1160>
New cross validation 0, for  <function deepmatcher_structured_dblp_google_scholar at 0x14cc376e1160>

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 120
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 200
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 400
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 17223
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
[{'test_loss': 0.17866221070289612, 'test_f1': 0.881720430107527, 'test_prec': 0.846815834767642, 'test_recall': 0.9196261682242991, 'labeled_instances': 60, 'train_positive_rate': 0.23333333333333334, 'pool_positive_rate': 0.18603973664277806, 'iteration_time': 419.8914387226105}, {'test_loss': 0.14967939257621765, 'test_f1': 0.8813559322033899, 'test_prec': 0.888045540796964, 'test_recall': 0.874766355140187, 'labeled_instances': 80, 'train_positive_rate': 0.2125, 'pool_positive_rate': 0.18608178265181124, 'iteration_time': 433.10447001457214}, {'test_loss': 0.17064212262630463, 'test_f1': 0.885987815491732, 'test_prec': 0.8289902280130294, 'test_recall': 0.9514018691588785, 'labeled_instances': 100, 'train_positive_rate': 0.19, 'pool_positive_rate': 0.1861823278631081, 'iteration_time': 418.4272680282593}, {'test_loss': 0.14647077023983002, 'test_f1': 0.9068150208623087, 'test_prec': 0.8997240110395585, 'test_recall': 0.914018691588785, 'labeled_instances': 120, 'train_positive_rate': 0.18333333333333332, 'pool_positive_rate': 0.1862246389522306, 'iteration_time': 417.86086869239807}, {'test_loss': 0.16562288999557495, 'test_f1': 0.905607476635514, 'test_prec': 0.905607476635514, 'test_recall': 0.905607476635514, 'labeled_instances': 140, 'train_positive_rate': 0.16428571428571428, 'pool_positive_rate': 0.18638412456828427, 'iteration_time': 410.36318922042847}, {'test_loss': 0.14636673033237457, 'test_f1': 0.9000473709142587, 'test_prec': 0.9125840537944284, 'test_recall': 0.8878504672897196, 'labeled_instances': 160, 'train_positive_rate': 0.16875, 'pool_positive_rate': 0.18636816503545683, 'iteration_time': 414.61397314071655}, {'test_loss': 0.15169966220855713, 'test_f1': 0.8885542168674698, 'test_prec': 0.9598698481561823, 'test_recall': 0.8271028037383178, 'labeled_instances': 180, 'train_positive_rate': 0.16111111111111112, 'pool_positive_rate': 0.1864695182772986, 'iteration_time': 450.7823259830475}, {'test_loss': 0.11103637516498566, 'test_f1': 0.9145413870246086, 'test_prec': 0.8772532188841202, 'test_recall': 0.9551401869158879, 'labeled_instances': 200, 'train_positive_rate': 0.15, 'pool_positive_rate': 0.1866298537273101, 'iteration_time': 437.60224628448486}, {'test_loss': 0.13053622841835022, 'test_f1': 0.9037817137386309, 'test_prec': 0.9263984298331698, 'test_recall': 0.8822429906542056, 'labeled_instances': 240, 'train_positive_rate': 0.15, 'pool_positive_rate': 0.18671612789259848, 'iteration_time': 423.7395942211151}, {'test_loss': 0.15444645285606384, 'test_f1': 0.8999073215940685, 'test_prec': 0.8924632352941176, 'test_recall': 0.9074766355140187, 'labeled_instances': 280, 'train_positive_rate': 0.16071428571428573, 'pool_positive_rate': 0.18662574514548783, 'iteration_time': 441.0218393802643}, {'test_loss': 0.15270575881004333, 'test_f1': 0.9144186046511628, 'test_prec': 0.9101851851851852, 'test_recall': 0.9186915887850468, 'labeled_instances': 320, 'train_positive_rate': 0.159375, 'pool_positive_rate': 0.18671241791397977, 'iteration_time': 423.8404760360718}, {'test_loss': 0.17302659153938293, 'test_f1': 0.906791569086651, 'test_prec': 0.9089201877934272, 'test_recall': 0.9046728971962616, 'labeled_instances': 360, 'train_positive_rate': 0.18055555555555555, 'pool_positive_rate': 0.18632509043467949, 'iteration_time': 459.66099858283997}, {'test_loss': 0.16811160743236542, 'test_f1': 0.9117100371747212, 'test_prec': 0.9066543438077634, 'test_recall': 0.9168224299065421, 'labeled_instances': 400, 'train_positive_rate': 0.195, 'pool_positive_rate': 0.1859953634904595, 'iteration_time': 456.02323842048645}, {'test_loss': 0.1190033107995987, 'test_f1': 0.9274116523400191, 'test_prec': 0.9482421875, 'test_recall': 0.9074766355140187, 'labeled_instances': 440, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.185842817136388, 'iteration_time': 433.203830242157}, {'test_loss': 0.1593906283378601, 'test_f1': 0.9174224343675418, 'test_prec': 0.937560975609756, 'test_recall': 0.8981308411214953, 'labeled_instances': 480, 'train_positive_rate': 0.20416666666666666, 'pool_positive_rate': 0.18568954189810666, 'iteration_time': 446.55213356018066}, {'test_loss': 0.136453777551651, 'test_f1': 0.912330051570558, 'test_prec': 0.9153339604891816, 'test_recall': 0.9093457943925234, 'labeled_instances': 520, 'train_positive_rate': 0.20384615384615384, 'pool_positive_rate': 0.1856552715081123, 'iteration_time': 444.78767466545105}, {'test_loss': 0.17780093848705292, 'test_f1': 0.9151910531220876, 'test_prec': 0.912639405204461, 'test_recall': 0.9177570093457944, 'labeled_instances': 560, 'train_positive_rate': 0.1982142857142857, 'pool_positive_rate': 0.18580087619276242, 'iteration_time': 443.0850622653961}, {'test_loss': 0.12302429974079132, 'test_f1': 0.9344780840488026, 'test_prec': 0.9046369203849519, 'test_recall': 0.9663551401869159, 'labeled_instances': 600, 'train_positive_rate': 0.19666666666666666, 'pool_positive_rate': 0.18582686638994164, 'iteration_time': 445.15027713775635}, {'test_loss': 0.139273002743721, 'test_f1': 0.928377153218495, 'test_prec': 0.9014084507042254, 'test_recall': 0.9570093457943926, 'labeled_instances': 640, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.18567207381052886, 'iteration_time': 490.4529809951782}, {'test_loss': 0.11565198004245758, 'test_f1': 0.9312119794103885, 'test_prec': 0.9325210871602624, 'test_recall': 0.9299065420560748, 'labeled_instances': 680, 'train_positive_rate': 0.19852941176470587, 'pool_positive_rate': 0.18569787825666445, 'iteration_time': 471.4862108230591}, {'test_loss': 0.10651861131191254, 'test_f1': 0.9345537757437071, 'test_prec': 0.915695067264574, 'test_recall': 0.9542056074766355, 'labeled_instances': 720, 'train_positive_rate': 0.19166666666666668, 'pool_positive_rate': 0.1859661879658244, 'iteration_time': 481.82456827163696}, {'test_loss': 0.13167056441307068, 'test_f1': 0.9324577861163227, 'test_prec': 0.935969868173258, 'test_recall': 0.9289719626168225, 'labeled_instances': 760, 'train_positive_rate': 0.19605263157894737, 'pool_positive_rate': 0.18574986332989127, 'iteration_time': 472.88198924064636}, {'test_loss': 0.14211630821228027, 'test_f1': 0.926689027311931, 'test_prec': 0.9508357915437562, 'test_recall': 0.9037383177570093, 'labeled_instances': 800, 'train_positive_rate': 0.19375, 'pool_positive_rate': 0.18583693600438408, 'iteration_time': 476.6379234790802}, {'test_loss': 0.1216215118765831, 'test_f1': 0.9265054528212423, 'test_prec': 0.9403272377285852, 'test_recall': 0.9130841121495327, 'labeled_instances': 840, 'train_positive_rate': 0.19523809523809524, 'pool_positive_rate': 0.18574131721906856, 'iteration_time': 480.69285345077515}, {'test_loss': 0.12292952090501785, 'test_f1': 0.927536231884058, 'test_prec': 0.9279700654817586, 'test_recall': 0.9271028037383178, 'labeled_instances': 880, 'train_positive_rate': 0.19204545454545455, 'pool_positive_rate': 0.18588998347916538, 'iteration_time': 481.14802289009094}, {'test_loss': 0.14430658519268036, 'test_f1': 0.9201520912547528, 'test_prec': 0.9361702127659575, 'test_recall': 0.9046728971962616, 'labeled_instances': 920, 'train_positive_rate': 0.18804347826086956, 'pool_positive_rate': 0.1861007176593265, 'iteration_time': 479.90820693969727}, {'test_loss': 0.1369076520204544, 'test_f1': 0.9328392774432608, 'test_prec': 0.9247015610651974, 'test_recall': 0.9411214953271028, 'labeled_instances': 960, 'train_positive_rate': 0.18541666666666667, 'pool_positive_rate': 0.18625099920063948, 'iteration_time': 482.1816985607147}, {'test_loss': 0.1334364116191864, 'test_f1': 0.9332711152589829, 'test_prec': 0.9319664492078286, 'test_recall': 0.9345794392523364, 'labeled_instances': 1000, 'train_positive_rate': 0.189, 'pool_positive_rate': 0.18603217653948098, 'iteration_time': 494.54305601119995}, {'test_loss': 0.10433708131313324, 'test_f1': 0.9573679332715477, 'test_prec': 0.9494485294117647, 'test_recall': 0.9654205607476636, 'labeled_instances': 17223, 'train_positive_rate': 0.18620449399059397, 'pool_positive_rate': 0.18620449399059397, 'iteration_time': 1494.7738046646118}]
New cross validation 1, for  <function deepmatcher_structured_dblp_google_scholar at 0x14cc376e1160>

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 160
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 200
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 240
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 320
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 720
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 760
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 17223
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
[{'test_loss': 0.176344633102417, 'test_f1': 0.8661559260928345, 'test_prec': 0.8363794604003482, 'test_recall': 0.8981308411214953, 'labeled_instances': 60, 'train_positive_rate': 0.26666666666666666, 'pool_positive_rate': 0.18592320689856084, 'iteration_time': 453.082727432251}, {'test_loss': 0.17730455100536346, 'test_f1': 0.8853717026378897, 'test_prec': 0.90935960591133, 'test_recall': 0.8626168224299066, 'labeled_instances': 80, 'train_positive_rate': 0.2375, 'pool_positive_rate': 0.18596511695735868, 'iteration_time': 442.4130654335022}, {'test_loss': 0.16319148242473602, 'test_f1': 0.9033668561434194, 'test_prec': 0.8488085456039441, 'test_recall': 0.9654205607476636, 'labeled_instances': 100, 'train_positive_rate': 0.23, 'pool_positive_rate': 0.18594872393856215, 'iteration_time': 420.8016781806946}, {'test_loss': 0.18813151121139526, 'test_f1': 0.8607802874743327, 'test_prec': 0.7677655677655678, 'test_recall': 0.9794392523364486, 'labeled_instances': 120, 'train_positive_rate': 0.23333333333333334, 'pool_positive_rate': 0.18587382330585278, 'iteration_time': 469.73920822143555}, {'test_loss': 0.15225625038146973, 'test_f1': 0.8817755014938115, 'test_prec': 0.8114689709347996, 'test_recall': 0.9654205607476636, 'labeled_instances': 140, 'train_positive_rate': 0.21428571428571427, 'pool_positive_rate': 0.18597436047532634, 'iteration_time': 457.7026298046112}, {'test_loss': 0.14012709259986877, 'test_f1': 0.9060579455662862, 'test_prec': 0.8543046357615894, 'test_recall': 0.9644859813084112, 'labeled_instances': 160, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.18607513332942624, 'iteration_time': 456.20350456237793}, {'test_loss': 0.20373907685279846, 'test_f1': 0.8943018703784255, 'test_prec': 0.8364524003254679, 'test_recall': 0.9607476635514018, 'labeled_instances': 180, 'train_positive_rate': 0.19444444444444445, 'pool_positive_rate': 0.18611746758199849, 'iteration_time': 438.4347655773163}, {'test_loss': 0.11173771321773529, 'test_f1': 0.9222170470423847, 'test_prec': 0.9192200557103064, 'test_recall': 0.9252336448598131, 'labeled_instances': 200, 'train_positive_rate': 0.18, 'pool_positive_rate': 0.1862773894143218, 'iteration_time': 437.424045085907}, {'test_loss': 0.10325922071933746, 'test_f1': 0.921999065857076, 'test_prec': 0.9215686274509803, 'test_recall': 0.922429906542056, 'labeled_instances': 240, 'train_positive_rate': 0.20833333333333334, 'pool_positive_rate': 0.18589177412706825, 'iteration_time': 437.44333004951477}, {'test_loss': 0.10604891180992126, 'test_f1': 0.9317757009345794, 'test_prec': 0.9317757009345794, 'test_recall': 0.9317757009345794, 'labeled_instances': 280, 'train_positive_rate': 0.21071428571428572, 'pool_positive_rate': 0.18579944519860708, 'iteration_time': 478.42354226112366}, {'test_loss': 0.11085996776819229, 'test_f1': 0.9236298292902065, 'test_prec': 0.889273356401384, 'test_recall': 0.9607476635514018, 'labeled_instances': 320, 'train_positive_rate': 0.221875, 'pool_positive_rate': 0.18552919600070994, 'iteration_time': 464.6718325614929}, {'test_loss': 0.11272411048412323, 'test_f1': 0.9280868385345998, 'test_prec': 0.8992112182296231, 'test_recall': 0.9588785046728971, 'labeled_instances': 360, 'train_positive_rate': 0.20833333333333334, 'pool_positive_rate': 0.18573207614303505, 'iteration_time': 466.2011458873749}, {'test_loss': 0.09526543319225311, 'test_f1': 0.9283746556473829, 'test_prec': 0.9124548736462094, 'test_recall': 0.9448598130841122, 'labeled_instances': 400, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.1858764786304464, 'iteration_time': 462.80529022216797}, {'test_loss': 0.11096151173114777, 'test_f1': 0.9134010643444606, 'test_prec': 0.9468405215646941, 'test_recall': 0.8822429906542056, 'labeled_instances': 440, 'train_positive_rate': 0.19772727272727272, 'pool_positive_rate': 0.18590240123934934, 'iteration_time': 460.524512052536}, {'test_loss': 0.1306692510843277, 'test_f1': 0.9241316270566727, 'test_prec': 0.9042933810375671, 'test_recall': 0.9448598130841122, 'labeled_instances': 480, 'train_positive_rate': 0.19166666666666668, 'pool_positive_rate': 0.18604790061518248, 'iteration_time': 474.50119280815125}, {'test_loss': 0.0939527153968811, 'test_f1': 0.9349442379182156, 'test_prec': 0.9297597042513863, 'test_recall': 0.9401869158878504, 'labeled_instances': 520, 'train_positive_rate': 0.19038461538461537, 'pool_positive_rate': 0.18607435789977847, 'iteration_time': 452.74920773506165}, {'test_loss': 0.10683432221412659, 'test_f1': 0.9349330872173512, 'test_prec': 0.9234275296262534, 'test_recall': 0.9467289719626168, 'labeled_instances': 560, 'train_positive_rate': 0.19285714285714287, 'pool_positive_rate': 0.18598091580147633, 'iteration_time': 494.48136806488037}, {'test_loss': 0.10340924561023712, 'test_f1': 0.9354988399071927, 'test_prec': 0.9290322580645162, 'test_recall': 0.9420560747663551, 'labeled_instances': 600, 'train_positive_rate': 0.19166666666666668, 'pool_positive_rate': 0.1860073392287794, 'iteration_time': 511.3076467514038}, {'test_loss': 0.08847560733556747, 'test_f1': 0.943081906524757, 'test_prec': 0.9340054995417049, 'test_recall': 0.9523364485981308, 'labeled_instances': 640, 'train_positive_rate': 0.1859375, 'pool_positive_rate': 0.18621479828740276, 'iteration_time': 491.6043860912323}, {'test_loss': 0.12077069282531738, 'test_f1': 0.937095282146161, 'test_prec': 0.9276556776556777, 'test_recall': 0.9467289719626168, 'labeled_instances': 680, 'train_positive_rate': 0.18235294117647058, 'pool_positive_rate': 0.1863628120655262, 'iteration_time': 487.3789095878601}, {'test_loss': 0.10683954507112503, 'test_f1': 0.935483870967742, 'test_prec': 0.9499036608863198, 'test_recall': 0.9214953271028037, 'labeled_instances': 720, 'train_positive_rate': 0.17916666666666667, 'pool_positive_rate': 0.1865115433557535, 'iteration_time': 487.0599820613861}, {'test_loss': 0.11817236244678497, 'test_f1': 0.9366494603472549, 'test_prec': 0.94062205466541, 'test_recall': 0.9327102803738317, 'labeled_instances': 760, 'train_positive_rate': 0.1868421052631579, 'pool_positive_rate': 0.18617505922371377, 'iteration_time': 495.7423882484436}, {'test_loss': 0.1022065281867981, 'test_f1': 0.9381017881705639, 'test_prec': 0.9207920792079208, 'test_recall': 0.9560747663551402, 'labeled_instances': 800, 'train_positive_rate': 0.19, 'pool_positive_rate': 0.18601960664921147, 'iteration_time': 492.8557503223419}, {'test_loss': 0.10966327786445618, 'test_f1': 0.9400369003690037, 'test_prec': 0.9280510018214936, 'test_recall': 0.9523364485981308, 'labeled_instances': 840, 'train_positive_rate': 0.19166666666666668, 'pool_positive_rate': 0.1859244338643716, 'iteration_time': 505.0416462421417}, {'test_loss': 0.11678633838891983, 'test_f1': 0.9320019020446981, 'test_prec': 0.9486931268151017, 'test_recall': 0.9158878504672897, 'labeled_instances': 880, 'train_positive_rate': 0.19090909090909092, 'pool_positive_rate': 0.18595117175549164, 'iteration_time': 493.8567748069763}, {'test_loss': 0.10538532584905624, 'test_f1': 0.9396914446002805, 'test_prec': 0.9401309635173059, 'test_recall': 0.9392523364485982, 'labeled_instances': 920, 'train_positive_rate': 0.19021739130434784, 'pool_positive_rate': 0.18597804085137704, 'iteration_time': 497.169650554657}, {'test_loss': 0.10024254024028778, 'test_f1': 0.9429373246024322, 'test_prec': 0.9438202247191011, 'test_recall': 0.9420560747663551, 'labeled_instances': 960, 'train_positive_rate': 0.19270833333333334, 'pool_positive_rate': 0.18582057430978294, 'iteration_time': 499.9147973060608}, {'test_loss': 0.11654032766819, 'test_f1': 0.9411764705882353, 'test_prec': 0.9402985074626866, 'test_recall': 0.9420560747663551, 'labeled_instances': 1000, 'train_positive_rate': 0.191, 'pool_positive_rate': 0.18590889477901745, 'iteration_time': 502.0869550704956}, {'test_loss': 0.10916712880134583, 'test_f1': 0.954460966542751, 'test_prec': 0.9491682070240296, 'test_recall': 0.9598130841121495, 'labeled_instances': 17223, 'train_positive_rate': 0.18620449399059397, 'pool_positive_rate': 0.18620449399059397, 'iteration_time': 1540.6941821575165}]
New cross validation 2, for  <function deepmatcher_structured_dblp_google_scholar at 0x14cc376e1160>

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 120
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 180
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 200
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 480
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 600
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 920
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 17223
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
[{'test_loss': 0.3039446473121643, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.15, 'pool_positive_rate': 0.18633106100332109, 'iteration_time': 461.806946516037}, {'test_loss': 0.32592108845710754, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 80, 'train_positive_rate': 0.1375, 'pool_positive_rate': 0.18643177973516886, 'iteration_time': 444.6427493095398}, {'test_loss': 0.27423611283302307, 'test_f1': 0.6966966966966965, 'test_prec': 0.9747899159663865, 'test_recall': 0.5420560747663551, 'labeled_instances': 100, 'train_positive_rate': 0.16, 'pool_positive_rate': 0.18635753080651754, 'iteration_time': 446.0215210914612}, {'test_loss': 0.1661936491727829, 'test_f1': 0.8463796477495108, 'test_prec': 0.8880903490759754, 'test_recall': 0.8084112149532711, 'labeled_instances': 120, 'train_positive_rate': 0.18333333333333332, 'pool_positive_rate': 0.1862246389522306, 'iteration_time': 487.58622789382935}, {'test_loss': 0.15637098252773285, 'test_f1': 0.8577194752774974, 'test_prec': 0.9320175438596491, 'test_recall': 0.794392523364486, 'labeled_instances': 140, 'train_positive_rate': 0.17142857142857143, 'pool_positive_rate': 0.18632558684071884, 'iteration_time': 470.9408495426178}, {'test_loss': 0.1439584195613861, 'test_f1': 0.8920800696257616, 'test_prec': 0.8346905537459284, 'test_recall': 0.9579439252336449, 'labeled_instances': 160, 'train_positive_rate': 0.1625, 'pool_positive_rate': 0.18642677137666294, 'iteration_time': 450.31505703926086}, {'test_loss': 0.13197334110736847, 'test_f1': 0.89009364218827, 'test_prec': 0.9416058394160584, 'test_recall': 0.8439252336448598, 'labeled_instances': 180, 'train_positive_rate': 0.16666666666666666, 'pool_positive_rate': 0.18641084316141524, 'iteration_time': 445.5302209854126}, {'test_loss': 0.17933380603790283, 'test_f1': 0.9056111352762071, 'test_prec': 0.8470301057770545, 'test_recall': 0.9728971962616823, 'labeled_instances': 200, 'train_positive_rate': 0.175, 'pool_positive_rate': 0.18633613346648653, 'iteration_time': 436.3025600910187}, {'test_loss': 0.11203372478485107, 'test_f1': 0.9274563820018366, 'test_prec': 0.9115523465703971, 'test_recall': 0.9439252336448598, 'labeled_instances': 240, 'train_positive_rate': 0.175, 'pool_positive_rate': 0.18636283342165696, 'iteration_time': 495.10742473602295}, {'test_loss': 0.12450537085533142, 'test_f1': 0.9253871421867668, 'test_prec': 0.9293119698397738, 'test_recall': 0.9214953271028037, 'labeled_instances': 280, 'train_positive_rate': 0.175, 'pool_positive_rate': 0.18638965944637903, 'iteration_time': 481.9879961013794}, {'test_loss': 0.08718094229698181, 'test_f1': 0.9263831732967536, 'test_prec': 0.9068934646374217, 'test_recall': 0.9467289719626168, 'labeled_instances': 320, 'train_positive_rate': 0.171875, 'pool_positive_rate': 0.1864757735313258, 'iteration_time': 471.0403382778168}, {'test_loss': 0.11690773069858551, 'test_f1': 0.9319129226493746, 'test_prec': 0.9237832874196511, 'test_recall': 0.9401869158878504, 'labeled_instances': 360, 'train_positive_rate': 0.16944444444444445, 'pool_positive_rate': 0.18656229615133724, 'iteration_time': 480.03030228614807}, {'test_loss': 0.11773145198822021, 'test_f1': 0.9247985675917636, 'test_prec': 0.8874570446735395, 'test_recall': 0.9654205607476636, 'labeled_instances': 400, 'train_positive_rate': 0.17, 'pool_positive_rate': 0.18658978779052487, 'iteration_time': 463.36466550827026}, {'test_loss': 0.10718660056591034, 'test_f1': 0.9375591296121097, 'test_prec': 0.9492337164750958, 'test_recall': 0.9261682242990654, 'labeled_instances': 440, 'train_positive_rate': 0.17045454545454544, 'pool_positive_rate': 0.1866174104748853, 'iteration_time': 461.10648679733276}, {'test_loss': 0.10814749449491501, 'test_f1': 0.9385474860335196, 'test_prec': 0.935064935064935, 'test_recall': 0.9420560747663551, 'labeled_instances': 480, 'train_positive_rate': 0.17083333333333334, 'pool_positive_rate': 0.18664516514364213, 'iteration_time': 459.6993408203125}, {'test_loss': 0.09011110663414001, 'test_f1': 0.9427107591988821, 'test_prec': 0.9396471680594243, 'test_recall': 0.9457943925233645, 'labeled_instances': 520, 'train_positive_rate': 0.17692307692307693, 'pool_positive_rate': 0.18649344429144465, 'iteration_time': 506.21441745758057}, {'test_loss': 0.13621272146701813, 'test_f1': 0.9249884951679707, 'test_prec': 0.9111514052583862, 'test_recall': 0.9392523364485982, 'labeled_instances': 560, 'train_positive_rate': 0.18035714285714285, 'pool_positive_rate': 0.1864010082218088, 'iteration_time': 497.3079311847687}, {'test_loss': 0.1342090368270874, 'test_f1': 0.9330819981149858, 'test_prec': 0.94106463878327, 'test_recall': 0.9252336448598131, 'labeled_instances': 600, 'train_positive_rate': 0.18666666666666668, 'pool_positive_rate': 0.18618781206761717, 'iteration_time': 495.9661374092102}, {'test_loss': 0.12276793271303177, 'test_f1': 0.9241639189825719, 'test_prec': 0.9316239316239316, 'test_recall': 0.9168224299065421, 'labeled_instances': 640, 'train_positive_rate': 0.1890625, 'pool_positive_rate': 0.18609419284809744, 'iteration_time': 486.32574820518494}, {'test_loss': 0.1165694072842598, 'test_f1': 0.9222748815165877, 'test_prec': 0.9355769230769231, 'test_recall': 0.9093457943925234, 'labeled_instances': 680, 'train_positive_rate': 0.18529411764705883, 'pool_positive_rate': 0.1862419150093695, 'iteration_time': 490.1621949672699}, {'test_loss': 0.10985037684440613, 'test_f1': 0.9344648750589346, 'test_prec': 0.9429115128449096, 'test_recall': 0.9261682242990654, 'labeled_instances': 720, 'train_positive_rate': 0.18194444444444444, 'pool_positive_rate': 0.18639035326910258, 'iteration_time': 486.622074842453}, {'test_loss': 0.11003144085407257, 'test_f1': 0.9343807763401109, 'test_prec': 0.9241316270566727, 'test_recall': 0.9448598130841122, 'labeled_instances': 760, 'train_positive_rate': 0.17763157894736842, 'pool_positive_rate': 0.1866002551175363, 'iteration_time': 486.02595949172974}, {'test_loss': 0.13077770173549652, 'test_f1': 0.932093023255814, 'test_prec': 0.9277777777777778, 'test_recall': 0.9364485981308411, 'labeled_instances': 800, 'train_positive_rate': 0.1775, 'pool_positive_rate': 0.18662850879863607, 'iteration_time': 500.98571014404297}, {'test_loss': 0.144743412733078, 'test_f1': 0.9114658925979681, 'test_prec': 0.9448345035105316, 'test_recall': 0.8803738317757009, 'labeled_instances': 840, 'train_positive_rate': 0.17857142857142858, 'pool_positive_rate': 0.18659586156381616, 'iteration_time': 479.25460839271545}, {'test_loss': 0.15085726976394653, 'test_f1': 0.920388349514563, 'test_prec': 0.9575757575757575, 'test_recall': 0.8859813084112149, 'labeled_instances': 880, 'train_positive_rate': 0.1806818181818182, 'pool_positive_rate': 0.18650186624242795, 'iteration_time': 494.6017029285431}, {'test_loss': 0.10482306778430939, 'test_f1': 0.9211026615969581, 'test_prec': 0.937137330754352, 'test_recall': 0.905607476635514, 'labeled_instances': 920, 'train_positive_rate': 0.18369565217391304, 'pool_positive_rate': 0.18634607127522543, 'iteration_time': 534.5026724338531}, {'test_loss': 0.12499533593654633, 'test_f1': 0.9265054528212423, 'test_prec': 0.9403272377285852, 'test_recall': 0.9130841121495327, 'labeled_instances': 960, 'train_positive_rate': 0.1875, 'pool_positive_rate': 0.18612802066039477, 'iteration_time': 528.0872182846069}, {'test_loss': 0.1414722204208374, 'test_f1': 0.9148112294288481, 'test_prec': 0.9487951807228916, 'test_recall': 0.883177570093458, 'labeled_instances': 1000, 'train_positive_rate': 0.185, 'pool_positive_rate': 0.18627874006040807, 'iteration_time': 514.9876754283905}, {'test_loss': 0.1050122082233429, 'test_f1': 0.9573679332715477, 'test_prec': 0.9494485294117647, 'test_recall': 0.9654205607476636, 'labeled_instances': 17223, 'train_positive_rate': 0.18620449399059397, 'pool_positive_rate': 0.18620449399059397, 'iteration_time': 1526.689486503601}]
New cross validation 3, for  <function deepmatcher_structured_dblp_google_scholar at 0x14cc376e1160>

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 120
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 200
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 440
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 680
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 760
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 800
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 17223
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
[{'test_loss': 0.14655271172523499, 'test_f1': 0.8652291105121295, 'test_prec': 0.833044982698962, 'test_recall': 0.9, 'labeled_instances': 60, 'train_positive_rate': 0.21666666666666667, 'pool_positive_rate': 0.18609800151488667, 'iteration_time': 471.048627614975}, {'test_loss': 0.15945737063884735, 'test_f1': 0.8749999999999999, 'test_prec': 0.8026521060842434, 'test_recall': 0.9616822429906542, 'labeled_instances': 80, 'train_positive_rate': 0.225, 'pool_positive_rate': 0.18602344980458496, 'iteration_time': 461.61738896369934}, {'test_loss': 0.20358093082904816, 'test_f1': 0.8577423415862359, 'test_prec': 0.7783701447067783, 'test_recall': 0.9551401869158879, 'labeled_instances': 100, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.18612392688197163, 'iteration_time': 463.38160586357117}, {'test_loss': 0.19447289407253265, 'test_f1': 0.9017038007863696, 'test_prec': 0.8465955701394585, 'test_recall': 0.9644859813084112, 'labeled_instances': 120, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.186107700403438, 'iteration_time': 454.98455810546875}, {'test_loss': 0.16579563915729523, 'test_f1': 0.8910798122065728, 'test_prec': 0.8952830188679245, 'test_recall': 0.8869158878504673, 'labeled_instances': 140, 'train_positive_rate': 0.19285714285714287, 'pool_positive_rate': 0.1861499736580226, 'iteration_time': 480.0551595687866}, {'test_loss': 0.1991119682788849, 'test_f1': 0.8628628628628628, 'test_prec': 0.9288793103448276, 'test_recall': 0.805607476635514, 'labeled_instances': 160, 'train_positive_rate': 0.19375, 'pool_positive_rate': 0.18613373967063238, 'iteration_time': 479.4668490886688}, {'test_loss': 0.13663318753242493, 'test_f1': 0.8815911193339501, 'test_prec': 0.8727106227106227, 'test_recall': 0.8906542056074767, 'labeled_instances': 180, 'train_positive_rate': 0.19444444444444445, 'pool_positive_rate': 0.18611746758199849, 'iteration_time': 468.0777814388275}, {'test_loss': 0.15995723009109497, 'test_f1': 0.9037102473498233, 'test_prec': 0.8567839195979899, 'test_recall': 0.9560747663551402, 'labeled_instances': 200, 'train_positive_rate': 0.185, 'pool_positive_rate': 0.18621864536215707, 'iteration_time': 464.0326614379883}, {'test_loss': 0.15692530572414398, 'test_f1': 0.895793499043977, 'test_prec': 0.9168297455968689, 'test_recall': 0.8757009345794392, 'labeled_instances': 240, 'train_positive_rate': 0.17083333333333334, 'pool_positive_rate': 0.18642171583348055, 'iteration_time': 452.4871037006378}, {'test_loss': 0.2026287466287613, 'test_f1': 0.8953330312641594, 'test_prec': 0.8689533861037819, 'test_recall': 0.9233644859813084, 'labeled_instances': 280, 'train_positive_rate': 0.16428571428571428, 'pool_positive_rate': 0.18656672372071062, 'iteration_time': 452.1052806377411}, {'test_loss': 0.17269587516784668, 'test_f1': 0.9069343065693432, 'test_prec': 0.8859180035650623, 'test_recall': 0.9289719626168225, 'labeled_instances': 320, 'train_positive_rate': 0.184375, 'pool_positive_rate': 0.18623912914867183, 'iteration_time': 496.06836676597595}, {'test_loss': 0.16630052030086517, 'test_f1': 0.8981981981981981, 'test_prec': 0.8669565217391304, 'test_recall': 0.9317757009345794, 'labeled_instances': 360, 'train_positive_rate': 0.18055555555555555, 'pool_positive_rate': 0.18632509043467949, 'iteration_time': 495.1744794845581}, {'test_loss': 0.11201832443475723, 'test_f1': 0.9229357798165138, 'test_prec': 0.9063063063063063, 'test_recall': 0.9401869158878504, 'labeled_instances': 400, 'train_positive_rate': 0.18, 'pool_positive_rate': 0.18635201807049873, 'iteration_time': 487.04729747772217}, {'test_loss': 0.13180992007255554, 'test_f1': 0.9186954524575103, 'test_prec': 0.9033423667570009, 'test_recall': 0.9345794392523364, 'labeled_instances': 440, 'train_positive_rate': 0.18863636363636363, 'pool_positive_rate': 0.18614073765119465, 'iteration_time': 489.3177270889282}, {'test_loss': 0.1331242173910141, 'test_f1': 0.9140229885057471, 'test_prec': 0.8995475113122172, 'test_recall': 0.9289719626168225, 'labeled_instances': 480, 'train_positive_rate': 0.19375, 'pool_positive_rate': 0.1859881741623365, 'iteration_time': 483.28672981262207}, {'test_loss': 0.179710254073143, 'test_f1': 0.9138240574506284, 'test_prec': 0.8791018998272885, 'test_recall': 0.9514018691588785, 'labeled_instances': 520, 'train_positive_rate': 0.19807692307692307, 'pool_positive_rate': 0.18583487996168352, 'iteration_time': 483.75454449653625}, {'test_loss': 0.14307591319084167, 'test_f1': 0.922429906542056, 'test_prec': 0.922429906542056, 'test_recall': 0.922429906542056, 'labeled_instances': 560, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.18574086298985776, 'iteration_time': 473.4596269130707}, {'test_loss': 0.1358174830675125, 'test_f1': 0.9240622140896615, 'test_prec': 0.9050179211469535, 'test_recall': 0.9439252336448598, 'labeled_instances': 600, 'train_positive_rate': 0.19833333333333333, 'pool_positive_rate': 0.18576670877699572, 'iteration_time': 481.32953333854675}, {'test_loss': 0.14632686972618103, 'test_f1': 0.9259927797833934, 'test_prec': 0.8952879581151832, 'test_recall': 0.9588785046728971, 'labeled_instances': 640, 'train_positive_rate': 0.19375, 'pool_positive_rate': 0.18591328468913948, 'iteration_time': 514.5026304721832}, {'test_loss': 0.11534035950899124, 'test_f1': 0.9301470588235294, 'test_prec': 0.9150090415913201, 'test_recall': 0.9457943925233645, 'labeled_instances': 680, 'train_positive_rate': 0.19705882352941176, 'pool_positive_rate': 0.1857583267847428, 'iteration_time': 528.5271005630493}, {'test_loss': 0.15810158848762512, 'test_f1': 0.923626619026351, 'test_prec': 0.8845166809238666, 'test_recall': 0.9663551401869159, 'labeled_instances': 720, 'train_positive_rate': 0.19305555555555556, 'pool_positive_rate': 0.18590559292249895, 'iteration_time': 504.1730353832245}, {'test_loss': 0.1471439152956009, 'test_f1': 0.9289012003693443, 'test_prec': 0.9178832116788321, 'test_recall': 0.9401869158878504, 'labeled_instances': 760, 'train_positive_rate': 0.19078947368421054, 'pool_positive_rate': 0.18599283241207556, 'iteration_time': 513.5209059715271}, {'test_loss': 0.111273393034935, 'test_f1': 0.9309701492537312, 'test_prec': 0.9292364990689013, 'test_recall': 0.9327102803738317, 'labeled_instances': 800, 'train_positive_rate': 0.19, 'pool_positive_rate': 0.18601960664921147, 'iteration_time': 510.0292921066284}, {'test_loss': 0.11602487415075302, 'test_f1': 0.921999065857076, 'test_prec': 0.9215686274509803, 'test_recall': 0.922429906542056, 'labeled_instances': 840, 'train_positive_rate': 0.19523809523809524, 'pool_positive_rate': 0.18574131721906856, 'iteration_time': 516.67817902565}, {'test_loss': 0.13643211126327515, 'test_f1': 0.9264504339881224, 'test_prec': 0.9061662198391421, 'test_recall': 0.9476635514018692, 'labeled_instances': 880, 'train_positive_rate': 0.19545454545454546, 'pool_positive_rate': 0.1857064186501866, 'iteration_time': 526.7518005371094}, {'test_loss': 0.11635489761829376, 'test_f1': 0.9347014925373135, 'test_prec': 0.9329608938547486, 'test_recall': 0.9364485981308411, 'labeled_instances': 920, 'train_positive_rate': 0.1956521739130435, 'pool_positive_rate': 0.1856713488315034, 'iteration_time': 519.4806554317474}, {'test_loss': 0.11939877271652222, 'test_f1': 0.939435968562182, 'test_prec': 0.929551692589204, 'test_recall': 0.9495327102803738, 'labeled_instances': 960, 'train_positive_rate': 0.19479166666666667, 'pool_positive_rate': 0.1856975957695382, 'iteration_time': 510.08159923553467}, {'test_loss': 0.14377492666244507, 'test_f1': 0.9230059935454127, 'test_prec': 0.910828025477707, 'test_recall': 0.9355140186915888, 'labeled_instances': 1000, 'train_positive_rate': 0.196, 'pool_positive_rate': 0.1856006903778586, 'iteration_time': 520.7001061439514}, {'test_loss': 0.10624176263809204, 'test_f1': 0.9565619223659889, 'test_prec': 0.9460694698354661, 'test_recall': 0.9672897196261683, 'labeled_instances': 17223, 'train_positive_rate': 0.18620449399059397, 'pool_positive_rate': 0.18620449399059397, 'iteration_time': 1568.6881074905396}]
New cross validation 4, for  <function deepmatcher_structured_dblp_google_scholar at 0x14cc376e1160>

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 200
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 440
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 720
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 17223
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
[{'test_loss': 0.21383309364318848, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.18333333333333332, 'pool_positive_rate': 0.1862145312591039, 'iteration_time': 464.88496136665344}, {'test_loss': 0.20235008001327515, 'test_f1': 0.840242669362993, 'test_prec': 0.9151982378854625, 'test_recall': 0.7766355140186916, 'labeled_instances': 80, 'train_positive_rate': 0.1875, 'pool_positive_rate': 0.18619844834626378, 'iteration_time': 466.50950837135315}, {'test_loss': 0.3034961223602295, 'test_f1': 0.8113504992117707, 'test_prec': 0.9267707082833133, 'test_recall': 0.7214953271028037, 'labeled_instances': 100, 'train_positive_rate': 0.17, 'pool_positive_rate': 0.18629912982538108, 'iteration_time': 463.01502203941345}, {'test_loss': 0.15553824603557587, 'test_f1': 0.8860435339308578, 'test_prec': 0.8153967007069913, 'test_recall': 0.9700934579439252, 'labeled_instances': 120, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.186107700403438, 'iteration_time': 443.9755139350891}, {'test_loss': 0.0913180410861969, 'test_f1': 0.9132212630622445, 'test_prec': 0.8885941644562334, 'test_recall': 0.9392523364485982, 'labeled_instances': 140, 'train_positive_rate': 0.21428571428571427, 'pool_positive_rate': 0.18597436047532634, 'iteration_time': 504.79167008399963}, {'test_loss': 0.15219682455062866, 'test_f1': 0.9024390243902439, 'test_prec': 0.8732517482517482, 'test_recall': 0.9336448598130841, 'labeled_instances': 160, 'train_positive_rate': 0.21875, 'pool_positive_rate': 0.1858993143058079, 'iteration_time': 490.611652135849}, {'test_loss': 0.10250253975391388, 'test_f1': 0.907325684024713, 'test_prec': 0.8595317725752508, 'test_recall': 0.9607476635514018, 'labeled_instances': 180, 'train_positive_rate': 0.21666666666666667, 'pool_positive_rate': 0.18588276711846505, 'iteration_time': 480.57388615608215}, {'test_loss': 0.12079772353172302, 'test_f1': 0.9035441902198295, 'test_prec': 0.8688524590163934, 'test_recall': 0.9411214953271028, 'labeled_instances': 200, 'train_positive_rate': 0.22, 'pool_positive_rate': 0.18580743699700406, 'iteration_time': 472.9069514274597}, {'test_loss': 0.13406066596508026, 'test_f1': 0.9000884173297966, 'test_prec': 0.8540268456375839, 'test_recall': 0.9514018691588785, 'labeled_instances': 240, 'train_positive_rate': 0.22083333333333333, 'pool_positive_rate': 0.18571512689159747, 'iteration_time': 459.10160994529724}, {'test_loss': 0.18327677249908447, 'test_f1': 0.902555218709398, 'test_prec': 0.841000807102502, 'test_recall': 0.9738317757009346, 'labeled_instances': 280, 'train_positive_rate': 0.20714285714285716, 'pool_positive_rate': 0.1858584666233843, 'iteration_time': 504.48533153533936}, {'test_loss': 0.1304042637348175, 'test_f1': 0.9168519341929746, 'test_prec': 0.8744698897370653, 'test_recall': 0.9635514018691589, 'labeled_instances': 320, 'train_positive_rate': 0.196875, 'pool_positive_rate': 0.18600248476601786, 'iteration_time': 505.10514998435974}, {'test_loss': 0.11335211992263794, 'test_f1': 0.9239179954441914, 'test_prec': 0.9013333333333333, 'test_recall': 0.9476635514018692, 'labeled_instances': 360, 'train_positive_rate': 0.19444444444444445, 'pool_positive_rate': 0.18602858328885727, 'iteration_time': 492.4639711380005}, {'test_loss': 0.15188896656036377, 'test_f1': 0.918942731277533, 'test_prec': 0.8691666666666666, 'test_recall': 0.974766355140187, 'labeled_instances': 400, 'train_positive_rate': 0.1825, 'pool_positive_rate': 0.18629257564049218, 'iteration_time': 500.24165749549866}, {'test_loss': 0.16645456850528717, 'test_f1': 0.9116360454943133, 'test_prec': 0.8569078947368421, 'test_recall': 0.9738317757009346, 'labeled_instances': 440, 'train_positive_rate': 0.18181818181818182, 'pool_positive_rate': 0.18631948996007866, 'iteration_time': 486.55542397499084}, {'test_loss': 0.16309760510921478, 'test_f1': 0.9179170344218888, 'test_prec': 0.8695652173913043, 'test_recall': 0.9719626168224299, 'labeled_instances': 480, 'train_positive_rate': 0.18125, 'pool_positive_rate': 0.1863465328794123, 'iteration_time': 500.11382508277893}, {'test_loss': 0.09462920576334, 'test_f1': 0.9349442379182156, 'test_prec': 0.9297597042513863, 'test_recall': 0.9401869158878504, 'labeled_instances': 520, 'train_positive_rate': 0.175, 'pool_positive_rate': 0.1865533137759684, 'iteration_time': 490.7100212574005}, {'test_loss': 0.11634404957294464, 'test_f1': 0.9265750828991001, 'test_prec': 0.9394812680115274, 'test_recall': 0.914018691588785, 'labeled_instances': 560, 'train_positive_rate': 0.18035714285714285, 'pool_positive_rate': 0.1864010082218088, 'iteration_time': 504.34435844421387}, {'test_loss': 0.11287505179643631, 'test_f1': 0.9295774647887324, 'test_prec': 0.9339622641509434, 'test_recall': 0.9252336448598131, 'labeled_instances': 600, 'train_positive_rate': 0.17833333333333334, 'pool_positive_rate': 0.18648860013234675, 'iteration_time': 481.49440360069275}, {'test_loss': 0.12687520682811737, 'test_f1': 0.9259962049335864, 'test_prec': 0.9402697495183044, 'test_recall': 0.9121495327102803, 'labeled_instances': 640, 'train_positive_rate': 0.184375, 'pool_positive_rate': 0.1862751010070554, 'iteration_time': 482.1116762161255}, {'test_loss': 0.10786008834838867, 'test_f1': 0.935064935064935, 'test_prec': 0.9281767955801105, 'test_recall': 0.9420560747663551, 'labeled_instances': 680, 'train_positive_rate': 0.18235294117647058, 'pool_positive_rate': 0.1863628120655262, 'iteration_time': 522.8149425983429}, {'test_loss': 0.14310580492019653, 'test_f1': 0.9216674301420064, 'test_prec': 0.903863432165319, 'test_recall': 0.9401869158878504, 'labeled_instances': 720, 'train_positive_rate': 0.18333333333333332, 'pool_positive_rate': 0.18632975822577713, 'iteration_time': 533.3847208023071}, {'test_loss': 0.13969556987285614, 'test_f1': 0.9289667896678966, 'test_prec': 0.9171220400728597, 'test_recall': 0.9411214953271028, 'labeled_instances': 760, 'train_positive_rate': 0.18157894736842106, 'pool_positive_rate': 0.18641802830589807, 'iteration_time': 518.92675948143}, {'test_loss': 0.13940276205539703, 'test_f1': 0.9393237610004631, 'test_prec': 0.931129476584022, 'test_recall': 0.9476635514018692, 'labeled_instances': 800, 'train_positive_rate': 0.17875, 'pool_positive_rate': 0.1865676185836936, 'iteration_time': 514.3065569400787}, {'test_loss': 0.13296495378017426, 'test_f1': 0.9300567107750473, 'test_prec': 0.9407265774378585, 'test_recall': 0.9196261682242991, 'labeled_instances': 840, 'train_positive_rate': 0.1773809523809524, 'pool_positive_rate': 0.18665690044558383, 'iteration_time': 530.4846742153168}, {'test_loss': 0.09687376022338867, 'test_f1': 0.9343200740055504, 'test_prec': 0.924908424908425, 'test_recall': 0.9439252336448598, 'labeled_instances': 880, 'train_positive_rate': 0.18295454545454545, 'pool_positive_rate': 0.18637948968977544, 'iteration_time': 533.2959582805634}, {'test_loss': 0.13017915189266205, 'test_f1': 0.9312413474850022, 'test_prec': 0.9197812215132178, 'test_recall': 0.9429906542056075, 'labeled_instances': 920, 'train_positive_rate': 0.1858695652173913, 'pool_positive_rate': 0.18622339446727595, 'iteration_time': 527.5684847831726}, {'test_loss': 0.1212553009390831, 'test_f1': 0.936768149882904, 'test_prec': 0.9389671361502347, 'test_recall': 0.9345794392523364, 'labeled_instances': 960, 'train_positive_rate': 0.18333333333333332, 'pool_positive_rate': 0.1863739777408842, 'iteration_time': 519.7387852668762}, {'test_loss': 0.11629190295934677, 'test_f1': 0.9321561338289963, 'test_prec': 0.9269870609981515, 'test_recall': 0.9373831775700935, 'labeled_instances': 1000, 'train_positive_rate': 0.189, 'pool_positive_rate': 0.18603217653948098, 'iteration_time': 531.9215397834778}, {'test_loss': 0.10873632878065109, 'test_f1': 0.9557933922754769, 'test_prec': 0.9518072289156626, 'test_recall': 0.9598130841121495, 'labeled_instances': 17223, 'train_positive_rate': 0.18620449399059397, 'pool_positive_rate': 0.18620449399059397, 'iteration_time': 1542.129106760025}]
Could not create dir out, File exists




    ###########  New Dataset: <function deepmatcher_structured_walmart_amazon at 0x14cc376e1280>
New cross validation 0, for  <function deepmatcher_structured_walmart_amazon at 0x14cc376e1280>

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 100
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 200
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 1000
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 6144
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
[{'test_loss': 0.2891954779624939, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.06666666666666667, 'pool_positive_rate': 0.09401709401709402, 'iteration_time': 369.1254687309265}, {'test_loss': 0.3233940601348877, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 80, 'train_positive_rate': 0.0875, 'pool_positive_rate': 0.09383245382585752, 'iteration_time': 384.9200117588043}, {'test_loss': 0.31297945976257324, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 100, 'train_positive_rate': 0.08, 'pool_positive_rate': 0.09397749834546658, 'iteration_time': 388.5788378715515}, {'test_loss': 0.3183645009994507, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 120, 'train_positive_rate': 0.09166666666666666, 'pool_positive_rate': 0.09379150066401062, 'iteration_time': 372.0859785079956}, {'test_loss': 0.3496045470237732, 'test_f1': 0.102803738317757, 'test_prec': 0.5238095238095238, 'test_recall': 0.05699481865284974, 'labeled_instances': 140, 'train_positive_rate': 0.07857142857142857, 'pool_positive_rate': 0.0941039307128581, 'iteration_time': 391.74111342430115}, {'test_loss': 0.36881816387176514, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 160, 'train_positive_rate': 0.075, 'pool_positive_rate': 0.09425133689839572, 'iteration_time': 362.0901174545288}, {'test_loss': 0.43197906017303467, 'test_f1': 0.25384615384615383, 'test_prec': 0.4925373134328358, 'test_recall': 0.17098445595854922, 'labeled_instances': 180, 'train_positive_rate': 0.07222222222222222, 'pool_positive_rate': 0.09439973172367538, 'iteration_time': 395.39647579193115}, {'test_loss': 0.33614325523376465, 'test_f1': 0.06730769230769229, 'test_prec': 0.4666666666666667, 'test_recall': 0.03626943005181347, 'labeled_instances': 200, 'train_positive_rate': 0.075, 'pool_positive_rate': 0.09438088829071332, 'iteration_time': 391.3142387866974}, {'test_loss': 0.3934207260608673, 'test_f1': 0.20064724919093851, 'test_prec': 0.2672413793103448, 'test_recall': 0.16062176165803108, 'labeled_instances': 240, 'train_positive_rate': 0.07916666666666666, 'pool_positive_rate': 0.09434281842818429, 'iteration_time': 375.8197133541107}, {'test_loss': 0.2940557599067688, 'test_f1': 0.5225806451612903, 'test_prec': 0.6923076923076923, 'test_recall': 0.41968911917098445, 'labeled_instances': 280, 'train_positive_rate': 0.07142857142857142, 'pool_positive_rate': 0.09481582537517053, 'iteration_time': 382.4841651916504}, {'test_loss': 0.4954703748226166, 'test_f1': 0.08438818565400844, 'test_prec': 0.22727272727272727, 'test_recall': 0.05181347150259067, 'labeled_instances': 320, 'train_positive_rate': 0.065625, 'pool_positive_rate': 0.09529532967032966, 'iteration_time': 395.7383759021759}, {'test_loss': 0.29320961236953735, 'test_f1': 0.580441640378549, 'test_prec': 0.7419354838709677, 'test_recall': 0.47668393782383417, 'labeled_instances': 360, 'train_positive_rate': 0.075, 'pool_positive_rate': 0.09491701244813278, 'iteration_time': 395.2029724121094}, {'test_loss': 0.3433396518230438, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 400, 'train_positive_rate': 0.075, 'pool_positive_rate': 0.09505571030640668, 'iteration_time': 412.4316098690033}, {'test_loss': 0.3001020848751068, 'test_f1': 0.46822742474916385, 'test_prec': 0.660377358490566, 'test_recall': 0.3626943005181347, 'labeled_instances': 440, 'train_positive_rate': 0.07727272727272727, 'pool_positive_rate': 0.0950210378681627, 'iteration_time': 404.0681412220001}, {'test_loss': 0.2786093056201935, 'test_f1': 0.5403508771929825, 'test_prec': 0.8369565217391305, 'test_recall': 0.39896373056994816, 'labeled_instances': 480, 'train_positive_rate': 0.07916666666666666, 'pool_positive_rate': 0.0949858757062147, 'iteration_time': 392.6230294704437}, {'test_loss': 0.3416368067264557, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 520, 'train_positive_rate': 0.08269230769230769, 'pool_positive_rate': 0.0947724039829303, 'iteration_time': 390.53831672668457}, {'test_loss': 0.42756301164627075, 'test_f1': 0.11158798283261803, 'test_prec': 0.325, 'test_recall': 0.06735751295336788, 'labeled_instances': 560, 'train_positive_rate': 0.07857142857142857, 'pool_positive_rate': 0.09527220630372493, 'iteration_time': 392.0435242652893}, {'test_loss': 0.3952659070491791, 'test_f1': 0.5360230547550432, 'test_prec': 0.6038961038961039, 'test_recall': 0.48186528497409326, 'labeled_instances': 600, 'train_positive_rate': 0.07833333333333334, 'pool_positive_rate': 0.09541847041847042, 'iteration_time': 406.75187253952026}, {'test_loss': 0.2827666401863098, 'test_f1': 0.611260053619303, 'test_prec': 0.6333333333333333, 'test_recall': 0.5906735751295337, 'labeled_instances': 640, 'train_positive_rate': 0.0828125, 'pool_positive_rate': 0.0950218023255814, 'iteration_time': 388.3881332874298}, {'test_loss': 0.23688726127147675, 'test_f1': 0.6910994764397905, 'test_prec': 0.6984126984126984, 'test_recall': 0.6839378238341969, 'labeled_instances': 680, 'train_positive_rate': 0.08235294117647059, 'pool_positive_rate': 0.0951683748169839, 'iteration_time': 398.1273765563965}, {'test_loss': 0.40703466534614563, 'test_f1': 0.33440514469453375, 'test_prec': 0.4406779661016949, 'test_recall': 0.2694300518134715, 'labeled_instances': 720, 'train_positive_rate': 0.08472222222222223, 'pool_positive_rate': 0.09494837758112094, 'iteration_time': 423.3875377178192}, {'test_loss': 0.2610473930835724, 'test_f1': 0.6762177650429799, 'test_prec': 0.7564102564102564, 'test_recall': 0.6113989637305699, 'labeled_instances': 760, 'train_positive_rate': 0.08289473684210526, 'pool_positive_rate': 0.09528231797919762, 'iteration_time': 428.2186725139618}, {'test_loss': 0.2002936452627182, 'test_f1': 0.7435158501440923, 'test_prec': 0.8376623376623377, 'test_recall': 0.6683937823834197, 'labeled_instances': 800, 'train_positive_rate': 0.085, 'pool_positive_rate': 0.09505988023952096, 'iteration_time': 429.39343667030334}, {'test_loss': 0.21957837045192719, 'test_f1': 0.7116883116883116, 'test_prec': 0.7135416666666666, 'test_recall': 0.7098445595854922, 'labeled_instances': 840, 'train_positive_rate': 0.08928571428571429, 'pool_positive_rate': 0.09445701357466063, 'iteration_time': 419.4382402896881}, {'test_loss': 0.18024134635925293, 'test_f1': 0.7546174142480211, 'test_prec': 0.7688172043010753, 'test_recall': 0.7409326424870466, 'labeled_instances': 880, 'train_positive_rate': 0.08863636363636364, 'pool_positive_rate': 0.0946048632218845, 'iteration_time': 425.45356917381287}, {'test_loss': 0.20472222566604614, 'test_f1': 0.7588075880758809, 'test_prec': 0.7954545454545454, 'test_recall': 0.7253886010362695, 'labeled_instances': 920, 'train_positive_rate': 0.08804347826086957, 'pool_positive_rate': 0.09475497702909648, 'iteration_time': 437.6656503677368}, {'test_loss': 0.22358323633670807, 'test_f1': 0.7588075880758809, 'test_prec': 0.7954545454545454, 'test_recall': 0.7253886010362695, 'labeled_instances': 960, 'train_positive_rate': 0.084375, 'pool_positive_rate': 0.0954861111111111, 'iteration_time': 426.30934047698975}, {'test_loss': 0.1920430213212967, 'test_f1': 0.7557840616966581, 'test_prec': 0.75, 'test_recall': 0.7616580310880829, 'labeled_instances': 1000, 'train_positive_rate': 0.084, 'pool_positive_rate': 0.09564541213063764, 'iteration_time': 442.0990946292877}, {'test_loss': 0.1497599482536316, 'test_f1': 0.8594594594594595, 'test_prec': 0.8983050847457628, 'test_recall': 0.8238341968911918, 'labeled_instances': 6144, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.09375, 'iteration_time': 733.5761377811432}]
New cross validation 1, for  <function deepmatcher_structured_walmart_amazon at 0x14cc376e1280>

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 80
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 100
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 140
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 200
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 480
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 560
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 680
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 720
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 6144
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
[{'test_loss': 0.30266904830932617, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.08333333333333333, 'pool_positive_rate': 0.09385272846811309, 'iteration_time': 363.1026945114136}, {'test_loss': 0.32035017013549805, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 80, 'train_positive_rate': 0.1125, 'pool_positive_rate': 0.09350263852242745, 'iteration_time': 374.5442044734955}, {'test_loss': 0.42278024554252625, 'test_f1': 0.026200873362445413, 'test_prec': 0.08333333333333333, 'test_recall': 0.015544041450777202, 'labeled_instances': 100, 'train_positive_rate': 0.12, 'pool_positive_rate': 0.09331568497683654, 'iteration_time': 369.15626430511475}, {'test_loss': 0.3766123652458191, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 120, 'train_positive_rate': 0.10833333333333334, 'pool_positive_rate': 0.09345949535192563, 'iteration_time': 369.601042509079}, {'test_loss': 0.4351968765258789, 'test_f1': 0.265625, 'test_prec': 0.5396825396825397, 'test_recall': 0.17616580310880828, 'labeled_instances': 140, 'train_positive_rate': 0.10714285714285714, 'pool_positive_rate': 0.09343770819453698, 'iteration_time': 371.0348517894745}, {'test_loss': 0.43177151679992676, 'test_f1': 0.22727272727272727, 'test_prec': 0.4225352112676056, 'test_recall': 0.15544041450777202, 'labeled_instances': 160, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.09375, 'iteration_time': 382.97187304496765}, {'test_loss': 0.33852165937423706, 'test_f1': 0.13574660633484165, 'test_prec': 0.5357142857142857, 'test_recall': 0.07772020725388601, 'labeled_instances': 180, 'train_positive_rate': 0.08888888888888889, 'pool_positive_rate': 0.09389671361502347, 'iteration_time': 382.6472451686859}, {'test_loss': 0.4084330201148987, 'test_f1': 0.02, 'test_prec': 0.2857142857142857, 'test_recall': 0.010362694300518135, 'labeled_instances': 200, 'train_positive_rate': 0.085, 'pool_positive_rate': 0.09404441453566621, 'iteration_time': 390.14028310775757}, {'test_loss': 0.5888535976409912, 'test_f1': 0.05, 'test_prec': 0.1276595744680851, 'test_recall': 0.031088082901554404, 'labeled_instances': 240, 'train_positive_rate': 0.10833333333333334, 'pool_positive_rate': 0.09315718157181571, 'iteration_time': 388.4086971282959}, {'test_loss': 0.44948941469192505, 'test_f1': 0.2787456445993031, 'test_prec': 0.425531914893617, 'test_recall': 0.20725388601036268, 'labeled_instances': 280, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.09345156889495225, 'iteration_time': 376.4637944698334}, {'test_loss': 0.46261826157569885, 'test_f1': 0.3260869565217391, 'test_prec': 0.5421686746987951, 'test_recall': 0.23316062176165803, 'labeled_instances': 320, 'train_positive_rate': 0.090625, 'pool_positive_rate': 0.0939217032967033, 'iteration_time': 382.3812475204468}, {'test_loss': 0.44665950536727905, 'test_f1': 0.2777777777777778, 'test_prec': 0.5932203389830508, 'test_recall': 0.18134715025906736, 'labeled_instances': 360, 'train_positive_rate': 0.08888888888888889, 'pool_positive_rate': 0.09405255878284924, 'iteration_time': 394.6301944255829}, {'test_loss': 0.4437691867351532, 'test_f1': 0.2434782608695652, 'test_prec': 0.7567567567567568, 'test_recall': 0.14507772020725387, 'labeled_instances': 400, 'train_positive_rate': 0.0975, 'pool_positive_rate': 0.09348885793871867, 'iteration_time': 404.5234215259552}, {'test_loss': 0.5767272114753723, 'test_f1': 0.11764705882352941, 'test_prec': 0.3111111111111111, 'test_recall': 0.07253886010362694, 'labeled_instances': 440, 'train_positive_rate': 0.09318181818181819, 'pool_positive_rate': 0.0937938288920056, 'iteration_time': 398.6019277572632}, {'test_loss': 0.3275165855884552, 'test_f1': 0.5875, 'test_prec': 0.7401574803149606, 'test_recall': 0.48704663212435234, 'labeled_instances': 480, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.09375, 'iteration_time': 395.26309633255005}, {'test_loss': 0.4939996302127838, 'test_f1': 0.08658008658008656, 'test_prec': 0.2631578947368421, 'test_recall': 0.05181347150259067, 'labeled_instances': 520, 'train_positive_rate': 0.08846153846153847, 'pool_positive_rate': 0.09423897581792319, 'iteration_time': 395.62295031547546}, {'test_loss': 0.4482336640357971, 'test_f1': 0.40138408304498263, 'test_prec': 0.6041666666666666, 'test_recall': 0.3005181347150259, 'labeled_instances': 560, 'train_positive_rate': 0.08571428571428572, 'pool_positive_rate': 0.09455587392550144, 'iteration_time': 389.97493624687195}, {'test_loss': 0.24567653238773346, 'test_f1': 0.7031700288184439, 'test_prec': 0.7922077922077922, 'test_recall': 0.6321243523316062, 'labeled_instances': 600, 'train_positive_rate': 0.09, 'pool_positive_rate': 0.09415584415584416, 'iteration_time': 391.32692646980286}, {'test_loss': 0.4281432330608368, 'test_f1': 0.3840579710144927, 'test_prec': 0.6385542168674698, 'test_recall': 0.27461139896373055, 'labeled_instances': 640, 'train_positive_rate': 0.090625, 'pool_positive_rate': 0.09411337209302326, 'iteration_time': 390.6006166934967}, {'test_loss': 0.34531262516975403, 'test_f1': 0.528169014084507, 'test_prec': 0.8241758241758241, 'test_recall': 0.38860103626943004, 'labeled_instances': 680, 'train_positive_rate': 0.09117647058823529, 'pool_positive_rate': 0.09407027818448023, 'iteration_time': 407.0707914829254}, {'test_loss': 0.5449436902999878, 'test_f1': 0.21052631578947367, 'test_prec': 0.32608695652173914, 'test_recall': 0.15544041450777202, 'labeled_instances': 720, 'train_positive_rate': 0.09166666666666666, 'pool_positive_rate': 0.09402654867256637, 'iteration_time': 412.0629451274872}, {'test_loss': 0.4244322180747986, 'test_f1': 0.4281524926686217, 'test_prec': 0.49324324324324326, 'test_recall': 0.37823834196891193, 'labeled_instances': 760, 'train_positive_rate': 0.09078947368421053, 'pool_positive_rate': 0.09416790490341753, 'iteration_time': 417.5902373790741}, {'test_loss': 0.4969751238822937, 'test_f1': 0.1267605633802817, 'test_prec': 0.1978021978021978, 'test_recall': 0.09326424870466321, 'labeled_instances': 800, 'train_positive_rate': 0.0925, 'pool_positive_rate': 0.09393712574850299, 'iteration_time': 424.12553668022156}, {'test_loss': 0.2882431447505951, 'test_f1': 0.6125, 'test_prec': 0.7716535433070866, 'test_recall': 0.5077720207253886, 'labeled_instances': 840, 'train_positive_rate': 0.09404761904761905, 'pool_positive_rate': 0.09370286576168929, 'iteration_time': 426.4706995487213}, {'test_loss': 0.22695839405059814, 'test_f1': 0.7598944591029023, 'test_prec': 0.7741935483870968, 'test_recall': 0.7461139896373057, 'labeled_instances': 880, 'train_positive_rate': 0.09431818181818181, 'pool_positive_rate': 0.09365501519756839, 'iteration_time': 423.0478961467743}, {'test_loss': 0.20921950042247772, 'test_f1': 0.7647058823529412, 'test_prec': 0.7900552486187845, 'test_recall': 0.7409326424870466, 'labeled_instances': 920, 'train_positive_rate': 0.0967391304347826, 'pool_positive_rate': 0.09322358346094946, 'iteration_time': 421.4420790672302}, {'test_loss': 0.25522053241729736, 'test_f1': 0.6939890710382514, 'test_prec': 0.7341040462427746, 'test_recall': 0.6580310880829016, 'labeled_instances': 960, 'train_positive_rate': 0.09791666666666667, 'pool_positive_rate': 0.09297839506172839, 'iteration_time': 421.74375677108765}, {'test_loss': 0.31231561303138733, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 1000, 'train_positive_rate': 0.095, 'pool_positive_rate': 0.09350699844479005, 'iteration_time': 424.7405381202698}, {'test_loss': 0.1771838515996933, 'test_f1': 0.8563829787234042, 'test_prec': 0.8797814207650273, 'test_recall': 0.8341968911917098, 'labeled_instances': 6144, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.09375, 'iteration_time': 738.3554029464722}]
New cross validation 2, for  <function deepmatcher_structured_walmart_amazon at 0x14cc376e1280>

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 200
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 240
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 360
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 400
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 520
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 680
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 760
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 1000
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 6144
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
[{'test_loss': 0.32989391684532166, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.05, 'pool_positive_rate': 0.09418145956607495, 'iteration_time': 362.3017244338989}, {'test_loss': 0.39403748512268066, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 80, 'train_positive_rate': 0.05, 'pool_positive_rate': 0.09432717678100264, 'iteration_time': 366.28919506073}, {'test_loss': 0.4476602077484131, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 100, 'train_positive_rate': 0.05, 'pool_positive_rate': 0.09447385837193911, 'iteration_time': 367.54289054870605}, {'test_loss': 0.3378756046295166, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 120, 'train_positive_rate': 0.05, 'pool_positive_rate': 0.0946215139442231, 'iteration_time': 368.94464445114136}, {'test_loss': 0.3083173334598541, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 140, 'train_positive_rate': 0.06428571428571428, 'pool_positive_rate': 0.09443704197201866, 'iteration_time': 387.8669545650482}, {'test_loss': 0.3403988778591156, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 160, 'train_positive_rate': 0.075, 'pool_positive_rate': 0.09425133689839572, 'iteration_time': 376.04091453552246}, {'test_loss': 0.2956349849700928, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 180, 'train_positive_rate': 0.07777777777777778, 'pool_positive_rate': 0.09423205902079142, 'iteration_time': 382.5569820404053}, {'test_loss': 0.4181586503982544, 'test_f1': 0.3745019920318725, 'test_prec': 0.8103448275862069, 'test_recall': 0.24352331606217617, 'labeled_instances': 200, 'train_positive_rate': 0.09, 'pool_positive_rate': 0.09387617765814267, 'iteration_time': 374.6599860191345}, {'test_loss': 0.35544392466545105, 'test_f1': 0.4202898550724638, 'test_prec': 0.6987951807228916, 'test_recall': 0.3005181347150259, 'labeled_instances': 240, 'train_positive_rate': 0.0875, 'pool_positive_rate': 0.09400406504065041, 'iteration_time': 385.21146988868713}, {'test_loss': 0.4319155514240265, 'test_f1': 0.3533123028391167, 'test_prec': 0.45161290322580644, 'test_recall': 0.29015544041450775, 'labeled_instances': 280, 'train_positive_rate': 0.08214285714285714, 'pool_positive_rate': 0.09430422919508867, 'iteration_time': 393.5364966392517}, {'test_loss': 0.21788841485977173, 'test_f1': 0.6575342465753425, 'test_prec': 0.6976744186046512, 'test_recall': 0.6217616580310881, 'labeled_instances': 320, 'train_positive_rate': 0.078125, 'pool_positive_rate': 0.09460851648351648, 'iteration_time': 386.76343631744385}, {'test_loss': 0.3232788145542145, 'test_f1': 0.010050251256281407, 'test_prec': 0.16666666666666666, 'test_recall': 0.0051813471502590676, 'labeled_instances': 360, 'train_positive_rate': 0.075, 'pool_positive_rate': 0.09491701244813278, 'iteration_time': 392.423463344574}, {'test_loss': 0.24359893798828125, 'test_f1': 0.5985401459854015, 'test_prec': 0.5642201834862385, 'test_recall': 0.6373056994818653, 'labeled_instances': 400, 'train_positive_rate': 0.075, 'pool_positive_rate': 0.09505571030640668, 'iteration_time': 406.6922347545624}, {'test_loss': 0.19305384159088135, 'test_f1': 0.67966573816156, 'test_prec': 0.7349397590361446, 'test_recall': 0.6321243523316062, 'labeled_instances': 440, 'train_positive_rate': 0.07272727272727272, 'pool_positive_rate': 0.09537166900420757, 'iteration_time': 401.29611682891846}, {'test_loss': 0.18864338099956512, 'test_f1': 0.7002518891687657, 'test_prec': 0.6813725490196079, 'test_recall': 0.7202072538860104, 'labeled_instances': 480, 'train_positive_rate': 0.07708333333333334, 'pool_positive_rate': 0.09516242937853107, 'iteration_time': 407.76953387260437}, {'test_loss': 0.3465045094490051, 'test_f1': 0.5466237942122186, 'test_prec': 0.7203389830508474, 'test_recall': 0.44041450777202074, 'labeled_instances': 520, 'train_positive_rate': 0.075, 'pool_positive_rate': 0.09548364153627312, 'iteration_time': 409.88561725616455}, {'test_loss': 0.32012632489204407, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 560, 'train_positive_rate': 0.06964285714285715, 'pool_positive_rate': 0.0961676217765043, 'iteration_time': 405.00829315185547}, {'test_loss': 0.17279045283794403, 'test_f1': 0.7541899441340784, 'test_prec': 0.8181818181818182, 'test_recall': 0.6994818652849741, 'labeled_instances': 600, 'train_positive_rate': 0.075, 'pool_positive_rate': 0.09577922077922078, 'iteration_time': 407.61001420021057}, {'test_loss': 0.22019338607788086, 'test_f1': 0.7231638418079097, 'test_prec': 0.7950310559006211, 'test_recall': 0.6632124352331606, 'labeled_instances': 640, 'train_positive_rate': 0.075, 'pool_positive_rate': 0.09593023255813954, 'iteration_time': 413.63748359680176}, {'test_loss': 0.4787121117115021, 'test_f1': 0.2895622895622895, 'test_prec': 0.41346153846153844, 'test_recall': 0.22279792746113988, 'labeled_instances': 680, 'train_positive_rate': 0.07941176470588235, 'pool_positive_rate': 0.09553440702781844, 'iteration_time': 408.3613917827606}, {'test_loss': 0.16344350576400757, 'test_f1': 0.7731092436974789, 'test_prec': 0.8414634146341463, 'test_recall': 0.7150259067357513, 'labeled_instances': 720, 'train_positive_rate': 0.08194444444444444, 'pool_positive_rate': 0.09531710914454278, 'iteration_time': 417.0004630088806}, {'test_loss': 0.16928555071353912, 'test_f1': 0.8, 'test_prec': 0.89171974522293, 'test_recall': 0.7253886010362695, 'labeled_instances': 760, 'train_positive_rate': 0.08421052631578947, 'pool_positive_rate': 0.0950965824665676, 'iteration_time': 415.13338327407837}, {'test_loss': 0.194095179438591, 'test_f1': 0.7688172043010753, 'test_prec': 0.7988826815642458, 'test_recall': 0.7409326424870466, 'labeled_instances': 800, 'train_positive_rate': 0.085, 'pool_positive_rate': 0.09505988023952096, 'iteration_time': 420.6845142841339}, {'test_loss': 0.26173651218414307, 'test_f1': 0.6495176848874598, 'test_prec': 0.8559322033898306, 'test_recall': 0.5233160621761658, 'labeled_instances': 840, 'train_positive_rate': 0.0880952380952381, 'pool_positive_rate': 0.09464555052790347, 'iteration_time': 421.92183899879456}, {'test_loss': 0.2159738689661026, 'test_f1': 0.6824925816023739, 'test_prec': 0.7986111111111112, 'test_recall': 0.5958549222797928, 'labeled_instances': 880, 'train_positive_rate': 0.08636363636363636, 'pool_positive_rate': 0.09498480243161095, 'iteration_time': 435.51166892051697}, {'test_loss': 0.1874283105134964, 'test_f1': 0.7942028985507247, 'test_prec': 0.9013157894736842, 'test_recall': 0.7098445595854922, 'labeled_instances': 920, 'train_positive_rate': 0.08804347826086957, 'pool_positive_rate': 0.09475497702909648, 'iteration_time': 417.9657938480377}, {'test_loss': 0.1910095363855362, 'test_f1': 0.7457627118644068, 'test_prec': 0.8198757763975155, 'test_recall': 0.6839378238341969, 'labeled_instances': 960, 'train_positive_rate': 0.08645833333333333, 'pool_positive_rate': 0.09510030864197531, 'iteration_time': 435.6039443016052}, {'test_loss': 0.16197887063026428, 'test_f1': 0.8022284122562673, 'test_prec': 0.8674698795180723, 'test_recall': 0.7461139896373057, 'labeled_instances': 1000, 'train_positive_rate': 0.086, 'pool_positive_rate': 0.0952566096423017, 'iteration_time': 439.8037078380585}, {'test_loss': 0.17153127491474152, 'test_f1': 0.8633879781420764, 'test_prec': 0.9132947976878613, 'test_recall': 0.8186528497409327, 'labeled_instances': 6144, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.09375, 'iteration_time': 760.6579089164734}]
New cross validation 3, for  <function deepmatcher_structured_walmart_amazon at 0x14cc376e1280>

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 120
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 200
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 6144
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
[{'test_loss': 0.31217679381370544, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.09368836291913216, 'iteration_time': 363.19202399253845}, {'test_loss': 0.2960827052593231, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 80, 'train_positive_rate': 0.0875, 'pool_positive_rate': 0.09383245382585752, 'iteration_time': 382.21762108802795}, {'test_loss': 0.30695852637290955, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 100, 'train_positive_rate': 0.08, 'pool_positive_rate': 0.09397749834546658, 'iteration_time': 379.6262056827545}, {'test_loss': 0.42168232798576355, 'test_f1': 0.08547008547008546, 'test_prec': 0.24390243902439024, 'test_recall': 0.05181347150259067, 'labeled_instances': 120, 'train_positive_rate': 0.09166666666666666, 'pool_positive_rate': 0.09379150066401062, 'iteration_time': 379.990576505661}, {'test_loss': 0.336553692817688, 'test_f1': 0.2549800796812749, 'test_prec': 0.5517241379310345, 'test_recall': 0.16580310880829016, 'labeled_instances': 140, 'train_positive_rate': 0.07857142857142857, 'pool_positive_rate': 0.0941039307128581, 'iteration_time': 380.9826159477234}, {'test_loss': 0.33793365955352783, 'test_f1': 0.1732283464566929, 'test_prec': 0.36065573770491804, 'test_recall': 0.11398963730569948, 'labeled_instances': 160, 'train_positive_rate': 0.08125, 'pool_positive_rate': 0.09408422459893048, 'iteration_time': 371.2630350589752}, {'test_loss': 0.319240540266037, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 180, 'train_positive_rate': 0.07777777777777778, 'pool_positive_rate': 0.09423205902079142, 'iteration_time': 379.03917694091797}, {'test_loss': 0.5089643597602844, 'test_f1': 0.0198019801980198, 'test_prec': 0.2222222222222222, 'test_recall': 0.010362694300518135, 'labeled_instances': 200, 'train_positive_rate': 0.08, 'pool_positive_rate': 0.09421265141318977, 'iteration_time': 379.6339867115021}, {'test_loss': 0.3075892925262451, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 240, 'train_positive_rate': 0.07083333333333333, 'pool_positive_rate': 0.09468157181571815, 'iteration_time': 415.11638879776}, {'test_loss': 0.4694508910179138, 'test_f1': 0.13274336283185842, 'test_prec': 0.45454545454545453, 'test_recall': 0.07772020725388601, 'labeled_instances': 280, 'train_positive_rate': 0.08214285714285714, 'pool_positive_rate': 0.09430422919508867, 'iteration_time': 434.00082302093506}, {'test_loss': 0.5809460282325745, 'test_f1': 0.10256410256410256, 'test_prec': 0.2926829268292683, 'test_recall': 0.06217616580310881, 'labeled_instances': 320, 'train_positive_rate': 0.078125, 'pool_positive_rate': 0.09460851648351648, 'iteration_time': 436.56757044792175}, {'test_loss': 0.47525718808174133, 'test_f1': 0.12244897959183673, 'test_prec': 0.28846153846153844, 'test_recall': 0.07772020725388601, 'labeled_instances': 360, 'train_positive_rate': 0.08333333333333333, 'pool_positive_rate': 0.09439834024896265, 'iteration_time': 439.1002826690674}, {'test_loss': 0.5762956142425537, 'test_f1': 0.112, 'test_prec': 0.24561403508771928, 'test_recall': 0.07253886010362694, 'labeled_instances': 400, 'train_positive_rate': 0.085, 'pool_positive_rate': 0.09435933147632312, 'iteration_time': 436.68193531036377}, {'test_loss': 0.19099438190460205, 'test_f1': 0.7295918367346937, 'test_prec': 0.7185929648241206, 'test_recall': 0.7409326424870466, 'labeled_instances': 440, 'train_positive_rate': 0.08409090909090909, 'pool_positive_rate': 0.09449509116409537, 'iteration_time': 439.01099944114685}, {'test_loss': 0.4226338267326355, 'test_f1': 0.046511627906976744, 'test_prec': 0.22727272727272727, 'test_recall': 0.025906735751295335, 'labeled_instances': 480, 'train_positive_rate': 0.08333333333333333, 'pool_positive_rate': 0.09463276836158192, 'iteration_time': 431.93757462501526}, {'test_loss': 0.27835389971733093, 'test_f1': 0.6190476190476191, 'test_prec': 0.7272727272727273, 'test_recall': 0.538860103626943, 'labeled_instances': 520, 'train_positive_rate': 0.08461538461538462, 'pool_positive_rate': 0.0945945945945946, 'iteration_time': 447.1895875930786}, {'test_loss': 0.2771158218383789, 'test_f1': 0.5408450704225352, 'test_prec': 0.5925925925925926, 'test_recall': 0.49740932642487046, 'labeled_instances': 560, 'train_positive_rate': 0.08571428571428572, 'pool_positive_rate': 0.09455587392550144, 'iteration_time': 444.0800426006317}, {'test_loss': 0.6703532934188843, 'test_f1': 0.17793594306049823, 'test_prec': 0.2840909090909091, 'test_recall': 0.12953367875647667, 'labeled_instances': 600, 'train_positive_rate': 0.085, 'pool_positive_rate': 0.0946969696969697, 'iteration_time': 459.3279330730438}, {'test_loss': 0.4780309796333313, 'test_f1': 0.2804428044280443, 'test_prec': 0.48717948717948717, 'test_recall': 0.19689119170984457, 'labeled_instances': 640, 'train_positive_rate': 0.084375, 'pool_positive_rate': 0.09484011627906977, 'iteration_time': 455.232129573822}, {'test_loss': 0.20152759552001953, 'test_f1': 0.7610619469026548, 'test_prec': 0.8835616438356164, 'test_recall': 0.6683937823834197, 'labeled_instances': 680, 'train_positive_rate': 0.0838235294117647, 'pool_positive_rate': 0.09498535871156662, 'iteration_time': 461.93109130859375}, {'test_loss': 0.23257292807102203, 'test_f1': 0.6727272727272727, 'test_prec': 0.8102189781021898, 'test_recall': 0.5751295336787565, 'labeled_instances': 720, 'train_positive_rate': 0.08333333333333333, 'pool_positive_rate': 0.09513274336283185, 'iteration_time': 461.03955483436584}, {'test_loss': 0.1996546983718872, 'test_f1': 0.6863270777479893, 'test_prec': 0.7111111111111111, 'test_recall': 0.6632124352331606, 'labeled_instances': 760, 'train_positive_rate': 0.08421052631578947, 'pool_positive_rate': 0.0950965824665676, 'iteration_time': 474.41118359565735}, {'test_loss': 0.2784932553768158, 'test_f1': 0.6306818181818182, 'test_prec': 0.6981132075471698, 'test_recall': 0.5751295336787565, 'labeled_instances': 800, 'train_positive_rate': 0.085, 'pool_positive_rate': 0.09505988023952096, 'iteration_time': 463.3879578113556}, {'test_loss': 0.18304912745952606, 'test_f1': 0.8184281842818427, 'test_prec': 0.8579545454545454, 'test_recall': 0.7823834196891192, 'labeled_instances': 840, 'train_positive_rate': 0.08452380952380953, 'pool_positive_rate': 0.09521116138763197, 'iteration_time': 466.5410854816437}, {'test_loss': 0.2897496223449707, 'test_f1': 0.6233766233766233, 'test_prec': 0.8347826086956521, 'test_recall': 0.49740932642487046, 'labeled_instances': 880, 'train_positive_rate': 0.08295454545454546, 'pool_positive_rate': 0.0955547112462006, 'iteration_time': 470.99388575553894}, {'test_loss': 0.17301605641841888, 'test_f1': 0.8188976377952756, 'test_prec': 0.8297872340425532, 'test_recall': 0.8082901554404145, 'labeled_instances': 920, 'train_positive_rate': 0.08586956521739131, 'pool_positive_rate': 0.09513782542113323, 'iteration_time': 478.21616673469543}, {'test_loss': 0.1929670125246048, 'test_f1': 0.8152173913043478, 'test_prec': 0.8571428571428571, 'test_recall': 0.7772020725388601, 'labeled_instances': 960, 'train_positive_rate': 0.08541666666666667, 'pool_positive_rate': 0.09529320987654322, 'iteration_time': 487.9484348297119}, {'test_loss': 0.2854492664337158, 'test_f1': 0.6666666666666666, 'test_prec': 0.725609756097561, 'test_recall': 0.616580310880829, 'labeled_instances': 1000, 'train_positive_rate': 0.086, 'pool_positive_rate': 0.0952566096423017, 'iteration_time': 488.19111156463623}, {'test_loss': 0.17451351881027222, 'test_f1': 0.8624338624338624, 'test_prec': 0.8810810810810811, 'test_recall': 0.844559585492228, 'labeled_instances': 6144, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.09375, 'iteration_time': 841.7906265258789}]
New cross validation 4, for  <function deepmatcher_structured_walmart_amazon at 0x14cc376e1280>

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 200
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 560
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 880
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 6144
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
[{'test_loss': 0.4587256908416748, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.016666666666666666, 'pool_positive_rate': 0.09451019066403682, 'iteration_time': 416.63089179992676}, {'test_loss': 0.4598228931427002, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 80, 'train_positive_rate': 0.0125, 'pool_positive_rate': 0.09482189973614776, 'iteration_time': 412.98332023620605}, {'test_loss': 0.4004785120487213, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 100, 'train_positive_rate': 0.02, 'pool_positive_rate': 0.09497021839841165, 'iteration_time': 409.5722625255585}, {'test_loss': 0.46712902188301086, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 120, 'train_positive_rate': 0.03333333333333333, 'pool_positive_rate': 0.0949535192563081, 'iteration_time': 411.7341811656952}, {'test_loss': 0.5115741491317749, 'test_f1': 0.01, 'test_prec': 0.14285714285714285, 'test_recall': 0.0051813471502590676, 'labeled_instances': 140, 'train_positive_rate': 0.03571428571428571, 'pool_positive_rate': 0.09510326449033978, 'iteration_time': 405.48633456230164}, {'test_loss': 0.5581979155540466, 'test_f1': 0.07373271889400922, 'test_prec': 0.3333333333333333, 'test_recall': 0.04145077720207254, 'labeled_instances': 160, 'train_positive_rate': 0.0375, 'pool_positive_rate': 0.09525401069518717, 'iteration_time': 428.9298722743988}, {'test_loss': 0.32865771651268005, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 180, 'train_positive_rate': 0.044444444444444446, 'pool_positive_rate': 0.09523809523809523, 'iteration_time': 417.1942775249481}, {'test_loss': 0.5793329477310181, 'test_f1': 0.01932367149758454, 'test_prec': 0.14285714285714285, 'test_recall': 0.010362694300518135, 'labeled_instances': 200, 'train_positive_rate': 0.05, 'pool_positive_rate': 0.09522207267833109, 'iteration_time': 426.1952974796295}, {'test_loss': 0.49479931592941284, 'test_f1': 0.045248868778280535, 'test_prec': 0.17857142857142858, 'test_recall': 0.025906735751295335, 'labeled_instances': 240, 'train_positive_rate': 0.058333333333333334, 'pool_positive_rate': 0.09518970189701897, 'iteration_time': 419.23843455314636}, {'test_loss': 0.41189607977867126, 'test_f1': 0.345679012345679, 'test_prec': 0.84, 'test_recall': 0.21761658031088082, 'labeled_instances': 280, 'train_positive_rate': 0.06785714285714285, 'pool_positive_rate': 0.09498635743519782, 'iteration_time': 434.57925248146057}, {'test_loss': 0.44605886936187744, 'test_f1': 0.27419354838709675, 'test_prec': 0.6181818181818182, 'test_recall': 0.17616580310880828, 'labeled_instances': 320, 'train_positive_rate': 0.06875, 'pool_positive_rate': 0.09512362637362637, 'iteration_time': 431.32023429870605}, {'test_loss': 0.3631346821784973, 'test_f1': 0.3007518796992481, 'test_prec': 0.547945205479452, 'test_recall': 0.20725388601036268, 'labeled_instances': 360, 'train_positive_rate': 0.06111111111111111, 'pool_positive_rate': 0.09578146611341633, 'iteration_time': 438.05155754089355}, {'test_loss': 0.4671503007411957, 'test_f1': 0.03571428571428572, 'test_prec': 0.12903225806451613, 'test_recall': 0.02072538860103627, 'labeled_instances': 400, 'train_positive_rate': 0.0575, 'pool_positive_rate': 0.09627437325905293, 'iteration_time': 434.2365732192993}, {'test_loss': 0.27194085717201233, 'test_f1': 0.6188925081433224, 'test_prec': 0.8333333333333334, 'test_recall': 0.49222797927461137, 'labeled_instances': 440, 'train_positive_rate': 0.06363636363636363, 'pool_positive_rate': 0.09607293127629733, 'iteration_time': 433.44514083862305}, {'test_loss': 0.22760885953903198, 'test_f1': 0.7009646302250804, 'test_prec': 0.923728813559322, 'test_recall': 0.5647668393782384, 'labeled_instances': 480, 'train_positive_rate': 0.07291666666666667, 'pool_positive_rate': 0.09551553672316385, 'iteration_time': 460.94405698776245}, {'test_loss': 0.2848072648048401, 'test_f1': 0.5460992907801419, 'test_prec': 0.8651685393258427, 'test_recall': 0.39896373056994816, 'labeled_instances': 520, 'train_positive_rate': 0.07307692307692308, 'pool_positive_rate': 0.09566145092460882, 'iteration_time': 452.8888084888458}, {'test_loss': 0.2726100981235504, 'test_f1': 0.5517241379310345, 'test_prec': 0.6984126984126984, 'test_recall': 0.45595854922279794, 'labeled_instances': 560, 'train_positive_rate': 0.07857142857142857, 'pool_positive_rate': 0.09527220630372493, 'iteration_time': 451.97371554374695}, {'test_loss': 0.2040923684835434, 'test_f1': 0.7234042553191489, 'test_prec': 0.875, 'test_recall': 0.616580310880829, 'labeled_instances': 600, 'train_positive_rate': 0.08, 'pool_positive_rate': 0.09523809523809523, 'iteration_time': 455.4223198890686}, {'test_loss': 0.19655869901180267, 'test_f1': 0.780058651026393, 'test_prec': 0.8986486486486487, 'test_recall': 0.689119170984456, 'labeled_instances': 640, 'train_positive_rate': 0.0859375, 'pool_positive_rate': 0.09465843023255814, 'iteration_time': 463.48639369010925}, {'test_loss': 0.2307988554239273, 'test_f1': 0.7549295774647888, 'test_prec': 0.8271604938271605, 'test_recall': 0.694300518134715, 'labeled_instances': 680, 'train_positive_rate': 0.08529411764705883, 'pool_positive_rate': 0.09480234260614934, 'iteration_time': 453.14176630973816}, {'test_loss': 0.1879972219467163, 'test_f1': 0.8028846153846153, 'test_prec': 0.7488789237668162, 'test_recall': 0.8652849740932642, 'labeled_instances': 720, 'train_positive_rate': 0.08472222222222223, 'pool_positive_rate': 0.09494837758112094, 'iteration_time': 472.70183873176575}, {'test_loss': 0.16649699211120605, 'test_f1': 0.8238213399503722, 'test_prec': 0.7904761904761904, 'test_recall': 0.8601036269430051, 'labeled_instances': 760, 'train_positive_rate': 0.08421052631578947, 'pool_positive_rate': 0.0950965824665676, 'iteration_time': 457.01993107795715}, {'test_loss': 0.2659643888473511, 'test_f1': 0.7427184466019418, 'test_prec': 0.6986301369863014, 'test_recall': 0.7927461139896373, 'labeled_instances': 800, 'train_positive_rate': 0.08375, 'pool_positive_rate': 0.09524700598802395, 'iteration_time': 456.70475816726685}, {'test_loss': 0.46669936180114746, 'test_f1': 0.144, 'test_prec': 0.3157894736842105, 'test_recall': 0.09326424870466321, 'labeled_instances': 840, 'train_positive_rate': 0.08452380952380953, 'pool_positive_rate': 0.09521116138763197, 'iteration_time': 471.0533833503723}, {'test_loss': 0.15812420845031738, 'test_f1': 0.8044692737430168, 'test_prec': 0.8727272727272727, 'test_recall': 0.7461139896373057, 'labeled_instances': 880, 'train_positive_rate': 0.08409090909090909, 'pool_positive_rate': 0.09536474164133739, 'iteration_time': 487.7334973812103}, {'test_loss': 0.21863669157028198, 'test_f1': 0.7837837837837839, 'test_prec': 0.8192090395480226, 'test_recall': 0.7512953367875648, 'labeled_instances': 920, 'train_positive_rate': 0.08478260869565217, 'pool_positive_rate': 0.09532924961715161, 'iteration_time': 494.72299695014954}, {'test_loss': 0.16815334558486938, 'test_f1': 0.8045977011494253, 'test_prec': 0.9032258064516129, 'test_recall': 0.7253886010362695, 'labeled_instances': 960, 'train_positive_rate': 0.08333333333333333, 'pool_positive_rate': 0.09567901234567901, 'iteration_time': 481.1708414554596}, {'test_loss': 0.1890026181936264, 'test_f1': 0.7588075880758809, 'test_prec': 0.7954545454545454, 'test_recall': 0.7253886010362695, 'labeled_instances': 1000, 'train_positive_rate': 0.084, 'pool_positive_rate': 0.09564541213063764, 'iteration_time': 502.70642161369324}, {'test_loss': 0.15306583046913147, 'test_f1': 0.8398950131233596, 'test_prec': 0.851063829787234, 'test_recall': 0.8290155440414507, 'labeled_instances': 6144, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.09375, 'iteration_time': 851.2128405570984}]
Could not create dir out, File exists




    ###########  New Dataset: <function deepmatcher_textual_abt_buy at 0x14cc376e15e0>
New cross validation 0, for  <function deepmatcher_textual_abt_buy at 0x14cc376e15e0>

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 120
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 200
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 440
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 480
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 5743
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
[{'test_loss': 0.34740084409713745, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10733767376385711, 'iteration_time': 440.37699270248413}, {'test_loss': 0.3452213704586029, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 80, 'train_positive_rate': 0.125, 'pool_positive_rate': 0.10701041850609218, 'iteration_time': 447.0194215774536}, {'test_loss': 0.38278689980506897, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 100, 'train_positive_rate': 0.11, 'pool_positive_rate': 0.10721247563352826, 'iteration_time': 450.4678692817688}, {'test_loss': 0.48157691955566406, 'test_f1': 0.12903225806451613, 'test_prec': 0.2465753424657534, 'test_recall': 0.08737864077669903, 'labeled_instances': 120, 'train_positive_rate': 0.10833333333333334, 'pool_positive_rate': 0.10723812911257335, 'iteration_time': 438.69652485847473}, {'test_loss': 0.4041683077812195, 'test_f1': 0.21750663129973474, 'test_prec': 0.23976608187134502, 'test_recall': 0.19902912621359223, 'labeled_instances': 140, 'train_positive_rate': 0.10714285714285714, 'pool_positive_rate': 0.10726396573264323, 'iteration_time': 445.5878121852875}, {'test_loss': 0.38933390378952026, 'test_f1': 0.15483870967741936, 'test_prec': 0.23076923076923078, 'test_recall': 0.11650485436893204, 'labeled_instances': 160, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10746910263299302, 'iteration_time': 440.67271614074707}, {'test_loss': 0.5293482542037964, 'test_f1': 0.1388888888888889, 'test_prec': 0.24390243902439024, 'test_recall': 0.0970873786407767, 'labeled_instances': 180, 'train_positive_rate': 0.1111111111111111, 'pool_positive_rate': 0.1071364371741866, 'iteration_time': 444.1532998085022}, {'test_loss': 0.4223030209541321, 'test_f1': 0.2618181818181818, 'test_prec': 0.5217391304347826, 'test_recall': 0.17475728155339806, 'labeled_instances': 200, 'train_positive_rate': 0.115, 'pool_positive_rate': 0.1069817788201335, 'iteration_time': 452.72900891304016}, {'test_loss': 0.4006039500236511, 'test_f1': 0.08979591836734695, 'test_prec': 0.28205128205128205, 'test_recall': 0.05339805825242718, 'labeled_instances': 240, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10757768489914592, 'iteration_time': 470.8851251602173}, {'test_loss': 0.2669878602027893, 'test_f1': 0.67012987012987, 'test_prec': 0.7206703910614525, 'test_recall': 0.6262135922330098, 'labeled_instances': 280, 'train_positive_rate': 0.11071428571428571, 'pool_positive_rate': 0.1070840197693575, 'iteration_time': 469.3118431568146}, {'test_loss': 0.17644380033016205, 'test_f1': 0.7567567567567568, 'test_prec': 0.7661691542288557, 'test_recall': 0.7475728155339806, 'labeled_instances': 320, 'train_positive_rate': 0.1125, 'pool_positive_rate': 0.10695187165775401, 'iteration_time': 463.48135209083557}, {'test_loss': 0.24706541001796722, 'test_f1': 0.6855524079320113, 'test_prec': 0.8231292517006803, 'test_recall': 0.587378640776699, 'labeled_instances': 360, 'train_positive_rate': 0.11388888888888889, 'pool_positive_rate': 0.10681775961359836, 'iteration_time': 474.08269810676575}, {'test_loss': 0.23470936715602875, 'test_f1': 0.636085626911315, 'test_prec': 0.859504132231405, 'test_recall': 0.5048543689320388, 'labeled_instances': 400, 'train_positive_rate': 0.1075, 'pool_positive_rate': 0.10724312184166199, 'iteration_time': 490.99294686317444}, {'test_loss': 0.2500554621219635, 'test_f1': 0.7082294264339152, 'test_prec': 0.7282051282051282, 'test_recall': 0.6893203883495146, 'labeled_instances': 440, 'train_positive_rate': 0.10909090909090909, 'pool_positive_rate': 0.10710918348104846, 'iteration_time': 480.96262431144714}, {'test_loss': 0.22735948860645294, 'test_f1': 0.7419354838709677, 'test_prec': 0.8313253012048193, 'test_recall': 0.6699029126213593, 'labeled_instances': 480, 'train_positive_rate': 0.10208333333333333, 'pool_positive_rate': 0.1077332319969599, 'iteration_time': 486.0014419555664}, {'test_loss': 0.21678298711776733, 'test_f1': 0.7621483375959078, 'test_prec': 0.8054054054054054, 'test_recall': 0.7233009708737864, 'labeled_instances': 520, 'train_positive_rate': 0.1076923076923077, 'pool_positive_rate': 0.10721807390388666, 'iteration_time': 479.8586781024933}, {'test_loss': 0.22677293419837952, 'test_f1': 0.7649999999999999, 'test_prec': 0.788659793814433, 'test_recall': 0.7427184466019418, 'labeled_instances': 560, 'train_positive_rate': 0.1125, 'pool_positive_rate': 0.10669496430638627, 'iteration_time': 487.0818610191345}, {'test_loss': 0.2339066118001938, 'test_f1': 0.7551020408163266, 'test_prec': 0.7956989247311828, 'test_recall': 0.7184466019417476, 'labeled_instances': 600, 'train_positive_rate': 0.11, 'pool_positive_rate': 0.10694147384794866, 'iteration_time': 510.0470883846283}, {'test_loss': 0.2634631395339966, 'test_f1': 0.6869806094182825, 'test_prec': 0.8, 'test_recall': 0.6019417475728155, 'labeled_instances': 640, 'train_positive_rate': 0.109375, 'pool_positive_rate': 0.10699588477366255, 'iteration_time': 496.7021508216858}, {'test_loss': 0.33619266748428345, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 680, 'train_positive_rate': 0.11029411764705882, 'pool_positive_rate': 0.10685364408453486, 'iteration_time': 501.85546612739563}, {'test_loss': 0.24187618494033813, 'test_f1': 0.7726161369193154, 'test_prec': 0.7783251231527094, 'test_recall': 0.7669902912621359, 'labeled_instances': 720, 'train_positive_rate': 0.10972222222222222, 'pool_positive_rate': 0.10690822217798128, 'iteration_time': 499.47526812553406}, {'test_loss': 0.2684935927391052, 'test_f1': 0.712468193384224, 'test_prec': 0.7486631016042781, 'test_recall': 0.6796116504854369, 'labeled_instances': 760, 'train_positive_rate': 0.11315789473684211, 'pool_positive_rate': 0.10636162954043749, 'iteration_time': 506.869033575058}, {'test_loss': 0.23494288325309753, 'test_f1': 0.7796610169491525, 'test_prec': 0.7777777777777778, 'test_recall': 0.7815533980582524, 'labeled_instances': 800, 'train_positive_rate': 0.11625, 'pool_positive_rate': 0.10580619057252681, 'iteration_time': 510.11810064315796}, {'test_loss': 0.18900299072265625, 'test_f1': 0.7807486631016042, 'test_prec': 0.8690476190476191, 'test_recall': 0.7087378640776699, 'labeled_instances': 840, 'train_positive_rate': 0.11666666666666667, 'pool_positive_rate': 0.10564960228431572, 'iteration_time': 527.2465631961823}, {'test_loss': 0.18480178713798523, 'test_f1': 0.7999999999999999, 'test_prec': 0.8247422680412371, 'test_recall': 0.7766990291262136, 'labeled_instances': 880, 'train_positive_rate': 0.1159090909090909, 'pool_positive_rate': 0.10569607238330249, 'iteration_time': 523.1533815860748}, {'test_loss': 0.158196359872818, 'test_f1': 0.7919799498746868, 'test_prec': 0.8186528497409327, 'test_recall': 0.7669902912621359, 'labeled_instances': 920, 'train_positive_rate': 0.11847826086956521, 'pool_positive_rate': 0.10512129380053908, 'iteration_time': 539.5356502532959}, {'test_loss': 0.19420559704303741, 'test_f1': 0.7807228915662651, 'test_prec': 0.7751196172248804, 'test_recall': 0.7864077669902912, 'labeled_instances': 960, 'train_positive_rate': 0.11770833333333333, 'pool_positive_rate': 0.10516412293539619, 'iteration_time': 534.8994998931885}, {'test_loss': 0.1502135694026947, 'test_f1': 0.8195876288659795, 'test_prec': 0.8736263736263736, 'test_recall': 0.7718446601941747, 'labeled_instances': 1000, 'train_positive_rate': 0.115, 'pool_positive_rate': 0.105629348513599, 'iteration_time': 540.0328092575073}, {'test_loss': 0.1452794075012207, 'test_f1': 0.905940594059406, 'test_prec': 0.9242424242424242, 'test_recall': 0.8883495145631068, 'labeled_instances': 5743, 'train_positive_rate': 0.10726101340762667, 'pool_positive_rate': 0.10726101340762667, 'iteration_time': 911.7126693725586}]
New cross validation 1, for  <function deepmatcher_textual_abt_buy at 0x14cc376e15e0>

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 120
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 160
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 200
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 240
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 320
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 520
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 1000
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 5743
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
[{'test_loss': 0.4015655517578125, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.11666666666666667, 'pool_positive_rate': 0.10716171036424424, 'iteration_time': 430.8098335266113}, {'test_loss': 0.3757624924182892, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 80, 'train_positive_rate': 0.0875, 'pool_positive_rate': 0.10754017305315204, 'iteration_time': 458.09773564338684}, {'test_loss': 0.33286574482917786, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 100, 'train_positive_rate': 0.11, 'pool_positive_rate': 0.10721247563352826, 'iteration_time': 449.0002245903015}, {'test_loss': 0.3364936113357544, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 120, 'train_positive_rate': 0.10833333333333334, 'pool_positive_rate': 0.10723812911257335, 'iteration_time': 444.7676043510437}, {'test_loss': 0.4398101568222046, 'test_f1': 0.3351351351351351, 'test_prec': 0.3780487804878049, 'test_recall': 0.30097087378640774, 'labeled_instances': 140, 'train_positive_rate': 0.11428571428571428, 'pool_positive_rate': 0.10708548991611637, 'iteration_time': 442.963520526886}, {'test_loss': 0.3316039443016052, 'test_f1': 0.27586206896551724, 'test_prec': 0.6545454545454545, 'test_recall': 0.17475728155339806, 'labeled_instances': 160, 'train_positive_rate': 0.125, 'pool_positive_rate': 0.10675264194877306, 'iteration_time': 451.06999349594116}, {'test_loss': 0.3275811970233917, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 180, 'train_positive_rate': 0.1111111111111111, 'pool_positive_rate': 0.1071364371741866, 'iteration_time': 457.36443424224854}, {'test_loss': 0.48224011063575745, 'test_f1': 0.3506849315068493, 'test_prec': 0.4025157232704403, 'test_recall': 0.3106796116504854, 'labeled_instances': 200, 'train_positive_rate': 0.105, 'pool_positive_rate': 0.10734259426303445, 'iteration_time': 465.29308795928955}, {'test_loss': 0.4830491244792938, 'test_f1': 0.3571428571428571, 'test_prec': 0.46153846153846156, 'test_recall': 0.2912621359223301, 'labeled_instances': 240, 'train_positive_rate': 0.10833333333333334, 'pool_positive_rate': 0.10721424677448664, 'iteration_time': 480.32978653907776}, {'test_loss': 0.31521281599998474, 'test_f1': 0.6380697050938338, 'test_prec': 0.7125748502994012, 'test_recall': 0.5776699029126213, 'labeled_instances': 280, 'train_positive_rate': 0.09642857142857143, 'pool_positive_rate': 0.10781621819513088, 'iteration_time': 467.4246711730957}, {'test_loss': 0.3149612247943878, 'test_f1': 0.5597269624573379, 'test_prec': 0.9425287356321839, 'test_recall': 0.39805825242718446, 'labeled_instances': 320, 'train_positive_rate': 0.096875, 'pool_positive_rate': 0.10787387055135533, 'iteration_time': 479.1734161376953}, {'test_loss': 0.19501791894435883, 'test_f1': 0.7874015748031495, 'test_prec': 0.8571428571428571, 'test_recall': 0.7281553398058253, 'labeled_instances': 360, 'train_positive_rate': 0.09722222222222222, 'pool_positive_rate': 0.10793237971391417, 'iteration_time': 474.60682010650635}, {'test_loss': 0.35436150431632996, 'test_f1': 0.5406976744186047, 'test_prec': 0.6739130434782609, 'test_recall': 0.45145631067961167, 'labeled_instances': 400, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10780460415496912, 'iteration_time': 476.7982542514801}, {'test_loss': 0.2759486734867096, 'test_f1': 0.62004662004662, 'test_prec': 0.5964125560538116, 'test_recall': 0.6456310679611651, 'labeled_instances': 440, 'train_positive_rate': 0.10227272727272728, 'pool_positive_rate': 0.10767490099943429, 'iteration_time': 504.1870720386505}, {'test_loss': 0.21191361546516418, 'test_f1': 0.7526881720430108, 'test_prec': 0.8433734939759037, 'test_recall': 0.6796116504854369, 'labeled_instances': 480, 'train_positive_rate': 0.09791666666666667, 'pool_positive_rate': 0.10811324339730193, 'iteration_time': 494.0703115463257}, {'test_loss': 0.1420000046491623, 'test_f1': 0.7525252525252526, 'test_prec': 0.7842105263157895, 'test_recall': 0.7233009708737864, 'labeled_instances': 520, 'train_positive_rate': 0.09807692307692308, 'pool_positive_rate': 0.10817537813517136, 'iteration_time': 486.8332588672638}, {'test_loss': 0.24989649653434753, 'test_f1': 0.6766467065868264, 'test_prec': 0.8828125, 'test_recall': 0.5485436893203883, 'labeled_instances': 560, 'train_positive_rate': 0.09821428571428571, 'pool_positive_rate': 0.10823847192745514, 'iteration_time': 478.77944827079773}, {'test_loss': 0.1935461163520813, 'test_f1': 0.7696476964769647, 'test_prec': 0.8711656441717791, 'test_recall': 0.6893203883495146, 'labeled_instances': 600, 'train_positive_rate': 0.09333333333333334, 'pool_positive_rate': 0.10888586428154773, 'iteration_time': 483.8180058002472}, {'test_loss': 0.20028936862945557, 'test_f1': 0.7049180327868854, 'test_prec': 0.80625, 'test_recall': 0.6262135922330098, 'labeled_instances': 640, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.10895551636292378, 'iteration_time': 485.3925337791443}, {'test_loss': 0.18480075895786285, 'test_f1': 0.8033707865168539, 'test_prec': 0.9533333333333334, 'test_recall': 0.6941747572815534, 'labeled_instances': 680, 'train_positive_rate': 0.09558823529411764, 'pool_positive_rate': 0.10882875765356508, 'iteration_time': 524.2015860080719}, {'test_loss': 0.18034665286540985, 'test_f1': 0.7927461139896372, 'test_prec': 0.85, 'test_recall': 0.7427184466019418, 'labeled_instances': 720, 'train_positive_rate': 0.10138888888888889, 'pool_positive_rate': 0.10810272745371292, 'iteration_time': 509.3186950683594}, {'test_loss': 0.1692298948764801, 'test_f1': 0.7932692307692307, 'test_prec': 0.7857142857142857, 'test_recall': 0.8009708737864077, 'labeled_instances': 760, 'train_positive_rate': 0.10394736842105264, 'pool_positive_rate': 0.10776640577965081, 'iteration_time': 538.7976357936859}, {'test_loss': 0.15617252886295319, 'test_f1': 0.7819148936170214, 'test_prec': 0.8647058823529412, 'test_recall': 0.7135922330097088, 'labeled_instances': 800, 'train_positive_rate': 0.10375, 'pool_positive_rate': 0.10782925348978353, 'iteration_time': 531.9623379707336}, {'test_loss': 0.2643762230873108, 'test_f1': 0.7142857142857142, 'test_prec': 0.7009345794392523, 'test_recall': 0.7281553398058253, 'labeled_instances': 840, 'train_positive_rate': 0.10357142857142858, 'pool_positive_rate': 0.10789312665714869, 'iteration_time': 533.9310457706451}, {'test_loss': 0.16211669147014618, 'test_f1': 0.7775061124694376, 'test_prec': 0.7832512315270936, 'test_recall': 0.7718446601941747, 'labeled_instances': 880, 'train_positive_rate': 0.10340909090909091, 'pool_positive_rate': 0.107958050586058, 'iteration_time': 527.9219181537628}, {'test_loss': 0.17816263437271118, 'test_f1': 0.8029925187032417, 'test_prec': 0.8256410256410256, 'test_recall': 0.7815533980582524, 'labeled_instances': 920, 'train_positive_rate': 0.10108695652173913, 'pool_positive_rate': 0.10843873108024052, 'iteration_time': 541.3599066734314}, {'test_loss': 0.1833023875951767, 'test_f1': 0.8232323232323232, 'test_prec': 0.8578947368421053, 'test_recall': 0.7912621359223301, 'labeled_instances': 960, 'train_positive_rate': 0.10208333333333333, 'pool_positive_rate': 0.10830022998118335, 'iteration_time': 546.0129442214966}, {'test_loss': 0.15701346099376678, 'test_f1': 0.8188585607940446, 'test_prec': 0.8375634517766497, 'test_recall': 0.8009708737864077, 'labeled_instances': 1000, 'train_positive_rate': 0.101, 'pool_positive_rate': 0.10858106683533629, 'iteration_time': 569.9142107963562}, {'test_loss': 0.1057564988732338, 'test_f1': 0.9121951219512194, 'test_prec': 0.9166666666666666, 'test_recall': 0.9077669902912622, 'labeled_instances': 5743, 'train_positive_rate': 0.10726101340762667, 'pool_positive_rate': 0.10726101340762667, 'iteration_time': 961.9230914115906}]
New cross validation 2, for  <function deepmatcher_textual_abt_buy at 0x14cc376e15e0>

Test : 60
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 180
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 200
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 600
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 880
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 920
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 5743
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
[{'test_loss': 0.3444758355617523, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.08333333333333333, 'pool_positive_rate': 0.10751363716347, 'iteration_time': 467.57873821258545}, {'test_loss': 0.3639969825744629, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 80, 'train_positive_rate': 0.075, 'pool_positive_rate': 0.107716757902172, 'iteration_time': 463.7302134037018}, {'test_loss': 0.44964826107025146, 'test_f1': 0.052401746724890834, 'test_prec': 0.2608695652173913, 'test_recall': 0.02912621359223301, 'labeled_instances': 100, 'train_positive_rate': 0.09, 'pool_positive_rate': 0.10756689704058126, 'iteration_time': 464.9917299747467}, {'test_loss': 0.2782019078731537, 'test_f1': 0.4786885245901639, 'test_prec': 0.7373737373737373, 'test_recall': 0.35436893203883496, 'labeled_instances': 120, 'train_positive_rate': 0.075, 'pool_positive_rate': 0.1079494931531211, 'iteration_time': 467.96136808395386}, {'test_loss': 0.34817516803741455, 'test_f1': 0.1434977578475336, 'test_prec': 0.9411764705882353, 'test_recall': 0.07766990291262135, 'labeled_instances': 140, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10744244154917008, 'iteration_time': 458.46298480033875}, {'test_loss': 0.3105553388595581, 'test_f1': 0.5268817204301075, 'test_prec': 0.5903614457831325, 'test_recall': 0.47572815533980584, 'labeled_instances': 160, 'train_positive_rate': 0.10625, 'pool_positive_rate': 0.10728998746193803, 'iteration_time': 467.92582750320435}, {'test_loss': 0.3698071837425232, 'test_f1': 0.4522968197879858, 'test_prec': 0.8311688311688312, 'test_recall': 0.3106796116504854, 'labeled_instances': 180, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10749595541973755, 'iteration_time': 476.85149598121643}, {'test_loss': 0.27929461002349854, 'test_f1': 0.5770491803278688, 'test_prec': 0.8888888888888888, 'test_recall': 0.42718446601941745, 'labeled_instances': 200, 'train_positive_rate': 0.09, 'pool_positive_rate': 0.1078838174273859, 'iteration_time': 487.9110279083252}, {'test_loss': 0.43180033564567566, 'test_f1': 0.11382113821138212, 'test_prec': 0.35, 'test_recall': 0.06796116504854369, 'labeled_instances': 240, 'train_positive_rate': 0.09166666666666666, 'pool_positive_rate': 0.1079411230238052, 'iteration_time': 475.7989909648895}, {'test_loss': 0.3942481577396393, 'test_f1': 0.26229508196721313, 'test_prec': 0.40404040404040403, 'test_recall': 0.1941747572815534, 'labeled_instances': 280, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10763316858868753, 'iteration_time': 505.8197605609894}, {'test_loss': 0.43552732467651367, 'test_f1': 0.3656509695290859, 'test_prec': 0.4258064516129032, 'test_recall': 0.32038834951456313, 'labeled_instances': 320, 'train_positive_rate': 0.096875, 'pool_positive_rate': 0.10787387055135533, 'iteration_time': 506.3189687728882}, {'test_loss': 0.4453050494194031, 'test_f1': 0.29113924050632917, 'test_prec': 0.41818181818181815, 'test_recall': 0.22330097087378642, 'labeled_instances': 360, 'train_positive_rate': 0.10555555555555556, 'pool_positive_rate': 0.10737506966375628, 'iteration_time': 499.02883219718933}, {'test_loss': 0.450710266828537, 'test_f1': 0.20408163265306123, 'test_prec': 0.25547445255474455, 'test_recall': 0.16990291262135923, 'labeled_instances': 400, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10780460415496912, 'iteration_time': 496.9882252216339}, {'test_loss': 0.15173116326332092, 'test_f1': 0.7737226277372263, 'test_prec': 0.775609756097561, 'test_recall': 0.7718446601941747, 'labeled_instances': 440, 'train_positive_rate': 0.09545454545454546, 'pool_positive_rate': 0.1082406185178201, 'iteration_time': 498.7689952850342}, {'test_loss': 0.33190277218818665, 'test_f1': 0.6184971098265896, 'test_prec': 0.7642857142857142, 'test_recall': 0.5194174757281553, 'labeled_instances': 480, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.10849325479764393, 'iteration_time': 510.8549470901489}, {'test_loss': 0.25442907214164734, 'test_f1': 0.5562130177514794, 'test_prec': 0.7121212121212122, 'test_recall': 0.4563106796116505, 'labeled_instances': 520, 'train_positive_rate': 0.09038461538461538, 'pool_positive_rate': 0.10894122152019912, 'iteration_time': 513.2607090473175}, {'test_loss': 0.18072675168514252, 'test_f1': 0.832080200501253, 'test_prec': 0.8601036269430051, 'test_recall': 0.8058252427184466, 'labeled_instances': 560, 'train_positive_rate': 0.09821428571428571, 'pool_positive_rate': 0.10823847192745514, 'iteration_time': 522.4756517410278}, {'test_loss': 0.161484494805336, 'test_f1': 0.8396946564885497, 'test_prec': 0.8823529411764706, 'test_recall': 0.8009708737864077, 'labeled_instances': 600, 'train_positive_rate': 0.105, 'pool_positive_rate': 0.10752479097802839, 'iteration_time': 524.1588778495789}, {'test_loss': 0.23804521560668945, 'test_f1': 0.7927461139896372, 'test_prec': 0.85, 'test_recall': 0.7427184466019418, 'labeled_instances': 640, 'train_positive_rate': 0.103125, 'pool_positive_rate': 0.10777973740936704, 'iteration_time': 527.618533372879}, {'test_loss': 0.1853792816400528, 'test_f1': 0.8280871670702179, 'test_prec': 0.8260869565217391, 'test_recall': 0.8300970873786407, 'labeled_instances': 680, 'train_positive_rate': 0.10294117647058823, 'pool_positive_rate': 0.10784120086904997, 'iteration_time': 516.2207810878754}, {'test_loss': 0.1740936040878296, 'test_f1': 0.8159203980099503, 'test_prec': 0.8367346938775511, 'test_recall': 0.7961165048543689, 'labeled_instances': 720, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10830181166633486, 'iteration_time': 512.5526080131531}, {'test_loss': 0.18120385706424713, 'test_f1': 0.8135593220338982, 'test_prec': 0.8115942028985508, 'test_recall': 0.8155339805825242, 'labeled_instances': 760, 'train_positive_rate': 0.09605263157894736, 'pool_positive_rate': 0.10897049969897651, 'iteration_time': 524.4146502017975}, {'test_loss': 0.23172026872634888, 'test_f1': 0.7927461139896372, 'test_prec': 0.85, 'test_recall': 0.7427184466019418, 'labeled_instances': 800, 'train_positive_rate': 0.09875, 'pool_positive_rate': 0.10863847865668623, 'iteration_time': 532.3739173412323}, {'test_loss': 0.22365587949752808, 'test_f1': 0.797843665768194, 'test_prec': 0.896969696969697, 'test_recall': 0.7184466019417476, 'labeled_instances': 840, 'train_positive_rate': 0.09523809523809523, 'pool_positive_rate': 0.10932082398531512, 'iteration_time': 549.9258441925049}, {'test_loss': 0.17569410800933838, 'test_f1': 0.824742268041237, 'test_prec': 0.8791208791208791, 'test_recall': 0.7766990291262136, 'labeled_instances': 880, 'train_positive_rate': 0.09545454545454546, 'pool_positive_rate': 0.10939749126053876, 'iteration_time': 547.2571997642517}, {'test_loss': 0.19159063696861267, 'test_f1': 0.8295165394402035, 'test_prec': 0.8716577540106952, 'test_recall': 0.7912621359223301, 'labeled_instances': 920, 'train_positive_rate': 0.0967391304347826, 'pool_positive_rate': 0.10926809040016587, 'iteration_time': 540.5474803447723}, {'test_loss': 0.39333340525627136, 'test_f1': 0.1825095057034221, 'test_prec': 0.42105263157894735, 'test_recall': 0.11650485436893204, 'labeled_instances': 960, 'train_positive_rate': 0.09895833333333333, 'pool_positive_rate': 0.1089274513903408, 'iteration_time': 545.8598201274872}, {'test_loss': 0.18503011763095856, 'test_f1': 0.8125, 'test_prec': 0.8764044943820225, 'test_recall': 0.7572815533980582, 'labeled_instances': 1000, 'train_positive_rate': 0.102, 'pool_positive_rate': 0.10837022981235504, 'iteration_time': 552.4255158901215}, {'test_loss': 0.09959632903337479, 'test_f1': 0.8877805486284289, 'test_prec': 0.9128205128205128, 'test_recall': 0.8640776699029126, 'labeled_instances': 5743, 'train_positive_rate': 0.10726101340762667, 'pool_positive_rate': 0.10726101340762667, 'iteration_time': 948.5908651351929}]
New cross validation 3, for  <function deepmatcher_textual_abt_buy at 0x14cc376e15e0>

Test : 60
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 140
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 200
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 5743
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
[{'test_loss': 0.3364280164241791, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.11666666666666667, 'pool_positive_rate': 0.10716171036424424, 'iteration_time': 454.0178110599518}, {'test_loss': 0.3332030475139618, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 80, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10736358820413208, 'iteration_time': 471.7897267341614}, {'test_loss': 0.3769596815109253, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 100, 'train_positive_rate': 0.08, 'pool_positive_rate': 0.10774410774410774, 'iteration_time': 462.5590934753418}, {'test_loss': 0.28014257550239563, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 120, 'train_positive_rate': 0.08333333333333333, 'pool_positive_rate': 0.10777165214298418, 'iteration_time': 486.96876978874207}, {'test_loss': 0.3426448404788971, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 140, 'train_positive_rate': 0.07857142857142857, 'pool_positive_rate': 0.10797786899875067, 'iteration_time': 474.8547306060791}, {'test_loss': 0.3465084433555603, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 160, 'train_positive_rate': 0.08125, 'pool_positive_rate': 0.10800644814615798, 'iteration_time': 481.7424256801605}, {'test_loss': 0.3559509515762329, 'test_f1': 0.00947867298578199, 'test_prec': 0.2, 'test_recall': 0.0048543689320388345, 'labeled_instances': 180, 'train_positive_rate': 0.08333333333333333, 'pool_positive_rate': 0.108035232788064, 'iteration_time': 471.05197525024414}, {'test_loss': 0.3346090018749237, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 200, 'train_positive_rate': 0.09, 'pool_positive_rate': 0.1078838174273859, 'iteration_time': 478.33690071105957}, {'test_loss': 0.4245734214782715, 'test_f1': 0.2611683848797251, 'test_prec': 0.4470588235294118, 'test_recall': 0.18446601941747573, 'labeled_instances': 240, 'train_positive_rate': 0.09583333333333334, 'pool_positive_rate': 0.10775940396147556, 'iteration_time': 488.31968235969543}, {'test_loss': 0.18308871984481812, 'test_f1': 0.7410926365795724, 'test_prec': 0.7255813953488373, 'test_recall': 0.7572815533980582, 'labeled_instances': 280, 'train_positive_rate': 0.08928571428571429, 'pool_positive_rate': 0.10818231740801758, 'iteration_time': 493.1049921512604}, {'test_loss': 0.20339232683181763, 'test_f1': 0.6204986149584488, 'test_prec': 0.7225806451612903, 'test_recall': 0.5436893203883495, 'labeled_instances': 320, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.1080582703300756, 'iteration_time': 523.7190728187561}, {'test_loss': 0.1782565414905548, 'test_f1': 0.7042253521126761, 'test_prec': 0.8389261744966443, 'test_recall': 0.6067961165048543, 'labeled_instances': 360, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10774660969719488, 'iteration_time': 501.6922266483307}, {'test_loss': 0.3298420011997223, 'test_f1': 0.5072046109510085, 'test_prec': 0.624113475177305, 'test_recall': 0.42718446601941745, 'labeled_instances': 400, 'train_positive_rate': 0.1025, 'pool_positive_rate': 0.10761744338386674, 'iteration_time': 497.94042921066284}, {'test_loss': 0.1713225543498993, 'test_f1': 0.7098445595854923, 'test_prec': 0.7611111111111111, 'test_recall': 0.6650485436893204, 'labeled_instances': 440, 'train_positive_rate': 0.10681818181818181, 'pool_positive_rate': 0.10729775598717707, 'iteration_time': 505.34125995635986}, {'test_loss': 0.1885797530412674, 'test_f1': 0.7313019390581718, 'test_prec': 0.8516129032258064, 'test_recall': 0.6407766990291263, 'labeled_instances': 480, 'train_positive_rate': 0.10833333333333334, 'pool_positive_rate': 0.1071632148964469, 'iteration_time': 500.64066433906555}, {'test_loss': 0.17551925778388977, 'test_f1': 0.7916666666666666, 'test_prec': 0.8539325842696629, 'test_recall': 0.7378640776699029, 'labeled_instances': 520, 'train_positive_rate': 0.10384615384615385, 'pool_positive_rate': 0.10760099559640053, 'iteration_time': 516.2258546352386}, {'test_loss': 0.15436530113220215, 'test_f1': 0.8031088082901555, 'test_prec': 0.8611111111111112, 'test_recall': 0.7524271844660194, 'labeled_instances': 560, 'train_positive_rate': 0.10714285714285714, 'pool_positive_rate': 0.1072737796642871, 'iteration_time': 508.7397449016571}, {'test_loss': 0.21192826330661774, 'test_f1': 0.6837606837606837, 'test_prec': 0.8275862068965517, 'test_recall': 0.5825242718446602, 'labeled_instances': 600, 'train_positive_rate': 0.11166666666666666, 'pool_positive_rate': 0.10674703480458876, 'iteration_time': 526.0334420204163}, {'test_loss': 0.15982189774513245, 'test_f1': 0.8028169014084506, 'test_prec': 0.7772727272727272, 'test_recall': 0.8300970873786407, 'labeled_instances': 640, 'train_positive_rate': 0.115625, 'pool_positive_rate': 0.10621203213795806, 'iteration_time': 531.4217438697815}, {'test_loss': 0.15252676606178284, 'test_f1': 0.8198433420365536, 'test_prec': 0.8870056497175142, 'test_recall': 0.7621359223300971, 'labeled_instances': 680, 'train_positive_rate': 0.11470588235294117, 'pool_positive_rate': 0.1062611100138258, 'iteration_time': 527.7980036735535}, {'test_loss': 0.15278732776641846, 'test_f1': 0.806366047745358, 'test_prec': 0.8888888888888888, 'test_recall': 0.7378640776699029, 'labeled_instances': 720, 'train_positive_rate': 0.11388888888888889, 'pool_positive_rate': 0.10631096954011547, 'iteration_time': 539.4923670291901}, {'test_loss': 0.14022904634475708, 'test_f1': 0.8198433420365536, 'test_prec': 0.8870056497175142, 'test_recall': 0.7621359223300971, 'labeled_instances': 760, 'train_positive_rate': 0.11447368421052631, 'pool_positive_rate': 0.10616094722054988, 'iteration_time': 534.8269758224487}, {'test_loss': 0.15688949823379517, 'test_f1': 0.8021680216802168, 'test_prec': 0.9079754601226994, 'test_recall': 0.7184466019417476, 'labeled_instances': 800, 'train_positive_rate': 0.11125, 'pool_positive_rate': 0.1066154157394295, 'iteration_time': 533.4722757339478}, {'test_loss': 0.16940078139305115, 'test_f1': 0.8011049723756906, 'test_prec': 0.9294871794871795, 'test_recall': 0.7038834951456311, 'labeled_instances': 840, 'train_positive_rate': 0.11785714285714285, 'pool_positive_rate': 0.1054456455231491, 'iteration_time': 542.8208725452423}, {'test_loss': 0.12593580782413483, 'test_f1': 0.8271028037383177, 'test_prec': 0.7972972972972973, 'test_recall': 0.8592233009708737, 'labeled_instances': 880, 'train_positive_rate': 0.11818181818181818, 'pool_positive_rate': 0.10528480361916512, 'iteration_time': 544.58757853508}, {'test_loss': 0.17306199669837952, 'test_f1': 0.8329048843187661, 'test_prec': 0.8852459016393442, 'test_recall': 0.7864077669902912, 'labeled_instances': 920, 'train_positive_rate': 0.11956521739130435, 'pool_positive_rate': 0.10491395397055775, 'iteration_time': 541.5622601509094}, {'test_loss': 0.17132613062858582, 'test_f1': 0.804177545691906, 'test_prec': 0.8700564971751412, 'test_recall': 0.7475728155339806, 'labeled_instances': 960, 'train_positive_rate': 0.11979166666666667, 'pool_positive_rate': 0.10474597532929124, 'iteration_time': 575.3858995437622}, {'test_loss': 0.16238510608673096, 'test_f1': 0.8250652741514359, 'test_prec': 0.8926553672316384, 'test_recall': 0.7669902912621359, 'labeled_instances': 1000, 'train_positive_rate': 0.12, 'pool_positive_rate': 0.10457516339869281, 'iteration_time': 555.4357960224152}, {'test_loss': 0.11606471240520477, 'test_f1': 0.8987654320987655, 'test_prec': 0.914572864321608, 'test_recall': 0.883495145631068, 'labeled_instances': 5743, 'train_positive_rate': 0.10726101340762667, 'pool_positive_rate': 0.10726101340762667, 'iteration_time': 960.1372811794281}]
New cross validation 4, for  <function deepmatcher_textual_abt_buy at 0x14cc376e15e0>

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 80
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 160
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 200
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 280
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 320
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 440
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 800
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 5743
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
[{'test_loss': 0.3352450430393219, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.18333333333333332, 'pool_positive_rate': 0.10645785676579271, 'iteration_time': 468.8239276409149}, {'test_loss': 0.3302168846130371, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 80, 'train_positive_rate': 0.1625, 'pool_positive_rate': 0.10648066395903232, 'iteration_time': 476.9153940677643}, {'test_loss': 0.3571617305278778, 'test_f1': 0.11715481171548117, 'test_prec': 0.42424242424242425, 'test_recall': 0.06796116504854369, 'labeled_instances': 100, 'train_positive_rate': 0.14, 'pool_positive_rate': 0.10668084352294879, 'iteration_time': 463.0203535556793}, {'test_loss': 0.5232369899749756, 'test_f1': 0.18045112781954886, 'test_prec': 0.4, 'test_recall': 0.11650485436893204, 'labeled_instances': 120, 'train_positive_rate': 0.14166666666666666, 'pool_positive_rate': 0.1065267650720256, 'iteration_time': 477.0315773487091}, {'test_loss': 0.4481181502342224, 'test_f1': 0.11501597444089458, 'test_prec': 0.16822429906542055, 'test_recall': 0.08737864077669903, 'labeled_instances': 140, 'train_positive_rate': 0.1357142857142857, 'pool_positive_rate': 0.10655006246653578, 'iteration_time': 474.4279057979584}, {'test_loss': 0.4017711877822876, 'test_f1': 0.21604938271604937, 'test_prec': 0.2966101694915254, 'test_recall': 0.16990291262135923, 'labeled_instances': 160, 'train_positive_rate': 0.13125, 'pool_positive_rate': 0.10657352677771807, 'iteration_time': 479.43017411231995}, {'test_loss': 0.2495374083518982, 'test_f1': 0.5372168284789643, 'test_prec': 0.8058252427184466, 'test_recall': 0.4029126213592233, 'labeled_instances': 180, 'train_positive_rate': 0.13333333333333333, 'pool_positive_rate': 0.10641740068308467, 'iteration_time': 499.91026163101196}, {'test_loss': 0.2102372795343399, 'test_f1': 0.6833712984054671, 'test_prec': 0.6437768240343348, 'test_recall': 0.7281553398058253, 'labeled_instances': 200, 'train_positive_rate': 0.135, 'pool_positive_rate': 0.10626014793433158, 'iteration_time': 498.7237455844879}, {'test_loss': 0.3502565026283264, 'test_f1': 0.4458598726114649, 'test_prec': 0.6481481481481481, 'test_recall': 0.33980582524271846, 'labeled_instances': 240, 'train_positive_rate': 0.12916666666666668, 'pool_positive_rate': 0.10630565146283845, 'iteration_time': 492.25557708740234}, {'test_loss': 0.23635391891002655, 'test_f1': 0.695890410958904, 'test_prec': 0.7987421383647799, 'test_recall': 0.616504854368932, 'labeled_instances': 280, 'train_positive_rate': 0.125, 'pool_positive_rate': 0.1063518213435841, 'iteration_time': 490.2119975090027}, {'test_loss': 0.38045233488082886, 'test_f1': 0.44660194174757284, 'test_prec': 0.6699029126213593, 'test_recall': 0.33495145631067963, 'labeled_instances': 320, 'train_positive_rate': 0.125, 'pool_positive_rate': 0.10621427254287295, 'iteration_time': 508.38541173934937}, {'test_loss': 0.35737383365631104, 'test_f1': 0.35540069686411146, 'test_prec': 0.6296296296296297, 'test_recall': 0.24757281553398058, 'labeled_instances': 360, 'train_positive_rate': 0.11666666666666667, 'pool_positive_rate': 0.10663198959687907, 'iteration_time': 509.3456971645355}, {'test_loss': 0.2528989613056183, 'test_f1': 0.6985915492957746, 'test_prec': 0.8322147651006712, 'test_recall': 0.6019417475728155, 'labeled_instances': 400, 'train_positive_rate': 0.1175, 'pool_positive_rate': 0.10649447875725249, 'iteration_time': 503.33914399147034}, {'test_loss': 0.2921295166015625, 'test_f1': 0.36585365853658536, 'test_prec': 0.4918032786885246, 'test_recall': 0.2912621359223301, 'labeled_instances': 440, 'train_positive_rate': 0.11818181818181818, 'pool_positive_rate': 0.10635489345653404, 'iteration_time': 506.0836441516876}, {'test_loss': 0.21941155195236206, 'test_f1': 0.7311320754716981, 'test_prec': 0.7110091743119266, 'test_recall': 0.7524271844660194, 'labeled_instances': 480, 'train_positive_rate': 0.11666666666666667, 'pool_positive_rate': 0.10640319209576288, 'iteration_time': 492.02860283851624}, {'test_loss': 0.2370341420173645, 'test_f1': 0.7272727272727272, 'test_prec': 0.7169811320754716, 'test_recall': 0.7378640776699029, 'labeled_instances': 520, 'train_positive_rate': 0.11923076923076924, 'pool_positive_rate': 0.10606930882634501, 'iteration_time': 497.03109526634216}, {'test_loss': 0.2323458045721054, 'test_f1': 0.7573333333333334, 'test_prec': 0.8402366863905325, 'test_recall': 0.6893203883495146, 'labeled_instances': 560, 'train_positive_rate': 0.11964285714285715, 'pool_positive_rate': 0.10592321049585182, 'iteration_time': 496.8328926563263}, {'test_loss': 0.20849895477294922, 'test_f1': 0.7950617283950617, 'test_prec': 0.8090452261306532, 'test_recall': 0.7815533980582524, 'labeled_instances': 600, 'train_positive_rate': 0.11833333333333333, 'pool_positive_rate': 0.10596927863114913, 'iteration_time': 518.616509437561}, {'test_loss': 0.2099512815475464, 'test_f1': 0.7808564231738037, 'test_prec': 0.8115183246073299, 'test_recall': 0.7524271844660194, 'labeled_instances': 640, 'train_positive_rate': 0.1171875, 'pool_positive_rate': 0.10601606897903194, 'iteration_time': 522.116955280304}, {'test_loss': 0.2552618086338043, 'test_f1': 0.7371134020618556, 'test_prec': 0.7857142857142857, 'test_recall': 0.6941747572815534, 'labeled_instances': 680, 'train_positive_rate': 0.1161764705882353, 'pool_positive_rate': 0.10606359865692278, 'iteration_time': 547.1926624774933}, {'test_loss': 0.2524467408657074, 'test_f1': 0.7853403141361257, 'test_prec': 0.8522727272727273, 'test_recall': 0.7281553398058253, 'labeled_instances': 720, 'train_positive_rate': 0.11388888888888889, 'pool_positive_rate': 0.10631096954011547, 'iteration_time': 559.6467487812042}, {'test_loss': 0.19282491505146027, 'test_f1': 0.7651331719128328, 'test_prec': 0.7632850241545893, 'test_recall': 0.7669902912621359, 'labeled_instances': 760, 'train_positive_rate': 0.10921052631578948, 'pool_positive_rate': 0.10696367650010034, 'iteration_time': 550.774489402771}, {'test_loss': 0.20095083117485046, 'test_f1': 0.7902439024390243, 'test_prec': 0.7941176470588235, 'test_recall': 0.7864077669902912, 'labeled_instances': 800, 'train_positive_rate': 0.10625, 'pool_positive_rate': 0.10742464090633219, 'iteration_time': 546.8424828052521}, {'test_loss': 0.2781899571418762, 'test_f1': 0.7393617021276596, 'test_prec': 0.8176470588235294, 'test_recall': 0.6747572815533981, 'labeled_instances': 840, 'train_positive_rate': 0.10357142857142858, 'pool_positive_rate': 0.10789312665714869, 'iteration_time': 542.0569636821747}, {'test_loss': 0.25546422600746155, 'test_f1': 0.7272727272727274, 'test_prec': 0.8095238095238095, 'test_recall': 0.6601941747572816, 'labeled_instances': 880, 'train_positive_rate': 0.10454545454545454, 'pool_positive_rate': 0.1077524162039893, 'iteration_time': 547.6157755851746}, {'test_loss': 0.23144789040088654, 'test_f1': 0.7811764705882352, 'test_prec': 0.7579908675799086, 'test_recall': 0.8058252427184466, 'labeled_instances': 920, 'train_positive_rate': 0.10326086956521739, 'pool_positive_rate': 0.10802405142027784, 'iteration_time': 532.8642055988312}, {'test_loss': 0.19190619885921478, 'test_f1': 0.7970297029702972, 'test_prec': 0.8131313131313131, 'test_recall': 0.7815533980582524, 'labeled_instances': 960, 'train_positive_rate': 0.10208333333333333, 'pool_positive_rate': 0.10830022998118335, 'iteration_time': 538.9810240268707}, {'test_loss': 0.17647063732147217, 'test_f1': 0.8048780487804877, 'test_prec': 0.8088235294117647, 'test_recall': 0.8009708737864077, 'labeled_instances': 1000, 'train_positive_rate': 0.103, 'pool_positive_rate': 0.10815939278937381, 'iteration_time': 535.1806724071503}, {'test_loss': 0.14434009790420532, 'test_f1': 0.8905852417302799, 'test_prec': 0.9358288770053476, 'test_recall': 0.8495145631067961, 'labeled_instances': 5743, 'train_positive_rate': 0.10726101340762667, 'pool_positive_rate': 0.10726101340762667, 'iteration_time': 968.4944858551025}]
Could not create dir out, File exists




    ###########  New Dataset: <function deepmatcher_structured_itunes_amazon at 0x14cc376e1310>
New cross validation 0, for  <function deepmatcher_structured_itunes_amazon at 0x14cc376e1310>

Test : 60
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 80
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 100
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 120
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 140
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 160
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 180
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 200
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 240
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 280
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 320
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 360
-- Random test --

[{'test_loss': 0.46488457918167114, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.15, 'pool_positive_rate': 0.26436781609195403, 'iteration_time': 386.9175934791565}, {'test_loss': 0.4532473385334015, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 80, 'train_positive_rate': 0.1625, 'pool_positive_rate': 0.2697095435684647, 'iteration_time': 376.958208322525}, {'test_loss': 0.24346384406089783, 'test_f1': 0.9056603773584906, 'test_prec': 0.9230769230769231, 'test_recall': 0.8888888888888888, 'labeled_instances': 100, 'train_positive_rate': 0.17, 'pool_positive_rate': 0.27601809954751133, 'iteration_time': 388.56197929382324}, {'test_loss': 0.1346164494752884, 'test_f1': 0.896551724137931, 'test_prec': 0.8387096774193549, 'test_recall': 0.9629629629629629, 'labeled_instances': 120, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.26865671641791045, 'iteration_time': 388.54505586624146}, {'test_loss': 0.09467832744121552, 'test_f1': 0.9285714285714286, 'test_prec': 0.896551724137931, 'test_recall': 0.9629629629629629, 'labeled_instances': 140, 'train_positive_rate': 0.22142857142857142, 'pool_positive_rate': 0.2596685082872928, 'iteration_time': 391.4081070423126}, {'test_loss': 0.08524949848651886, 'test_f1': 0.9615384615384615, 'test_prec': 1.0, 'test_recall': 0.9259259259259259, 'labeled_instances': 160, 'train_positive_rate': 0.23125, 'pool_positive_rate': 0.2546583850931677, 'iteration_time': 401.556161403656}, {'test_loss': 0.1555650234222412, 'test_f1': 0.9433962264150944, 'test_prec': 0.9615384615384616, 'test_recall': 0.9259259259259259, 'labeled_instances': 180, 'train_positive_rate': 0.24444444444444444, 'pool_positive_rate': 0.24113475177304963, 'iteration_time': 396.7725160121918}, {'test_loss': 0.062030889093875885, 'test_f1': 0.9811320754716981, 'test_prec': 1.0, 'test_recall': 0.9629629629629629, 'labeled_instances': 200, 'train_positive_rate': 0.26, 'pool_positive_rate': 0.21487603305785125, 'iteration_time': 397.29147958755493}, {'test_loss': 0.11363299936056137, 'test_f1': 0.9259259259259259, 'test_prec': 0.9259259259259259, 'test_recall': 0.9259259259259259, 'labeled_instances': 240, 'train_positive_rate': 0.26666666666666666, 'pool_positive_rate': 0.1728395061728395, 'iteration_time': 411.08125376701355}, {'test_loss': 0.09052795171737671, 'test_f1': 0.9454545454545454, 'test_prec': 0.9285714285714286, 'test_recall': 0.9629629629629629, 'labeled_instances': 280, 'train_positive_rate': 0.25357142857142856, 'pool_positive_rate': 0.17073170731707318, 'iteration_time': 404.6049988269806}, {'test_loss': 0.08078259974718094, 'test_f1': 0.9629629629629629, 'test_prec': 0.9629629629629629, 'test_recall': 0.9629629629629629, 'labeled_instances': 320, 'train_positive_rate': 0.24375, 'pool_positive_rate': 0.0, 'iteration_time': 397.496155500412}]
New cross validation 1, for  <function deepmatcher_structured_itunes_amazon at 0x14cc376e1310>

Test : 60
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 80
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 100
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 120
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 140
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 160
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 180
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 200
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 240
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 280
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 320
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 360
-- Random test --

[{'test_loss': 0.31324607133865356, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.23333333333333334, 'pool_positive_rate': 0.24521072796934865, 'iteration_time': 379.53902673721313}, {'test_loss': 0.28578341007232666, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 80, 'train_positive_rate': 0.225, 'pool_positive_rate': 0.24896265560165975, 'iteration_time': 381.8030662536621}, {'test_loss': 0.26350417733192444, 'test_f1': 0.8750000000000001, 'test_prec': 1.0, 'test_recall': 0.7777777777777778, 'labeled_instances': 100, 'train_positive_rate': 0.23, 'pool_positive_rate': 0.248868778280543, 'iteration_time': 377.9694607257843}, {'test_loss': 0.1212460920214653, 'test_f1': 0.9090909090909091, 'test_prec': 0.8928571428571429, 'test_recall': 0.9259259259259259, 'labeled_instances': 120, 'train_positive_rate': 0.26666666666666666, 'pool_positive_rate': 0.22885572139303484, 'iteration_time': 372.700736284256}, {'test_loss': 0.15297214686870575, 'test_f1': 0.9019607843137256, 'test_prec': 0.9583333333333334, 'test_recall': 0.8518518518518519, 'labeled_instances': 140, 'train_positive_rate': 0.2785714285714286, 'pool_positive_rate': 0.2154696132596685, 'iteration_time': 381.6974604129791}, {'test_loss': 0.17024502158164978, 'test_f1': 0.92, 'test_prec': 1.0, 'test_recall': 0.8518518518518519, 'labeled_instances': 160, 'train_positive_rate': 0.28125, 'pool_positive_rate': 0.20496894409937888, 'iteration_time': 379.16024470329285}, {'test_loss': 0.20216096937656403, 'test_f1': 0.912280701754386, 'test_prec': 0.8666666666666667, 'test_recall': 0.9629629629629629, 'labeled_instances': 180, 'train_positive_rate': 0.2722222222222222, 'pool_positive_rate': 0.20567375886524822, 'iteration_time': 395.95366883277893}, {'test_loss': 0.2177959382534027, 'test_f1': 0.9056603773584906, 'test_prec': 0.9230769230769231, 'test_recall': 0.8888888888888888, 'labeled_instances': 200, 'train_positive_rate': 0.28, 'pool_positive_rate': 0.18181818181818182, 'iteration_time': 391.61328411102295}, {'test_loss': 0.18180066347122192, 'test_f1': 0.9411764705882353, 'test_prec': 1.0, 'test_recall': 0.8888888888888888, 'labeled_instances': 240, 'train_positive_rate': 0.2625, 'pool_positive_rate': 0.18518518518518517, 'iteration_time': 416.5136740207672}, {'test_loss': 0.15340816974639893, 'test_f1': 0.9285714285714286, 'test_prec': 0.896551724137931, 'test_recall': 0.9629629629629629, 'labeled_instances': 280, 'train_positive_rate': 0.2642857142857143, 'pool_positive_rate': 0.0975609756097561, 'iteration_time': 417.6565856933594}, {'test_loss': 0.05726916342973709, 'test_f1': 0.9629629629629629, 'test_prec': 0.9629629629629629, 'test_recall': 0.9629629629629629, 'labeled_instances': 320, 'train_positive_rate': 0.240625, 'pool_positive_rate': 1.0, 'iteration_time': 416.5215663909912}]
New cross validation 2, for  <function deepmatcher_structured_itunes_amazon at 0x14cc376e1310>

Test : 60
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 80
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 100
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 120
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 140
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 160
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 180
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 200
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 240
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 280
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 320
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 360
-- Random test --

[{'test_loss': 0.46065375208854675, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.25287356321839083, 'iteration_time': 386.6183168888092}, {'test_loss': 0.24186080694198608, 'test_f1': 0.8461538461538461, 'test_prec': 0.88, 'test_recall': 0.8148148148148148, 'labeled_instances': 80, 'train_positive_rate': 0.25, 'pool_positive_rate': 0.24066390041493776, 'iteration_time': 394.20207166671753}, {'test_loss': 0.20046591758728027, 'test_f1': 0.8888888888888888, 'test_prec': 0.8888888888888888, 'test_recall': 0.8888888888888888, 'labeled_instances': 100, 'train_positive_rate': 0.27, 'pool_positive_rate': 0.23076923076923078, 'iteration_time': 392.7549059391022}, {'test_loss': 0.1608612835407257, 'test_f1': 0.923076923076923, 'test_prec': 0.96, 'test_recall': 0.8888888888888888, 'labeled_instances': 120, 'train_positive_rate': 0.25, 'pool_positive_rate': 0.23880597014925373, 'iteration_time': 394.1476767063141}, {'test_loss': 0.18422478437423706, 'test_f1': 0.9259259259259259, 'test_prec': 0.9259259259259259, 'test_recall': 0.9259259259259259, 'labeled_instances': 140, 'train_positive_rate': 0.2357142857142857, 'pool_positive_rate': 0.24861878453038674, 'iteration_time': 385.66947078704834}, {'test_loss': 0.15773311257362366, 'test_f1': 0.923076923076923, 'test_prec': 0.96, 'test_recall': 0.8888888888888888, 'labeled_instances': 160, 'train_positive_rate': 0.2375, 'pool_positive_rate': 0.2484472049689441, 'iteration_time': 394.59005880355835}, {'test_loss': 0.1491437554359436, 'test_f1': 0.912280701754386, 'test_prec': 0.8666666666666667, 'test_recall': 0.9629629629629629, 'labeled_instances': 180, 'train_positive_rate': 0.25, 'pool_positive_rate': 0.23404255319148937, 'iteration_time': 389.062135219574}, {'test_loss': 0.18285727500915527, 'test_f1': 0.9433962264150944, 'test_prec': 0.9615384615384616, 'test_recall': 0.9259259259259259, 'labeled_instances': 200, 'train_positive_rate': 0.255, 'pool_positive_rate': 0.2231404958677686, 'iteration_time': 392.6636211872101}, {'test_loss': 0.23026376962661743, 'test_f1': 0.9090909090909091, 'test_prec': 0.8928571428571429, 'test_recall': 0.9259259259259259, 'labeled_instances': 240, 'train_positive_rate': 0.25, 'pool_positive_rate': 0.2222222222222222, 'iteration_time': 404.74546813964844}, {'test_loss': 0.1375812590122223, 'test_f1': 0.9433962264150944, 'test_prec': 0.9615384615384616, 'test_recall': 0.9259259259259259, 'labeled_instances': 280, 'train_positive_rate': 0.25357142857142856, 'pool_positive_rate': 0.17073170731707318, 'iteration_time': 398.12215304374695}, {'test_loss': 0.08897653967142105, 'test_f1': 0.9454545454545454, 'test_prec': 0.9285714285714286, 'test_recall': 0.9629629629629629, 'labeled_instances': 320, 'train_positive_rate': 0.24375, 'pool_positive_rate': 0.0, 'iteration_time': 399.9862422943115}]
New cross validation 3, for  <function deepmatcher_structured_itunes_amazon at 0x14cc376e1310>

Test : 60
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 80
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 100
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 120
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 140
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 160
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 180
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 200
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 240
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 280
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 320
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 360
-- Random test --

[{'test_loss': 0.4597531259059906, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.13333333333333333, 'pool_positive_rate': 0.2681992337164751, 'iteration_time': 377.69340920448303}, {'test_loss': 0.1862596571445465, 'test_f1': 0.8846153846153846, 'test_prec': 0.92, 'test_recall': 0.8518518518518519, 'labeled_instances': 80, 'train_positive_rate': 0.15, 'pool_positive_rate': 0.27385892116182575, 'iteration_time': 372.38723826408386}, {'test_loss': 0.1417766958475113, 'test_f1': 0.923076923076923, 'test_prec': 0.96, 'test_recall': 0.8888888888888888, 'labeled_instances': 100, 'train_positive_rate': 0.18, 'pool_positive_rate': 0.27149321266968324, 'iteration_time': 366.4941403865814}, {'test_loss': 0.11897917091846466, 'test_f1': 0.9019607843137256, 'test_prec': 0.9583333333333334, 'test_recall': 0.8518518518518519, 'labeled_instances': 120, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.26865671641791045, 'iteration_time': 384.9690182209015}, {'test_loss': 0.148467555642128, 'test_f1': 0.9056603773584906, 'test_prec': 0.9230769230769231, 'test_recall': 0.8888888888888888, 'labeled_instances': 140, 'train_positive_rate': 0.20714285714285716, 'pool_positive_rate': 0.27071823204419887, 'iteration_time': 381.1089713573456}, {'test_loss': 0.17955709993839264, 'test_f1': 0.9019607843137256, 'test_prec': 0.9583333333333334, 'test_recall': 0.8518518518518519, 'labeled_instances': 160, 'train_positive_rate': 0.225, 'pool_positive_rate': 0.2608695652173913, 'iteration_time': 384.3714463710785}, {'test_loss': 0.16740138828754425, 'test_f1': 0.923076923076923, 'test_prec': 0.96, 'test_recall': 0.8888888888888888, 'labeled_instances': 180, 'train_positive_rate': 0.2111111111111111, 'pool_positive_rate': 0.28368794326241137, 'iteration_time': 382.16899394989014}, {'test_loss': 0.09662526100873947, 'test_f1': 0.9259259259259259, 'test_prec': 0.9259259259259259, 'test_recall': 0.9259259259259259, 'labeled_instances': 200, 'train_positive_rate': 0.22, 'pool_positive_rate': 0.2809917355371901, 'iteration_time': 383.0271067619324}, {'test_loss': 0.1508265882730484, 'test_f1': 0.9285714285714286, 'test_prec': 0.896551724137931, 'test_recall': 0.9629629629629629, 'labeled_instances': 240, 'train_positive_rate': 0.24583333333333332, 'pool_positive_rate': 0.2345679012345679, 'iteration_time': 406.85012698173523}, {'test_loss': 0.08312470465898514, 'test_f1': 0.9615384615384615, 'test_prec': 1.0, 'test_recall': 0.9259259259259259, 'labeled_instances': 280, 'train_positive_rate': 0.23214285714285715, 'pool_positive_rate': 0.3170731707317073, 'iteration_time': 397.66806292533875}, {'test_loss': 0.1626053899526596, 'test_f1': 0.9259259259259259, 'test_prec': 0.9259259259259259, 'test_recall': 0.9259259259259259, 'labeled_instances': 320, 'train_positive_rate': 0.24375, 'pool_positive_rate': 0.0, 'iteration_time': 393.53163957595825}]
New cross validation 4, for  <function deepmatcher_structured_itunes_amazon at 0x14cc376e1310>

Test : 60
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 80
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 100
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 120
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 140
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 160
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 180
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 200
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 240
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 280
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)

Test : 320
-- Random test --


Test : 360
-- Random test --

[{'test_loss': 0.3922761082649231, 'test_f1': 0.6521739130434783, 'test_prec': 0.7894736842105263, 'test_recall': 0.5555555555555556, 'labeled_instances': 60, 'train_positive_rate': 0.23333333333333334, 'pool_positive_rate': 0.24521072796934865, 'iteration_time': 394.20248532295227}, {'test_loss': 0.2377178966999054, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 80, 'train_positive_rate': 0.225, 'pool_positive_rate': 0.24896265560165975, 'iteration_time': 397.2301256656647}, {'test_loss': 0.062403131276369095, 'test_f1': 0.9642857142857143, 'test_prec': 0.9310344827586207, 'test_recall': 1.0, 'labeled_instances': 100, 'train_positive_rate': 0.27, 'pool_positive_rate': 0.23076923076923078, 'iteration_time': 396.0921597480774}, {'test_loss': 0.18177153170108795, 'test_f1': 0.923076923076923, 'test_prec': 0.96, 'test_recall': 0.8888888888888888, 'labeled_instances': 120, 'train_positive_rate': 0.25833333333333336, 'pool_positive_rate': 0.23383084577114427, 'iteration_time': 389.4061915874481}, {'test_loss': 0.1090671494603157, 'test_f1': 0.9259259259259259, 'test_prec': 0.9259259259259259, 'test_recall': 0.9259259259259259, 'labeled_instances': 140, 'train_positive_rate': 0.2785714285714286, 'pool_positive_rate': 0.2154696132596685, 'iteration_time': 389.1858808994293}, {'test_loss': 0.08957500010728836, 'test_f1': 0.9615384615384615, 'test_prec': 1.0, 'test_recall': 0.9259259259259259, 'labeled_instances': 160, 'train_positive_rate': 0.275, 'pool_positive_rate': 0.2111801242236025, 'iteration_time': 399.45685052871704}, {'test_loss': 0.1677558571100235, 'test_f1': 0.9259259259259259, 'test_prec': 0.9259259259259259, 'test_recall': 0.9259259259259259, 'labeled_instances': 180, 'train_positive_rate': 0.2722222222222222, 'pool_positive_rate': 0.20567375886524822, 'iteration_time': 393.2146706581116}, {'test_loss': 0.09930486232042313, 'test_f1': 0.9454545454545454, 'test_prec': 0.9285714285714286, 'test_recall': 0.9629629629629629, 'labeled_instances': 200, 'train_positive_rate': 0.255, 'pool_positive_rate': 0.2231404958677686, 'iteration_time': 401.3423614501953}, {'test_loss': 0.17738761007785797, 'test_f1': 0.923076923076923, 'test_prec': 0.96, 'test_recall': 0.8888888888888888, 'labeled_instances': 240, 'train_positive_rate': 0.2625, 'pool_positive_rate': 0.18518518518518517, 'iteration_time': 403.6129901409149}, {'test_loss': 0.12475495040416718, 'test_f1': 0.9433962264150944, 'test_prec': 0.9615384615384616, 'test_recall': 0.9259259259259259, 'labeled_instances': 280, 'train_positive_rate': 0.26785714285714285, 'pool_positive_rate': 0.07317073170731707, 'iteration_time': 395.95671796798706}, {'test_loss': 0.03658095374703407, 'test_f1': 0.9629629629629629, 'test_prec': 0.9629629629629629, 'test_recall': 0.9629629629629629, 'labeled_instances': 320, 'train_positive_rate': 0.24375, 'pool_positive_rate': 0.0, 'iteration_time': 416.98712515830994}]
Could not create dir out, File exists
End of job!
