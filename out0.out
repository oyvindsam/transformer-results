We are running from this directory: /cluster/work/oyvinsam
The name of the job is: alt-0
The job ID is 106692
The job was run on these nodes: idun-04-12
Number of nodes: 1
We are using 1 cores
We are using 1 cores per node
Total of 1 cores
Fri Mar 26 15:00:40 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.27.04    Driver Version: 460.27.04    CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla P100-PCIE...  Off  | 00000000:03:00.0 Off |                    0 |
| N/A   32C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
Launch Python
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
[50, 75, 100, 120, 140, 160, 180, 200, 250, 300, 400, 500, 600, 700, 800, 900, 1000]
    ########### 



New Dataset: <function deepmatcher_structured_amazon_google at 0x15537488b310>
New cross validation 0

Test : 50
-- Random test --

      a.index  b.index  matching
2254      795     2594      True
4334      527     2199     False
3318     1198     1253     False
5233     1244     1256     False
6344      699      328     False
5857      751     2283     False
6647      644      330      True
2462       64     2826     False
3752     1362     3136     False
1657      578     3183     False
6296      208       69     False
4561       26      176     False
468      1174      946     False
2922      757      340      True
1979      817      400      True
2638      562      257     False
543       672     1432     False
1188      615     1853     False
1726     1290     2402     False
132      1055      243     False
5325      658     1579     False
2807      628      276      True
1672      316     2865     False
476       226     2466     False
5162      620      932     False
2155       76     3003     False
1921      737     3094     False
6477     1258     2399     False
5595      823     3029     False
2753      683     2986     False
4954      851     2752     False
3464      839      508     False
1056      604     2332     False
5783      518     2803     False
6276      645     1132     False
2057      465     1150     False
2858      271     2821     False
3611      140      345     False
5839      549     1897     False
1421      520     1307     False
3467      808      535      True
3722      382      957     False
503      1108     2763     False
1543      511     1162     False
1153      456     2550      True
4020      258     1852     False
2251     1353     3048     False
2751      312     3168     False
5426     1020      758     False
2845      536     1595     False
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.3303679823875427,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 75
-- Random test --

      a.index  b.index  matching
2828      531     2853     False
1899     1148      192     False
3404      248     1828     False
6592      942     2080     False
4096     1279     1030      True
...       ...      ...       ...
4901      562      372     False
517      1190     1955     False
4506     1074     1127     False
6399      229      203     False
4010      394     2909      True

[75 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.24308054149150848,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 100
-- Random test --

      a.index  b.index  matching
2706      547     3204     False
4712     1148     2112     False
1108      360     2856      True
1124      467     2495     False
4977      731     2996     False
...       ...      ...       ...
4632      827     2238     False
3676      502     1756     False
1087      944      741     False
6393     1004      794      True
6127      606     2377     False

[100 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.2516129032258065,
 'test_loss': 0.4091038405895233,
 'test_prec': 0.5131578947368421,
 'test_recall': 0.16666666666666666}
--------------------------------------------------------------------------------

Test : 120
-- Random test --

      a.index  b.index  matching
728       514     2959     False
3878      632      795     False
3184     1246     1034     False
6781      605     3204     False
6597      528     1136     False
...       ...      ...       ...
5304      394      703     False
4106      654     2792     False
1277      934      577     False
705       678     3022     False
4457      722     2156     False

[120 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.3180987202925046,
 'test_loss': 0.3910970389842987,
 'test_prec': 0.2779552715654952,
 'test_recall': 0.3717948717948718}
--------------------------------------------------------------------------------

Test : 140
-- Random test --

      a.index  b.index  matching
5776      655     3127     False
2106      629      275      True
3305      605     2257     False
6460       45     2060      True
325       524     1856     False
...       ...      ...       ...
275        29     1020     False
6868      662      125     False
6289     1056     2093     False
5411     1349      566     False
4998      115      889     False

[140 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.35757575757575755,
 'test_loss': 0.3651345372200012,
 'test_prec': 0.6145833333333334,
 'test_recall': 0.25213675213675213}
--------------------------------------------------------------------------------

Test : 160
-- Random test --

      a.index  b.index  matching
430       632     2961     False
32         72     3110     False
4558      737      986     False
2012     1173      899      True
2314      778     2574      True
...       ...      ...       ...
6065      522     3027     False
770       796     2521     False
3111      548      551     False
2284      218     2818     False
5525      553      984     False

[160 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.2745098039215686,
 'test_loss': 0.33462420105934143,
 'test_prec': 0.5833333333333334,
 'test_recall': 0.1794871794871795}
--------------------------------------------------------------------------------

Test : 180
-- Random test --

      a.index  b.index  matching
5200      467     3045     False
997      1321     2143     False
1153      456     2550      True
6197      557      893     False
993        30     2839     False
...       ...      ...       ...
4197      608     1678     False
288       942      854     False
2130      648     3144     False
228       511     3175     False
208       517     1180     False

[180 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.4025695931477516,
 'test_loss': 0.4230603575706482,
 'test_prec': 0.4034334763948498,
 'test_recall': 0.4017094017094017}
--------------------------------------------------------------------------------

Test : 200
-- Random test --

      a.index  b.index  matching
1649      772      263     False
496       827     2496     False
4091     1329     2501     False
4184       15      352     False
6859      514     2853     False
...       ...      ...       ...
3530      883      324     False
3127       40     1821     False
2893      732     1015     False
6657      578     2877     False
2937     1242      348     False

[200 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.054474708171206226,
 'test_loss': 0.4233511984348297,
 'test_prec': 0.30434782608695654,
 'test_recall': 0.029914529914529916}
--------------------------------------------------------------------------------

Test : 250
-- Random test --

      a.index  b.index  matching
6638     1148     1485     False
4733      647      424     False
3496      746     2632      True
4339      220     1803     False
2247      827      957     False
...       ...      ...       ...
6446      371     2411     False
6834      361      254     False
6271      654      314      True
1868     1110     2039     False
4669      599      307     False

[250 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.450632911392405,
 'test_loss': 0.47907546162605286,
 'test_prec': 0.5527950310559007,
 'test_recall': 0.3803418803418803}
--------------------------------------------------------------------------------

Test : 300
-- Random test --

      a.index  b.index  matching
4859      135     2497     False
2784     1005     3028     False
1722     1250     1607     False
635       516      372     False
659       465     1564     False
...       ...      ...       ...
5527     1115     1083     False
836       773     1585     False
2584       44      260     False
4452      616     2959     False
996       979      994      True

[300 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5333333333333333,
 'test_loss': 0.3448541462421417,
 'test_prec': 0.4927536231884058,
 'test_recall': 0.5811965811965812}
--------------------------------------------------------------------------------

Test : 400
-- Random test --

      a.index  b.index  matching
973       689      659     False
2479      942      878      True
4370      547     3027     False
2867      355     1583     False
4215      796       31     False
...       ...      ...       ...
3871      781     2818     False
5615      876      172      True
2966      126     2689     False
5976      608     1865     False
6015     1349      369     False

[400 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5751633986928104,
 'test_loss': 0.31685227155685425,
 'test_prec': 0.5866666666666667,
 'test_recall': 0.5641025641025641}
--------------------------------------------------------------------------------

Test : 500
-- Random test --

      a.index  b.index  matching
2020     1032      648     False
1305       12     3109     False
2082       93     2137     False
2730      859     2817     False
2140      839     2607      True
...       ...      ...       ...
3848      556     3016      True
4235      738     3154     False
914       704      407      True
4695      804     2192     False
5991     1078     2587     False

[500 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5576519916142558,
 'test_loss': 0.40998780727386475,
 'test_prec': 0.5473251028806584,
 'test_recall': 0.5683760683760684}
--------------------------------------------------------------------------------

Test : 600
-- Random test --

      a.index  b.index  matching
6272     1321     2313     False
6653      932     2141     False
195       250      362     False
4327     1316      659      True
164      1101     2889     False
...       ...      ...       ...
379       621      289      True
536       823     2441     False
5347      736     1146     False
326       875     2462     False
5250      910     3188     False

[600 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.2326869806094183,
 'test_loss': 0.4971655011177063,
 'test_prec': 0.33070866141732286,
 'test_recall': 0.1794871794871795}
--------------------------------------------------------------------------------

Test : 700
-- Random test --

      a.index  b.index  matching
2887      452      355     False
5635     1127     2198     False
1247      371     1159     False
5989      683     3132     False
2590      967     1093     False
...       ...      ...       ...
3217      883       99     False
1264      556     2313     False
1213      753     2791     False
5756      518     1514     False
5774      587     3091     False

[700 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.44999999999999996,
 'test_loss': 0.4491102993488312,
 'test_prec': 0.5421686746987951,
 'test_recall': 0.38461538461538464}
--------------------------------------------------------------------------------

Test : 800
-- Random test --

      a.index  b.index  matching
804      1199      580      True
3760      218      959     False
3244     1282     2154     False
47       1186     2393     False
1669      161     2982     False
...       ...      ...       ...
124       606     1183     False
5145      251     1828     False
2276      274     3014     False
6304      269      808     False
3054      854     1134     False

[800 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5395348837209303,
 'test_loss': 0.39810729026794434,
 'test_prec': 0.5918367346938775,
 'test_recall': 0.49572649572649574}
--------------------------------------------------------------------------------

Test : 900
-- Random test --

      a.index  b.index  matching
5052     1262      921     False
810      1064     2836     False
408       605     3171     False
2976      970     1648     False
1492     1353     2804     False
...       ...      ...       ...
975      1170     1368     False
3672      588       70     False
54       1111     2839     False
4740      481     2459      True
6713     1194      573      True

[900 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5721153846153846,
 'test_loss': 0.3075709044933319,
 'test_prec': 0.6538461538461539,
 'test_recall': 0.5085470085470085}
--------------------------------------------------------------------------------

Test : 1000
-- Random test --

      a.index  b.index  matching
6300      736     2471     False
6830      312      577      True
5179      599     1666     False
4056     1175      515     False
6715      292     2973     False
...       ...      ...       ...
2586     1308     2386     False
4927      284     3024     False
3129      882     3192     False
2361      272     2292     False
5593      587     1137     False

[1000 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5253012048192771,
 'test_loss': 0.36390548944473267,
 'test_prec': 0.6022099447513812,
 'test_recall': 0.4658119658119658}
--------------------------------------------------------------------------------

Test : 6874
-- Random test --

      a.index  b.index  matching
1084     1044     2540     False
5241      608       70     False
1991      963      869      True
3535      516      242     False
5811       87     2863     False
...       ...      ...       ...
253       599      836     False
2787      737      444     False
3136     1114     1420      True
5765      753     2688     False
3183      376      219     False

[6874 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6909090909090909,
 'test_loss': 0.2799018621444702,
 'test_prec': 0.7378640776699029,
 'test_recall': 0.6495726495726496}
--------------------------------------------------------------------------------
New cross validation 1

Test : 50
-- Random test --

      a.index  b.index  matching
1703      827     2167     False
3659      976     1492      True
6032       27     1447      True
785       322      182     False
6170      250     2791     False
189       180     1542      True
782        41     2043      True
1621     1160     2158     False
668      1145     1162     False
711       722     2370     False
3813      322      426     False
803      1186     1213     False
3919      923      902     False
6485      565       70     False
3842      208     3164     False
84        518     3091     False
5783      518     2803     False
4185      208     1844     False
5748     1092     3124     False
3041      957     1068     False
4472      592      354     False
6648      575      886     False
6681     1183      993     False
74        225     3199     False
6696     1255     2145     False
2314      778     2574      True
3734      389     2008     False
471      1345     2909     False
1762      572      338     False
1946      282     2072     False
6811     1287      204     False
6376      620     2391     False
1012      970     2219     False
1598     1321     2501     False
3289     1282      932     False
3931     1114     1966     False
5409      846      422      True
3555      642      372     False
6860      371     3175     False
2663     1196     2045     False
780       613     2894     False
1628      636      277      True
5914      321     2314     False
5216      273     3092     False
4257     1290     1080     False
5038      837      986     False
1441      359     2355     False
6711      371     2497     False
4225      646     2313     False
1510     1257      782     False
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.2632538676261902,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 75
-- Random test --

      a.index  b.index  matching
3739      528     1350     False
6173      516      176     False
1903      113     1075     False
3809      216      354     False
5367      543     2607     False
...       ...      ...       ...
5987      787     1118     False
4566      589     3033     False
1969      989     1226     False
6706      225     1585     False
383       196      405     False

[75 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.45709142088890076,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 100
-- Random test --

      a.index  b.index  matching
3883      508      917     False
3509      216      954     False
1602      497     3204     False
3890      371     1095     False
5453      522     3204     False
...       ...      ...       ...
1798      521     1808      True
34        584     2518     False
320       484      521     False
1281      591     2200     False
3563      513     2131     False

[100 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.3670588235294117,
 'test_loss': 0.36074987053871155,
 'test_prec': 0.4083769633507853,
 'test_recall': 0.3333333333333333}
--------------------------------------------------------------------------------

Test : 120
-- Random test --

      a.index  b.index  matching
5354      536      902     False
2704      316      793     False
1069      892      800      True
2455      251     2837     False
6607      858     1010     False
...       ...      ...       ...
6291      944      153     False
260       273     3133     False
4017      750     1816     False
6168     1159     2117      True
2104     1001     2339     False

[120 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.3133922815322876,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 140
-- Random test --

      a.index  b.index  matching
4818     1174      371     False
3866      347     2159     False
2833      597      372     False
547       514      924     False
3109      971     3048     False
...       ...      ...       ...
5086      823     3171     False
6491      492      332     False
2431      565       99     False
5057     1285     2656     False
6087      981     3014     False

[140 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.4722222222222222,
 'test_loss': 0.29632580280303955,
 'test_prec': 0.5151515151515151,
 'test_recall': 0.4358974358974359}
--------------------------------------------------------------------------------

Test : 160
-- Random test --

      a.index  b.index  matching
626       731     2143     False
3277       90     2791     False
4153      620      911     False
3059      705      792     False
4928     1190     2926     False
...       ...      ...       ...
3645      837      361     False
4809      497     1001     False
3950      261     1739     False
4251      662     1497     False
3848      556     3016      True

[160 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.17204301075268819,
 'test_loss': 0.44958049058914185,
 'test_prec': 0.5333333333333333,
 'test_recall': 0.10256410256410256}
--------------------------------------------------------------------------------

Test : 180
-- Random test --

      a.index  b.index  matching
4885      452      257     False
4188      354     2869      True
6275      781      998     False
6556        3     1361     False
6229      731     3009     False
...       ...      ...       ...
394       273     1265     False
1925     1220      559      True
6011      589     1136     False
6104      516      917     False
5698      599     3022     False

[180 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5245346869712352,
 'test_loss': 0.3269461989402771,
 'test_prec': 0.4341736694677871,
 'test_recall': 0.6623931623931624}
--------------------------------------------------------------------------------

Test : 200
-- Random test --

      a.index  b.index  matching
1518      255     3134     False
898       736     2671     False
5649      484     1696     False
6109      519     1163     False
2671      524     1409     False
...       ...      ...       ...
178      1170     1085     False
4651      189     1508      True
3596     1284     1427     False
6241        5     1640     False
6553      511     1075     False

[200 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.49627791563275436,
 'test_loss': 0.29814770817756653,
 'test_prec': 0.591715976331361,
 'test_recall': 0.42735042735042733}
--------------------------------------------------------------------------------

Test : 250
-- Random test --

      a.index  b.index  matching
5263     1174      893     False
6664      487     1525     False
2701      248       16     False
4785      291     3004     False
790       157      107     False
...       ...      ...       ...
4198      369     1442     False
1143     1244     1066     False
1474     1122      442     False
2713      837      263     False
2298      851     2447      True

[250 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.3716381418092909,
 'test_loss': 0.5277361273765564,
 'test_prec': 0.4342857142857143,
 'test_recall': 0.3247863247863248}
--------------------------------------------------------------------------------

Test : 300
-- Random test --

      a.index  b.index  matching
925       135     3160     False
2309     1021      312     False
5719        5     1889     False
2540      971     3021     False
3178      547     2847     False
...       ...      ...       ...
2773     1258     2044     False
4083      270      168     False
66        271      959     False
1237      257      728     False
956       574     1170     False

[300 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.37209302325581395,
 'test_loss': 0.39885130524635315,
 'test_prec': 0.40816326530612246,
 'test_recall': 0.3418803418803419}
--------------------------------------------------------------------------------

Test : 400
-- Random test --

      a.index  b.index  matching
6242     1166     2505     False
247       987      825      True
6249      165     1111     False
1950       35     2283     False
1915     1286     2739      True
...       ...      ...       ...
3119      574     1075     False
5086      823     3171     False
6818     1114     1360     False
4456      618     1129     False
1919     1037      769     False

[400 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.512249443207127,
 'test_loss': 0.42590147256851196,
 'test_prec': 0.5348837209302325,
 'test_recall': 0.49145299145299143}
--------------------------------------------------------------------------------

Test : 500
-- Random test --

      a.index  b.index  matching
5324     1279     3025     False
1238      605     3029     False
2631     1308      900     False
3004      546      216     False
4517      604       73     False
...       ...      ...       ...
6655     1341     2996     False
384      1309      662      True
3079      632      924      True
2082       93     2137     False
533      1170     2130     False

[500 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.33057212829589844,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 600
-- Random test --

      a.index  b.index  matching
4900      511     2848     False
2734      474     1075     False
1264      556     2313     False
739       910       91     False
2505     1078      204     False
...       ...      ...       ...
4676      572      367     False
2980       15     3089     False
6863     1264     2937     False
5515       44     3021     False
5211      605     2480     False

[600 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.47572815533980584,
 'test_loss': 0.324851393699646,
 'test_prec': 0.550561797752809,
 'test_recall': 0.4188034188034188}
--------------------------------------------------------------------------------

Test : 700
-- Random test --

      a.index  b.index  matching
2342      578     1207     False
3508      361     1865     False
6010      209      128     False
4697     1361     2242     False
2657      930      151     False
...       ...      ...       ...
3292      593      368     False
4905      827     1086     False
5546       39     2052      True
3793      532     1402     False
6705      584     1715     False

[700 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.528395061728395,
 'test_loss': 0.3037694990634918,
 'test_prec': 0.6257309941520468,
 'test_recall': 0.45726495726495725}
--------------------------------------------------------------------------------

Test : 800
-- Random test --

      a.index  b.index  matching
280       139      893     False
4931       87     2867     False
3507      271     3187     False
3714      553      893     False
5535      320     1016     False
...       ...      ...       ...
5549      361     1612     False
795      1272     1033     False
1144      123     1740      True
4551      557     1146     False
533      1170     2130     False

[800 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.4927536231884058,
 'test_loss': 0.3605569005012512,
 'test_prec': 0.5666666666666667,
 'test_recall': 0.4358974358974359}
--------------------------------------------------------------------------------

Test : 900
-- Random test --

      a.index  b.index  matching
4040      858     2847     False
3561     1275     2936     False
2706      547     3204     False
5853      276     2804     False
6010      209      128     False
...       ...      ...       ...
3559      490     2497     False
6684     1232     2418     False
3153      140      151     False
523        27     3060     False
674        97     1087     False

[900 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6438356164383562,
 'test_loss': 0.28565922379493713,
 'test_prec': 0.6911764705882353,
 'test_recall': 0.6025641025641025}
--------------------------------------------------------------------------------

Test : 1000
-- Random test --

      a.index  b.index  matching
1517        3      788     False
2508     1185      792     False
3732      371     2821     False
3189     1262      923     False
2402      544     1159     False
...       ...      ...       ...
895       592     2177     False
218      1279     3134     False
1366      313     2888     False
611       779     2030     False
2215     1234     2593      True

[1000 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.503562945368171,
 'test_loss': 0.30165335536003113,
 'test_prec': 0.5668449197860963,
 'test_recall': 0.452991452991453}
--------------------------------------------------------------------------------

Test : 6874
-- Random test --

      a.index  b.index  matching
1830      690      147     False
1466      672     1240     False
2249     1242     1068     False
6847      946     2544     False
5804      852     3160     False
...       ...      ...       ...
6263      892      192     False
6009      538     2852     False
226        93     2867     False
600       653     3202     False
3077      371     2257     False

[6874 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7080459770114943,
 'test_loss': 0.2539353370666504,
 'test_prec': 0.7661691542288557,
 'test_recall': 0.6581196581196581}
--------------------------------------------------------------------------------
New cross validation 2

Test : 50
-- Random test --

      a.index  b.index  matching
1199      924     2574     False
1139     1275     1433     False
6619     1051     2360      True
514      1183     1177     False
5117      550     2818     False
272       584      111     False
4565      443     2252     False
6385     1210     1579     False
5595      823     3029     False
4594      183     2159     False
1998      614     3183     False
3360        6     2839     False
1229       26      448     False
1488      608      324     False
1627      981     3009     False
1456      799     2615     False
5700     1341      196     False
1661      608     1763     False
5379        3     1066     False
3103     1246     1256     False
6269     1028     2296     False
5995      165      109     False
2261     1017     1623     False
368       287     2616     False
4229     1084     2067      True
554      1167      907      True
2900      852      312     False
4805      751     2358     False
5459      316     1334     False
1616      662     1773     False
413      1118     3188     False
4737      497     1569      True
1801      645      273     False
4983     1145     1075     False
5206      867     2510     False
763       857     2251     False
1949      531       16     False
4982     1024     2432     False
1743      186     1497     False
3639     1282      190     False
884      1333      993      True
6567      574     2480     False
6739     1322      216     False
2905      858     2837     False
6309     1282     2524     False
5397      511     3027     False
4157      736      911     False
5818       26      568     False
1048      316      268     False
6867      298     2966     False
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.27798327803611755,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 75
-- Random test --

      a.index  b.index  matching
5546       39     2052      True
5012      602       99     False
3162      576     2894     False
914       704      407      True
4806      602     3188     False
...       ...      ...       ...
1513      547      998     False
4281      139     3188     False
5030     1257     2587     False
2868      660     2907     False
5674      753     1514     False

[75 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.08799999999999998,
 'test_loss': 0.3759765625,
 'test_prec': 0.6875,
 'test_recall': 0.04700854700854701}
--------------------------------------------------------------------------------

Test : 100
-- Random test --

      a.index  b.index  matching
3359     1298      698      True
531       490      915     False
455       772      324     False
2850      541     1170     False
702       804     1078     False
...       ...      ...       ...
725       181      632     False
5520      208      112     False
5838     1318     3119     False
5613      197     1998     False
5366      333     2177      True

[100 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.23595674335956573,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 120
-- Random test --

      a.index  b.index  matching
6543     1145     2837     False
1103     1229      444     False
6549      202     1517     False
4882      512     2497     False
6752      465       71     False
...       ...      ...       ...
6716      215       96     False
2480      559      954     False
1590     1069     3207     False
920       348     1011     False
778       659     1204     False

[120 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.3726235741444867,
 'test_loss': 0.34427887201309204,
 'test_prec': 0.3356164383561644,
 'test_recall': 0.4188034188034188}
--------------------------------------------------------------------------------

Test : 140
-- Random test --

      a.index  b.index  matching
145      1246     1236     False
813      1058     2069     False
1829      747     1021     False
6266      587     1748     False
4523      710     1566     False
...       ...      ...       ...
6630      270      352     False
2132     1244      199     False
3002     1005     2789     False
638       309      279     False
521      1176     2154     False

[140 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.4896073903002309,
 'test_loss': 0.3417312204837799,
 'test_prec': 0.5326633165829145,
 'test_recall': 0.452991452991453}
--------------------------------------------------------------------------------

Test : 160
-- Random test --

      a.index  b.index  matching
1510     1257      782     False
3014      523      375     False
607       589     2367      True
3534      264      984     False
5536      587     1473     False
...       ...      ...       ...
6639      128     1841     False
2403      548     3025     False
4313      851     3026     False
6375     1270      614     False
257       654     2833     False

[160 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5183585313174947,
 'test_loss': 0.32274356484413147,
 'test_prec': 0.5240174672489083,
 'test_recall': 0.5128205128205128}
--------------------------------------------------------------------------------

Test : 180
-- Random test --

      a.index  b.index  matching
1745      932      175      True
3574      606     2821     False
2349      736      430     False
831       158     1911     False
4135      400     2943     False
...       ...      ...       ...
1526      250      192     False
5942      532     3033     False
2346      257     1709     False
2436      620      921     False
4324      512      375     False

[180 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.27884615384615385,
 'test_loss': 0.43629950284957886,
 'test_prec': 0.31868131868131866,
 'test_recall': 0.24786324786324787}
--------------------------------------------------------------------------------

Test : 200
-- Random test --

      a.index  b.index  matching
4692      216      950     False
6644      119     1774      True
1403      452       68     False
5301      512     3160     False
4807      276     2996      True
...       ...      ...       ...
6550      512     1083     False
3862      208     1882     False
376      1064     2011     False
2897     1341      836     False
5706      739     2827     False

[200 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.39698492462311563,
 'test_loss': 0.3922521770000458,
 'test_prec': 0.4817073170731707,
 'test_recall': 0.33760683760683763}
--------------------------------------------------------------------------------

Test : 250
-- Random test --

      a.index  b.index  matching
1059      803     3161     False
5210      271     2847     False
5421      821     2073     False
3616      729     2860     False
3798     1034     3192     False
...       ...      ...       ...
5236      899      802     False
5072      829     1117     False
2619      993     1253     False
3686      220       56     False
5667     1329     3048     False

[250 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5570175438596491,
 'test_loss': 0.28408387303352356,
 'test_prec': 0.5720720720720721,
 'test_recall': 0.5427350427350427}
--------------------------------------------------------------------------------

Test : 300
-- Random test --

      a.index  b.index  matching
1579     1115      783     False
2307      501     2165     False
2366      981     3023     False
5345     1329     2804     False
3460     1072     2546     False
...       ...      ...       ...
6158      921      177      True
2502     1317      318     False
4924      211      559     False
4577       93     1129     False
1724      857     2505      True

[300 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.48330058939096265,
 'test_loss': 0.45911186933517456,
 'test_prec': 0.44727272727272727,
 'test_recall': 0.5256410256410257}
--------------------------------------------------------------------------------

Test : 400
-- Random test --

      a.index  b.index  matching
5549      361     1612     False
2885       35     1157     False
1984      199       65      True
3406     1290      313     False
3435      632      125     False
...       ...      ...       ...
6497      145     1364     False
2866      823     1636     False
127       333     2524     False
1998      614     3183     False
6245      474     2441     False

[400 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5450643776824035,
 'test_loss': 0.42046457529067993,
 'test_prec': 0.5474137931034483,
 'test_recall': 0.5427350427350427}
--------------------------------------------------------------------------------

Test : 500
-- Random test --

      a.index  b.index  matching
877       920     2558      True
5923     1269     2720     False
4429      441     2163      True
4155      216      426     False
4516      343     3058     False
...       ...      ...       ...
1659      580     1772     False
6443      614      915     False
1126     1067       12      True
4640      562     3032     False
4268      365     3099     False

[500 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.20845070422535208,
 'test_loss': 0.5565046072006226,
 'test_prec': 0.30578512396694213,
 'test_recall': 0.1581196581196581}
--------------------------------------------------------------------------------

Test : 600
-- Random test --

      a.index  b.index  matching
4040      858     2847     False
1964      361     3188     False
2463      320      900     False
5007     1114     2739     False
747      1347     2133     False
...       ...      ...       ...
1536     1151     2063     False
955       851     2920      True
2769       48     2074      True
2281       26      580     False
3025      139     1213     False

[600 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.33053221288515405,
 'test_loss': 0.34347549080848694,
 'test_prec': 0.4796747967479675,
 'test_recall': 0.25213675213675213}
--------------------------------------------------------------------------------

Test : 700
-- Random test --

      a.index  b.index  matching
3585     1105     2061     False
5118      177     1481      True
4244      406     3041     False
2083     1266     1089     False
2742      622     1538     False
...       ...      ...       ...
3587      738     1441     False
415      1145     1497     False
1272      563     1901     False
6579     1055     2774     False
2638      562      257     False

[700 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.3012048192771084,
 'test_loss': 0.39024618268013,
 'test_prec': 0.5102040816326531,
 'test_recall': 0.21367521367521367}
--------------------------------------------------------------------------------

Test : 800
-- Random test --

      a.index  b.index  matching
2201      267      371     False
2059     1078     2717     False
1870     1273     2473     False
3198      465      531     False
6728      546     1696      True
...       ...      ...       ...
2256      722     3167     False
1906     1264     3060     False
3516      944      801     False
2039      541     1014     False
3486     1299     3110     False

[800 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5563218390804598,
 'test_loss': 0.3123580813407898,
 'test_prec': 0.6019900497512438,
 'test_recall': 0.5170940170940171}
--------------------------------------------------------------------------------

Test : 900
-- Random test --

      a.index  b.index  matching
2957      923      426     False
3389     1110      433     False
3611      140      345     False
3096      723     1075     False
530       197     1841     False
...       ...      ...       ...
595        13     3082     False
2700     1257     1955     False
3480      520     3055     False
4623     1115     2468     False
1655     1353     1666     False

[900 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6293706293706293,
 'test_loss': 0.30861541628837585,
 'test_prec': 0.6923076923076923,
 'test_recall': 0.5769230769230769}
--------------------------------------------------------------------------------

Test : 1000
-- Random test --

      a.index  b.index  matching
4747      742     2617      True
2728      539     1350     False
905       604     1643     False
3607      930      566     False
3784      250     3003     False
...       ...      ...       ...
667       739      311     False
2226      593      430     False
2207      571     1137     False
719       175     3060     False
804      1199      580      True

[1000 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5488372093023256,
 'test_loss': 0.346893310546875,
 'test_prec': 0.6020408163265306,
 'test_recall': 0.5042735042735043}
--------------------------------------------------------------------------------

Test : 6874
-- Random test --

      a.index  b.index  matching
5389     1244     1273     False
4794      774      314     False
2521      606     1001     False
2651      606     2863     False
4957      371     1182     False
...       ...      ...       ...
1360      753     3160     False
3908      802     2598      True
4667      882     1566      True
1086      155     1893     False
5108      267      508     False

[6874 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7016706443914081,
 'test_loss': 0.22310146689414978,
 'test_prec': 0.7945945945945946,
 'test_recall': 0.6282051282051282}
--------------------------------------------------------------------------------
New cross validation 3

Test : 50
-- Random test --

      a.index  b.index  matching
3862      208     1882     False
977       829     3155     False
6803     1235      750     False
2914      778     2553     False
6585      670      566     False
4646      957     1061     False
2358      866     3060     False
2628     1349     1612     False
656       579     2529     False
2779      139     1842     False
5161      632      375     False
2565      355     2865     False
5845      851      792     False
5439      598      923     False
4720      858     1095     False
3350     1136      933      True
133       157     2503     False
6645      823     3199     False
5156      425     3039     False
2883      649     3063     False
6136     1145     1207     False
3798     1034     3192     False
22        719     3106     False
2271     1246     1300     False
3677       79      268     False
1219      775     2860     False
2469     1244     1034     False
2621     1052     2056     False
3774      642      568     False
5589      184     1525     False
1350       29      403     False
3898     1329      836     False
3863      350     1853     False
6268      733      565     False
5585     1123     2563     False
1317      528     1214     False
3642      348      945     False
2509      571     2816     False
2592      539      264     False
2846      737      902     False
5251     1272     2044     False
3236      900      629     False
1045      946     2547     False
2198      174     1583     False
4222      897      182     False
3376      176     2804     False
6350      621      298     False
2626     1075      991      True
1050      827     3024     False
5010      248     2513     False
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.3941219747066498,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 75
-- Random test --

      a.index  b.index  matching
3200      891     2811     False
2372      916     2557      True
2582      495     2234     False
5401      202     1648     False
2314      778     2574      True
...       ...      ...       ...
2266     1145     2165     False
904      1118      257     False
6562      447      672     False
6575      174     1190     False
6333     1293     2839     False

[75 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.3791126608848572,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 100
-- Random test --

      a.index  b.index  matching
3198      465      531     False
2376      585     2656     False
59        557      426     False
2647     1072      360     False
4242      648     2824     False
...       ...      ...       ...
25       1182     2398     False
5507      426     2334      True
5440      490     2833     False
401       518     2863     False
2086      431     1014     False

[100 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.22442244224422445,
 'test_loss': 0.2798629403114319,
 'test_prec': 0.4927536231884058,
 'test_recall': 0.1452991452991453}
--------------------------------------------------------------------------------

Test : 120
-- Random test --

      a.index  b.index  matching
371       804     2333     False
4013      923      331     False
1525     1118     3161     False
6504      135     1701     False
1445      944     2081     False
...       ...      ...       ...
5163      512     1473     False
4423      394     2159     False
5080      753     1007     False
441       957      857      True
5928     1337     2123     False

[120 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.43540669856459324,
 'test_loss': 0.3002016544342041,
 'test_prec': 0.4945652173913043,
 'test_recall': 0.3888888888888889}
--------------------------------------------------------------------------------

Test : 140
-- Random test --

      a.index  b.index  matching
6190      540     3111     False
3296      589     3038      True
5200      467     3045     False
3034      515     3014     False
6290      389     3016     False
...       ...      ...       ...
2246      883      921      True
6694      781     1514     False
599       502       57     False
5493      604      111     False
1313      738     2039     False

[140 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.3462686567164179,
 'test_loss': 0.3857223391532898,
 'test_prec': 0.5742574257425742,
 'test_recall': 0.24786324786324787}
--------------------------------------------------------------------------------

Test : 160
-- Random test --

      a.index  b.index  matching
1024      176     2501     False
4835      310     2082     False
3184     1246     1034     False
3229      523     2419     False
5883      309     2095     False
...       ...      ...       ...
6504      135     1701     False
6312      586        0     False
6554      753     2853     False
6826      265      242     False
6697     1066     2050     False

[160 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.25139477849006653,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 180
-- Random test --

      a.index  b.index  matching
4461      662     1011     False
3570      617     3168     False
5241      608       70     False
1256      518     1512     False
3003     1117     1431      True
...       ...      ...       ...
1693      361     1842     False
3772      958      554      True
1604      492     2818     False
3563      513     2131     False
4548      642      352      True

[180 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.4885496183206107,
 'test_loss': 0.32695135474205017,
 'test_prec': 0.4413793103448276,
 'test_recall': 0.5470085470085471}
--------------------------------------------------------------------------------

Test : 200
-- Random test --

      a.index  b.index  matching
1704      606     2497     False
5567     1152      261     False
5551      512     2468     False
1399     1175     2236     False
5300      571     1010     False
...       ...      ...       ...
2802      267     2391     False
2508     1185      792     False
116       378     2628      True
2100      454     2136      True
1849      443     2419     False

[200 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.47058823529411764,
 'test_loss': 0.35188570618629456,
 'test_prec': 0.5235602094240838,
 'test_recall': 0.42735042735042733}
--------------------------------------------------------------------------------

Test : 250
-- Random test --

      a.index  b.index  matching
2099      973     1648     False
5838     1318     3119     False
208       517     1180     False
3570      617     3168     False
2820       59     2908     False
...       ...      ...       ...
4193      480     2757     False
4745      592      953     False
1633      737      508     False
4657      565     1213     False
3014      523      375     False

[250 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.41543026706231456,
 'test_loss': 0.4111061096191406,
 'test_prec': 0.6796116504854369,
 'test_recall': 0.29914529914529914}
--------------------------------------------------------------------------------

Test : 300
-- Random test --

      a.index  b.index  matching
4365      516       99     False
6360      839     1151     False
4999     1212      548      True
3523     1226      503      True
525       513     2153     False
...       ...      ...       ...
5115      751     3151     False
3440       90     1908     False
879       822     2811     False
5930      553      902     False
6160     1345     3221     False

[300 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5281553398058253,
 'test_loss': 0.29511699080467224,
 'test_prec': 0.48398576512455516,
 'test_recall': 0.5811965811965812}
--------------------------------------------------------------------------------

Test : 400
-- Random test --

      a.index  b.index  matching
4538      847     1841     False
4128      971     3022     False
4267      251     1791     False
1740      799     2592      True
1804      851     2426     False
...       ...      ...       ...
4647     1105     1039     False
706       171     3091     False
5296      599     3048     False
51        773     1182     False
5173      670      904     False

[400 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5092592592592594,
 'test_loss': 0.4271295368671417,
 'test_prec': 0.5555555555555556,
 'test_recall': 0.4700854700854701}
--------------------------------------------------------------------------------

Test : 500
-- Random test --

      a.index  b.index  matching
4166      528     1036     False
4259      562     1564     False
1398     1001     2071     False
4108      923     2860     False
2692      587     1007     False
...       ...      ...       ...
6734     1148     3028     False
770       796     2521     False
349       298      946     False
4439      944      175     False
3522       15      192     False

[500 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.558252427184466,
 'test_loss': 0.387970507144928,
 'test_prec': 0.6460674157303371,
 'test_recall': 0.49145299145299143}
--------------------------------------------------------------------------------

Test : 600
-- Random test --

      a.index  b.index  matching
3648      793     2570      True
2651      606     2863     False
160       689     2932     False
2345      948     2054     False
4461      662     1011     False
...       ...      ...       ...
4957      371     1182     False
722       618     2141     False
3678      970      734     False
6391      581     2396     False
3288      512      367     False

[600 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.512141280353201,
 'test_loss': 0.45380955934524536,
 'test_prec': 0.5296803652968036,
 'test_recall': 0.49572649572649574}
--------------------------------------------------------------------------------

Test : 700
-- Random test --

      a.index  b.index  matching
3455      523      959     False
6615      273     3063     False
2123      123      506     False
4011      941     2425     False
5967     1212     2072     False
...       ...      ...       ...
156       804     2401     False
4797      174     1164     False
6508     1004      784     False
5353     1272     3026     False
5158       92      734     False

[700 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.634989200863931,
 'test_loss': 0.3054632544517517,
 'test_prec': 0.6419213973799127,
 'test_recall': 0.6282051282051282}
--------------------------------------------------------------------------------

Test : 800
-- Random test --

      a.index  b.index  matching
617      1076     2067     False
5249      852     1188     False
5065      465     3043     False
1489      570     2270     False
6084      547     1207     False
...       ...      ...       ...
1414      705     2399     False
2611      246     3117     False
1961      705     3089     False
755       480     3221     False
4141     1290     2720     False

[800 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5646551724137931,
 'test_loss': 0.37153980135917664,
 'test_prec': 0.5695652173913044,
 'test_recall': 0.5598290598290598}
--------------------------------------------------------------------------------

Test : 900
-- Random test --

      a.index  b.index  matching
5048      753      332     False
5518      897      338     False
4867      322     2391     False
2303      490     2518     False
1683      181      288     False
...       ...      ...       ...
6211     1198     1265     False
2308     1145      831     False
1965      874     1068     False
6131     1241     3134     False
4230     1057     1531     False

[900 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5311778290993071,
 'test_loss': 0.33825331926345825,
 'test_prec': 0.5778894472361809,
 'test_recall': 0.49145299145299143}
--------------------------------------------------------------------------------

Test : 1000
-- Random test --

      a.index  b.index  matching
918       139     2112     False
4485      632     1132     False
767       689     3050     False
142        93     1512     False
4817      228     1687     False
...       ...      ...       ...
2830      389     1475     False
4421      858     2600     False
110       741     2860     False
2310      837     1151     False
6753     1038     2373     False

[1000 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.4769230769230769,
 'test_loss': 0.34692057967185974,
 'test_prec': 0.5961538461538461,
 'test_recall': 0.3974358974358974}
--------------------------------------------------------------------------------

Test : 6874
-- Random test --

      a.index  b.index  matching
4612      521     3109     False
1391      858     2195     False
1559      597     1842     False
5351     1136      415     False
6380      863      330     False
...       ...      ...       ...
2884      245     2994     False
712      1322      426     False
678       865     2205     False
5093      592      371     False
6706      225     1585     False

[6874 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7130044843049327,
 'test_loss': 0.26586776971817017,
 'test_prec': 0.75,
 'test_recall': 0.6794871794871795}
--------------------------------------------------------------------------------
New cross validation 4

Test : 50
-- Random test --

      a.index  b.index  matching
3945      520     2843     False
5927      890     3023      True
77       1299      697      True
1888      511      342     False
1144      123     1740      True
4423      394     2159     False
1658     1277     1031      True
5901     1127     2789     False
5133      208       60     False
5163      512     1473     False
4817      228     1687     False
4456      618     1129     False
1104      774     1150     False
6088     1275     2432      True
2746      897     3188     False
987       881     2584     False
3527      624     2762     False
363        44     2143     False
4870      556      836     False
5874     1357      614      True
2335      548     2122     False
34        584     2518     False
2131     1269     2402     False
3005      814     1397     False
6452       47     2072     False
2432      258      777     False
6328      562      338     False
3023      444     2909     False
302       740      930      True
5286      516     2112     False
2027      174     1534     False
5141       54      415     False
188       348     1585      True
2024      213      129     False
2507     1265      470      True
5021     1264     1033     False
3144     1264     3026     False
4669      599      307     False
3250      863     2789     False
4120     1329     3022     False
1791      711      251     False
2480      559      954     False
253       599      836     False
5669      348     2441     False
2615     1105     2402     False
1996      157     1733     False
1519      951      891      True
5613      197     1998     False
4598      342     3049     False
6396     1195     3103     False
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.2715727388858795,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 75
-- Random test --

      a.index  b.index  matching
1696     1038     2339      True
2553      547     1075     False
1402       12     1968     False
1765     1118      369     False
976       934      793     False
...       ...      ...       ...
6292     1174      897     False
1650      751     2502     False
152         3     1256     False
5827     1149      985     False
5764      181     1538      True

[75 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.25730642676353455,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 100
-- Random test --

      a.index  b.index  matching
4804       80      544     False
1607      460     2512      True
6660      555     3108     False
6765      781     2195     False
5286      516     2112     False
...       ...      ...       ...
3309      627     1449     False
4270      482     3130     False
81       1177     1163     False
295       519     1788     False
2948      651      317      True

[100 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.3087557603686636,
 'test_loss': 0.306304395198822,
 'test_prec': 0.335,
 'test_recall': 0.2863247863247863}
--------------------------------------------------------------------------------

Test : 120
-- Random test --

      a.index  b.index  matching
59        557      426     False
4870      556      836     False
4654      829        2     False
6598     1286     2935      True
5392      135       16     False
...       ...      ...       ...
5744     1324     2984     False
685       722     2238     False
5574     1174      485     False
2439      779     2669     False
1500      941     2263     False

[120 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.40933743119239807,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 140
-- Random test --

      a.index  b.index  matching
3599      508      367     False
2952      139      452     False
5156      425     3039     False
4380      638      294     False
1321     1237      509      True
...       ...      ...       ...
3221      543      176     False
2386     1001      741     False
6134      518     1095     False
5012      602       99     False
3798     1034     3192     False

[140 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5,
 'test_loss': 0.36940884590148926,
 'test_prec': 0.5396039603960396,
 'test_recall': 0.4658119658119658}
--------------------------------------------------------------------------------

Test : 160
-- Random test --

      a.index  b.index  matching
2853      287     2620     False
410       255     3055     False
2030      396     3134     False
2160      615      192     False
5430      799     1076     False
...       ...      ...       ...
3873      283     2988     False
1023     1179     2821     False
5961      271     3194     False
1715      301     2984     False
3131     1095      538     False

[160 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.2752688172043011,
 'test_loss': 0.592937707901001,
 'test_prec': 0.27705627705627706,
 'test_recall': 0.27350427350427353}
--------------------------------------------------------------------------------

Test : 180
-- Random test --

      a.index  b.index  matching
456      1118      921     False
4633      271     1001     False
6450      923      358     False
6592      942     2080     False
4904      518     3190     False
...       ...      ...       ...
3203      492     3126     False
6392     1132     1618     False
6700      135      192     False
2216      225     2821     False
1700      523     2959     False

[180 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.48163265306122444,
 'test_loss': 0.32712143659591675,
 'test_prec': 0.4609375,
 'test_recall': 0.5042735042735043}
--------------------------------------------------------------------------------

Test : 200
-- Random test --

      a.index  b.index  matching
5188     1143     3106     False
3908      802     2598      True
2517       41     1128     False
4825     1130      986     False
668      1145     1162     False
...       ...      ...       ...
5477      615      368      True
2436      620      921     False
599       502       57     False
2448      897      893     False
6444       82     2992     False

[200 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.43414634146341463,
 'test_loss': 0.35985544323921204,
 'test_prec': 0.5056818181818182,
 'test_recall': 0.3803418803418803}
--------------------------------------------------------------------------------

Test : 250
-- Random test --

      a.index  b.index  matching
2594      496     3126     False
4347      389     1655     False
5913      349     2045     False
625      1294      703      True
5735      258     2193     False
...       ...      ...       ...
239      1283      496      True
387       735      185     False
4644      396     1214     False
4612      521     3109     False
1021       88     2112     False

[250 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.42372881355932207,
 'test_loss': 0.3931083679199219,
 'test_prec': 0.625,
 'test_recall': 0.32051282051282054}
--------------------------------------------------------------------------------

Test : 300
-- Random test --

      a.index  b.index  matching
1646      442     2180      True
4643     1064     1561     False
5943     1284     2926     False
4484      432     2414     False
1864      946     2018     False
...       ...      ...       ...
5966      840     2941      True
451       902     2605      True
4204      946     1821     False
3021      605      998      True
1035      515     1655     False

[300 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.46543778801843316,
 'test_loss': 0.40093231201171875,
 'test_prec': 0.505,
 'test_recall': 0.43162393162393164}
--------------------------------------------------------------------------------

Test : 400
-- Random test --

      a.index  b.index  matching
4875     1024     2399     False
701       566      316     False
2913     1127      208     False
4613      346     3144     False
4552     1119     2253     False
...       ...      ...       ...
1909      618      291      True
2573       76      533     False
1088      516     1842     False
1272      563     1901     False
2923      560     2216     False

[400 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.3263672888278961,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 500
-- Random test --

      a.index  b.index  matching
5172     1113     3185     False
4242      648     2824     False
4706     1078     2765     False
20        709     1548     False
1678      523      286     False
...       ...      ...       ...
3362      420     1837     False
3592     1244     1312     False
5953     1015     1134     False
2802      267     2391     False
6085     1329     3023     False

[500 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5226130653266332,
 'test_loss': 0.34519413113594055,
 'test_prec': 0.6341463414634146,
 'test_recall': 0.4444444444444444}
--------------------------------------------------------------------------------

Test : 600
-- Random test --

      a.index  b.index  matching
4501      729     2852     False
3826      273     1367     False
425       322      216     False
3648      793     2570      True
6826      265      242     False
...       ...      ...       ...
6796     1001      219     False
2420      642      465     False
1285     1334       75     False
2950      553      917     False
5591      599     3023     False

[600 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5088161209068011,
 'test_loss': 0.3573947250843048,
 'test_prec': 0.6196319018404908,
 'test_recall': 0.43162393162393164}
--------------------------------------------------------------------------------

Test : 700
-- Random test --

      a.index  b.index  matching
5494     1001     2589     False
2596      225     3215     False
882       549      731     False
4100      577      122     False
3503      119     1586     False
...       ...      ...       ...
3149     1148     3160     False
4029     1251      533      True
6628      858     3199     False
3148      825     2871     False
4251      662     1497     False

[700 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5432692307692307,
 'test_loss': 0.328224778175354,
 'test_prec': 0.6208791208791209,
 'test_recall': 0.4829059829059829}
--------------------------------------------------------------------------------

Test : 800
-- Random test --

      a.index  b.index  matching
5265     1096      383     False
6169      892      911     False
2638      562      257     False
159       837     2606     False
6703       26      977     False
...       ...      ...       ...
2478      761     1852     False
296      1336      677     False
5202     1024     2937     False
1259      558     3022     False
1946      282     2072     False

[800 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.572093023255814,
 'test_loss': 0.3299936354160309,
 'test_prec': 0.6275510204081632,
 'test_recall': 0.5256410256410257}
--------------------------------------------------------------------------------

Test : 900
-- Random test --

      a.index  b.index  matching
2965      532     3092     False
6286     1293     3003     False
2548      642     2377     False
5124      233     2840     False
1805     1022     1534     False
...       ...      ...       ...
1226      520     1016     False
3988      456      565     False
663       105      647     False
5746      118     1771      True
4202      767      379      True

[900 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5476190476190477,
 'test_loss': 0.33742502331733704,
 'test_prec': 0.6182795698924731,
 'test_recall': 0.49145299145299143}
--------------------------------------------------------------------------------

Test : 1000
-- Random test --

      a.index  b.index  matching
5762      371     2803     False
1322     1322      917     False
3682      165     1983     False
3891      137       65     False
2013     1065     1629     False
...       ...      ...       ...
5046      736       99     False
1191      923      954     False
5478      225     2600     False
172       146     2816     False
4425     1170     2370     False

[1000 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5323741007194244,
 'test_loss': 0.44529590010643005,
 'test_prec': 0.6065573770491803,
 'test_recall': 0.47435897435897434}
--------------------------------------------------------------------------------

Test : 6874
-- Random test --

      a.index  b.index  matching
206       223       82     False
6819     1253      532      True
3282     1045     3106     False
2080     1329      307     False
6698      107     2807     False
...       ...      ...       ...
3345       19      609     False
80       1136     3185     False
5561     1306      632     False
651       140     3032     False
6814     1127      292     False

[6874 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7276887871853547,
 'test_loss': 0.25946909189224243,
 'test_prec': 0.7832512315270936,
 'test_recall': 0.6794871794871795}
--------------------------------------------------------------------------------
Could not create dir out, File exists
    ########### 



New Dataset: <function deepmatcher_structured_dblp_acm at 0x1553060e6ca0>
New cross validation 0

Test : 50
-- Random test --

      a.index  b.index  matching
5483     2005     1052     False
4556     1538       98     False
4056      144     2225     False
1811     2237     1472     False
763      1136     1148      True
3515     2179     1787     False
1142     2495     1632     False
5365      123      418     False
6608     1975       72     False
2478     2350     2261     False
6658      307     2159     False
4701     1439     1512     False
6343     2246     1953     False
1034      628     1462     False
7173       55      545     False
4631      466     2050     False
3666     1044     1042     False
5023     1181      455     False
3089      747      340     False
2034      445      239      True
5284     1287     1088     False
5840     2203      342     False
6384     2436      600      True
2908     1658      850     False
5820     2486     1160     False
965      1480      855     False
6334     1812     1138      True
1803      899      371     False
169       198      778     False
5277     2233     1304      True
1618     1616     1909     False
4247      778     1751      True
4318     1542      777     False
4525     1530      640     False
5371     2232      591     False
3001      987     1194     False
3379     2357      213     False
7362     2209     1827      True
4816      545     1448     False
4899     2307     1942      True
736       932      688     False
4604     2119     1987     False
877      1577     1596     False
2272     2246      258     False
3862      854     1046     False
101       507      443     False
6556     1132      181      True
1042     2115      190      True
7288     1231      923     False
7180     2402     1048     False
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8914893617021276,
 'test_loss': 0.11002955585718155,
 'test_prec': 0.844758064516129,
 'test_recall': 0.9436936936936937}
--------------------------------------------------------------------------------

Test : 75
-- Random test --

      a.index  b.index  matching
1748     2091     1746     False
4432     1448      127     False
1956     1993      497     False
1213     2191     1601     False
5382     2267     1836     False
...       ...      ...       ...
5663      939     1632     False
5595     1409     1390     False
5967     1722     1837     False
6266      854      932     False
1598     2375     1116      True

[75 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9166666666666666,
 'test_loss': 0.14198830723762512,
 'test_prec': 0.8719512195121951,
 'test_recall': 0.9662162162162162}
--------------------------------------------------------------------------------

Test : 100
-- Random test --

      a.index  b.index  matching
5619     1253      356     False
3374     2014     1071     False
593      1923     1733      True
5173       22      990     False
4191     1395     1097     False
...       ...      ...       ...
2220      162      822     False
4276      121     1261     False
4946      775      344      True
3383     1738      147     False
4616     1610     1650     False

[100 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9546961325966851,
 'test_loss': 0.06913594156503677,
 'test_prec': 0.9370932754880694,
 'test_recall': 0.972972972972973}
--------------------------------------------------------------------------------

Test : 120
-- Random test --

      a.index  b.index  matching
5196     2450     1083     False
5146     1218     1227      True
6158      753      879     False
1134     2201      957      True
4867     1200      115      True
...       ...      ...       ...
6597      144      955     False
6722     1242      817     False
3488     2511      850     False
3795     1937     1487      True
5302      612     1991     False

[120 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9331848552338531,
 'test_loss': 0.083866648375988,
 'test_prec': 0.9229074889867841,
 'test_recall': 0.9436936936936937}
--------------------------------------------------------------------------------

Test : 140
-- Random test --

      a.index  b.index  matching
6780     1892      952     False
2225     1973     1383      True
7042      737     1162     False
2330      185     1552     False
5085     2102      967      True
...       ...      ...       ...
6114      973     1055     False
4667     2055      519      True
2912     1975     1839     False
7019      978     1522     False
7226      397     1915     False

[140 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9324618736383442,
 'test_loss': 0.09032835066318512,
 'test_prec': 0.9029535864978903,
 'test_recall': 0.963963963963964}
--------------------------------------------------------------------------------

Test : 160
-- Random test --

      a.index  b.index  matching
3929      628       78     False
5623      932     1313     False
6820     1361     1904     False
6799      743     1267     False
6867     1102     1166     False
...       ...      ...       ...
3433      843     1044     False
5847      994      817      True
1462      439     1574      True
3155     2613     1217     False
3647     1832     1909     False

[160 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9652855543113102,
 'test_loss': 0.04489080607891083,
 'test_prec': 0.9599109131403119,
 'test_recall': 0.9707207207207207}
--------------------------------------------------------------------------------

Test : 180
-- Random test --

      a.index  b.index  matching
5756      736      808     False
2555     2602      246     False
2472      356      581     False
4081      921      400      True
3353     1443      426      True
...       ...      ...       ...
4946      775      344      True
6265     1220     1587     False
6907     2224       53     False
543      1385     1755     False
4753     1022      917     False

[180 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9047619047619048,
 'test_loss': 0.1753530651330948,
 'test_prec': 0.8371647509578544,
 'test_recall': 0.9842342342342343}
--------------------------------------------------------------------------------

Test : 200
-- Random test --

      a.index  b.index  matching
6549     1899      598     False
6349     1659     2244     False
5713     2148      527     False
2399     2497     1715     False
5349      752     1692     False
...       ...      ...       ...
2805     1540     1961     False
1037     1369      669     False
4468     1209     1052     False
108      1049      242      True
2029      418     1525     False

[200 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.928950159066808,
 'test_loss': 0.13110044598579407,
 'test_prec': 0.8777555110220441,
 'test_recall': 0.9864864864864865}
--------------------------------------------------------------------------------

Test : 250
-- Random test --

      a.index  b.index  matching
6997     1753     1318     False
1537     2357      188      True
5444     1169     2201     False
3547      909     1756      True
6819     1245      688     False
...       ...      ...       ...
3124     1278       62     False
5797      661      419     False
4814     1811      481      True
468        40     1848     False
5380     1545     1308     False

[250 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9682539682539683,
 'test_loss': 0.05837712809443474,
 'test_prec': 0.9748858447488584,
 'test_recall': 0.9617117117117117}
--------------------------------------------------------------------------------

Test : 300
-- Random test --

      a.index  b.index  matching
5847      994      817      True
5581     2224     1752     False
661      2395        2     False
1628     2268     1373     False
2562     1187     1320     False
...       ...      ...       ...
1623     1848      512     False
2152     1139      320     False
573       410      973      True
4691     1689      589     False
6523      747      688     False

[300 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9751693002257337,
 'test_loss': 0.045520029962062836,
 'test_prec': 0.9773755656108597,
 'test_recall': 0.972972972972973}
--------------------------------------------------------------------------------

Test : 400
-- Random test --

      a.index  b.index  matching
6763      797     1884     False
3267     2595     1765     False
2674     1634     2182     False
4292      473       23      True
6748     1705      344     False
...       ...      ...       ...
6186     2287     1745     False
2334     1756     1345     False
6122     2154     2227     False
6128      984      590     False
5162      789      846     False

[400 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9741282339707535,
 'test_loss': 0.04496440663933754,
 'test_prec': 0.9730337078651685,
 'test_recall': 0.9752252252252253}
--------------------------------------------------------------------------------

Test : 500
-- Random test --

      a.index  b.index  matching
4503     2246     1519     False
5128     1180      266     False
1388     1388      763      True
5375     1540     2077     False
691       687      207     False
...       ...      ...       ...
342      1450      103     False
5873     1782      942      True
192      1369     2125     False
3233     1470      903     False
4397     1129      590     False

[500 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9830124575311437,
 'test_loss': 0.03526245802640915,
 'test_prec': 0.9886104783599089,
 'test_recall': 0.9774774774774775}
--------------------------------------------------------------------------------

Test : 600
-- Random test --

      a.index  b.index  matching
2233     2302     2276     False
5196     2450     1083     False
3113      595     1785     False
240      1129      268     False
6361     2540     1419     False
...       ...      ...       ...
4195     1360      636     False
7295     2560      404      True
59       2416      976      True
3751     1469      465      True
2647      256      497     False

[600 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9798657718120806,
 'test_loss': 0.03749088943004608,
 'test_prec': 0.9733333333333334,
 'test_recall': 0.9864864864864865}
--------------------------------------------------------------------------------

Test : 700
-- Random test --

      a.index  b.index  matching
1429     2338     2288      True
3039     2475     1245      True
640      1279     1167     False
4565     2005      459     False
4695     2508     2133     False
...       ...      ...       ...
3009     1885     1783     False
452      2598     1001     False
5140      542     1463     False
6206     1971     1744     False
2483     2123     1675     False

[700 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9784824462061155,
 'test_loss': 0.04025701433420181,
 'test_prec': 0.9840546697038725,
 'test_recall': 0.972972972972973}
--------------------------------------------------------------------------------

Test : 800
-- Random test --

      a.index  b.index  matching
4723      746     1751     False
5257      229     1667     False
3737     2098     1203     False
538      1849      715     False
4961      439     1659     False
...       ...      ...       ...
3929      628       78     False
1125     2535       40      True
2543      892        4     False
4559     1090      755     False
2240     1480     1880     False

[800 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9771689497716894,
 'test_loss': 0.03377987816929817,
 'test_prec': 0.9907407407407407,
 'test_recall': 0.963963963963964}
--------------------------------------------------------------------------------

Test : 900
-- Random test --

      a.index  b.index  matching
4611      787     1011     False
981      2209      463     False
4761     1066      382     False
3922      556     2198     False
4653     1090     1274     False
...       ...      ...       ...
6274     2395      501     False
1486     2383     1071      True
7282     1714     1270      True
2312     1159      688     False
5443      804        4     False

[900 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9829738933030647,
 'test_loss': 0.04017764702439308,
 'test_prec': 0.9908466819221968,
 'test_recall': 0.9752252252252253}
--------------------------------------------------------------------------------

Test : 1000
-- Random test --

      a.index  b.index  matching
1690     1074      664     False
6613       58     1765     False
6961     2160     1579      True
4538      743     1571     False
6213      783     1915     False
...       ...      ...       ...
3446      645     1599     False
5590      175     1164     False
7402     2091     1604     False
2712     1061     1918     False
7389      970     1630     False

[1000 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9694224235560589,
 'test_loss': 0.05295668542385101,
 'test_prec': 0.9749430523917996,
 'test_recall': 0.963963963963964}
--------------------------------------------------------------------------------

Test : 7417
-- Random test --

      a.index  b.index  matching
2469     2439       96      True
4067      754       57      True
1885     1899      619     False
6765     2492     1124      True
435      1336      932     False
...       ...      ...       ...
6873     1420      670      True
3236      705     2129     False
5911      909     1048     False
82        387      650     False
347       552      667     False

[7417 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.987598647125141,
 'test_loss': 0.024489274248480797,
 'test_prec': 0.9887133182844243,
 'test_recall': 0.9864864864864865}
--------------------------------------------------------------------------------
New cross validation 1

Test : 50
-- Random test --

      a.index  b.index  matching
2879     1004      342     False
441       743     1785      True
5410      757      510     False
4183      784      440     False
635       558      932     False
1201     1899      744     False
449       287     1016     False
6399     2474     2214     False
5160     1610     1679     False
1465      626      710      True
5386      915     2210     False
5187      925      379     False
6798     1452      512     False
2508     1724      238     False
1945     1788      577     False
4711       11     1051     False
3149      408     1774      True
1874     1139       93     False
4922      777      542     False
4427     1079      548     False
4404      381      736     False
2912     1975     1839     False
6535      257     1074     False
258      2188     1226     False
721      2008     1236      True
3858     1108     1758     False
7168       60      960     False
6076      458     2118      True
4606      816      663     False
4586     2578     1848      True
6832      691      620     False
6386     1033     1649     False
2924     2232     1648     False
597      2602     1939     False
21       1938       73      True
4301      644      582     False
2055     2081      225     False
5697     1729      329     False
895       644      225     False
6846     1450     1274     False
4402     1021        0     False
3548      153      759     False
3086     1116     1463     False
619      1440      361     False
7318      356      109     False
6086     1310     1935     False
3151      762     2082      True
5602     2037     1883     False
4549      880      990     False
1680      397      473     False
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.21136146783828735,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 75
-- Random test --

      a.index  b.index  matching
2712     1061     1918     False
4645     2294      689     False
4236     2273      419      True
3985     2111     2138     False
3243      688     2010     False
...       ...      ...       ...
5664     2413     2267      True
1222     1572     1362      True
4680     1044     1771     False
3052     1972     1827     False
7380      165     1669     False

[75 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9345372460496614,
 'test_loss': 0.09710187464952469,
 'test_prec': 0.9366515837104072,
 'test_recall': 0.9324324324324325}
--------------------------------------------------------------------------------

Test : 100
-- Random test --

      a.index  b.index  matching
5309      234      768     False
6627     1274     1262      True
4132     1050      689     False
3997     2395     1601     False
4359     1542      253     False
...       ...      ...       ...
3539     1892      589     False
656       135     1423     False
4236     2273      419      True
2170     1595     2196     False
5252     1388      756     False

[100 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6887608069164266,
 'test_loss': 0.45606207847595215,
 'test_prec': 0.956,
 'test_recall': 0.5382882882882883}
--------------------------------------------------------------------------------

Test : 120
-- Random test --

      a.index  b.index  matching
3361     1741     1119     False
3375     1940     1029     False
123       289     2250     False
1018     2391      226     False
3207      437     1252     False
...       ...      ...       ...
5455     1987      532      True
5866      978      179      True
1407      889      212     False
1609     1265     1603      True
3472      921     1203     False

[120 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9610678531701891,
 'test_loss': 0.057189952582120895,
 'test_prec': 0.9494505494505494,
 'test_recall': 0.972972972972973}
--------------------------------------------------------------------------------

Test : 140
-- Random test --

      a.index  b.index  matching
5632       78      262     False
4660     1864     2088      True
5543      547     2222      True
2479     1300       76     False
3520     1968     1049     False
...       ...      ...       ...
2856     2305     1906     False
5181     1459     1205     False
3316      976     1455     False
4276      121     1261     False
3457     1828     1901     False

[140 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9285714285714285,
 'test_loss': 0.09970565140247345,
 'test_prec': 0.89375,
 'test_recall': 0.9662162162162162}
--------------------------------------------------------------------------------

Test : 160
-- Random test --

      a.index  b.index  matching
4228      213     1860      True
2638        9     1318     False
2537     1159     1313     False
3915     2426     1667     False
949       336     2169      True
...       ...      ...       ...
1437     2562     1031     False
162      1105     1854     False
4833      472      551     False
3413     1116     1376     False
187       759     1897      True

[160 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9024896265560166,
 'test_loss': 0.15148557722568512,
 'test_prec': 0.8365384615384616,
 'test_recall': 0.9797297297297297}
--------------------------------------------------------------------------------

Test : 180
-- Random test --

      a.index  b.index  matching
2702      856      340     False
6845     2232     2024     False
35       1143     1812     False
6346      513     1717      True
5145      387      527     False
...       ...      ...       ...
6832      691      620     False
328       927     1511     False
1797       47     1133      True
6096      261     1931      True
4699     2123     1396     False

[180 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9456521739130435,
 'test_loss': 0.09751914441585541,
 'test_prec': 0.9138655462184874,
 'test_recall': 0.9797297297297297}
--------------------------------------------------------------------------------

Test : 200
-- Random test --

      a.index  b.index  matching
2967      711     1871      True
4191     1395     1097     False
86         21      306     False
497      1540     1912     False
7150      899     1814      True
...       ...      ...       ...
4542      289     1123     False
2935     2354       67     False
5173       22      990     False
4872     2308      202     False
3400     2143     1356     False

[200 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9649122807017545,
 'test_loss': 0.0476178303360939,
 'test_prec': 0.9401709401709402,
 'test_recall': 0.990990990990991}
--------------------------------------------------------------------------------

Test : 250
-- Random test --

      a.index  b.index  matching
4215     1690      695      True
1712      210     2154      True
4460       78        4     False
5014     1577     1049     False
7084     1346       53     False
...       ...      ...       ...
5927     2037      508     False
4498     1771     2019     False
4828      511      483      True
3760     1481      262     False
1677     1517     1798     False

[250 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8970438328236493,
 'test_loss': 0.17904503643512726,
 'test_prec': 0.819366852886406,
 'test_recall': 0.990990990990991}
--------------------------------------------------------------------------------

Test : 300
-- Random test --

      a.index  b.index  matching
2237     2232        4     False
826       169     1473     False
1004      304      334     False
1848      162     1881     False
478      1107      246     False
...       ...      ...       ...
732       130      530     False
5911      909     1048     False
4192     1028     1741     False
4712      615     1417      True
7340     1978      479      True

[300 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9632925472747497,
 'test_loss': 0.05813712254166603,
 'test_prec': 0.9516483516483516,
 'test_recall': 0.9752252252252253}
--------------------------------------------------------------------------------

Test : 400
-- Random test --

      a.index  b.index  matching
6448      935      755     False
6333      305      772      True
4532     2553     1342     False
7275     1015     1407     False
2528      374     1732     False
...       ...      ...       ...
3020     2308     2078     False
5415     2489      753      True
2402       26      755     False
135      1450     1454     False
1646     1867     1610      True

[400 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9843400447427293,
 'test_loss': 0.030296575278043747,
 'test_prec': 0.9777777777777777,
 'test_recall': 0.990990990990991}
--------------------------------------------------------------------------------

Test : 500
-- Random test --

      a.index  b.index  matching
3992     1229      354     False
672       448      238     False
7370     1159     1752     False
6028      385      694     False
1810     2602     1665     False
...       ...      ...       ...
3330        0      544     False
4290      475      911      True
4977      718     1640     False
3054      778     2077     False
4488     1015      501     False

[500 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9678135405105438,
 'test_loss': 0.05663560330867767,
 'test_prec': 0.9540481400437637,
 'test_recall': 0.9819819819819819}
--------------------------------------------------------------------------------

Test : 600
-- Random test --

      a.index  b.index  matching
6878     1430     1475      True
3387      181     1393     False
3764     1646     1915     False
2690     1220     1217     False
5603      612     1498     False
...       ...      ...       ...
3527      903      647     False
3510      970       87     False
617      2541      119      True
5335      185      254      True
3198      919      497     False

[600 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9796839729119639,
 'test_loss': 0.04240673407912254,
 'test_prec': 0.9819004524886877,
 'test_recall': 0.9774774774774775}
--------------------------------------------------------------------------------

Test : 700
-- Random test --

      a.index  b.index  matching
1479     1317     1147     False
4883      398      148     False
279       635     1902      True
2753     2209     1771     False
97       2371     2101     False
...       ...      ...       ...
2412     1099      637     False
6716     2303      269     False
5482      890      865      True
2        2476     1309     False
6559       15     1812     False

[700 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9864864864864865,
 'test_loss': 0.029115719720721245,
 'test_prec': 0.9864864864864865,
 'test_recall': 0.9864864864864865}
--------------------------------------------------------------------------------

Test : 800
-- Random test --

      a.index  b.index  matching
4621      644     1427     False
3285       78        0     False
872      1930      198     False
5391      783     2239      True
7412     2371     1189     False
...       ...      ...       ...
4452     1196      951     False
1651     1983     2098      True
346        31     1370     False
5559     2151     1225      True
3834      597     1867     False

[800 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9863325740318906,
 'test_loss': 0.03059123083949089,
 'test_prec': 0.9976958525345622,
 'test_recall': 0.9752252252252253}
--------------------------------------------------------------------------------

Test : 900
-- Random test --

      a.index  b.index  matching
4341     1670     1718     False
5849     1771      706     False
6412      361     1432     False
295       229      281     False
3232      512     1766     False
...       ...      ...       ...
505       169     1987      True
6325      987     1163     False
6173      810      917     False
1827     2554     1011     False
1588     2244     1216     False

[900 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9795454545454545,
 'test_loss': 0.029805850237607956,
 'test_prec': 0.9885321100917431,
 'test_recall': 0.9707207207207207}
--------------------------------------------------------------------------------

Test : 1000
-- Random test --

      a.index  b.index  matching
6246     1163      594     False
4352      162     1150     False
1563     1993     1507     False
6484     2369     1220     False
6938     1747      316     False
...       ...      ...       ...
2122     1729      331     False
3215     1353      589     False
6935      789       56     False
5451     1394      361     False
1452      131      334     False

[1000 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9732142857142857,
 'test_loss': 0.05049904063344002,
 'test_prec': 0.9646017699115044,
 'test_recall': 0.9819819819819819}
--------------------------------------------------------------------------------

Test : 7417
-- Random test --

      a.index  b.index  matching
3239     1015      382     False
7144      525      639      True
978      2081     1205     False
871      1046       37      True
3905     2077     1532      True
...       ...      ...       ...
2310     1060     1812     False
866       973      488     False
2736     1530     1794     False
148      1729     1512     False
6699     1178      613     False

[7417 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9886877828054299,
 'test_loss': 0.020617008209228516,
 'test_prec': 0.9931818181818182,
 'test_recall': 0.9842342342342343}
--------------------------------------------------------------------------------
New cross validation 2

Test : 50
-- Random test --

      a.index  b.index  matching
2667       39      562     False
2253      135     2227     False
2926     1881      258     False
5843     2392      850     False
1970      396     1215     False
752      2191     1924     False
490      1247     1490     False
6968     2473      501     False
2890     1056      338      True
5230     2562     1612     False
233      1309     2263      True
4369     1257       49     False
1043     1883     2022     False
6755       11     2010      True
6713      137     1203     False
428       472      546     False
6277     1091      368     False
4911      353     1620      True
3921     2335     2060     False
2909     1758      707      True
4270      954       46     False
7077     1321     1598     False
4332     2287      501     False
270      1685     1119     False
4126     2313     1108     False
6092      780     1811      True
5678      648     1418     False
6915      341     1885     False
776      2435     2253     False
1327     1637      865     False
6924      526      418      True
6589      220       34     False
6956     1891      470     False
3252     1985     1159     False
6884      580       33      True
3695     2058      269     False
6796      783     2243     False
4871     1543     2111     False
5744      229     1490     False
3474      953     1650     False
459       317     1647     False
6841     2266     1475     False
1591      579      331      True
3782     1848     2133     False
7349     2162     1870     False
4151     1185      340     False
1542     2008     1254     False
6852     1320     2255     False
6432     1771     2013     False
4876     1664      694     False
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9172932330827067,
 'test_loss': 0.1359878033399582,
 'test_prec': 0.8767967145790554,
 'test_recall': 0.9617117117117117}
--------------------------------------------------------------------------------

Test : 75
-- Random test --

      a.index  b.index  matching
352      2302     1427     False
5562     1489      365      True
5564     2162      583     False
1021     1658     1837     False
5170      205     2211     False
...       ...      ...       ...
6214     1291      455     False
5744      229     1490     False
5776     2183     1463     False
4500     1858     1095      True
1379     1369      598     False

[75 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9379157427937918,
 'test_loss': 0.07038446515798569,
 'test_prec': 0.9235807860262009,
 'test_recall': 0.9527027027027027}
--------------------------------------------------------------------------------

Test : 100
-- Random test --

      a.index  b.index  matching
2860      755     1572      True
369      2390     1177     False
6454     1107     1939      True
6842     2497     1119     False
2481     1098     1850     False
...       ...      ...       ...
7158     1722     1130     False
1982     2178     1614     False
181      1142     1995     False
2887     2093      542     False
4211     1653      834      True

[100 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9678135405105438,
 'test_loss': 0.04755176603794098,
 'test_prec': 0.9540481400437637,
 'test_recall': 0.9819819819819819}
--------------------------------------------------------------------------------

Test : 120
-- Random test --

      a.index  b.index  matching
2065     1336      412     False
1288      838      246     False
3149      408     1774      True
6949      769      267     False
5875     2171      855     False
...       ...      ...       ...
4990     2144     1168     False
3566     1697      390      True
4436     1163      243     False
1399       20     1873     False
1984      476     1016     False

[120 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9426321709786277,
 'test_loss': 0.08723433315753937,
 'test_prec': 0.9415730337078652,
 'test_recall': 0.9436936936936937}
--------------------------------------------------------------------------------

Test : 140
-- Random test --

      a.index  b.index  matching
5660       71      899     False
6308     1055     1117     False
5014     1577     1049     False
7367       18     2211     False
4893     1448       62     False
...       ...      ...       ...
7144      525      639      True
3131      433     2152     False
282      2385      420     False
7232     1047     1091     False
2753     2209     1771     False

[140 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9411764705882353,
 'test_loss': 0.08342954516410828,
 'test_prec': 0.9645390070921985,
 'test_recall': 0.918918918918919}
--------------------------------------------------------------------------------

Test : 160
-- Random test --

      a.index  b.index  matching
5012     1034     1542     False
762      1201     1758     False
1363      873     2225     False
5489     1662     1622     False
4167      183     1114     False
...       ...      ...       ...
1234     2260      925     False
4266     1559      992     False
5274     1452      745     False
977       591     1890     False
1310      889     2277     False

[160 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9406593406593406,
 'test_loss': 0.1052316203713417,
 'test_prec': 0.9184549356223176,
 'test_recall': 0.963963963963964}
--------------------------------------------------------------------------------

Test : 180
-- Random test --

      a.index  b.index  matching
6833       76      753     False
7157     2580      620     False
890      2061     1768     False
6169     2297       35     False
6096      261     1931      True
...       ...      ...       ...
2377     1595     1512     False
5950     2550      343     False
1941     1333      819     False
4109     2571     1756     False
728      2130      917     False

[180 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9337979094076654,
 'test_loss': 0.11250472068786621,
 'test_prec': 0.9640287769784173,
 'test_recall': 0.9054054054054054}
--------------------------------------------------------------------------------

Test : 200
-- Random test --

      a.index  b.index  matching
361       778      476     False
2849      644     1182     False
4738     1779      235     False
2089      925     2074     False
155       736      557     False
...       ...      ...       ...
5033     1016     1663      True
5675     1151      995     False
2335     1247     1472     False
679       234     1591     False
6577     1261     1318     False

[200 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.946094609460946,
 'test_loss': 0.07716520875692368,
 'test_prec': 0.9247311827956989,
 'test_recall': 0.9684684684684685}
--------------------------------------------------------------------------------

Test : 250
-- Random test --

      a.index  b.index  matching
4663     1139      323     False
1365     2296     1048     False
3919     1385      340     False
1839     1815     2239     False
7130     2051      328     False
...       ...      ...       ...
3573     2074     1667     False
6764     2248     2126      True
239      1448     1752     False
7289      697     1590      True
7003     1043      448     False

[250 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9539842873176206,
 'test_loss': 0.08174702525138855,
 'test_prec': 0.9507829977628636,
 'test_recall': 0.9572072072072072}
--------------------------------------------------------------------------------

Test : 300
-- Random test --

      a.index  b.index  matching
3608      644     1447     False
7083     2547      638     False
1015     2108      755     False
5710     1394     1839     False
2931     2518     1046     False
...       ...      ...       ...
6151     2351     1026     False
733        39      228     False
4700     2441     1321     False
4502       39      229     False
3403      671     2290      True

[300 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9642058165548099,
 'test_loss': 0.061067353934049606,
 'test_prec': 0.9577777777777777,
 'test_recall': 0.9707207207207207}
--------------------------------------------------------------------------------

Test : 400
-- Random test --

      a.index  b.index  matching
4805      705     2124     False
3873      738      860      True
3344     1305      603      True
4826     2435     1847     False
4587      742     1866     False
...       ...      ...       ...
3342      557      220     False
4042      147     1651     False
6362     1385      952     False
6879     2446     2182     False
7260     2096     1100     False

[400 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9613259668508287,
 'test_loss': 0.056011393666267395,
 'test_prec': 0.9436008676789588,
 'test_recall': 0.9797297297297297}
--------------------------------------------------------------------------------

Test : 500
-- Random test --

      a.index  b.index  matching
6200     2261     1825     False
4396      987     1758     False
4771       24     1132     False
1811     2237     1472     False
3306     1979     1340     False
...       ...      ...       ...
1438     1919     1452     False
1778      232     1173     False
7100     2203      343     False
5722     2220     1794      True
935       525        0     False

[500 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9571899012074643,
 'test_loss': 0.08806474506855011,
 'test_prec': 0.9336188436830836,
 'test_recall': 0.9819819819819819}
--------------------------------------------------------------------------------

Test : 600
-- Random test --

      a.index  b.index  matching
5571     1043     1042     False
5791      182     1511     False
3374     2014     1071     False
5650      361      141     False
576      1597     1360      True
...       ...      ...       ...
4235      248      931     False
6619     2294     1318     False
4371     2302     1787     False
4463      988     1001     False
2982     1650     1079      True

[600 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9571899012074643,
 'test_loss': 0.05350838229060173,
 'test_prec': 0.9336188436830836,
 'test_recall': 0.9819819819819819}
--------------------------------------------------------------------------------

Test : 700
-- Random test --

      a.index  b.index  matching
4520     1771     1046     False
3214     1443      623     False
1933     2296     2010     False
158       157     1822      True
568       105      469     False
...       ...      ...       ...
6162      289     1938     False
1927     1378      101      True
3703     2058      836     False
5590      175     1164     False
4048      328     1348     False

[700 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9774266365688488,
 'test_loss': 0.049296196550130844,
 'test_prec': 0.9796380090497737,
 'test_recall': 0.9752252252252253}
--------------------------------------------------------------------------------

Test : 800
-- Random test --

      a.index  b.index  matching
672       448      238     False
5489     1662     1622     False
766      2603     1600     False
4717      814      964     False
6097     1857     1438     False
...       ...      ...       ...
1886      393     2010     False
3924      256     1020      True
2014     1576     2276     False
5501     1811     1301     False
6882     2183     1787     False

[800 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.984090909090909,
 'test_loss': 0.0355149582028389,
 'test_prec': 0.9931192660550459,
 'test_recall': 0.9752252252252253}
--------------------------------------------------------------------------------

Test : 900
-- Random test --

      a.index  b.index  matching
6967     2601      547     False
3073     2268      441      True
5607     1733      493      True
6683     1118     1463     False
1949     2472      173     False
...       ...      ...       ...
694       542      952     False
1050     1235      125     False
1449      995     1872     False
1969      228      201     False
6796      783     2243     False

[900 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9692832764505119,
 'test_loss': 0.04885915294289589,
 'test_prec': 0.9793103448275862,
 'test_recall': 0.9594594594594594}
--------------------------------------------------------------------------------

Test : 1000
-- Random test --

      a.index  b.index  matching
1672      998     2266      True
5143      392      949     False
3180      592      304     False
999      2474     1924      True
4552      327     1040     False
...       ...      ...       ...
2660      953        2     False
5833     1252      246     False
2527     1986     1873     False
3130     1796     1514     False
290      2074      576     False

[1000 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9807909604519773,
 'test_loss': 0.04479805752635002,
 'test_prec': 0.9841269841269841,
 'test_recall': 0.9774774774774775}
--------------------------------------------------------------------------------

Test : 7417
-- Random test --

      a.index  b.index  matching
517      2318     1570     False
2560      306      991     False
6959      495     1103      True
4334     1011     1299     False
1949     2472      173     False
...       ...      ...       ...
6601     1172      524     False
6870     2400      218     False
1565     2341      240     False
1413     1467     1506     False
614      2014     1526      True

[7417 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9920903954802259,
 'test_loss': 0.0146359046921134,
 'test_prec': 0.9954648526077098,
 'test_recall': 0.9887387387387387}
--------------------------------------------------------------------------------
New cross validation 3

Test : 50
-- Random test --

      a.index  b.index  matching
6945     1477     1771     False
3390     2504     1772     False
7160      190     1829     False
1753      479     2263     False
1970      396     1215     False
1704     2517      316     False
7077     1321     1598     False
5314      393      171     False
6718     1215      258     False
5196     2450     1083     False
1265     2509      343     False
3378     1744      817     False
3306     1979     1340     False
6850      290      470      True
4613      361      980      True
6347     1463     1699     False
4457       78     1881     False
262      2553      889     False
6519     2435      246     False
3396     2601      927     False
5106      950     2183      True
73        690     1906     False
6769     2181      231      True
4983     2201      164     False
6733        4     1450      True
4857     1826     1034      True
6966     2496      917     False
3138      903      646      True
3003     1564      240     False
1         217     2135     False
249       775     1189     False
4611      787     1011     False
4954      964     1167     False
3966     1812      943     False
3645      917     1827     False
1146     1337     1959     False
2612     1304      777     False
5327     2096      589     False
3137      368     1274     False
6002      907      526     False
855       808      567     False
3990     2008      952     False
5373     1287     1828     False
6484     2369     1220     False
1760     1595     1384     False
1159     1355     1772     False
1709     2488      243     False
5836      472      527     False
2400     1107      147     False
6752      357      869     False
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.899645808736718,
 'test_loss': 0.15682236850261688,
 'test_prec': 0.9454094292803971,
 'test_recall': 0.8581081081081081}
--------------------------------------------------------------------------------

Test : 75
-- Random test --

      a.index  b.index  matching
2427     1243     1456     False
5956      656      340     False
3372     2573      961     False
5943     2581     1390      True
667      1098     1715     False
...       ...      ...       ...
329       289     1675     False
7201     1255     1707     False
6030     1365     2154     False
6784     2535       42     False
5470      198     1150     False

[75 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8962655601659751,
 'test_loss': 0.116924948990345,
 'test_prec': 0.8307692307692308,
 'test_recall': 0.972972972972973}
--------------------------------------------------------------------------------

Test : 100
-- Random test --

      a.index  b.index  matching
4670     1188      214     False
4745      984     1448     False
2384     2051       28     False
4973     1012     2167      True
3372     2573      961     False
...       ...      ...       ...
2804      737     2255     False
6227     2050     1620     False
169       198      778     False
3662     2036     1777     False
5989     1036     1711      True

[100 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.914826498422713,
 'test_loss': 0.11926422268152237,
 'test_prec': 0.8579881656804734,
 'test_recall': 0.9797297297297297}
--------------------------------------------------------------------------------

Test : 120
-- Random test --

      a.index  b.index  matching
5699      695     1976     False
5015     2570     1021     False
825      1801     1626      True
2592     1496     1743     False
5390       18     1855     False
...       ...      ...       ...
1142     2495     1632     False
2607     1183      857      True
5833     1252      246     False
5184     1046     1785     False
5817     1212     2103      True

[120 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9308035714285715,
 'test_loss': 0.09290560334920883,
 'test_prec': 0.922566371681416,
 'test_recall': 0.9391891891891891}
--------------------------------------------------------------------------------

Test : 140
-- Random test --

      a.index  b.index  matching
3226      103     1783     False
4117     2523     1376      True
2600     1616     1907      True
5279     1717      588     False
7043     2443     1408     False
...       ...      ...       ...
6807      840     1766      True
5098      137     1829     False
5761     2084     1606     False
6316      329     1251      True
642      1028      339     False

[140 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8929663608562691,
 'test_loss': 0.19201339781284332,
 'test_prec': 0.8156424581005587,
 'test_recall': 0.9864864864864865}
--------------------------------------------------------------------------------

Test : 160
-- Random test --

      a.index  b.index  matching
2657     1491      176     False
5829      538     1519     False
4678     2108      586     False
3053     1870     2250     False
1545      633      548     False
...       ...      ...       ...
124      1792      938      True
2108     2318     1827     False
4878     1491      919     False
7257     1139     1746     False
742      1459     2259     False

[160 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8811188811188811,
 'test_loss': 0.20282508432865143,
 'test_prec': 0.7917414721723519,
 'test_recall': 0.9932432432432432}
--------------------------------------------------------------------------------

Test : 180
-- Random test --

      a.index  b.index  matching
5692     1805     1764      True
7038     1033     2019     False
6056      640     1050      True
4803      861     1665     False
344      1215      215      True
...       ...      ...       ...
3058     1611      631      True
4588     1277     1619     False
2185     1799     1427     False
2141      963      931      True
171       742     1862     False

[180 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9373601789709173,
 'test_loss': 0.11253520101308823,
 'test_prec': 0.9311111111111111,
 'test_recall': 0.9436936936936937}
--------------------------------------------------------------------------------

Test : 200
-- Random test --

      a.index  b.index  matching
5435     1940     1151     False
2680     1421     1029      True
6096      261     1931      True
4941      932     1799     False
6176      674     1342     False
...       ...      ...       ...
5793     1784      307     False
1299     2062      964     False
4835     1375     1238     False
3517     2182       46     False
1995      197     1493      True

[200 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9104166666666667,
 'test_loss': 0.20192617177963257,
 'test_prec': 0.8468992248062015,
 'test_recall': 0.9842342342342343}
--------------------------------------------------------------------------------

Test : 250
-- Random test --

      a.index  b.index  matching
3583     2131     2261     False
5195      158      850     False
248      1108     1881      True
5130      899     1852     False
5881     2046     1463     False
...       ...      ...       ...
2338      257       49     False
4800     2245      210      True
2859     1816     2246     False
1012     1513     2085     False
1072      110     1722     False

[250 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9551569506726457,
 'test_loss': 0.05631890147924423,
 'test_prec': 0.9508928571428571,
 'test_recall': 0.9594594594594594}
--------------------------------------------------------------------------------

Test : 300
-- Random test --

      a.index  b.index  matching
2854      635        2     False
2877      692     1976     False
5889      687     2201     False
3526     1651     1883     False
3303     1043     1771     False
...       ...      ...       ...
4709     1964     1529     False
4845      233      463     False
536      1542      577     False
2327     1459     1163     False
4597     1562     2274      True

[300 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9402985074626866,
 'test_loss': 0.11209245771169662,
 'test_prec': 0.8927125506072875,
 'test_recall': 0.9932432432432432}
--------------------------------------------------------------------------------

Test : 400
-- Random test --

      a.index  b.index  matching
6944     1284      436     False
5207     1705     1168     False
6185     2402     2010     False
6925     1071     1238     False
1021     1658     1837     False
...       ...      ...       ...
5258        7     1463     False
4664     1285      185     False
5980     2296     1758     False
6935      789       56     False
2137      485     1881     False

[400 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9668141592920354,
 'test_loss': 0.06161215156316757,
 'test_prec': 0.95,
 'test_recall': 0.9842342342342343}
--------------------------------------------------------------------------------

Test : 500
-- Random test --

      a.index  b.index  matching
761       193     1197     False
5239        7     1046     False
1713      234     1795     False
5193     2294     1947     False
3663      750      411      True
...       ...      ...       ...
1929      980     1122     False
2109     1088     1001     False
4046      145     1407     False
3725      156      238     False
6331      295      757      True

[500 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9796380090497738,
 'test_loss': 0.033464837819337845,
 'test_prec': 0.9840909090909091,
 'test_recall': 0.9752252252252253}
--------------------------------------------------------------------------------

Test : 600
-- Random test --

      a.index  b.index  matching
868      1168     1382     False
3335      766     1679     False
461       147      463      True
3654      897     2117     False
1109     1794      110     False
...       ...      ...       ...
4641      186     1962     False
2315     2075     1981     False
3274     1163      340     False
5985     1400      589     False
748      2175      722     False

[600 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9743016759776536,
 'test_loss': 0.041715141385793686,
 'test_prec': 0.9667405764966741,
 'test_recall': 0.9819819819819819}
--------------------------------------------------------------------------------

Test : 700
-- Random test --

      a.index  b.index  matching
4938     2008     1035     False
2097     2232     1447     False
3698     1818     1821     False
4499     1732      917     False
6450     2199      833      True
...       ...      ...       ...
1736      905      215     False
188      2051     1108     False
6197      972     1513      True
686      1866     1707     False
7123     1447     2205      True

[700 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9776785714285714,
 'test_loss': 0.03868773579597473,
 'test_prec': 0.9690265486725663,
 'test_recall': 0.9864864864864865}
--------------------------------------------------------------------------------

Test : 800
-- Random test --

      a.index  b.index  matching
2981      744     1147     False
4944      371     1884     False
7068      703     1259     False
1138     1900      509      True
7348     2143     1548     False
...       ...      ...       ...
4001      866      555     False
4650     2542     1475     False
5180     1365      238     False
325      2562     1020     False
6386     1033     1649     False

[800 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9774774774774775,
 'test_loss': 0.043227385729551315,
 'test_prec': 0.9774774774774775,
 'test_recall': 0.9774774774774775}
--------------------------------------------------------------------------------

Test : 900
-- Random test --

      a.index  b.index  matching
4912     2008     1962     False
6980       20     1601     False
4231      531      466     False
4319     1689     1161     False
2512      152      398      True
...       ...      ...       ...
3265     1278      340     False
1951     1655     1309     False
7250     2570     1297     False
5129      478     1262     False
6422     2030     2208      True

[900 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9796839729119639,
 'test_loss': 0.03607643023133278,
 'test_prec': 0.9819004524886877,
 'test_recall': 0.9774774774774775}
--------------------------------------------------------------------------------

Test : 1000
-- Random test --

      a.index  b.index  matching
4338      715      332     False
852      2601      527     False
686      1866     1707     False
811      2435     1167     False
3384     2558     1933     False
...       ...      ...       ...
713      2224     1313     False
607      2528      506      True
3113      595     1785     False
3050     2369      259     False
7171     1897      667     False

[1000 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9784335981838819,
 'test_loss': 0.06462614238262177,
 'test_prec': 0.9862700228832952,
 'test_recall': 0.9707207207207207}
--------------------------------------------------------------------------------

Test : 7417
-- Random test --

      a.index  b.index  matching
5667     2524      755     False
350      2244      344     False
6140     1353     2126     False
777      1124       29      True
2269     1459     1427     False
...       ...      ...       ...
3329     1546     1667     False
3120      692        4     False
2251     2342     2073     False
5073     2101     2259     False
5442      289     1872     False

[7417 rows x 3 columns]
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9853107344632768,
 'test_loss': 0.02048826776444912,
 'test_prec': 0.9886621315192744,
 'test_recall': 0.9819819819819819}
--------------------------------------------------------------------------------
New cross validation 4

Test : 50
-- Random test --

      a.index  b.index  matching
88        557     2055     False
6087      627     1088     False
7233      143     1560     False
2890     1056      338      True
6552     1107      281     False
2744     2048      585     False
2020     1231      330      True
3792      299      335      True
6318     1268      754     False
6957     1533     1017     False
6657      525     1758     False
4190      542     1761     False
1561      123     1209     False
4734     2095      371     False
1713      234     1795     False
2332     2552      984     False
4706      431     1078     False
3221      257     1191     False
4335     2294     1795      True
565       707     1569      True
2726     1690     1674     False
4119     1459     1125     False
4503     2246     1519     False
124      1792      938      True
4546      640     1512     False
7263     1753      583     False
1354      811      576     False
292      2022     1342     False
5067     1207      802      True
804      2162      998     False
1007        3     1479     False
2942     2126      178     False
1855     2367     1805      True
5795     1975      858      True
6237     1266     2142      True
4397     1129      590     False
7109     1211      976     False
6646     1497     1118      True
3561     2586     2166      True
988       644       66     False
436       101      197      True
2949      371      810     False
6204       66     1895     False
7275     1015     1407     False
7280       11     1048     False
6137     1619     1704     False
2885       94      583     False
3297      627     1527     False
4537     1113      699     False
1715     1578     1134     False
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9190938511326862,
 'test_loss': 0.10447342693805695,
 'test_prec': 0.8819875776397516,
 'test_recall': 0.9594594594594594}
--------------------------------------------------------------------------------

Test : 75
-- Random test --

      a.index  b.index  matching
5824      335     2104     False
3699      162      589     False
2688      393     1918     False
1821      706     1475     False
73        690     1906     False
...       ...      ...       ...
1643     1481     1756     False
1372       78     1600     False
3260     2525     1721      True
2119     1329     1667     False
599      2418      230     False

[75 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.17119666934013367,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 100
-- Random test --

      a.index  b.index  matching
7187     2182     1645     False
2105      977     1905     False
795      2085      816      True
3411      786     1522     False
4456      456      941      True
...       ...      ...       ...
7144      525      639      True
7172      433      562     False
3720     1482     1405      True
6558     1292     1403     False
1259      174      965      True

[100 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8735177865612649,
 'test_loss': 0.16751863062381744,
 'test_prec': 0.778169014084507,
 'test_recall': 0.9954954954954955}
--------------------------------------------------------------------------------

Test : 120
-- Random test --

      a.index  b.index  matching
3805     1600      510     False
6479      705     2125     False
1134     2201      957      True
6185     2402     2010     False
113      1232      242     False
...       ...      ...       ...
6771      419      974      True
116       665     2019     False
7186      224      633      True
5974      925     1114     False
1731      405     2083     False

[120 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9401129943502825,
 'test_loss': 0.08121880143880844,
 'test_prec': 0.9433106575963719,
 'test_recall': 0.9369369369369369}
--------------------------------------------------------------------------------

Test : 140
-- Random test --

      a.index  b.index  matching
7302      538      258     False
241      1770       93     False
2940     2224       77     False
4037      816      595     False
3062     2367     1397     False
...       ...      ...       ...
6051      429     1364      True
206       372     1555     False
1541     2224     1697     False
1637      403       53     False
788       142     1862     False

[140 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9195402298850573,
 'test_loss': 0.10939596593379974,
 'test_prec': 0.8576998050682261,
 'test_recall': 0.990990990990991}
--------------------------------------------------------------------------------

Test : 160
-- Random test --

      a.index  b.index  matching
4694     1912      415      True
2460      199      543      True
6250      289     1667     False
2535      312     1597     False
4857     1826     1034      True
...       ...      ...       ...
4900     2095     1195     False
6711      902      610      True
3338     1360     1427     False
5334     1233     2053     False
3495      829     1884     False

[160 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9578107183580388,
 'test_loss': 0.06170143559575081,
 'test_prec': 0.9699769053117783,
 'test_recall': 0.9459459459459459}
--------------------------------------------------------------------------------

Test : 180
-- Random test --

      a.index  b.index  matching
20       1021      225     False
4161       69     1236     False
3580     2209     1609     False
6747      932     2077     False
6514      980     2261     False
...       ...      ...       ...
6051      429     1364      True
1920     1944     1587     False
1765      162      147     False
3112      797     1171     False
4596      628     1723     False

[180 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9494949494949495,
 'test_loss': 0.06716687232255936,
 'test_prec': 0.9463087248322147,
 'test_recall': 0.9527027027027027}
--------------------------------------------------------------------------------

Test : 200
-- Random test --

      a.index  b.index  matching
306      2315     1340     False
1135      865     1846     False
2910     1933     1898     False
4081      921      400      True
1564     1496      377     False
...       ...      ...       ...
4931     1933     1999     False
2534      900      441     False
3202      378     1125     False
2354      593     1740      True
118        40     1558      True

[200 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9531428571428571,
 'test_loss': 0.07167273759841919,
 'test_prec': 0.9675174013921114,
 'test_recall': 0.9391891891891891}
--------------------------------------------------------------------------------

Test : 250
-- Random test --

      a.index  b.index  matching
2290     2391      927     False
1177     2500     1541      True
7297      205      694     False
38       1189     1969      True
440       863     1042     False
...       ...      ...       ...
3431     1059       45      True
5790        9     1881     False
1561      123     1209     False
3594     1548     1678     False
442      1161     1880     False

[250 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9614112458654906,
 'test_loss': 0.0697312131524086,
 'test_prec': 0.9416846652267818,
 'test_recall': 0.9819819819819819}
--------------------------------------------------------------------------------

Test : 300
-- Random test --

      a.index  b.index  matching
6602     2497      346     False
432       798     1281      True
3475     2318      685     False
2361     2224      243     False
1670     1812     1083     False
...       ...      ...       ...
856       381      578     False
2690     1220     1217     False
7150      899     1814      True
5009      291     1754     False
2592     1496     1743     False

[300 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9698324022346367,
 'test_loss': 0.0635119304060936,
 'test_prec': 0.9623059866962306,
 'test_recall': 0.9774774774774775}
--------------------------------------------------------------------------------

Test : 400
-- Random test --

      a.index  b.index  matching
1601      834     2163     False
1117     1107     1490     False
2870     1944      291     False
2006     2129      378     False
1593     1471     2261     False
...       ...      ...       ...
6989      992     1170     False
6830     2411      921      True
4172     1718     1631      True
4164     2518     2019     False
3205     2313     1519     False

[400 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9730337078651685,
 'test_loss': 0.05091223120689392,
 'test_prec': 0.9708520179372198,
 'test_recall': 0.9752252252252253}
--------------------------------------------------------------------------------

Test : 500
-- Random test --

      a.index  b.index  matching
5031      135     1679     False
4778      641     1043      True
5681     1370      786     False
1718     2494     1021     False
4934      931      530     False
...       ...      ...       ...
1343     2099     1772     False
1504     2308     2106     False
5226       49     1848     False
4146      976     1640     False
2037      590       36      True

[500 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9625425652667423,
 'test_loss': 0.06692850589752197,
 'test_prec': 0.9702517162471396,
 'test_recall': 0.954954954954955}
--------------------------------------------------------------------------------

Test : 600
-- Random test --

      a.index  b.index  matching
786       857     1507     False
2583     2296      379     False
2249     1882      651     False
4936      655      319      True
5409     1655     2240     False
...       ...      ...       ...
2133      720     1248      True
378      2416     1632     False
6681     2220      783     False
1790      669     2099      True
247      2494     1761     False

[600 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9830890642615557,
 'test_loss': 0.03426475077867508,
 'test_prec': 0.9841986455981941,
 'test_recall': 0.9819819819819819}
--------------------------------------------------------------------------------

Test : 700
-- Random test --

      a.index  b.index  matching
4887     1647     1539     False
5140      542     1463     False
235      2402      360     False
2993     1651      276     False
1939     1365     1829     False
...       ...      ...       ...
2045     1854      681     False
5621      827      173      True
5692     1805     1764      True
6910     1658     1406     False
4371     2302     1787     False

[700 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9646017699115044,
 'test_loss': 0.07116646319627762,
 'test_prec': 0.9478260869565217,
 'test_recall': 0.9819819819819819}
--------------------------------------------------------------------------------

Test : 800
-- Random test --

      a.index  b.index  matching
2759      688     1194     False
2801     1587     1738      True
4903     2546     1416     False
888      2116      304     False
6422     2030     2208      True
...       ...      ...       ...
1654     1450      755     False
1272     2514      484     False
5406     2232     1983     False
4176      932     1749     False
1678     2561     2107     False

[800 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9841628959276018,
 'test_loss': 0.02581775188446045,
 'test_prec': 0.9886363636363636,
 'test_recall': 0.9797297297297297}
--------------------------------------------------------------------------------

Test : 900
-- Random test --

      a.index  b.index  matching
6313     1985     1787     False
3917     1975      539     False
1765      162      147     False
7210     1488      199     False
727       287     1317     False
...       ...      ...       ...
2925     1470      368     False
7084     1346       53     False
2123       99      636     False
3687     2194      116      True
1304     1304      591     False

[900 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9787234042553192,
 'test_loss': 0.04361066222190857,
 'test_prec': 0.9732739420935412,
 'test_recall': 0.9842342342342343}
--------------------------------------------------------------------------------

Test : 1000
-- Random test --

      a.index  b.index  matching
3585     1108     1715     False
2669     1217     1831     False
5428     2069      685     False
3638     1102     2150     False
4357     2037      418     False
...       ...      ...       ...
2009      926     1326     False
3116     1235      118     False
7340     1978      479      True
6633     2246     1791     False
2517     2275      141     False

[1000 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9819413092550789,
 'test_loss': 0.03345848247408867,
 'test_prec': 0.9841628959276018,
 'test_recall': 0.9797297297297297}
--------------------------------------------------------------------------------

Test : 7417
-- Random test --

      a.index  b.index  matching
5602     2037     1883     False
1612       99      232     False
3367     2473      654     False
5919     2422     1839     False
4587      742     1866     False
...       ...      ...       ...
5055     1243     2119      True
5483     2005     1052     False
5080     1661     1957     False
5026        7     1035     False
7347     2080     1829     False

[7417 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9887133182844244,
 'test_loss': 0.017405739054083824,
 'test_prec': 0.9909502262443439,
 'test_recall': 0.9864864864864865}
--------------------------------------------------------------------------------
Could not create dir out, File exists
    ########### 



New Dataset: <function deepmatcher_structured_dblp_google_scholar at 0x1553060e6d30>
New cross validation 0

Test : 50
-- Random test --

       a.index  b.index  matching
6886      1842    16179     False
744       2280    25749     False
9717      2342    52778     False
11937      593    46883     False
11357     1864    38562     False
101        563    43933     False
10654     1842    35825     False
5803      1529     1043     False
16911     1049    18168     False
10581      356    45288      True
2545       562    11541     False
123       2142     8018     False
19        2455    31743     False
16587      135    52470      True
5050       297    13830     False
13846     2577    61565      True
9899      1963    57134     False
7112      1148    31823     False
12006     2276    29530      True
7556      1749    30836     False
13135     2336    29138     False
6956       772    24387     False
11461     1262    45618      True
16247      630    26123     False
2300       566    44593     False
5332      2420    12829     False
828        601    13281     False
13441     2538    48032     False
3410       370    38935     False
13222      146     4967     False
5377      2479    30326      True
3745      1099    57120     False
3362      2040    17415     False
14744      452    55320     False
4990       687    38046     False
1086      2107    10139      True
3887      2466    48536     False
2009      1925    54393     False
169       1244    61006     False
3288      2277    28447     False
10514       18    10325     False
10363      997    28685      True
3682       568    42156     False
11398      254    22722     False
10133     2409     9194     False
16295      901    60624     False
14038       71    37725      True
9767       635     3598     False
971       1841    53356     False
5841      1466    19179     False
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.24707290530204773,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 75
-- Random test --

       a.index  b.index  matching
4955      2312    35666     False
11564     1742    40694     False
16421      742    52833      True
8570      1792    42063      True
3085      1694     4643     False
...        ...      ...       ...
8367      2500    57739     False
3847       238    29895     False
3893      1440    41792     False
6572      2005    53793     False
4237      2316    52986      True

[75 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8138528138528139,
 'test_loss': 0.2115742415189743,
 'test_prec': 0.7029231815091774,
 'test_recall': 0.9663551401869159}
--------------------------------------------------------------------------------

Test : 100
-- Random test --

       a.index  b.index  matching
5087       182     8936     False
846       1269    24021      True
15516      259    61429     False
3418      2285     3113      True
12803      696    38706     False
...        ...      ...       ...
1163      2195    10695     False
11718     1023    49287     False
9373      1944    33240     False
15665     1193    50065     False
1938      1815    39054     False

[100 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.834321866350336,
 'test_loss': 0.2924688756465912,
 'test_prec': 0.7230980123372173,
 'test_recall': 0.985981308411215}
--------------------------------------------------------------------------------

Test : 120
-- Random test --

       a.index  b.index  matching
15310       15     3190      True
17069        5    41920     False
5720      2451    59717     False
5343      1147    57457      True
3136       396    35687     False
...        ...      ...       ...
10348      353    22839     False
8324      2275    44390     False
8657      2168     6580     False
2371       349    42439     False
4310        66    14340      True

[120 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8499324019828751,
 'test_loss': 0.2185744047164917,
 'test_prec': 0.8207136640557006,
 'test_recall': 0.8813084112149533}
--------------------------------------------------------------------------------

Test : 140
-- Random test --

       a.index  b.index  matching
4289      1876    27533      True
11240     1369    45887     False
3106      2559     9452     False
16493     1542    57689     False
9961       441    35593     False
...        ...      ...       ...
5754      1296    41678     False
4562       142      372      True
9558      1840    41398     False
8006      1200    36653     False
12888     2208    63588     False

[140 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.897278314310799,
 'test_loss': 0.14098964631557465,
 'test_prec': 0.8460264900662252,
 'test_recall': 0.9551401869158879}
--------------------------------------------------------------------------------

Test : 160
-- Random test --

       a.index  b.index  matching
3965        19    32587     False
248       2560    12731     False
327       1986    62583     False
3000      1229    38191     False
3645       720    42235     False
...        ...      ...       ...
16947     1288    24667     False
2196       922     5173      True
12189     2256    46707     False
11208     2490    56834     False
9154      2300    19864     False

[160 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8714492055849784,
 'test_loss': 0.1721321940422058,
 'test_prec': 0.8987090367428004,
 'test_recall': 0.8457943925233645}
--------------------------------------------------------------------------------

Test : 180
-- Random test --

       a.index  b.index  matching
5224      1467    26746     False
9481      2300    14281     False
6469      1324    58030     False
11147     1374    15425     False
1592       390    14023     False
...        ...      ...       ...
2019       612    27198     False
1909       177    39417     False
10064      798    63951     False
12485     2264    26626      True
15629     2420    23109     False

[180 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9136822773186409,
 'test_loss': 0.0990433394908905,
 'test_prec': 0.898014440433213,
 'test_recall': 0.9299065420560748}
--------------------------------------------------------------------------------

Test : 200
-- Random test --

       a.index  b.index  matching
3508      1842    32114     False
15788     2125     9753     False
16971     2611     5398     False
6334       267    38677     False
2514       604    47010     False
...        ...      ...       ...
6381       243    13871     False
4733       535    33318     False
980       2338    18926     False
9927      2573     3898     False
8275        95    19455     False

[200 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8948069241011983,
 'test_loss': 0.17808057367801666,
 'test_prec': 0.8520710059171598,
 'test_recall': 0.9420560747663551}
--------------------------------------------------------------------------------

Test : 250
-- Random test --

       a.index  b.index  matching
11846      687    44986     False
3968      2564    12109     False
6380       379    23228      True
3118      2161     9403     False
14695     1404    22756     False
...        ...      ...       ...
15037      280    53104     False
6475       289    53508      True
16931     1856    30586     False
5371      2537     4263     False
13922      335    49782      True

[250 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8803912850155625,
 'test_loss': 0.14132589101791382,
 'test_prec': 0.8396946564885496,
 'test_recall': 0.9252336448598131}
--------------------------------------------------------------------------------

Test : 300
-- Random test --

       a.index  b.index  matching
3310      1228     3244      True
13826     1749    14827     False
1397      2279    41598     False
3960      2332     2139     False
3115      2533    18136      True
...        ...      ...       ...
1892       504     8189     False
16490     2456    21032     False
13044     1610     5525     False
6003      2603    16311     False
5320       758    59307     False

[300 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9195837275307474,
 'test_loss': 0.10349708795547485,
 'test_prec': 0.9310344827586207,
 'test_recall': 0.908411214953271}
--------------------------------------------------------------------------------

Test : 400
-- Random test --

       a.index  b.index  matching
10716     1664    31984     False
13865      687    32699      True
14769      605     1685     False
10734      252    59265     False
9301       311    21298      True
...        ...      ...       ...
10013     2385    29360     False
13737      645    52662     False
2730      1525    26496     False
573       1752    51185     False
12362     1534    26047      True

[400 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9285380663241476,
 'test_loss': 0.10175947844982147,
 'test_prec': 0.9281045751633987,
 'test_recall': 0.9289719626168225}
--------------------------------------------------------------------------------

Test : 500
-- Random test --

       a.index  b.index  matching
10395      488    31316     False
5796       758    52385     False
12920     2232    54193     False
4565       772    15801     False
6029      2184    61103      True
...        ...      ...       ...
14869     1883    19441      True
15322     2057    54014     False
13795     2196     8027     False
5767      2220    42187     False
16212     1401    43981     False

[500 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9199817101051668,
 'test_loss': 0.14621961116790771,
 'test_prec': 0.900626678603402,
 'test_recall': 0.9401869158878504}
--------------------------------------------------------------------------------

Test : 600
-- Random test --

       a.index  b.index  matching
14069     1792    47694     False
3935      1953     7046     False
2684       359    45743     False
8677       239    52795      True
15027      408    13295     False
...        ...      ...       ...
2735      1543    30895     False
16444     1840    37892     False
12500     2368    37045     False
3432       758    50108     False
13502      831    60322      True

[600 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.925035360678925,
 'test_loss': 0.12496144324541092,
 'test_prec': 0.9333967649857279,
 'test_recall': 0.9168224299065421}
--------------------------------------------------------------------------------

Test : 700
-- Random test --

       a.index  b.index  matching
994        307     2509      True
13400       17    55719     False
11665      570    29138     False
2404      2093    61385     False
7315      1785     1887     False
...        ...      ...       ...
5058      1700     7089     False
7736      2102      720      True
10133     2409     9194     False
10277     1821    11426     False
1973      2280    17209     False

[700 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9393939393939394,
 'test_loss': 0.10145306587219238,
 'test_prec': 0.9232851985559567,
 'test_recall': 0.9560747663551402}
--------------------------------------------------------------------------------

Test : 800
-- Random test --

       a.index  b.index  matching
595        996    45271     False
11044      900    26215     False
9610      1146    54055     False
868       1270     5147     False
12026     2132    34631     False
...        ...      ...       ...
7096      1618    25298     False
15349     1005    28227     False
2925      1594    43176     False
13286     2254     8821     False
10225      229    11019     False

[800 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9089261440869959,
 'test_loss': 0.13940517604351044,
 'test_prec': 0.882145998240985,
 'test_recall': 0.9373831775700935}
--------------------------------------------------------------------------------

Test : 900
-- Random test --

       a.index  b.index  matching
4358       993     4723     False
14638     1282     4927     False
3549      1200    34408     False
7102       563    22295     False
6402      1146    58607     False
...        ...      ...       ...
14659     1212    57461     False
16940     2389    34362     False
11499      933      674     False
2621      1442    26179     False
7606      1957    47772     False

[900 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9325323475046211,
 'test_loss': 0.11250888556241989,
 'test_prec': 0.9223034734917733,
 'test_recall': 0.9429906542056075}
--------------------------------------------------------------------------------

Test : 1000
-- Random test --

       a.index  b.index  matching
11630     2521    32445     False
15558      778     1461     False
15486      938    40206      True
3849       242    30712     False
7753      2132    27508      True
...        ...      ...       ...
6475       289    53508      True
17013     1377    29405     False
8035      1120    11368     False
5273       406    17124      True
10202     2588    13708     False

[1000 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.932573599240266,
 'test_loss': 0.10346026718616486,
 'test_prec': 0.9478764478764479,
 'test_recall': 0.9177570093457944}
--------------------------------------------------------------------------------

Test : 17223
-- Random test --

       a.index  b.index  matching
6936      1186    58149     False
4259       485    48282      True
8738      1773    35459      True
5777      1856    48964     False
2633      1313    63494      True
...        ...      ...       ...
11720     2495    61925     False
12172     1953    27311     False
13494     1560    47255     False
5053      2370    38178     False
5247      1659    50108     False

[17223 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9578508568781844,
 'test_loss': 0.10335394740104675,
 'test_prec': 0.9494949494949495,
 'test_recall': 0.9663551401869159}
--------------------------------------------------------------------------------
New cross validation 1

Test : 50
-- Random test --

       a.index  b.index  matching
13519     1869    46828     False
9208      2505     9513     False
2589      1796    59911     False
11155     1560     8133      True
16300      667     9709      True
11040      639    34889      True
3272      1176    51230      True
15469      647    10867     False
68        1190    53516      True
6912      1367     3973     False
15099     1543     7998     False
7353      1568    30242     False
10975     2196    15106     False
8516      1012    55098     False
12944     1321     8517      True
1157       267    12540     False
7831      1283    36034     False
7139      1143      241     False
15166     1683    38470     False
4744      1203     2187     False
7543      1338     7654     False
316        352    17040      True
12285      274     7524     False
9980       145    23081     False
1524       441    53098     False
1921       547    47694     False
14179     1180    30724     False
2877      2401    50885      True
11246     1439     1459     False
10659      348    58198     False
160        590    51553      True
10395      488    31316     False
4202       422    52029     False
4785      1439    44214      True
11494       82     8561      True
15845     1862    38466     False
10242     1290    54581     False
2899      1912    53925     False
10409     2416    10966     False
9639      1802    36628      True
16536     2515     4146     False
16563     1692    42920     False
11787     1504    11379     False
1422      1244    49970     False
16729     1560    62580     False
8454      1337    41368     False
16159      492     4911     False
4080      1104    44246      True
7345      1749    18506     False
5569      2270    27759     False
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7720430107526881,
 'test_loss': 0.2069655954837799,
 'test_prec': 0.9088607594936708,
 'test_recall': 0.6710280373831776}
--------------------------------------------------------------------------------

Test : 75
-- Random test --

       a.index  b.index  matching
4438       988    36484     False
9085      1470    60632     False
14255     1933    56025      True
4840      1133    33392      True
2840      1973    32942     False
...        ...      ...       ...
14385     2388    50062     False
11765     1288    31232     False
1326       631    30895     False
4488      1305    43350      True
6392       657     2073     False

[75 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.869830213321724,
 'test_loss': 0.1728808730840683,
 'test_prec': 0.8141809290953546,
 'test_recall': 0.9336448598130841}
--------------------------------------------------------------------------------

Test : 100
-- Random test --

       a.index  b.index  matching
1110      1633    28132     False
6254      1179    40077      True
12781     1549     9709     False
14738     1616    18107     False
12743     2568    39054     False
...        ...      ...       ...
12495     1133     4376      True
5793       563    12466     False
8021      1200    59495     False
12883     1840    32362     False
169       1244    61006     False

[100 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8598409542743539,
 'test_loss': 0.13733983039855957,
 'test_prec': 0.9182590233545648,
 'test_recall': 0.8084112149532711}
--------------------------------------------------------------------------------

Test : 120
-- Random test --

       a.index  b.index  matching
1271      1841     9039     False
2340      1049    48726     False
13348     1146    29138     False
8597      2398    31763     False
14710     2085    26792     False
...        ...      ...       ...
9315       288     9039     False
5668      2401    44167     False
6501      2538    43727     False
11798      389    45247     False
4388        66    52479      True

[120 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8652751423149905,
 'test_loss': 0.22944609820842743,
 'test_prec': 0.8786127167630058,
 'test_recall': 0.8523364485981308}
--------------------------------------------------------------------------------

Test : 140
-- Random test --

       a.index  b.index  matching
9924      1605    49574     False
14530      408    18281     False
1018       604    12466     False
13146     1749    34364     False
9743        19    31909     False
...        ...      ...       ...
11541      618    53137     False
5939      1632    44784     False
12126     1288    25978     False
11681     2421    14825     False
15736     2614    15513      True

[140 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8298969072164949,
 'test_loss': 0.23771430552005768,
 'test_prec': 0.9252873563218391,
 'test_recall': 0.7523364485981309}
--------------------------------------------------------------------------------

Test : 160
-- Random test --

       a.index  b.index  matching
2336      1643    51585     False
12910      960    27440      True
5039      1738    27460      True
6514      1704    47395     False
16637     1834    57138     False
...        ...      ...       ...
9268       759    32571     False
2077       837    41474     False
14872     1682    20705      True
7149      2220    45879     False
12132     1652    41909      True

[160 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8991483639623488,
 'test_loss': 0.1316942274570465,
 'test_prec': 0.8639104220499569,
 'test_recall': 0.9373831775700935}
--------------------------------------------------------------------------------

Test : 180
-- Random test --

       a.index  b.index  matching
10055     2300    44760     False
6014      1187     8829      True
15335      946    60672     False
9664      1439     3053     False
16467      177    19873     False
...        ...      ...       ...
13595     1200    58212     False
6644       288    33952     False
10500     2277     9456     False
7794      2509     1509      True
708       1023    52406     False

[180 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9226618705035972,
 'test_loss': 0.13653776049613953,
 'test_prec': 0.8890814558058926,
 'test_recall': 0.9588785046728971}
--------------------------------------------------------------------------------

Test : 200
-- Random test --

       a.index  b.index  matching
12172     1953    27311     False
2881       506    35144     False
16354      942     7505     False
6103      1127     4615     False
13911      477    38677     False
...        ...      ...       ...
16914     1826    44025     False
8956      1155    13722     False
6706      2568    57533      True
11995      496    52389      True
2152      1561    22590     False

[200 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9056437389770723,
 'test_loss': 0.13523277640342712,
 'test_prec': 0.8572621035058431,
 'test_recall': 0.9598130841121495}
--------------------------------------------------------------------------------

Test : 250
-- Random test --

       a.index  b.index  matching
7473       526    29184     False
4788      1288     8868     False
10298     1057    24261      True
16864       68    29360     False
9046       519    34481     False
...        ...      ...       ...
15362     1645    49153     False
4580      1049    47010     False
10777     1749    44912     False
12970     1068    36278      True
16194     1626    23202     False

[250 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9064039408866994,
 'test_loss': 0.15919902920722961,
 'test_prec': 0.8701633705932932,
 'test_recall': 0.9457943925233645}
--------------------------------------------------------------------------------

Test : 300
-- Random test --

       a.index  b.index  matching
9333       151    44179     False
16469     2276    43607     False
11893     2517    58364     False
6498      1953    55055      True
4004      2506    43933     False
...        ...      ...       ...
2307      2216    23579     False
15215     1332    16132      True
16471     1419    15683     False
2610      1794    54433     False
8760      1360    53199     False

[300 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9302961275626425,
 'test_loss': 0.10001178085803986,
 'test_prec': 0.9075555555555556,
 'test_recall': 0.9542056074766355}
--------------------------------------------------------------------------------

Test : 400
-- Random test --

       a.index  b.index  matching
15537      858    38121      True
1948      1921    38812     False
16383     2188    14775      True
7604      1872     8300     False
15756      139    49351     False
...        ...      ...       ...
13080     1439    25353     False
2964      1841    50108     False
5823      1156      932     False
10122     2500     6312     False
2342      1290     5131      True

[400 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.909090909090909,
 'test_loss': 0.12972261011600494,
 'test_prec': 0.8979033728350045,
 'test_recall': 0.9205607476635514}
--------------------------------------------------------------------------------

Test : 500
-- Random test --

       a.index  b.index  matching
9849      1704    48130     False
16542      581    58798     False
2044       603    50550     False
2322      2036    21637     False
4545      1419    27311     False
...        ...      ...       ...
11435     2330     9516     False
15610     2400    20876     False
5278      1680     4961     False
16228      267    33904     False
16239      104    47913     False

[500 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9237132352941178,
 'test_loss': 0.1327524334192276,
 'test_prec': 0.9086799276672695,
 'test_recall': 0.9392523364485982}
--------------------------------------------------------------------------------

Test : 600
-- Random test --

       a.index  b.index  matching
7382       696    57667     False
13904     2338    51065     False
15452     1877    50151     False
4027      1673     8098     False
5883        95    19568     False
...        ...      ...       ...
4129      1464    52471     False
333       2531    32267      True
11518     2517    32137     False
1559       960    59605     False
14996     1337    55876     False

[600 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9317051108095885,
 'test_loss': 0.13366229832172394,
 'test_prec': 0.9027169149868537,
 'test_recall': 0.9626168224299065}
--------------------------------------------------------------------------------

Test : 700
-- Random test --

       a.index  b.index  matching
7611      1560    45906     False
1980      1142    48708      True
17060     1376    43341     False
6914      2330    58131     False
5392      1678    50094      True
...        ...      ...       ...
6817       612    47851     False
6687      1212     6706     False
11840       95    11591     False
5160       224    11014     False
13310     1944    49835     False

[700 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9254864736592312,
 'test_loss': 0.13133227825164795,
 'test_prec': 0.940212150433944,
 'test_recall': 0.9112149532710281}
--------------------------------------------------------------------------------

Test : 800
-- Random test --

       a.index  b.index  matching
15106       75    17479     False
17130      562    53378     False
15227      944    57454     False
14222     2437    12831     False
15081     2466     6003     False
...        ...      ...       ...
1040      2303     7534     False
8452      1015     6754     False
9092      2492    37915     False
4446      1683    44912     False
14520      170    40875     False

[800 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9315571887919155,
 'test_loss': 0.12317462265491486,
 'test_prec': 0.9159891598915989,
 'test_recall': 0.9476635514018692}
--------------------------------------------------------------------------------

Test : 900
-- Random test --

       a.index  b.index  matching
15071     2188     7012      True
5494      2558     9154     False
17013     1377    29405     False
14505     1560    15627      True
12061     1981    30082     False
...        ...      ...       ...
10825     2001     2845     False
12388     1405    45489     False
4463      2232    59439     False
15334     1677    28048      True
6227       184    54706     False

[900 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9386814200092208,
 'test_loss': 0.13161452114582062,
 'test_prec': 0.9262966333030027,
 'test_recall': 0.9514018691588785}
--------------------------------------------------------------------------------

Test : 1000
-- Random test --

       a.index  b.index  matching
14265      449    58638     False
10570       95    13394     False
7241       640    52662     False
10481     1716    18478     False
5385       104    19080     False
...        ...      ...       ...
9101      1749    28648     False
7064       934    33856     False
2762       703    63466     False
11928     1212    41755     False
15739      182      899     False

[1000 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9291784702549575,
 'test_loss': 0.1026054099202156,
 'test_prec': 0.9389312977099237,
 'test_recall': 0.9196261682242991}
--------------------------------------------------------------------------------

Test : 17223
-- Random test --

       a.index  b.index  matching
16193     2246    41194      True
17106     1816    41656     False
16557     2396    50108     False
12613     1742    63040     False
7574      1836     4166     False
...        ...      ...       ...
1021      2256    26179     False
5399      2455    37532     False
2896       883     7572     False
6736       329    61810     False
1068       713    34940     False

[17223 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9554730983302412,
 'test_loss': 0.10554659366607666,
 'test_prec': 0.9484346224677717,
 'test_recall': 0.9626168224299065}
--------------------------------------------------------------------------------
New cross validation 2

Test : 50
-- Random test --

       a.index  b.index  matching
5717       140    46297     False
129        703    47913     False
9219       546     3888     False
10702      819    47617     False
349        840    57136     False
7326      2380    57857     False
4537      2264    35967     False
15127     1213    50901     False
10028      204    18085     False
4327       304    23632      True
3436      2452    34845     False
15166     1683    38470     False
7916      2564    24963     False
9769      2604    61725     False
16632     2368    26633     False
7987      2564    28465     False
3486      2491    51481     False
905       2564     6409     False
3945      1700    32904     False
4820      2495    59029     False
13433      659    53275     False
15385     2559     4315     False
11445      479    39339     False
7089      1518    55639     False
2431      2608    12112     False
11162     1543    35170      True
4200      1015    27896     False
2012      2561    26155     False
4738        90    22722     False
4377      2498    37872      True
12577     1785     9493     False
14789      794    42885     False
10820     1238    16351      True
592        681     7756     False
5770       562    61304     False
10480     2310    64033     False
17047      732    16381      True
16342       56    42806     False
11706     1993    44280      True
5414      1714    19199      True
8421       122    62491     False
7856      1749    34720     False
12726     1622    44858      True
13765       94    12017     False
8570      1792    42063      True
13535     1704    33308      True
15792      333    62407     False
16087     2315    23262     False
15762     1811    26568     False
1866      1004    11019     False
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.854609929078014,
 'test_loss': 0.17852841317653656,
 'test_prec': 0.8128161888701517,
 'test_recall': 0.9009345794392524}
--------------------------------------------------------------------------------

Test : 75
-- Random test --

       a.index  b.index  matching
5884       960    34736     False
7268      1408    55598     False
13461      563    20204     False
15720      882    45540     False
4562       142      372      True
...        ...      ...       ...
5484      1741    35088     False
9363       369    62711     False
1930       689    28440     False
13355     1361    26792     False
234       2466    52778     False

[75 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8665723715228665,
 'test_loss': 0.1787225604057312,
 'test_prec': 0.8744053282588011,
 'test_recall': 0.8588785046728972}
--------------------------------------------------------------------------------

Test : 100
-- Random test --

       a.index  b.index  matching
15419     2303    30350      True
16418     1419    34989     False
14037     2422    39694     False
8424      1344     6819     False
13771     1437      967     False
...        ...      ...       ...
7314      1561     1832     False
13901      427     8452      True
904       2384    50828     False
9034      2443    34299     False
12774     1362    38242     False

[100 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8196392785571143,
 'test_loss': 0.2832273840904236,
 'test_prec': 0.8833693304535637,
 'test_recall': 0.7644859813084112}
--------------------------------------------------------------------------------

Test : 120
-- Random test --

       a.index  b.index  matching
15950     1953    10458     False
4775      1883    35865     False
23        1656    45351      True
3599        90    49887     False
7789      1868    49380      True
...        ...      ...       ...
13018     1880    55283     False
4231       632    11740     False
217        223    39681     False
10807     2418    51552     False
14262     1685    61368     False

[120 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8861712135465664,
 'test_loss': 0.11506332457065582,
 'test_prec': 0.8920454545454546,
 'test_recall': 0.8803738317757009}
--------------------------------------------------------------------------------

Test : 140
-- Random test --

       a.index  b.index  matching
15119      995    57284     False
6555      1734    32994     False
14810      203    40350     False
9436       103    15568      True
1737      2336    12708     False
...        ...      ...       ...
6262      2521    20426     False
12244     2289    42478      True
658       1283    51743     False
16417     1607    54205     False
879       2466    34299     False

[140 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8834412580943571,
 'test_loss': 0.18858826160430908,
 'test_prec': 0.8745421245421245,
 'test_recall': 0.8925233644859814}
--------------------------------------------------------------------------------

Test : 160
-- Random test --

       a.index  b.index  matching
3215      2579    62878     False
16634     1160    53862     False
11607     1362    64109     False
4421       176    57077     False
6975      2588    13295     False
...        ...      ...       ...
16056      837    29561      True
2162      1707    40377      True
3295      1899    19184     False
7327      1610    55371     False
6077       181    63305      True

[160 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8858603066439523,
 'test_loss': 0.19146889448165894,
 'test_prec': 0.8137715179968701,
 'test_recall': 0.9719626168224299}
--------------------------------------------------------------------------------

Test : 180
-- Random test --

       a.index  b.index  matching
571       1715    45275      True
17195      182    39854     False
1639      1842    39128     False
10080      434    62483     False
13972     1821    42562     False
...        ...      ...       ...
8399      1815    24387     False
16837      632    41942     False
2442       525    20284     False
10017     2561    55684     False
13114     1099    22216     False

[180 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8830935251798562,
 'test_loss': 0.16870218515396118,
 'test_prec': 0.8509532062391681,
 'test_recall': 0.9177570093457944}
--------------------------------------------------------------------------------

Test : 200
-- Random test --

       a.index  b.index  matching
8268      2250    60740     False
76        1442    54315     False
6457      1734    31882     False
6653      1679     7011     False
1764      1218    45739      True
...        ...      ...       ...
11536      473    38268      True
6687      1212     6706     False
1476       711    50858     False
15595      511    12386     False
7810      1727    10990     False

[200 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8781869688385269,
 'test_loss': 0.16651082038879395,
 'test_prec': 0.8874045801526718,
 'test_recall': 0.8691588785046729}
--------------------------------------------------------------------------------

Test : 250
-- Random test --

       a.index  b.index  matching
6489      1802    34940     False
5208      1240    51297      True
3083      2272    42830     False
11876     2574    53286     False
13993     1534    57125     False
...        ...      ...       ...
13946     2457    16366      True
5919      1749    44025     False
5297      2330    37915     False
11041     2564    15934     False
127       1660    39229      True

[250 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.902671755725191,
 'test_loss': 0.10103614628314972,
 'test_prec': 0.9220272904483431,
 'test_recall': 0.8841121495327103}
--------------------------------------------------------------------------------

Test : 300
-- Random test --

       a.index  b.index  matching
3702       330    28522     False
16254      842    53104     False
5486       526    54237     False
9126      2406    32338     False
6108      1182    32601      True
...        ...      ...       ...
13548     2510     5970     False
6355      1981    19278     False
9098      2405    38474     False
3357       176    60883     False
15649      413    53513      True

[300 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9251336898395722,
 'test_loss': 0.12869805097579956,
 'test_prec': 0.8841567291311755,
 'test_recall': 0.9700934579439252}
--------------------------------------------------------------------------------

Test : 400
-- Random test --

       a.index  b.index  matching
16517     1616    19226     False
3430       107    47172     False
6657      2300    52181     False
965       1508     6295     False
843       1834     5869      True
...        ...      ...       ...
789         33    18241     False
8719      1298      466      True
9399       776    13722      True
10681      653    42976      True
7636      1955    62491     False

[400 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9317160826594789,
 'test_loss': 0.10822026431560516,
 'test_prec': 0.8970588235294118,
 'test_recall': 0.9691588785046729}
--------------------------------------------------------------------------------

Test : 500
-- Random test --

       a.index  b.index  matching
2514       604    47010     False
16058       92    59265     False
5320       758    59307     False
16933     1217    42091     False
9121      1197     8831      True
...        ...      ...       ...
887        151    47010     False
15523     1148     6179     False
8547       632    11310     False
653       1821    15386     False
1307       453    38759     False

[500 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9153605015673981,
 'test_loss': 0.1605052947998047,
 'test_prec': 0.8787618228718831,
 'test_recall': 0.9551401869158879}
--------------------------------------------------------------------------------

Test : 600
-- Random test --

       a.index  b.index  matching
2494      1148     5245     False
13259      687    20719     False
2610      1794    54433     False
16534     1683     4615     False
764       1944    20247     False
...        ...      ...       ...
2978      2517    36890     False
16241     1222    17149      True
4958      1826     5132     False
4346      2564    52821     False
5082      2310    63588     False

[600 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9325378614043139,
 'test_loss': 0.11642470210790634,
 'test_prec': 0.9161406672678089,
 'test_recall': 0.9495327102803738}
--------------------------------------------------------------------------------

Test : 700
-- Random test --

       a.index  b.index  matching
11383     1148    27230     False
11008     2310      996     False
4190      1942     6738      True
4605      1826    13713     False
15072     2349    60327     False
...        ...      ...       ...
12219     1901    59751     False
12273      613     9933      True
587        141    15868     False
8096      1342    44600     False
9296      2514    26672      True

[700 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9408528198074277,
 'test_loss': 0.09546972811222076,
 'test_prec': 0.9234923492349235,
 'test_recall': 0.9588785046728971}
--------------------------------------------------------------------------------

Test : 800
-- Random test --

       a.index  b.index  matching
7689       562    57199     False
12523     1643    55055     False
11323     2383      942     False
9046       519    34481     False
9432       859    60400     False
...        ...      ...       ...
11339     1560     2464     False
15476       61    21283     False
16273      182    36691     False
1802      2386    10564      True
7953      1313      631     False

[800 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9282428702851886,
 'test_loss': 0.12881489098072052,
 'test_prec': 0.9139492753623188,
 'test_recall': 0.9429906542056075}
--------------------------------------------------------------------------------

Test : 900
-- Random test --

       a.index  b.index  matching
1932      1759    12712     False
4542       375    17140      True
6383      1681    23578     False
10905     1166     1899      True
15344      832    56210     False
...        ...      ...       ...
8791      2503    21427     False
7396       758    37494     False
11959     1573    45905      True
530        570    34166     False
7083      1188    52875     False

[900 rows x 3 columns]
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9222699093943729,
 'test_loss': 0.12992872297763824,
 'test_prec': 0.9415774099318404,
 'test_recall': 0.9037383177570093}
--------------------------------------------------------------------------------

Test : 1000
-- Random test --

       a.index  b.index  matching
2478      2380    34940     False
5066       404    51653     False
3220         3    25469     False
13274     1944     3336     False
13719     2554    48928     False
...        ...      ...       ...
2695      2521    46632     False
2615      1156    63037     False
7088       626    14499     False
6245      1714    18595     False
6554      2587    60772     False

[1000 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9363295880149813,
 'test_loss': 0.10699966549873352,
 'test_prec': 0.9380863039399625,
 'test_recall': 0.9345794392523364}
--------------------------------------------------------------------------------

Test : 17223
-- Random test --

       a.index  b.index  matching
1125      2431     2488     False
11286      115    12540     False
346        212     9099     False
5316      2030    47913     False
4069       229    31280     False
...        ...      ...       ...
3730        12    61919     False
653       1821    15386     False
641       1082    28746     False
12149      492      818     False
2885      1746    59852     False

[17223 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9453197405004634,
 'test_loss': 0.12247005850076675,
 'test_prec': 0.9375,
 'test_recall': 0.9532710280373832}
--------------------------------------------------------------------------------
New cross validation 3

Test : 50
-- Random test --

       a.index  b.index  matching
5759       520    27009     False
5655      1954    60370      True
16882     1929    47512     False
2171      1061    13989     False
14273      578    12112     False
948        722    27778     False
3850      1692    11147     False
14083       95     1112     False
16280      204    25396     False
7343       652     7876     False
5923       691    12466     False
1498      1828    13700     False
14240     2264    21917     False
11600       45    59605     False
5089      1852     4443     False
11527      228    33729     False
5831       474    62941      True
4809      1715    46865     False
314       1863    13660     False
363       1428    54940     False
1963      2249    28688     False
562        321    39715     False
15454     1146    27082     False
4273       924    31474     False
15160      604    10703     False
3262      1282    26552     False
15280     2235    15454      True
2353       390    34130     False
4445      1681    31053     False
2267      1561    25298     False
11444     1145     3284     False
11681     2421    14825     False
5685      1004     6070     False
13671     1953    52703     False
5644      2600     8255     False
2411      1920    29061     False
47        2272     6326     False
2511      2029    33055     False
13013      228    17082     False
9523        95    25741     False
10637      631    48702     False
17067     1200    19184     False
16548     1944     8129     False
15571       41     7969     False
14903     1244    27667     False
15112      562     2706     False
508        234    63415     False
8749        19    25559     False
3748       773    48851     False
13006      281    38045      True
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.3744426667690277,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 75
-- Random test --

       a.index  b.index  matching
16117      783    23948     False
12302     1510    45096     False
15645      705    13715      True
1203      2036    23133     False
347       2568     5130     False
...        ...      ...       ...
1598      1991     3725     False
11858     1954    31882      True
15228      527    26044     False
6308       812     5278     False
7279      1382    53775      True

[75 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8545454545454546,
 'test_loss': 0.17876142263412476,
 'test_prec': 0.831858407079646,
 'test_recall': 0.8785046728971962}
--------------------------------------------------------------------------------

Test : 100
-- Random test --

       a.index  b.index  matching
17046      304    26578     False
4638      1033    58135      True
6126       719     6891      True
13013      228    17082     False
7980      2111    23468     False
...        ...      ...       ...
2286       264    39079     False
3493      1792    56675      True
7692      1981     9988     False
1500       960    61117     False
7512        19    61022     False

[100 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8320825515947466,
 'test_loss': 0.2378738969564438,
 'test_prec': 0.835216572504708,
 'test_recall': 0.8289719626168224}
--------------------------------------------------------------------------------

Test : 120
-- Random test --

       a.index  b.index  matching
14624     2604     7235     False
9851      2521    33081     False
2860       682    20876     False
1225      2374    18632     False
11335     2525    17905     False
...        ...      ...       ...
11680      637    62491     False
13509      561    15861     False
17145      704    52854     False
13029     1105    25877     False
13842      776    23947     False

[120 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8789748457522544,
 'test_loss': 0.14744144678115845,
 'test_prec': 0.892960462873674,
 'test_recall': 0.8654205607476636}
--------------------------------------------------------------------------------

Test : 140
-- Random test --

       a.index  b.index  matching
7583       483    22839     False
5765        66    44931     False
3483      1916    11528     False
12311     1965    51991     False
6822      2403    12700     False
...        ...      ...       ...
9377      1828    56270     False
11766      716    22798     False
710       1391    11384      True
14450     1954    52100      True
8531      1525    49664     False

[140 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9192825112107623,
 'test_loss': 0.10217361897230148,
 'test_prec': 0.8836206896551724,
 'test_recall': 0.9579439252336449}
--------------------------------------------------------------------------------

Test : 160
-- Random test --

       a.index  b.index  matching
4722      1752    21619     False
13048      734    48154     False
8219      1749     6067     False
5989      1501    63016     False
9071      2300    31322     False
...        ...      ...       ...
511        899    27270     False
16043      604    53378     False
14992      574    62233     False
2520      2560    15024     False
2552      1920    26155     False

[160 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.899781181619256,
 'test_loss': 0.146430104970932,
 'test_prec': 0.8460905349794239,
 'test_recall': 0.9607476635514018}
--------------------------------------------------------------------------------

Test : 180
-- Random test --

       a.index  b.index  matching
229       2298    11707     False
13972     1821    42562     False
8968        19    30952     False
15520     1392    54424     False
6821      1742    23465     False
...        ...      ...       ...
13371      924     3533     False
6355      1981    19278     False
9859       229    29409     False
8078       197    57630     False
8899        40    45884     False

[180 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9043312708234174,
 'test_loss': 0.11013577878475189,
 'test_prec': 0.9214354995150339,
 'test_recall': 0.8878504672897196}
--------------------------------------------------------------------------------

Test : 200
-- Random test --

       a.index  b.index  matching
15535       90     7729     False
8916       905    17862     False
15936     1968    61585     False
9411      1005    49630     False
6471      2073    14374      True
...        ...      ...       ...
675        670    34485      True
10616       45    16634     False
13015      373    34045     False
1506      2610    34045     False
2261      1133    38408     False

[200 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8776550552251485,
 'test_loss': 0.2848983108997345,
 'test_prec': 0.8045171339563862,
 'test_recall': 0.9654205607476636}
--------------------------------------------------------------------------------

Test : 250
-- Random test --

       a.index  b.index  matching
13490     2565    63981     False
2355      1981    44760     False
8703       469    27009     False
5752       177    41738     False
6859      1015    35679      True
...        ...      ...       ...
2616       456    59601      True
16637     1834    57138     False
3474      1172    10962     False
9281      1600    57016     False
8672      1254    10145     False

[250 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9064748201438849,
 'test_loss': 0.1197304055094719,
 'test_prec': 0.9310344827586207,
 'test_recall': 0.883177570093458}
--------------------------------------------------------------------------------

Test : 300
-- Random test --

       a.index  b.index  matching
15026      861    16311     False
16704      492    11748     False
6896      1936    10632      True
9596       570    18378     False
11330      336    57461     False
...        ...      ...       ...
360       1327    26844      True
8284      1949    34833     False
7891      2332    44561     False
663       1462    14264     False
1323       138    34846     False

[300 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9139307897071872,
 'test_loss': 0.1476379930973053,
 'test_prec': 0.8699324324324325,
 'test_recall': 0.9626168224299065}
--------------------------------------------------------------------------------

Test : 400
-- Random test --

      a.index  b.index  matching
8927     2539    43308     False
4627     1023    32701     False
7791     2500     2170     False
2307     2216    23579     False
6581     1438     1796      True
...       ...      ...       ...
6289     1039    55539      True
6564      994    34787     False
6726     2463    32695      True
7397     2560    60186     False
2141     2360    45165     False

[400 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9314045730284647,
 'test_loss': 0.09028186649084091,
 'test_prec': 0.9301025163094129,
 'test_recall': 0.9327102803738317}
--------------------------------------------------------------------------------

Test : 500
-- Random test --

       a.index  b.index  matching
2348      2279    42612     False
8252      1531    22394     False
3636      1127    28206     False
12775     1133    59480     False
13917     1200    18082     False
...        ...      ...       ...
16251     2562     4589     False
8616      1419    35045     False
15166     1683    38470     False
10045     2561    60063     False
12073      169    38677     False

[500 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.933768656716418,
 'test_loss': 0.1132378801703453,
 'test_prec': 0.9320297951582868,
 'test_recall': 0.9355140186915888}
--------------------------------------------------------------------------------

Test : 600
-- Random test --

       a.index  b.index  matching
14748      657     7823     False
5894      2006    60624      True
16235     2560    11444     False
9537       293    34851     False
17193     1612    28422     False
...        ...      ...       ...
13197      365    18297      True
5776      2265    17905     False
14919     2082    17331     False
10951     2468    45307     False
1134      1975    59558     False

[600 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9317757009345794,
 'test_loss': 0.11877866834402084,
 'test_prec': 0.9317757009345794,
 'test_recall': 0.9317757009345794}
--------------------------------------------------------------------------------

Test : 700
-- Random test --

       a.index  b.index  matching
16459     1754    50047     False
6474      2513    57837     False
16054     1684    50627     False
13679      960    42029     False
13317      659    52662     False
...        ...      ...       ...
6146      2587    55579     False
16086      979    62736      True
8969       570     6677     False
4491      1125     4154      True
11250      791    56086     False

[700 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9276995305164318,
 'test_loss': 0.13678403198719025,
 'test_prec': 0.9320754716981132,
 'test_recall': 0.9233644859813084}
--------------------------------------------------------------------------------

Test : 800
-- Random test --

       a.index  b.index  matching
2088      1442    62882      True
17044     2565    24625     False
28        1953    42525     False
15394      960     6409     False
9541       713    56612     False
...        ...      ...       ...
4039      2506    47615     False
15765     1439    22308     False
12232     1901    46762     False
8758      1082    63428     False
4874      1313    11409     False

[800 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.934622467771639,
 'test_loss': 0.13016004860401154,
 'test_prec': 0.9210526315789473,
 'test_recall': 0.9485981308411215}
--------------------------------------------------------------------------------

Test : 900
-- Random test --

       a.index  b.index  matching
41        1920     1560     False
3465      1200    41405     False
15728      758    49373     False
9134      1004     9990     False
3325      2562    56721     False
...        ...      ...       ...
11541      618    53137     False
11124     1213     8771     False
15696      911    25016     False
2393      1511    14822     False
17187     1158    31984      True

[900 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9389067524115755,
 'test_loss': 0.10621235519647598,
 'test_prec': 0.9232158988256549,
 'test_recall': 0.9551401869158879}
--------------------------------------------------------------------------------

Test : 1000
-- Random test --

       a.index  b.index  matching
3200       540    38576      True
9460      2233    39072      True
2617      2577    23079     False
9595      2509    13981     False
15533     1589    62001      True
...        ...      ...       ...
9316      1276    50922      True
10428      729    17347      True
2524       779    53122     False
16260     1706    24204     False
7586      2396    30234     False

[1000 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9294642857142857,
 'test_loss': 0.12205615639686584,
 'test_prec': 0.8897435897435897,
 'test_recall': 0.9728971962616823}
--------------------------------------------------------------------------------

Test : 17223
-- Random test --

       a.index  b.index  matching
16360     1133    40688     False
3791      1331    55684     False
5762      2030      405     False
3352      2168    57127     False
5336       997    17313     False
...        ...      ...       ...
14827     1392    41368      True
1891      1200    53286     False
7435      2581     4215     False
1949      1953    23646     False
6785      2543    16057     False

[17223 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.953831948291782,
 'test_loss': 0.12508957087993622,
 'test_prec': 0.9425182481751825,
 'test_recall': 0.9654205607476636}
--------------------------------------------------------------------------------
New cross validation 4

Test : 50
-- Random test --

       a.index  b.index  matching
13572      185    55034     False
4415      1518    29061     False
15127     1213    50901     False
1255      1362     7374     False
1801      1712    17562     False
8588      2083    49417      True
14747     1133    13989      True
15579     1443    49977      True
15245     2208    28746     False
11754     2333    56771     False
181       2420    47649     False
10877     2560     6899     False
11514     1857    26818      True
1192      1529    43737     False
11085     1365    26879     False
812       2506    22242     False
14481     1812    46937      True
12134     2568    39932     False
901       2538    19704     False
2455       772     6903     False
6053      2001    57488     False
4124       604    31322     False
4650      1439    26554     False
13230     2432    22295     False
15512      501    14805     False
2022       392    27382     False
127       1660    39229      True
12594     2390      295     False
14894      203    41920     False
4185        12    24966     False
11472     1102     4120      True
13378     1840    51042     False
11003     1508    38092     False
9512      1213    35170     False
586       1407    57488     False
7062      1655    32116     False
379        858    46443     False
14215     2300     1043     False
8303      2092    13143      True
16703     1365     1071     False
4968        56    12829     False
3661      2380    17474     False
11922     1960     5624     False
5680       229    36529     False
5178      1981    45909     False
6677      1815     7572     False
6755      1944     1750      True
14092     2332    19951     False
6733       237    58788     False
12252      517    57440     False
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.87248322147651,
 'test_loss': 0.16212880611419678,
 'test_prec': 0.8369098712446352,
 'test_recall': 0.9112149532710281}
--------------------------------------------------------------------------------

Test : 75
-- Random test --

       a.index  b.index  matching
9003      2330    34299     False
5975      2185    12676     False
13541      453    29138     False
15292     1401    40054     False
16977     1883    16923     False
...        ...      ...       ...
15606      228     9132     False
8155      1134       16      True
12914     1221    16057     False
766       1840    31328     False
2210      1840    33801     False

[75 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8916211293260474,
 'test_loss': 0.14240394532680511,
 'test_prec': 0.8694493783303731,
 'test_recall': 0.9149532710280374}
--------------------------------------------------------------------------------

Test : 100
-- Random test --

       a.index  b.index  matching
15182     1643     7844     False
13036     1698    23845     False
5903      1830    26244     False
1639      1842    39128     False
4762       618    44220     False
...        ...      ...       ...
8277      2294    54206     False
12377     1958     3725     False
3321       548    10990     False
692       2354     8820      True
10863     2219    28074      True

[100 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8774928774928775,
 'test_loss': 0.17362508177757263,
 'test_prec': 0.8918918918918919,
 'test_recall': 0.8635514018691589}
--------------------------------------------------------------------------------

Test : 120
-- Random test --

       a.index  b.index  matching
16774      441    36667     False
4718       291    45265     False
10621      637    14191     False
5965      1558    21340     False
16677      519    27230     False
...        ...      ...       ...
10533      632    48587     False
17087     1842    50005     False
8838      1065    38879      True
1175      1868    13731     False
10863     2219    28074      True

[120 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8760259179265659,
 'test_loss': 0.22678522765636444,
 'test_prec': 0.8144578313253013,
 'test_recall': 0.9476635514018692}
--------------------------------------------------------------------------------

Test : 140
-- Random test --

       a.index  b.index  matching
10509     2593    64262     False
9202      1503    22121      True
6864       733    48064     False
944        256    34093      True
12938     1244    29825     False
...        ...      ...       ...
17055     1288    18752     False
14851     1815    51361     False
11808     1185    49264     False
5658      2513    18780     False
9667      1205    46318     False

[140 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8966480446927374,
 'test_loss': 0.12382359057664871,
 'test_prec': 0.8933209647495362,
 'test_recall': 0.9}
--------------------------------------------------------------------------------

Test : 160
-- Random test --

       a.index  b.index  matching
4550      1429    24414     False
894       1920    50062     False
10129     2456    27453      True
6868       990    50278     False
2730      1525    26496     False
...        ...      ...       ...
10633     1244    45957     False
8224       707    41474     False
3908      1826    49267     False
15333        8     9058     False
3964      1348    20418     False

[160 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9139307897071872,
 'test_loss': 0.07950899004936218,
 'test_prec': 0.8699324324324325,
 'test_recall': 0.9626168224299065}
--------------------------------------------------------------------------------

Test : 180
-- Random test --

       a.index  b.index  matching
4462      2029    40109     False
13872     2249    14535     False
1118      1235    52688      True
12761     1741    52811     False
6142      2315    51185     False
...        ...      ...       ...
16919     1587    12259     False
7906       696    13533     False
1645        19    20343     False
16269     1065    50886     False
8997       713    38943     False

[180 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8862494289629967,
 'test_loss': 0.15169407427310944,
 'test_prec': 0.8668453976764968,
 'test_recall': 0.9065420560747663}
--------------------------------------------------------------------------------

Test : 200
-- Random test --

       a.index  b.index  matching
14511     1401    43919     False
6011       541    18579     False
3389      2455    53327     False
7665      1848    52886      True
1230      1082    45010     False
...        ...      ...       ...
10404     2549    59008      True
4735      2483    56451     False
7649       177    35854     False
13628     2432    25475     False
1479      2609    15812     False

[200 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9147149801148919,
 'test_loss': 0.1168297529220581,
 'test_prec': 0.86756077116513,
 'test_recall': 0.9672897196261683}
--------------------------------------------------------------------------------

Test : 250
-- Random test --

       a.index  b.index  matching
9389      1424    39692      True
15411     1239     6677     False
16311      612    48814     False
16327     1821    11740     False
4467       497    24144     False
...        ...      ...       ...
4300      2598    39695      True
17162      938    49974     False
16185     1842    57982     False
16746     1990    12267      True
278       1698    24132     False

[250 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8717948717948719,
 'test_loss': 0.1766636222600937,
 'test_prec': 0.8404163052905465,
 'test_recall': 0.905607476635514}
--------------------------------------------------------------------------------

Test : 300
-- Random test --

       a.index  b.index  matching
4847      2007    58117     False
3414      2433    38579     False
17121     1976    45743     False
15372     1578    22536     False
7144      1969    39677     False
...        ...      ...       ...
4133       196    46744      True
12601      337    23625      True
992       1249     8398      True
4085       229    34372     False
852       1821    38545     False

[300 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9125109361329834,
 'test_loss': 0.1351119428873062,
 'test_prec': 0.8577302631578947,
 'test_recall': 0.974766355140187}
--------------------------------------------------------------------------------

Test : 400
-- Random test --

       a.index  b.index  matching
12627     1749    63389     False
3813      1005    59938     False
1990      1713    38913     False
12483      832    34681     False
6787      1966     8524      True
...        ...      ...       ...
4636       604    19923     False
14509      477     5278     False
9355      2351    63261     False
14068     2342    34299     False
11975     1213    18988     False

[400 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9259423503325943,
 'test_loss': 0.14695125818252563,
 'test_prec': 0.8810126582278481,
 'test_recall': 0.9757009345794393}
--------------------------------------------------------------------------------

Test : 500
-- Random test --

       a.index  b.index  matching
16742     1475    50720     False
7076       205     3858     False
11078       21    47245     False
8437      1993    40729     False
2264      2431    33431     False
...        ...      ...       ...
2410      1828    29277      True
8214       272     7492     False
7421      1193    24194     False
9074      1185    29410     False
2148      1435    51866     False

[500 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9192488262910796,
 'test_loss': 0.14056545495986938,
 'test_prec': 0.9235849056603773,
 'test_recall': 0.9149532710280374}
--------------------------------------------------------------------------------

Test : 600
-- Random test --

       a.index  b.index  matching
10642     1512     2830      True
11735     2281    44600     False
15949     1253    49426     False
1016      1767    41701     False
2131      1319     5668     False
...        ...      ...       ...
14870     2564    35086     False
14118      819    39121     False
5489      1887    27806     False
1176      1451    26223      True
10323     2506    56760     False

[600 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9145584725536993,
 'test_loss': 0.1285906732082367,
 'test_prec': 0.9346341463414635,
 'test_recall': 0.8953271028037383}
--------------------------------------------------------------------------------

Test : 700
-- Random test --

       a.index  b.index  matching
2314      2588    11202     False
3183       282    54941     False
5798      1068    36667     False
6828      1714    47099     False
3262      1282    26552     False
...        ...      ...       ...
16792      520    39715     False
15150     1746    56347     False
14881     2300     2892     False
3728      1683    55610     False
1765      2614    26660      True

[700 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9406264609630668,
 'test_loss': 0.10370897501707077,
 'test_prec': 0.941066417212348,
 'test_recall': 0.9401869158878504}
--------------------------------------------------------------------------------

Test : 800
-- Random test --

       a.index  b.index  matching
9886       432    32830     False
8384      1407    47153     False
15940     2300    56760     False
5446      1012    22071     False
16611      840    57559     False
...        ...      ...       ...
16266     1712    50502     False
793       1211    40192      True
14735     2552    13482     False
3703      1341    54424     False
11425     2564     6890     False

[800 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9312557286892759,
 'test_loss': 0.14214184880256653,
 'test_prec': 0.9136690647482014,
 'test_recall': 0.9495327102803738}
--------------------------------------------------------------------------------

Test : 900
-- Random test --

       a.index  b.index  matching
6673      1242    39569     False
11903     1640    23646     False
15155     1752    63421     False
15779     2571    32736      True
11800     2256    34934     False
...        ...      ...       ...
1945      2245    26179     False
14273      578    12112     False
2171      1061    13989     False
7838      2456    23036     False
12072      451    40851     False

[900 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9402023919043238,
 'test_loss': 0.12012247741222382,
 'test_prec': 0.9257246376811594,
 'test_recall': 0.9551401869158879}
--------------------------------------------------------------------------------

Test : 1000
-- Random test --

       a.index  b.index  matching
806          6    52821     False
3326      1037    34393     False
2594      1920    49714     False
5172      1037    24364      True
9267      1288    10545     False
...        ...      ...       ...
3264       104    63022     False
14093     2399    56451     False
3736       178    45265     False
11883      122    39339     False
16675     2068    52438      True

[1000 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9383753501400561,
 'test_loss': 0.1163455918431282,
 'test_prec': 0.9375,
 'test_recall': 0.9392523364485982}
--------------------------------------------------------------------------------

Test : 17223
-- Random test --

       a.index  b.index  matching
3478      1288    27684     False
3378      1333    63776      True
1878      1004    22661     False
9198      2530    18093     False
3567      1975    41015     False
...        ...      ...       ...
16894     1105    39799     False
5910        95    20602     False
14545      855    49923     False
12883     1840    32362     False
9758       708    59279     False

[17223 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9569643683479871,
 'test_loss': 0.10230362415313721,
 'test_prec': 0.9477543538038496,
 'test_recall': 0.9663551401869159}
--------------------------------------------------------------------------------
Could not create dir out, File exists
    ########### 



New Dataset: <function deepmatcher_structured_walmart_amazon at 0x1553060e6e50>
New cross validation 0

Test : 50
-- Random test --

      a.index  b.index  matching
4489      852    14707     False
4159      822     9734     False
2780      419     5216     False
2927     2160    15757     False
3142     1720    20522      True
3491     2085     6140     False
535      1269     7953     False
2836     1132    14707     False
2902       58    20807     False
544      2196    17366      True
3979     1262    12734      True
2197     1527     5049     False
1357     1631     6556     False
2860      612     4733     False
3960     2100      984     False
604      1699    17616     False
1144     1172    16301     False
2195     1581     6075     False
4772      327    20715     False
3039     1365    10473     False
2666     1761    21681     False
432      1098    11745     False
2406      822    21693     False
1186     2190    21661      True
2570     2143     8239     False
811       342    13307     False
2952     2546    21955     False
2552      419    13254     False
2535     1016    17235     False
4252      725    16800      True
4649     2220    17892     False
1022     2080    18134     False
1400     1296     9734     False
5745      792     6397     False
2574      582    11379     False
351       821      609     False
1760     1153    13245      True
2042     1694    20397      True
4512     1134     6753     False
5838     1502     7665     False
5741     2371     6949     False
1720      419       30     False
5004     1536     4044     False
5025      577     9160     False
2881      219    12694     False
4025     1861     6115     False
410      1879     8607     False
2728     1537    20635     False
4651      429    15215     False
5694      584     4868     False
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.2900906801223755,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 75
-- Random test --

      a.index  b.index  matching
2821     1153    13243     False
5563       56    20182     False
2829     2405    14932     False
3573     2405    18732     False
649      1258    14686     False
...       ...      ...       ...
1844     1473     3250      True
2307     1172    16731     False
6128      305    19748     False
1380     1673    13271     False
293       215    20664     False

[75 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.019900497512437814,
 'test_loss': 0.34099677205085754,
 'test_prec': 0.25,
 'test_recall': 0.010362694300518135}
--------------------------------------------------------------------------------

Test : 100
-- Random test --

      a.index  b.index  matching
2789     2297    12789     False
5647     2548     3616     False
6078      348     1188     False
4428     1504     6840     False
646      1699    20801     False
...       ...      ...       ...
2634     1136    17382     False
3758     1699    16966     False
290       672    14822     False
5151       58     3549     False
3620     1948     4289     False

[100 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.3238222599029541,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 120
-- Random test --

      a.index  b.index  matching
3585     1573    13416     False
2402      753     7558     False
3500      396     7149      True
6116       92    12789     False
4196     1024    19648     False
...       ...      ...       ...
966      1605    13427     False
1445     1191    15387     False
205       918     6137     False
1388        2    16495     False
2784      706    14765     False

[120 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.3075723350048065,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 140
-- Random test --

      a.index  b.index  matching
3623     1959     6740     False
6045     1432    15920     False
4495     2113     9288     False
4474     1334    14525     False
1724     1413      799     False
...       ...      ...       ...
3220     2539    10705      True
2248     1532     2689     False
4294      889     8826     False
3849     1048     4830     False
1274     1170    12137     False

[140 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.27299943566322327,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 160
-- Random test --

      a.index  b.index  matching
843      1862     7472     False
1388        2    16495     False
3714     2263     3021     False
1259     1910     5797     False
4845     1178    12474     False
...       ...      ...       ...
3347     2236    14107     False
161      1809    20067     False
3708     1425     4733     False
2121     2149     2872     False
3466      627    10869     False

[160 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.3507412374019623,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 180
-- Random test --

      a.index  b.index  matching
738      2249     7204     False
3472     1296    18152     False
427      1354    18778     False
356       634      928     False
729       429     5217     False
...       ...      ...       ...
2373     1237    21547     False
2322     1595    15395     False
1689      419     5215     False
3549     1888     8235     False
4929      539     1564     False

[180 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.18705035971223022,
 'test_loss': 0.3866361081600189,
 'test_prec': 0.3058823529411765,
 'test_recall': 0.13471502590673576}
--------------------------------------------------------------------------------

Test : 200
-- Random test --

      a.index  b.index  matching
5271     2422     3371     False
432      1098    11745     False
4811     1660    11172      True
4187     2546    13373     False
1590      896     3556     False
...       ...      ...       ...
5515      337    16323     False
2578     2133    18827     False
4109     1711    16373     False
333      2439    10806     False
5337     1594     4395     False

[200 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.3088299632072449,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 250
-- Random test --

      a.index  b.index  matching
1774      757      449     False
1219      497    13644     False
5531     1630    10852     False
1437      597     8342     False
5515      337    16323     False
...       ...      ...       ...
3976      547     9303     False
5709      879     7032     False
4022     2322     3140     False
502      1295      510     False
4082     1948    10328     False

[250 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.4735376044568246,
 'test_loss': 0.21679838001728058,
 'test_prec': 0.5120481927710844,
 'test_recall': 0.44041450777202074}
--------------------------------------------------------------------------------

Test : 300
-- Random test --

      a.index  b.index  matching
956      2412    20963     False
2933      414     1529     False
5030     1169    13308     False
2565      832    14586     False
633      1145    10785     False
...       ...      ...       ...
2859      909    15128     False
1701     1701    18550     False
1823     2241    16499     False
2279      744     2825     False
3702      887    18151     False

[300 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.02816901408450704,
 'test_loss': 0.5329874753952026,
 'test_prec': 0.15,
 'test_recall': 0.015544041450777202}
--------------------------------------------------------------------------------

Test : 400
-- Random test --

      a.index  b.index  matching
4272     2122     7860     False
4663       62    15919     False
3965      688     4783      True
633      1145    10785     False
6139     2322     5072     False
...       ...      ...       ...
5229     1178    14701     False
351       821      609     False
226      2293    10546     False
5245     1064    21924     False
3880     1257      286     False

[400 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.07434944237918216,
 'test_loss': 0.6816223859786987,
 'test_prec': 0.13157894736842105,
 'test_recall': 0.05181347150259067}
--------------------------------------------------------------------------------

Test : 500
-- Random test --

      a.index  b.index  matching
3634     1930    15375      True
1609      280    21955     False
1186     2190    21661      True
1977      896    14820     False
4959       25     1034     False
...       ...      ...       ...
3211      680      843      True
344      1761    21432     False
1514       66     3668      True
735      1080    14454      True
4613     1988    19147     False

[500 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7519181585677749,
 'test_loss': 0.19783265888690948,
 'test_prec': 0.7424242424242424,
 'test_recall': 0.7616580310880829}
--------------------------------------------------------------------------------

Test : 600
-- Random test --

      a.index  b.index  matching
4967     1611      114     False
1174     1891    19706     False
399       740    17812     False
2352     2546     9064     False
1022     2080    18134     False
...       ...      ...       ...
2054     1899     5458      True
4087     1995    16720     False
1827      102    13721     False
4374     1673    15267     False
2292      741    11537      True

[600 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6531791907514451,
 'test_loss': 0.26595833897590637,
 'test_prec': 0.738562091503268,
 'test_recall': 0.5854922279792746}
--------------------------------------------------------------------------------

Test : 700
-- Random test --

      a.index  b.index  matching
1153     1348     8642     False
5110     1966    10566     False
2884     1882    11436     False
5367       41    18720     False
5251     2488     5635      True
...       ...      ...       ...
5133      417    20429     False
2947     1511    14511     False
4347     1825     5955     False
2675      339     5576     False
359      2349     2809     False

[700 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7675675675675676,
 'test_loss': 0.20012493431568146,
 'test_prec': 0.8022598870056498,
 'test_recall': 0.7357512953367875}
--------------------------------------------------------------------------------

Test : 800
-- Random test --

      a.index  b.index  matching
708      2192     3016     False
3746      370    15071      True
3438      284      877     False
5547     1073    14421     False
2218       65    15083     False
...       ...      ...       ...
5220      571     1341     False
3763      462    14691     False
3677     1060    17561     False
3102     1564     4890     False
5183     1016    17237     False

[800 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7210526315789473,
 'test_loss': 0.2408931851387024,
 'test_prec': 0.732620320855615,
 'test_recall': 0.7098445595854922}
--------------------------------------------------------------------------------

Test : 900
-- Random test --

      a.index  b.index  matching
4636      621     1159     False
5370      996     2750      True
4241     1594    20353     False
2808      632     3169     False
4812     2272     6386     False
...       ...      ...       ...
5909     2349     2279     False
97         81    20177     False
5795      978    17238     False
5632      968    15233     False
6054     2439    14765     False

[900 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6121372031662269,
 'test_loss': 0.30242645740509033,
 'test_prec': 0.6236559139784946,
 'test_recall': 0.6010362694300518}
--------------------------------------------------------------------------------

Test : 1000
-- Random test --

      a.index  b.index  matching
5108     1528      250     False
2850     1699    16374     False
6042     1882     8255     False
2663      201     3555     False
227       456    10915     False
...       ...      ...       ...
5724      967    17203     False
1562      781    21212     False
296       305    14227     False
5306     1016    14346     False
4968     1656      799     False

[1000 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7598944591029023,
 'test_loss': 0.19874249398708344,
 'test_prec': 0.7741935483870968,
 'test_recall': 0.7461139896373057}
--------------------------------------------------------------------------------

Test : 6144
-- Random test --

      a.index  b.index  matching
5650      333     1749     False
2465     2230    19286     False
4377     1516    14759     False
6028     1711    17548     False
5048     1483    10144     False
...       ...      ...       ...
5942       25     6528     False
2535     1016    17235     False
4371     1933    15086     False
95        672    12918     False
1845     2265    21671     False

[6144 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8471849865951743,
 'test_loss': 0.1799120157957077,
 'test_prec': 0.8777777777777778,
 'test_recall': 0.8186528497409327}
--------------------------------------------------------------------------------
New cross validation 1

Test : 50
-- Random test --

      a.index  b.index  matching
5790     1737    12280     False
4361     2315     2142     False
4087     1995    16720     False
226      2293    10546     False
1666     1959    17837     False
1330      278    20067     False
3897      618     5571     False
3177       29     2074     False
5568     2349      335     False
4760     1394    19580      True
5537     2216     8570     False
5935     1066     8297      True
3777     1070    15508     False
3395     2472    13427     False
4781      199     3535     False
887       582    20640     False
4921     1404    18622     False
1823     2241    16499     False
5327     2322     8708     False
5063     1301    11263     False
5257     1258     6742     False
5665       22    16363     False
1621     2322    19320     False
4366     1583    15144     False
5465      949     9368     False
3217      671    18863     False
1059     2361     6743     False
4704      588    20108      True
373      2033     6562     False
4654     1695    17603     False
5793     2293     6551     False
2893     2020    17203     False
356       634      928     False
3906      589    20807     False
3275     1716     9715     False
4552      883     4979     False
5718      625    16598     False
1082      305    10293     False
2689     1869     8591     False
5708       79    18557     False
2276     2186     3614     False
989      2085    16120     False
4071      417     2819     False
2681     1733    17687     False
4474     1334    14525     False
1191     1439    19654      True
198      1016    20224     False
3957      684    19624     False
5715     2504    20715     False
4947     1609     2509      True
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.3060426115989685,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 75
-- Random test --

      a.index  b.index  matching
4560     1809    17381     False
1616      697    16650     False
2918     1229    18895     False
5220      571     1341     False
2695     2471    20429     False
...       ...      ...       ...
3841     2250    19451     False
5571     1711    17898     False
728      1534     1089     False
3658     2361      806     False
966      1605    13427     False

[75 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.3115358352661133,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 100
-- Random test --

      a.index  b.index  matching
1850     1145    18670     False
3607      166     8786     False
471      2341    15015     False
1142     1048    21573     False
3743      967    19011     False
...       ...      ...       ...
3914     2018    16450     False
4864     1246     2985     False
1556      852    14687     False
3414       81    18359     False
1636     1398     4586      True

[100 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.32291609048843384,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 120
-- Random test --

      a.index  b.index  matching
5999      745    11811     False
3013       53      805     False
3678     2391      809     False
5452     2349    10251     False
5557      226     7131     False
...       ...      ...       ...
525      2391    11013     False
3343     1242     6400     False
1909     1827     2584     False
5539      576    20429     False
2359      509     1798     False

[120 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.3137531578540802,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 140
-- Random test --

      a.index  b.index  matching
1775     2263     1019     False
4898     2128    18103     False
271      1959     4728     False
78       2548    18724     False
3467     2112     9288     False
...       ...      ...       ...
2710     1091    19597     False
2577     2046    17529     False
2147     1070     3973     False
802       760     1477     False
2282      621    13149     False

[140 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.04975124378109452,
 'test_loss': 0.2810734808444977,
 'test_prec': 0.625,
 'test_recall': 0.025906735751295335}
--------------------------------------------------------------------------------

Test : 160
-- Random test --

      a.index  b.index  matching
1597     2372    11964     False
5306     1016    14346     False
5408     1062    13373     False
4683     2438    12841     False
2806      700    16598     False
...       ...      ...       ...
5132     1861    18357      True
5191     2128    16274     False
2862      932     4722     False
3495     1656    12971     False
2876      822    12781     False

[160 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.3140324056148529,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 180
-- Random test --

      a.index  b.index  matching
6008     2082    12789     False
1370     1825     5339     False
3357       73     2262     False
662      1997    12451      True
4881     2428     8459     False
...       ...      ...       ...
2443     2430    18507     False
3503      640     6573     False
2269     2546    16910     False
1379     2361      286     False
645      2246    16773     False

[180 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.36220472440944884,
 'test_loss': 0.24603717029094696,
 'test_prec': 0.7540983606557377,
 'test_recall': 0.23834196891191708}
--------------------------------------------------------------------------------

Test : 200
-- Random test --

      a.index  b.index  matching
5736     2536    12333      True
1100     1740    10497     False
4132     1933     9137     False
2795     1927      954     False
1597     2372    11964     False
...       ...      ...       ...
4598     2477     6906     False
2875     2395     2582     False
4784     1294     6262     False
2142     1296     6750     False
3942     1429    15069     False

[200 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.49000000000000005,
 'test_loss': 0.4183305501937866,
 'test_prec': 0.47342995169082125,
 'test_recall': 0.5077720207253886}
--------------------------------------------------------------------------------

Test : 250
-- Random test --

      a.index  b.index  matching
6042     1882     8255     False
3889     1183    20239     False
1547     2504    18507     False
5430     2101     7931     False
5567      742    12769     False
...       ...      ...       ...
2540     1839     2815     False
424       226     2943     False
1087     1508    13127     False
802       760     1477     False
683      1136    17380     False

[250 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.07407407407407408,
 'test_loss': 0.41835862398147583,
 'test_prec': 0.34782608695652173,
 'test_recall': 0.04145077720207254}
--------------------------------------------------------------------------------

Test : 300
-- Random test --

      a.index  b.index  matching
2805      399    22018     False
405       519    14264     False
453       864     5880     False
854       429     5216     False
855      2328    18170     False
...       ...      ...       ...
1036      935    19579     False
2306     1334     4528     False
4713     1901     8929     False
2712     2126     7704     False
261      2101     3885     False

[300 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.20216606498194944,
 'test_loss': 0.4296724796295166,
 'test_prec': 0.3333333333333333,
 'test_recall': 0.14507772020725387}
--------------------------------------------------------------------------------

Test : 400
-- Random test --

      a.index  b.index  matching
1502     2149    10785     False
936      1205     8315     False
1737     1340     8497     False
720      1955    20238     False
1840      711     3219     False
...       ...      ...       ...
1078     2408     6808      True
1122      724     3902     False
559      2002     6980     False
362       693    17702     False
1781     2151     7338      True

[400 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7335243553008597,
 'test_loss': 0.1894531548023224,
 'test_prec': 0.8205128205128205,
 'test_recall': 0.6632124352331606}
--------------------------------------------------------------------------------

Test : 500
-- Random test --

      a.index  b.index  matching
2774     2259    14834      True
4907      353    12764     False
4629     1839     5349     False
3799     1699    16900     False
2790       73    10555     False
...       ...      ...       ...
866      1561     6235     False
3706     1257    17846     False
3333     1784     4395     False
5646     1289    20260     False
6074     2332    18200      True

[500 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.744047619047619,
 'test_loss': 0.1924237161874771,
 'test_prec': 0.8741258741258742,
 'test_recall': 0.6476683937823834}
--------------------------------------------------------------------------------

Test : 600
-- Random test --

      a.index  b.index  matching
2610     1489     2077      True
87        742    12764     False
823       944    14176     False
5708       79    18557     False
5337     1594     4395     False
...       ...      ...       ...
6056      660     4867     False
5908      912    11771     False
1002     1672     9026     False
4691     1815    17249     False
3299      124    10929     False

[600 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7371428571428572,
 'test_loss': 0.25272315740585327,
 'test_prec': 0.821656050955414,
 'test_recall': 0.6683937823834197}
--------------------------------------------------------------------------------

Test : 700
-- Random test --

      a.index  b.index  matching
811       342    13307     False
3104      967    18444     False
5979     1816     7233     False
5189     2371    12980     False
746      1564     8934     False
...       ...      ...       ...
5030     1169    13308     False
5037     1796    14540     False
598      2389    18507     False
5786     1413     8764     False
4933      765     7441     False

[700 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7202216066481995,
 'test_loss': 0.21248014271259308,
 'test_prec': 0.7738095238095238,
 'test_recall': 0.6735751295336787}
--------------------------------------------------------------------------------

Test : 800
-- Random test --

      a.index  b.index  matching
379       448    13174     False
4327     2297     2822     False
4511     1534     7056     False
5014      893     7594     False
3021      701    10754     False
...       ...      ...       ...
5025      577     9160     False
4374     1673    15267     False
2515      922    19110     False
4868      428     4976     False
3343     1242     6400     False

[800 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7609254498714654,
 'test_loss': 0.19394151866436005,
 'test_prec': 0.7551020408163265,
 'test_recall': 0.7668393782383419}
--------------------------------------------------------------------------------

Test : 900
-- Random test --

      a.index  b.index  matching
3175     1443     7210     False
5535     1793     9737     False
5760      215     8643     False
4482      178    14798     False
4093      735    11723     False
...       ...      ...       ...
10        483     1149     False
1547     2504    18507     False
61       1761     6603     False
1212      917    17317      True
5850     1959      806     False

[900 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7726161369193154,
 'test_loss': 0.2384239286184311,
 'test_prec': 0.7314814814814815,
 'test_recall': 0.8186528497409327}
--------------------------------------------------------------------------------

Test : 1000
-- Random test --

      a.index  b.index  matching
2462     1030    10555      True
3412     1334     6561     False
3437     2284    17549     False
3553     1135     2822     False
2830     2304     6397     False
...       ...      ...       ...
5376     1484    21490     False
5392     2052     2300     False
2569       41    11056     False
5825     2020    18444     False
288      2297     4739     False

[1000 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8247978436657681,
 'test_loss': 0.1798684298992157,
 'test_prec': 0.8595505617977528,
 'test_recall': 0.7927461139896373}
--------------------------------------------------------------------------------

Test : 6144
-- Random test --

      a.index  b.index  matching
2911      744    15530     False
1370     1825     5339     False
4110      576    17837     False
2264     2209    17162      True
5780      884    17167     False
...       ...      ...       ...
64       1205     8312     False
5265     1963     6961      True
2986     1937    18673     False
6023     1129     2670     False
6000     1211    16347     False

[6144 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.868421052631579,
 'test_loss': 0.15184254944324493,
 'test_prec': 0.8823529411764706,
 'test_recall': 0.8549222797927462}
--------------------------------------------------------------------------------
New cross validation 2

Test : 50
-- Random test --

      a.index  b.index  matching
5930      661     8607     False
5928     1296      286     False
1774      757      449     False
1298      794    19963     False
5738      522    14014      True
27       2475    15249     False
1268      497    10989     False
1923     1917    14149     False
938      1292    18602      True
2262      429    15214     False
4225     2112     4733     False
297       595    14869      True
3355      184     5560     False
570       900    14328     False
4683     2438    12841     False
568      2472     6743     False
4407     1225    13302     False
2974     2216      121     False
5404     1424     8192      True
4553     1933     5117     False
4861      967    16608     False
1219      497    13644     False
2034     2504    18443     False
3754     1117    17314     False
3951     2297    10747     False
3776      211    17684     False
5938      172     7297     False
1888     1475     6605     False
4778      101     2593      True
3424     1182     6829     False
4714     1016    18558     False
5170     1405    14177     False
821      2429     6266     False
999       615    12451     False
5484      226    15314     False
576      1257    13427     False
3616     1323    15278     False
3150     1459    20526     False
2145       25    14930     False
597      2341     7893      True
1502     2149    10785     False
2696     2520    20198     False
497        99    14511     False
2268     1419    20145     False
1066     2166    15394     False
1345     1605     8791     False
4273       81    16844     False
4409     1399    18149     False
791       172     7295     False
2361     2069    10794     False
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.28387850522994995,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 75
-- Random test --

      a.index  b.index  matching
2108     1247     1358     False
3413      967    19283     False
2276     2186     3614     False
4443     1135    14949     False
2970      883     4974     False
...       ...      ...       ...
5190     2318    13035     False
1756     2260     7334     False
877       719     1218     False
2923     1132    16608     False
1109     1571     2689     False

[75 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.27816101908683777,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 100
-- Random test --

      a.index  b.index  matching
2230     2469    17843     False
2071       40     2828     False
2691      547    13288     False
5248     1247    14077     False
353       853     7686     False
...       ...      ...       ...
3834     1300    16763     False
6053     1525    11087     False
4762      627    11014     False
2055      523    14091     False
4367      887     5349     False

[100 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.29897984862327576,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 120
-- Random test --

      a.index  b.index  matching
4115     2514    10644     False
1340     2430      806     False
2257     2332    21693     False
2541      787     6998     False
4099     1745     1551     False
...       ...      ...       ...
4211      967    18200     False
2067      398    18813     False
5708       79    18557     False
4484      883     7139     False
4529      322     5930     False

[120 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.30414116382598877,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 140
-- Random test --

      a.index  b.index  matching
301      2119      683     False
2025     1564    20729     False
3936     1172    17973     False
5250     1334    10550     False
2066     2405     8668      True
...       ...      ...       ...
1769       47     9387     False
1689      419     5215     False
3758     1699    16966     False
554      1809    19780     False
813      1997     2480     False

[140 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.2879231870174408,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 160
-- Random test --

      a.index  b.index  matching
3035      822      806     False
2517     2363    18601     False
4523     2071    14726     False
1895     2405     4965     False
306      1007    19065     False
...       ...      ...       ...
1153     1348     8642     False
5525      973    19569     False
5683       58     1571     False
929       238      203     False
6007       29    15291     False

[160 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0975609756097561,
 'test_loss': 0.2413325011730194,
 'test_prec': 0.8333333333333334,
 'test_recall': 0.05181347150259067}
--------------------------------------------------------------------------------

Test : 180
-- Random test --

      a.index  b.index  matching
3451     1852    15749     False
5492       53    12781     False
3659     2002     6979     False
4733      182    11396     False
3570      229     3282     False
...       ...      ...       ...
4189     2461     7240     False
4847      626     8791     False
1721      327    14686     False
5977      652     6708      True
3050      794    15687     False

[180 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.34375000000000006,
 'test_loss': 0.34665465354919434,
 'test_prec': 0.34554973821989526,
 'test_recall': 0.34196891191709844}
--------------------------------------------------------------------------------

Test : 200
-- Random test --

      a.index  b.index  matching
3228     1242    19320     False
5120     1905     5775     False
3531     2467    17204     False
5271     2422     3371     False
6006     1816    20675     False
...       ...      ...       ...
3826     2464     7034     False
4432     1468    10254     False
3102     1564     4890     False
3174     2144    12785     False
5104      214     8788     False

[200 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.2595157027244568,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 250
-- Random test --

      a.index  b.index  matching
1374       53     9734     False
512      2063     5068     False
5209       32    21322     False
84         16    15183     False
2601     1405    10555     False
...       ...      ...       ...
5281     2517     8763     False
4861      967    16608     False
2058     1037    12168      True
2850     1699    16374     False
1381      462     2827     False

[250 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.25058111548423767,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 300
-- Random test --

      a.index  b.index  matching
6102      688     6799     False
2057      382     4490     False
523       280    17184     False
1821     1671    19639     False
1451      627     4730     False
...       ...      ...       ...
5427     1429     1304     False
3714     2263     3021     False
5787     1334     6567     False
5963       38    20198     False
5891     1044     3009      True

[300 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.49266862170087977,
 'test_loss': 0.2491997331380844,
 'test_prec': 0.5675675675675675,
 'test_recall': 0.43523316062176165}
--------------------------------------------------------------------------------

Test : 400
-- Random test --

      a.index  b.index  matching
4809       70    16125     False
5728     2126     8868     False
5648      495     5799     False
3037       99     4525     False
3352     2389    17561     False
...       ...      ...       ...
2727     2069     1173     False
3594     1973     1139     False
1455      239     8651     False
4144     1656     6729     False
4650     2050    21912      True

[400 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6896551724137931,
 'test_loss': 0.1913611888885498,
 'test_prec': 0.6572769953051644,
 'test_recall': 0.7253886010362695}
--------------------------------------------------------------------------------

Test : 500
-- Random test --

      a.index  b.index  matching
2563     2020    14701     False
793      1129    10606     False
2495     2362    17735     False
2399     1934     5537     False
5031      683     1850     False
...       ...      ...       ...
3128     1453    17239     False
1297      280    16597     False
6033     2071    12822     False
2845     1560     6398     False
1080       25     7115     False

[500 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7487437185929648,
 'test_loss': 0.2093774378299713,
 'test_prec': 0.7268292682926829,
 'test_recall': 0.772020725388601}
--------------------------------------------------------------------------------

Test : 600
-- Random test --

      a.index  b.index  matching
1919     2237     1696      True
5401     1483     7538     False
4942     1132      805     False
4207     1413    12764     False
5752     1844    20809     False
...       ...      ...       ...
23       2251    14404     False
1441     2434     4727     False
1611     1988     9474      True
898      1547    13133     False
3186     1022     6033     False

[600 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6980609418282547,
 'test_loss': 0.20691949129104614,
 'test_prec': 0.75,
 'test_recall': 0.6528497409326425}
--------------------------------------------------------------------------------

Test : 700
-- Random test --

      a.index  b.index  matching
1109     1571     2689     False
141      1535    18999      True
2948      810    11428      True
1418      725    10315     False
180       565      651     False
...       ...      ...       ...
5665       22    16363     False
2072     1508    14528     False
5698     1959     2819     False
2615       73     5088     False
964      1132    18153     False

[700 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7943661971830985,
 'test_loss': 0.1714114397764206,
 'test_prec': 0.8703703703703703,
 'test_recall': 0.7305699481865285}
--------------------------------------------------------------------------------

Test : 800
-- Random test --

      a.index  b.index  matching
3803     2361    12781     False
5506     1695    16651     False
4168     1888      799     False
4357     2390     2829     False
6002     2105    10505     False
...       ...      ...       ...
2976     1699    16221     False
5229     1178    14701     False
2792     2363    14699     False
5959     2251     3885     False
301      2119      683     False

[800 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6727272727272727,
 'test_loss': 0.25257188081741333,
 'test_prec': 0.8102189781021898,
 'test_recall': 0.5751295336787565}
--------------------------------------------------------------------------------

Test : 900
-- Random test --

      a.index  b.index  matching
3979     1262    12734      True
3169     1647    16392     False
1439     1791    19538      True
127       324     6458     False
2088      561    18152      True
...       ...      ...       ...
5268      688    12851     False
6109       79    18558     False
2590      339    15539     False
5031      683     1850     False
2623      693    20663     False

[900 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.12949640287769784,
 'test_loss': 0.39606204628944397,
 'test_prec': 0.21176470588235294,
 'test_recall': 0.09326424870466321}
--------------------------------------------------------------------------------

Test : 1000
-- Random test --

      a.index  b.index  matching
4727     1833     9593     False
593       397     4859     False
5147      700    12781     False
5238     2126    21636     False
628        79    17237     False
...       ...      ...       ...
818      2305    14736     False
4355      339    11601     False
4085     1860     7664     False
479      1365    14487     False
5723      389    16342     False

[1000 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7246376811594204,
 'test_loss': 0.25489920377731323,
 'test_prec': 0.6787330316742082,
 'test_recall': 0.7772020725388601}
--------------------------------------------------------------------------------

Test : 6144
-- Random test --

      a.index  b.index  matching
3592      786     3507     False
2410     1060    18444     False
5740       65     3176     False
4133     2083     6577     False
4536     2552     8306     False
...       ...      ...       ...
4147      532    12098     False
4724     1983    10894     False
4028      967     2819     False
2772     1907    14421     False
1163     1656     7870     False

[6144 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8609625668449197,
 'test_loss': 0.16669468581676483,
 'test_prec': 0.8895027624309392,
 'test_recall': 0.8341968911917098}
--------------------------------------------------------------------------------
New cross validation 3

Test : 50
-- Random test --

      a.index  b.index  matching
2178     2471      286     False
5413     2549    14193     False
4316     1843     4900      True
5177     1294    11988     False
2169     1135     6749     False
1525     1010     3126     False
5815      683     5787     False
4163     2260     2211     False
712      2471    18153     False
3561     2071     6772     False
1912      382     2581     False
5265     1963     6961      True
1883       66     3670     False
5927      582     9297     False
1960      175    20939     False
507      1525     8562     False
5563       56    20182     False
4497     1178    10751     False
396       514    14881      True
1757     2361    13427     False
2903     1030    20073     False
1064     2216     1832     False
4945     1957    19902     False
1119       16    19394     False
6102      688     6799     False
2674      166    16333     False
6112     1242     1114     False
2503       73     2516     False
3604     1348     6599     False
2969      688    12853     False
838      1516    10829     False
3342      280    16316     False
3614      585    13589     False
3962     1863    21325      True
2997     1134    14644     False
2470     1016    17239     False
589      1342     9323     False
4563      702     2689     False
6055      944    14190     False
4978     1641    20292     False
4086     1719    15203     False
2237       65    11132     False
5725      934      698     False
1760     1153    13245      True
2959     2504    20125     False
4242      887    17505     False
427      1354    18778     False
4880     2191    13888     False
2489       47    17556     False
5004     1536     4044     False
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.29190051555633545,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 75
-- Random test --

      a.index  b.index  matching
506      1776    15489      True
6031     1560     8846     False
303      1103    14719     False
15       1241    18557     False
5778     2031    11752     False
...       ...      ...       ...
3301     1600     1749     False
3469     1888      118     False
921       822    20429     False
5029      281       60     False
2663      201     3555     False

[75 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.3211487829685211,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 100
-- Random test --

      a.index  b.index  matching
3264     1927    14736     False
2133     1155    10921     False
3945     1888    19565     False
5928     1296      286     False
353       853     7686     False
...       ...      ...       ...
104      2431    21935     False
5220      571     1341     False
1779     1813    16935     False
1845     2265    21671     False
292      2541    14698     False

[100 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.36047476530075073,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 120
-- Random test --

      a.index  b.index  matching
4732     1699    18049     False
1673     1405     8245     False
3980     2248     8368      True
5824      670     8590     False
3915     1996    19010     False
...       ...      ...       ...
146       678     2999     False
5628     2293    21146     False
1260     2020    12781     False
1230     2106     1253      True
5066     2305     8576     False

[120 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.06730769230769229,
 'test_loss': 0.30187153816223145,
 'test_prec': 0.4666666666666667,
 'test_recall': 0.03626943005181347}
--------------------------------------------------------------------------------

Test : 140
-- Random test --

      a.index  b.index  matching
1256      742    19565     False
5429     2361     4728     False
5075     1761     4576      True
5244      348     1187     False
278      2510    11287     False
...       ...      ...       ...
1960      175    20939     False
3302     1413     4711     False
5367       41    18720     False
4902      688     8841     False
4934      822    17203     False

[140 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.04672897196261682,
 'test_loss': 0.49634674191474915,
 'test_prec': 0.23809523809523808,
 'test_recall': 0.025906735751295335}
--------------------------------------------------------------------------------

Test : 160
-- Random test --

      a.index  b.index  matching
3573     2405    18732     False
4080     2117    19846     False
4925     1701    16455     False
2246      634    10844     False
71       1963     1019     False
...       ...      ...       ...
3179     2048    10489     False
4933      765     7441     False
2365      911    19024     False
669       278    20657     False
5331     1294    13944     False

[160 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.13452914798206275,
 'test_loss': 0.3716285526752472,
 'test_prec': 0.5,
 'test_recall': 0.07772020725388601}
--------------------------------------------------------------------------------

Test : 180
-- Random test --

      a.index  b.index  matching
3056     2332    17846     False
5680     2051    20778     False
5580     1016    18821     False
4451      626    21794     False
1120       73    21292     False
...       ...      ...       ...
2814      908    12999     False
4191      932     2814     False
5606       25     6981     False
1612     1614     8880     False
3493     1972     8138     False

[180 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.13270142180094785,
 'test_loss': 0.24745996296405792,
 'test_prec': 0.7777777777777778,
 'test_recall': 0.07253886010362694}
--------------------------------------------------------------------------------

Test : 200
-- Random test --

      a.index  b.index  matching
1214     2069     1172     False
5743     1367     3647     False
1558      265     3518     False
1168     2201    13661     False
5585      417     6740     False
...       ...      ...       ...
5559     2293     4525     False
4313     2079    15962     False
5398     2090     9283     False
778       465     7305     False
1510     1007    21613     False

[200 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.25409836065573765,
 'test_loss': 0.39947327971458435,
 'test_prec': 0.6078431372549019,
 'test_recall': 0.16062176165803108}
--------------------------------------------------------------------------------

Test : 250
-- Random test --

      a.index  b.index  matching
4666      735    12386     False
5273     2389     8786     False
5114      636     8730     False
2846      735     8429     False
1269      737     6759      True
...       ...      ...       ...
94        967    18153     False
5420     1282    11195     False
3611     2255     2075     False
36       1979    12918     False
5294      636     6681     False

[250 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5414141414141413,
 'test_loss': 0.44391965866088867,
 'test_prec': 0.44370860927152317,
 'test_recall': 0.694300518134715}
--------------------------------------------------------------------------------

Test : 300
-- Random test --

      a.index  b.index  matching
2114     2145     8789     False
5877      896     3099     False
2847      818    12177     False
920      2477    19527     False
3169     1647    16392     False
...       ...      ...       ...
4789     1522     1025      True
2558     1589     7435     False
834      1454    10763     False
3010      802    20115     False
376      1454    19570     False

[300 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.15714285714285714,
 'test_loss': 0.4061175286769867,
 'test_prec': 0.25287356321839083,
 'test_recall': 0.11398963730569948}
--------------------------------------------------------------------------------

Test : 400
-- Random test --

      a.index  b.index  matching
3364     1957    18173     False
5279      935     9896     False
2937      967    16333     False
4549     1888    14667     False
1837     2220     8786     False
...       ...      ...       ...
4494      195    18583     False
5036     1466    11923     False
618        22    16504     False
3847     2464    12857     False
776      2100     8944     False

[400 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7238605898123326,
 'test_loss': 0.17829100787639618,
 'test_prec': 0.75,
 'test_recall': 0.6994818652849741}
--------------------------------------------------------------------------------

Test : 500
-- Random test --

      a.index  b.index  matching
2251     1169    13307     False
5196      792     8849     False
5307      921     2449     False
3250     2019    17753     False
5832      353    12765     False
...       ...      ...       ...
5639     2002    20448     False
2560      661     9989     False
4103     2012    17452     False
1977      896    14820     False
3399     2201    11698     False

[500 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5630026809651475,
 'test_loss': 0.3144572675228119,
 'test_prec': 0.5833333333333334,
 'test_recall': 0.5440414507772021}
--------------------------------------------------------------------------------

Test : 600
-- Random test --

      a.index  b.index  matching
122       719     6972      True
5823      814     2813     False
4193     1209     7697     False
965      1091     7000     False
1585     1209    18494     False
...       ...      ...       ...
4991     1956    17084     False
1379     2361      286     False
1453      821    14402     False
2818     2103    14836     False
2763      722    10500     False

[600 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7572254335260116,
 'test_loss': 0.18650023639202118,
 'test_prec': 0.8562091503267973,
 'test_recall': 0.6787564766839378}
--------------------------------------------------------------------------------

Test : 700
-- Random test --

      a.index  b.index  matching
594      2507     5038      True
765      1197    20774     False
114        25    14931     False
2823     2538    12225     False
633      1145    10785     False
...       ...      ...       ...
1782     1397    20805      True
3204     2328    13242     False
1071      887     4723     False
1813     1172    14263     False
5317      988    17858     False

[700 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7446808510638299,
 'test_loss': 0.2040826976299286,
 'test_prec': 0.7650273224043715,
 'test_recall': 0.7253886010362695}
--------------------------------------------------------------------------------

Test : 800
-- Random test --

      a.index  b.index  matching
1857     2471    19011     False
1346      565    12610     False
1416      734     5991      True
3575      495      122     False
2485      774    18730     False
...       ...      ...       ...
5231     1959    17892     False
5536     1145     2872     False
3434     1631    13855     False
2106     1178    20429     False
239       337    19585     False

[800 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.743661971830986,
 'test_loss': 0.16854579746723175,
 'test_prec': 0.8148148148148148,
 'test_recall': 0.6839378238341969}
--------------------------------------------------------------------------------

Test : 900
-- Random test --

      a.index  b.index  matching
4372     1553     7169     False
2201     1198     6883     False
1491      561    18165     False
4102     1073    12506     False
4800     2481     3596     False
...       ...      ...       ...
2819     1242     8451     False
479      1365    14487     False
5445     2222    14686     False
4245      975     5427     False
694      2090    15249     False

[900 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6946778711484594,
 'test_loss': 0.27599722146987915,
 'test_prec': 0.7560975609756098,
 'test_recall': 0.6424870466321243}
--------------------------------------------------------------------------------

Test : 1000
-- Random test --

      a.index  b.index  matching
5557      226     7131     False
3215      898     9385     False
241      2201     7699     False
357       561      820     False
1264     1080     4454     False
...       ...      ...       ...
346      2293      635     False
5753      576      304     False
870       327    20123     False
3131       49     8096      True
2387     2049    21191     False

[1000 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7888040712468193,
 'test_loss': 0.22541041672229767,
 'test_prec': 0.775,
 'test_recall': 0.8031088082901554}
--------------------------------------------------------------------------------

Test : 6144
-- Random test --

      a.index  b.index  matching
463       751     3527     False
2710     1091    19597     False
672       944      772     False
4533     1245    20732     False
5257     1258     6742     False
...       ...      ...       ...
5622     1673    13281     False
2281      852     2819     False
5869     1882     5842     False
3919     2446    12305     False
2233     1745    16721     False

[6144 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8759894459102902,
 'test_loss': 0.1378713846206665,
 'test_prec': 0.8924731182795699,
 'test_recall': 0.8601036269430051}
--------------------------------------------------------------------------------
New cross validation 4

Test : 50
-- Random test --

      a.index  b.index  matching
2941     2305     7304     False
6054     2439    14765     False
2906      823    18601     False
3807      634      925     False
2173      339    13558     False
830      1661    18490     False
1293      244    12785     False
5262      889    14679     False
6017     1806     8861     False
4855      541     4924     False
3441     2097     6991     False
1079     1699    16822     False
2548       32    12794     False
5973     2438     4769     False
1663     1132      286     False
5909     2349     2279     False
1644      700     8786     False
5584     2479    10669      True
4490     2149     8482     False
5372     1228    11499     False
1138     1978    13928     False
5799     1418    20654     False
3086      421    17315     False
1446     2396    16194     False
4436     1616     5677     False
62       2210    16870     False
396       514    14881      True
4994     1172    18585     False
255      1984     9928     False
4953      928    19902     False
6143      225      107     False
1739     1454    14715     False
2605     2236    11637     False
5814      932    16316     False
1932     2094    16173     False
5580     1016    18821     False
5646     1289    20260     False
958      2037     8516     False
4621      683     3792     False
3061     1741    17502     False
3753      852    13427     False
1816     1353    12867     False
3577     1689    21367     False
366      1296    19283     False
3272      949     7346      True
1571     1532    12787     False
4100     1246    13967     False
4628      787     8779     False
2588     1649    14883     False
5711     1315     2853     False
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.32658880949020386,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 75
-- Random test --

      a.index  b.index  matching
4190     1831     2754     False
4399     1282    13212     False
983      1711    16433     False
5668     2390     9288     False
4651      429    15215     False
...       ...      ...       ...
3946     1927    10529     False
2112     2165    21076      True
5608     2394    21057     False
4462      857     7347      True
3679      889    10730     False

[75 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0187793427230047,
 'test_loss': 0.2962058186531067,
 'test_prec': 0.1,
 'test_recall': 0.010362694300518135}
--------------------------------------------------------------------------------

Test : 100
-- Random test --

      a.index  b.index  matching
3317      883     7140     False
6124     2094    14487     False
3961      883    20152     False
4809       70    16125     False
3594     1973     1139     False
...       ...      ...       ...
4893      898     5302     False
2408     2019    17431     False
743      1321    21461     False
1002     1672     9026     False
3090       53    17837     False

[100 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.3991791605949402,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 120
-- Random test --

      a.index  b.index  matching
175      2436     6692     False
6099     2548     4869     False
3903     1532     6753     False
4405      459    20827     False
5243      405    11922     False
...       ...      ...       ...
3021      701    10754     False
363        53     4728     False
4865     1246     7944     False
1782     1397    20805      True
3645     1551     7854     False

[120 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.27634596824645996,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 140
-- Random test --

      a.index  b.index  matching
3146     2405    21334     False
1522      944     9392     False
3151      177     6960     False
250       149     8939     False
2004      261     7227     False
...       ...      ...       ...
792      2538     6488     False
5020      887    21955     False
3483      816    22045     False
2058     1037    12168      True
1722     2191    16173      True

[140 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.3471215069293976,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 160
-- Random test --

      a.index  b.index  matching
1544     2270    12717     False
3700     2265    15576     False
3620     1948     4289     False
1152     2407     2346     False
6128      305    19748     False
...       ...      ...       ...
47        978     2340     False
5368     2341    13095     False
2112     2165    21076      True
3989      698    17286     False
3704      261      154     False

[160 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.030303030303030304,
 'test_loss': 0.29154902696609497,
 'test_prec': 0.6,
 'test_recall': 0.015544041450777202}
--------------------------------------------------------------------------------

Test : 180
-- Random test --

      a.index  b.index  matching
4850      195    11254     False
1789     2365     3203     False
4067     1516    10798     False
1391     2405    21455     False
1242     1628    14270     False
...       ...      ...       ...
3522      967    20429     False
285      1260    19809     False
3092     2472    18152     False
1073     1247    19627     False
5564     1654     5414     False

[180 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.35507246376811596,
 'test_loss': 0.3094116449356079,
 'test_prec': 0.5903614457831325,
 'test_recall': 0.2538860103626943}
--------------------------------------------------------------------------------

Test : 200
-- Random test --

      a.index  b.index  matching
5133      417    20429     False
1642     1103     6761     False
5541      565    17702     False
5996     2265     4094     False
41       2253     1302     False
...       ...      ...       ...
1638      226     9013     False
1614     1153     9237      True
2076     1953    13422     False
4694      737    19569     False
3629     2237     7309     False

[200 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.46204620462046203,
 'test_loss': 0.334125280380249,
 'test_prec': 0.6363636363636364,
 'test_recall': 0.3626943005181347}
--------------------------------------------------------------------------------

Test : 250
-- Random test --

      a.index  b.index  matching
2475      172    21462     False
2404     1443     8792     False
2681     1733    17687     False
3179     2048    10489     False
1380     1673    13271     False
...       ...      ...       ...
4643     2078       68     False
4917     1132    21693     False
2329     1257     8786     False
3543     2274    11970     False
656       769     6362      True

[250 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.30046987533569336,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 300
-- Random test --

      a.index  b.index  matching
1986     1932     4979     False
3431     2361    20121     False
3947     2430     8786     False
1373     1583    21531     False
2759      909     4349     False
...       ...      ...       ...
2740     1711    21223     False
5405      636     5325     False
6069     2322     6398     False
1551      102     9793     False
4016     2305      853     False

[300 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.34782608695652173,
 'test_loss': 0.39878344535827637,
 'test_prec': 0.5783132530120482,
 'test_recall': 0.24870466321243523}
--------------------------------------------------------------------------------

Test : 400
-- Random test --

      a.index  b.index  matching
4000      948     1204     False
3356      129    18649     False
5657      572      733     False
5853     2305     4470     False
990      1578    12638     False
...       ...      ...       ...
1683     2126     9721     False
2438     1964    14803      True
2844     2192     3144      True
3109     1542    18263     False
2364      805    14294      True

[400 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.4748201438848921,
 'test_loss': 0.251281201839447,
 'test_prec': 0.7764705882352941,
 'test_recall': 0.34196891191709844}
--------------------------------------------------------------------------------

Test : 500
-- Random test --

      a.index  b.index  matching
3764     1694    11026      True
2418     2394    13254     False
2176     1630    13530     False
825       465     4862     False
2293     1834    18463     False
...       ...      ...       ...
3098       94     9051      True
5383     1699    17615     False
4495     2113     9288     False
5456     1983     8933     False
920      2477    19527     False

[500 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6449864498644986,
 'test_loss': 0.333906352519989,
 'test_prec': 0.6761363636363636,
 'test_recall': 0.616580310880829}
--------------------------------------------------------------------------------

Test : 600
-- Random test --

      a.index  b.index  matching
5875     2077       76     False
673      2018     5204     False
2276     2186     3614     False
2595     1927    15868     False
5608     2394    21057     False
...       ...      ...       ...
4806     1689     5498     False
2138      217    21980     False
2991      305     6580     False
5681      693    12610     False
4206      466    17505     False

[600 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6946386946386945,
 'test_loss': 0.21138112246990204,
 'test_prec': 0.6313559322033898,
 'test_recall': 0.772020725388601}
--------------------------------------------------------------------------------

Test : 700
-- Random test --

      a.index  b.index  matching
2997     1134    14644     False
1239     1708    17726     False
3031     1927     7304     False
2019      852    19283     False
4900     2150     3811     False
...       ...      ...       ...
5128     1672     4988     False
2517     2363    18601     False
5984      144      625     False
4431     1193     4493      True
4483      336     7733     False

[700 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6862170087976539,
 'test_loss': 0.22806428372859955,
 'test_prec': 0.7905405405405406,
 'test_recall': 0.6062176165803109}
--------------------------------------------------------------------------------

Test : 800
-- Random test --

      a.index  b.index  matching
3954      589     3547     False
1562      781    21212     False
5330      557    21998     False
2132     1862    15434      True
985        79    18556     False
...       ...      ...       ...
3601     1605    16598     False
5131     1229     2613     False
3795     1340    12477     False
819       719    15884     False
5745      792     6397     False

[800 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7780678851174935,
 'test_loss': 0.2229786068201065,
 'test_prec': 0.7842105263157895,
 'test_recall': 0.772020725388601}
--------------------------------------------------------------------------------

Test : 900
-- Random test --

      a.index  b.index  matching
2448      532     6031     False
5526     2208     3468     False
720      1955    20238     False
2029     1866    14359      True
1343      397    12919     False
...       ...      ...       ...
4909     1959    18152     False
294       820     7079     False
5209       32    21322     False
4301      735    18935     False
2222     1537    12414     False

[900 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7830423940149626,
 'test_loss': 0.1896282434463501,
 'test_prec': 0.7548076923076923,
 'test_recall': 0.8134715025906736}
--------------------------------------------------------------------------------

Test : 1000
-- Random test --

      a.index  b.index  matching
4932     2361      805     False
4926     2037      549     False
5245     1064    21924     False
981       144    12347     False
5374     1939    18466     False
...       ...      ...       ...
5710      797     6508      True
3929     2301    15128     False
2983     1092     7799     False
5435      563    18915      True
174      1506    17571     False

[1000 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7420147420147422,
 'test_loss': 0.21446660161018372,
 'test_prec': 0.705607476635514,
 'test_recall': 0.7823834196891192}
--------------------------------------------------------------------------------

Test : 6144
-- Random test --

      a.index  b.index  matching
5202     1695    18239     False
3769      641    15119     False
401      1699    18048     False
4821     2475    19908     False
2105     1418     2839     False
...       ...      ...       ...
1195      971    13426     False
1132     2448     5426     False
2113      889     2789     False
1491      561    18165     False
990      1578    12638     False

[6144 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8740359897172236,
 'test_loss': 0.15556466579437256,
 'test_prec': 0.8673469387755102,
 'test_recall': 0.8808290155440415}
--------------------------------------------------------------------------------
Could not create dir out, File exists
    ########### 



New Dataset: <function deepmatcher_textual_abt_buy at 0x1553060e81f0>
New cross validation 0

Test : 50
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
1586      612      616      True
4694      473      568     False
3095      764      648     False
199       852      821     False
3827      906      245     False
624       422      155     False
1393     1056       46     False
1454      631      716     False
3634       44      740     False
3323      661      671     False
3103      425      242     False
3787      636      758     False
3728      451      506     False
101      1076      526     False
2173      655      503     False
5065      476      629     False
576       194       81      True
3915      459      384     False
1315      715      567     False
132        55      102     False
4083      779      661     False
3066      489      736     False
1046      607      881     False
1954      785      121     False
808       496      561     False
1872      579      714     False
2794      257      194     False
4756      550      709     False
1779      482      415     False
1566      535      302     False
4472      912     1005     False
1370      337      183     False
3145      118      617     False
3783      617      988     False
1194      481      846     False
3892      901      961     False
907       921     1008     False
2063      665      641     False
2809      469      585     False
599       445      414     False
1477      383      483     False
5417      172      358     False
4153      906      294     False
5597      857      607     False
2522      402      391     False
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.39677557349205017,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 75
-- Random test --

      a.index  b.index  matching
3100      902      509     False
1380      711      325     False
1063       54      152     False
1934      961      366     False
5454      725      687      True
...       ...      ...       ...
4303       27       47      True
4829      276     1048     False
3403      662      121     False
2851      153      415     False
218       277      520      True

[75 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.3213903605937958,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 100
-- Random test --

      a.index  b.index  matching
476       483      793      True
5606     1037      692     False
3182      838      822     False
1490       74     1085     False
2405     1001      993     False
...       ...      ...       ...
816       850      814     False
4093      993      260     False
5367       14      302     False
3959      307      385     False
4182      633     1024      True

[100 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.4815584123134613,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 120
-- Random test --

      a.index  b.index  matching
652       503      560     False
4288      491      586     False
681       669      574     False
2637      688      585     False
5233      279      301      True
...       ...      ...       ...
3472      746      747     False
4286      561      887     False
4781      932     1029     False
2638      584      660     False
1319      728      158     False

[120 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.06349206349206349,
 'test_loss': 0.564139723777771,
 'test_prec': 0.17391304347826086,
 'test_recall': 0.038834951456310676}
--------------------------------------------------------------------------------

Test : 140
-- Random test --

      a.index  b.index  matching
505       906      905     False
4948      529      866     False
630        29       43      True
3071      641       70     False
5320      477      926     False
...       ...      ...       ...
3172     1056       72     False
511       619      742     False
769       926      101     False
2285      664      517     False
2848      250      641     False

[140 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.2803030303030303,
 'test_loss': 0.2797926068305969,
 'test_prec': 0.6379310344827587,
 'test_recall': 0.1796116504854369}
--------------------------------------------------------------------------------

Test : 160
-- Random test --

      a.index  b.index  matching
3463      342      661     False
2255      205      282      True
5688      803      696     False
2114      371      289      True
3302     1048      236     False
...       ...      ...       ...
3555      754      313     False
1735      407      171     False
1057     1000      619      True
2566      577      629     False
2867      477      960     False

[160 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.37914976477622986,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 180
-- Random test --

      a.index  b.index  matching
2793      477      736     False
3797       57      205     False
4879      758      160     False
3029        3      197     False
333       994      932     False
...       ...      ...       ...
44        637      429     False
3342      546      699     False
3104      789      302     False
5013      580      680      True
5516      577      631     False

[180 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.35702285170555115,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 200
-- Random test --

      a.index  b.index  matching
5195      687      926     False
1131      365      172     False
530       692      784     False
3512      305      129     False
4258      709      840     False
...       ...      ...       ...
1290      482      574     False
2568      487      544      True
856       180      132      True
2004      752      838     False
3027      561      863     False

[200 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.1685823754789272,
 'test_loss': 0.37036609649658203,
 'test_prec': 0.4,
 'test_recall': 0.10679611650485436}
--------------------------------------------------------------------------------

Test : 250
-- Random test --

      a.index  b.index  matching
1828      885      627     False
302       483      401     False
4045      523      940     False
2086      353      243     False
862       274      727     False
...       ...      ...       ...
1454      631      716     False
1230      654      558     False
2207      764     1012     False
1645      193      263      True
3271      614      640     False

[250 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7134831460674157,
 'test_loss': 0.15836024284362793,
 'test_prec': 0.8466666666666667,
 'test_recall': 0.616504854368932}
--------------------------------------------------------------------------------

Test : 300
-- Random test --

      a.index  b.index  matching
2353      616      503     False
3300      696      218     False
1818      593      585     False
5202      666      667     False
3272      290      394      True
...       ...      ...       ...
3179       32       57     False
5144       32      632     False
2728      793      511     False
1499      569      999     False
597       722      772     False

[300 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6,
 'test_loss': 0.25037890672683716,
 'test_prec': 0.7611940298507462,
 'test_recall': 0.49514563106796117}
--------------------------------------------------------------------------------

Test : 400
-- Random test --

      a.index  b.index  matching
5333      804      988     False
1778      142      626     False
4336      342      475     False
5354      480      587     False
4412      153       80     False
...       ...      ...       ...
5262      955      351     False
5437      955      881     False
2152       71      344     False
3387      900      961     False
1928      546      887     False

[400 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7756097560975609,
 'test_loss': 0.24383217096328735,
 'test_prec': 0.7794117647058824,
 'test_recall': 0.7718446601941747}
--------------------------------------------------------------------------------

Test : 500
-- Random test --

      a.index  b.index  matching
4549     1037      761     False
2997      476      577     False
1622      999      335     False
3686      537      642      True
1714      516      922     False
...       ...      ...       ...
4726      473      711     False
44        637      429     False
1364      777      638     False
4668      966     1008     False
136      1040      186      True

[500 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7206703910614525,
 'test_loss': 0.21713100373744965,
 'test_prec': 0.8486842105263158,
 'test_recall': 0.6262135922330098}
--------------------------------------------------------------------------------

Test : 600
-- Random test --

      a.index  b.index  matching
3546     1038      849     False
2354      452      583     False
619        14      300     False
1133      931     1087     False
1639       87       46     False
...       ...      ...       ...
4084      486     1000     False
1626      307      389     False
4737      885      907     False
2258      657      632      True
5690      973      402     False

[600 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8104265402843601,
 'test_loss': 0.1096576452255249,
 'test_prec': 0.7916666666666666,
 'test_recall': 0.8300970873786407}
--------------------------------------------------------------------------------

Test : 700
-- Random test --

      a.index  b.index  matching
3095      764      648     False
1893      269      344     False
4016      342      399     False
2765      807      162     False
1326      610      721      True
...       ...      ...       ...
3798      687      536     False
2013      841      880     False
3305      504      562     False
559       172      105     False
1726      458      583     False

[700 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7058823529411765,
 'test_loss': 0.2186526358127594,
 'test_prec': 0.745945945945946,
 'test_recall': 0.6699029126213593}
--------------------------------------------------------------------------------

Test : 800
-- Random test --

      a.index  b.index  matching
2254      947      584     False
5332      112       68     False
5013      580      680      True
5363       42      780     False
3893      298      453     False
...       ...      ...       ...
4157      109      939     False
2350      298      423     False
3191      902      584     False
3581      479      732     False
1750      845      822     False

[800 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7645429362880888,
 'test_loss': 0.25037774443626404,
 'test_prec': 0.8903225806451613,
 'test_recall': 0.6699029126213593}
--------------------------------------------------------------------------------

Test : 900
-- Random test --

      a.index  b.index  matching
355      1007      251      True
5353      177      209     False
5265      790      605      True
2879      424      862     False
4167      636      886     False
...       ...      ...       ...
2704      737      882     False
1768      577      510     False
1225      487     1000     False
37        152      139     False
3822      569      714     False

[900 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7596153846153846,
 'test_loss': 0.18039165437221527,
 'test_prec': 0.7523809523809524,
 'test_recall': 0.7669902912621359}
--------------------------------------------------------------------------------

Test : 1000
-- Random test --

      a.index  b.index  matching
1332      450      507     False
3324       11       57     False
1657      988      908     False
2771      445      574     False
4919      528      982     False
...       ...      ...       ...
1437      568      675     False
2387      837      291     False
788       357      432      True
2794      257      194     False
2491      740      834     False

[1000 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.79136690647482,
 'test_loss': 0.2068529576063156,
 'test_prec': 0.7819905213270142,
 'test_recall': 0.8009708737864077}
--------------------------------------------------------------------------------

Test : 5743
-- Random test --

      a.index  b.index  matching
181       534      634     False
2285      664      517     False
5301     1047      160     False
5438      655      504      True
5277      928      601     False
...       ...      ...       ...
2637      688      585     False
1204      965       72     False
1964      780       81     False
2746      400      633     False
2205      617     1083     False

[5743 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8939393939393939,
 'test_loss': 0.10953429341316223,
 'test_prec': 0.9315789473684211,
 'test_recall': 0.8592233009708737}
--------------------------------------------------------------------------------
New cross validation 1

Test : 50
-- Random test --

      a.index  b.index  matching
2597      491      991     False
1244      498      561     False
2231      999      461     False
947       979      913     False
3714      819     1055     False
12       1021       17     False
1247      484      586     False
3242      844      677     False
3228      465      604     False
3029        3      197     False
264       439      579      True
3093      942      864     False
885       789      300     False
3821      890      408     False
3561      595     1012     False
5552      128      286     False
3274      344      171     False
937       650      675     False
4230      998     1013      True
1612      860      859     False
2179      463      711      True
4213      500      843     False
2881      874      727     False
2988      270      344      True
1937      290      798     False
219       911     1016     False
3951      360      246     False
3928      902      573     False
2381      495      907     False
5643      718      812     False
2504       82       68      True
3119     1041     1023      True
3449      368      466     False
2496      479      844     False
2424      534      637     False
2593      176       74     False
3999      477      605     False
771       845      818     False
1332      450      507     False
1710      798      152      True
3429      547      595     False
2265      114      473     False
854       350      574     False
1044      481      573     False
3064      535       50     False
1930      477      880     False
1667      479     1012     False
2843       83      200      True
4659      532      298     False
1095      952      428     False
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.38250532746315,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 75
-- Random test --

      a.index  b.index  matching
4116      672      908     False
3828      708      864     False
543       905      536     False
4231      607     1057     False
3012      900      619     False
...       ...      ...       ...
2761      987      961     False
5622     1004      121     False
2801      740      890      True
927       644     1075     False
1490       74     1085     False

[75 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.04310344827586207,
 'test_loss': 0.35253816843032837,
 'test_prec': 0.19230769230769232,
 'test_recall': 0.024271844660194174}
--------------------------------------------------------------------------------

Test : 100
-- Random test --

      a.index  b.index  matching
949       649      999     False
3770      450      505     False
5682      495      459     False
1222      347      441      True
2614      288       93     False
...       ...      ...       ...
3250      328     1075     False
4869      531      665     False
3203       10      140     False
3523      474     1067     False
2106      226      446      True

[100 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.34982067346572876,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 120
-- Random test --

      a.index  b.index  matching
5146      652      901     False
5249      705      505     False
3866      649      663     False
4292      788      629     False
1194      481      846     False
...       ...      ...       ...
1636      685      446     False
3002      829      690     False
1942      972      400     False
1324      170      307     False
4422      479      631     False

[120 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.3479035198688507,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 140
-- Random test --

      a.index  b.index  matching
625       888      978     False
1686      858      561     False
4183       60      307     False
3744      694      888      True
4206      596      948     False
...       ...      ...       ...
427       894      923      True
947       979      913     False
3029        3      197     False
2197       53      908     False
844       631      692     False

[140 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.3332770764827728,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 160
-- Random test --

      a.index  b.index  matching
1272      657      639     False
4868      979      239     False
2758      477      459     False
4477       96       89     False
2801      740      890      True
...       ...      ...       ...
137      1076      682     False
3148     1011      528     False
3389      346      203     False
1560      724      737      True
5564      917     1007      True

[160 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.3353170156478882,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 180
-- Random test --

      a.index  b.index  matching
285       882      727     False
3730      903      544     False
2402      578     1061     False
4029      966     1005     False
1713      722      812     False
...       ...      ...       ...
4387      850      822     False
3082      717      812     False
2420      994      911     False
891      1037      656     False
5662      507      611     False

[180 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5380952380952382,
 'test_loss': 0.2483064830303192,
 'test_prec': 0.5280373831775701,
 'test_recall': 0.5485436893203883}
--------------------------------------------------------------------------------

Test : 200
-- Random test --

      a.index  b.index  matching
2209      644      637     False
2418      958       91     False
2828      903      654     False
1051      470      580     False
810      1074      624     False
...       ...      ...       ...
3         644      299     False
2663      328      637     False
539       390      393      True
4244      630      650     False
5118      574      926     False

[200 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.14184397163120566,
 'test_loss': 0.5563772320747375,
 'test_prec': 0.2631578947368421,
 'test_recall': 0.0970873786407767}
--------------------------------------------------------------------------------

Test : 250
-- Random test --

      a.index  b.index  matching
326       574      732     False
2106      226      446      True
1121       93       97      True
2752      673      784     False
2876      264      242     False
...       ...      ...       ...
3363      650      647     False
1663      148      246      True
4236      981     1067      True
5575      514      737     False
525       796      152     False

[250 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.39057239057239057,
 'test_loss': 0.40043869614601135,
 'test_prec': 0.6373626373626373,
 'test_recall': 0.2815533980582524}
--------------------------------------------------------------------------------

Test : 300
-- Random test --

      a.index  b.index  matching
1282      556      597      True
314       170       59     False
1419      753      884     False
4621     1009       89     False
5468      714      788      True
...       ...      ...       ...
4291      900      588     False
419       902      654     False
4701      183      860     False
3434      483      578     False
3413      636     1064     False

[300 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7333333333333334,
 'test_loss': 0.18541651964187622,
 'test_prec': 0.6762295081967213,
 'test_recall': 0.8009708737864077}
--------------------------------------------------------------------------------

Test : 400
-- Random test --

      a.index  b.index  matching
542      1060      152     False
3087      736      890     False
5141      364      328     False
1197      667      100     False
4260      644      641     False
...       ...      ...       ...
5273      593      414     False
4693      443      427     False
1090      665      626     False
5014      574      966     False
2117      217      286      True

[400 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7178217821782178,
 'test_loss': 0.19838152825832367,
 'test_prec': 0.7323232323232324,
 'test_recall': 0.7038834951456311}
--------------------------------------------------------------------------------

Test : 500
-- Random test --

      a.index  b.index  matching
1730      256       34     False
5020      858      560     False
4922     1074      169     False
393        47      257     False
3273      983      922     False
...       ...      ...       ...
1615      961       89     False
541       533      140     False
348       261      336      True
1329      191      141     False
2298      336      638     False

[500 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.19933554817275748,
 'test_loss': 0.41667893528938293,
 'test_prec': 0.3157894736842105,
 'test_recall': 0.14563106796116504}
--------------------------------------------------------------------------------

Test : 600
-- Random test --

      a.index  b.index  matching
704       197      122     False
4192      660      621     False
4682      431      158     False
415       164      160     False
4687      987      926     False
...       ...      ...       ...
4438      480      443     False
1484      916     1010     False
1462      470      506     False
2462      104      113      True
911       532      762     False

[600 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8052631578947368,
 'test_loss': 0.1520807445049286,
 'test_prec': 0.8793103448275862,
 'test_recall': 0.7427184466019418}
--------------------------------------------------------------------------------

Test : 700
-- Random test --

      a.index  b.index  matching
2381      495      907     False
372       700       78     False
866       798       64     False
2621      733      796     False
4780      894      548     False
...       ...      ...       ...
3290      983      600     False
4479       77      345     False
1449      736      840     False
2242      122      393     False
1785     1005      364     False

[700 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7795698924731183,
 'test_loss': 0.17719751596450806,
 'test_prec': 0.8734939759036144,
 'test_recall': 0.7038834951456311}
--------------------------------------------------------------------------------

Test : 800
-- Random test --

      a.index  b.index  matching
2010      433      965     False
87        850      676     False
823       720     1079     False
4368      563      764     False
5539      176      688     False
...       ...      ...       ...
607       747      938     False
5602      840      816     False
5340      443      576     False
4261     1010      566     False
3062      481      991     False

[800 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8260869565217391,
 'test_loss': 0.19769883155822754,
 'test_prec': 0.8221153846153846,
 'test_recall': 0.8300970873786407}
--------------------------------------------------------------------------------

Test : 900
-- Random test --

      a.index  b.index  matching
2193      579      988     False
421         9       50     False
258       203      169     False
4964      192      451     False
392        62       46     False
...       ...      ...       ...
1120      749      300     False
1593      238      603     False
3157      596      536     False
4175      191      634     False
1811      592      690     False

[900 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7890818858560793,
 'test_loss': 0.2174086570739746,
 'test_prec': 0.8071065989847716,
 'test_recall': 0.7718446601941747}
--------------------------------------------------------------------------------

Test : 1000
-- Random test --

      a.index  b.index  matching
2712      483      926     False
2610      304      917      True
2072      719      349     False
3986      684      900      True
2268      142      245     False
...       ...      ...       ...
5091      644      634     False
4045      523      940     False
2780      596     1012     False
1005      614      637      True
3582      903      631     False

[1000 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.792079207920792,
 'test_loss': 0.15514621138572693,
 'test_prec': 0.8080808080808081,
 'test_recall': 0.7766990291262136}
--------------------------------------------------------------------------------

Test : 5743
-- Random test --

      a.index  b.index  matching
2001      665      460     False
4290      481      577     False
3321      643      335     False
2309      754      912     False
2229      458      979     False
...       ...      ...       ...
2297       37      798     False
4356      915     1004     False
2682      106       26     False
2128      649      646     False
908       184      457     False

[5743 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8932038834951457,
 'test_loss': 0.12276341766119003,
 'test_prec': 0.8932038834951457,
 'test_recall': 0.8932038834951457}
--------------------------------------------------------------------------------
New cross validation 2

Test : 50
-- Random test --

      a.index  b.index  matching
2385      926      973     False
3887      813      830     False
1592      535      147     False
3024      999      179     False
2956       49      102      True
4508      534      517     False
4032       71      109      True
5450      767      698     False
310       760      469      True
692       486      654     False
1737      586      148     False
2733      615      515     False
5662      507      611     False
5555      739      622     False
5468      714      788      True
3934      677      890     False
2430      183      845     False
3489      168      566     False
3045      212      326     False
2308      328       50     False
2225       58      103     False
1591      323      339      True
1389     1007      316     False
5552      128      286     False
4650      937      579     False
5008      289      345      True
606       869     1087     False
3941      431      310      True
2131      688      577     False
1052      587      230     False
325       918     1068     False
3711      363      973     False
2522      402      391     False
3696      804      663     False
1403       32      515     False
3722      705      733      True
89        993      655     False
1063       54      152     False
1513      269      349      True
985       400      140     False
398       433       85     False
5158      794      823     False
1383      651      884      True
2297       37      798     False
1570      297      251     False
5688      803      696     False
2781      802      550     False
1390      561      734     False
3633      392     1086     False
3265       80       48     False
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.33342239260673523,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 75
-- Random test --

      a.index  b.index  matching
5430      334      147     False
3812      122      146      True
3377      142      399     False
1201      284      621     False
2164      944      955     False
...       ...      ...       ...
226       790      629     False
5568      194      485     False
3924      625      760     False
2811      295      115     False
1188       32      335     False

[75 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.3580704629421234,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 100
-- Random test --

      a.index  b.index  matching
5557      789      640     False
1478     1046      962      True
990       497     1039     False
2931      757      683     False
2112      838      677     False
...       ...      ...       ...
4840      946      418     False
298       551      871     False
2654       62       71     False
733       287      429     False
2509      813      331     False

[100 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.36679255962371826,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 120
-- Random test --

      a.index  b.index  matching
4529      524     1043     False
5445      712      782     False
3898     1056      159     False
16         14      517     False
5716      546      742     False
...       ...      ...       ...
4250       40       54      True
2019      754      832      True
5648       54      236     False
3080      774      995     False
348       261      336      True

[120 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.09701492537313433,
 'test_loss': 0.34427186846733093,
 'test_prec': 0.20967741935483872,
 'test_recall': 0.06310679611650485}
--------------------------------------------------------------------------------

Test : 140
-- Random test --

      a.index  b.index  matching
1212      393      434      True
5143      168       61     False
2650      432      366     False
338       786      311      True
2788       32      301     False
...       ...      ...       ...
344       900      846     False
1109       34       36      True
1419      753      884     False
788       357      432      True
111       670      822     False

[140 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.34411531686782837,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 160
-- Random test --

      a.index  b.index  matching
1303        3      764     False
2035      619      734     False
2788       32      301     False
334       844      676     False
2045      989      909     False
...       ...      ...       ...
4902      804      649     False
2677       94      963     False
832       176       59     False
5525      999      300     False
3864      190      299     False

[160 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.3311738967895508,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 180
-- Random test --

      a.index  b.index  matching
3838      370      418     False
3791      213      144     False
4917      495      793     False
2864     1080      813     False
3447       95      939     False
...       ...      ...       ...
2496      479      844     False
35       1011      648     False
1220      842      821     False
3481      843      676     False
3700      450      980     False

[180 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.3680654466152191,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 200
-- Random test --

      a.index  b.index  matching
2368      266      345     False
1767      803      690     False
2653      755      561     False
1947     1031      449     False
3707      534      648     False
...       ...      ...       ...
1310      237       14      True
3532      504      560     False
3455      736      882     False
714       713      759     False
456       930     1087     False

[200 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.40760869565217395,
 'test_loss': 0.3468467891216278,
 'test_prec': 0.46296296296296297,
 'test_recall': 0.3640776699029126}
--------------------------------------------------------------------------------

Test : 250
-- Random test --

      a.index  b.index  matching
1212      393      434      True
4399      477      511     False
3156      917     1008     False
5699      670      527     False
1067      143       64     False
...       ...      ...       ...
3858      940      627     False
3794      345      587     False
1118      720      780     False
5700      290      348     False
1169       45      870     False

[250 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.327710843373494,
 'test_loss': 0.3429705500602722,
 'test_prec': 0.3253588516746411,
 'test_recall': 0.3300970873786408}
--------------------------------------------------------------------------------

Test : 300
-- Random test --

      a.index  b.index  matching
3976      804      686     False
112       660      435     False
2501        9      635     False
5533      900      414     False
1751      486      980     False
...       ...      ...       ...
4669      528      913     False
4542      963       87     False
2965      295       25     False
4869      531      665     False
343       193      451     False

[300 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.09859154929577464,
 'test_loss': 0.5204981565475464,
 'test_prec': 0.1794871794871795,
 'test_recall': 0.06796116504854369}
--------------------------------------------------------------------------------

Test : 400
-- Random test --

      a.index  b.index  matching
2308      328       50     False
3677      477      415     False
4478      359      159     False
1914      790      880     False
2391      406      487      True
...       ...      ...       ...
759       671      825     False
5644      462      489     False
5491      961       88     False
4610      758      158     False
1609       95      965     False

[400 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7301587301587301,
 'test_loss': 0.20265412330627441,
 'test_prec': 0.8023255813953488,
 'test_recall': 0.6699029126213593}
--------------------------------------------------------------------------------

Test : 500
-- Random test --

      a.index  b.index  matching
3263       77      347     False
3060      439      577     False
5506      470      441     False
3557      572      647     False
1865      573      710      True
...       ...      ...       ...
521       329      635     False
1346      170      120     False
5311      629      873      True
876       846      824     False
3604      342      586     False

[500 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7473118279569892,
 'test_loss': 0.24359130859375,
 'test_prec': 0.8373493975903614,
 'test_recall': 0.6747572815533981}
--------------------------------------------------------------------------------

Test : 600
-- Random test --

      a.index  b.index  matching
3096      172      609     False
4021      578      837     False
4645      432       97     False
2296      775      716     False
4036     1039       87     False
...       ...      ...       ...
2366      458      508      True
1821      960      232     False
3048      548      595      True
4857      445      543     False
2037      190      632     False

[600 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7908163265306123,
 'test_loss': 0.16863511502742767,
 'test_prec': 0.8333333333333334,
 'test_recall': 0.7524271844660194}
--------------------------------------------------------------------------------

Test : 700
-- Random test --

      a.index  b.index  matching
1622      999      335     False
3733      241      585     False
2805      477      574     False
1181      529      753     False
4612      533      633     False
...       ...      ...       ...
4417      512      593     False
5639      566      697     False
3938      581      675      True
5625      922     1006     False
1525      296      318     False

[700 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6167146974063401,
 'test_loss': 0.23211562633514404,
 'test_prec': 0.7588652482269503,
 'test_recall': 0.5194174757281553}
--------------------------------------------------------------------------------

Test : 800
-- Random test --

      a.index  b.index  matching
3962      948      653     False
465       512      192     False
4785      606      524      True
3444      801      152     False
3741      611      696     False
...       ...      ...       ...
4922     1074      169     False
1563      350      846     False
4523      987      880     False
5035      674      839     False
2400      788      574     False

[800 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7611111111111111,
 'test_loss': 0.23519153892993927,
 'test_prec': 0.8896103896103896,
 'test_recall': 0.6650485436893204}
--------------------------------------------------------------------------------

Test : 900
-- Random test --

      a.index  b.index  matching
2633      849      663     False
80        597      289     False
1905      263     1044     False
596       913     1002      True
3559      625      650     False
...       ...      ...       ...
1246      857      948     False
742       865      905     False
428       895      622     False
2515      989     1022     False
3432      482      414     False

[900 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7696476964769647,
 'test_loss': 0.2506255507469177,
 'test_prec': 0.8711656441717791,
 'test_recall': 0.6893203883495146}
--------------------------------------------------------------------------------

Test : 1000
-- Random test --

      a.index  b.index  matching
4323      903      653     False
4039      958        2     False
5256      650      719     False
3217      569      666     False
3702      901      535     False
...       ...      ...       ...
3979      569     1083     False
4654       80       75      True
2323      301      426     False
272       298      318     False
1346      170      120     False

[1000 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8009592326139089,
 'test_loss': 0.18936724960803986,
 'test_prec': 0.7914691943127962,
 'test_recall': 0.8106796116504854}
--------------------------------------------------------------------------------

Test : 5743
-- Random test --

      a.index  b.index  matching
1654      630      742     False
5296      657      460     False
3080      774      995     False
3186       91       97     False
518       568      696     False
...       ...      ...       ...
351       485      271     False
5415      891      469     False
1704      698      218     False
4585      615      626     False
3628      827      430     False

[5743 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8860759493670887,
 'test_loss': 0.12781108915805817,
 'test_prec': 0.9259259259259259,
 'test_recall': 0.8495145631067961}
--------------------------------------------------------------------------------
New cross validation 3

Test : 50
-- Random test --

      a.index  b.index  matching
1651      482      791     False
4220      399       42     False
4095      627      473     False
4066       10      639     False
2819      142      566     False
1053      620     1083     False
3322      877      667     False
5399      529      762      True
2242      122      393     False
4045      523      940     False
148       812      673     False
2227      620      647     False
1729      967      572     False
1465      252      982     False
3905      315      568     False
5303      494      530      True
930       889      580     False
1634      338      672     False
863      1025        8      True
3956      614      140     False
4800     1038      760     False
5446      902      544     False
185       540      924     False
2511      879      891     False
4248      784      408     False
395       375      345     False
4073      596      588     False
2188      955      764     False
2646      482      911     False
2611      509      953     False
491       309      956      True
1885      480      793     False
1302      658      621     False
3780      963       89     False
344       900      846     False
3174      150      208      True
5381       87      297     False
1720      722      798     False
3935      116      171     False
2640      477      630     False
2735      153      732     False
1333      295      484     False
4003     1011      515     False
4851      248      181     False
4876      580      675     False
5587      540      590      True
2327      536      577     False
1126      896      624     False
5610      501      559     False
4178      288       91     False
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.329679399728775,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 75
-- Random test --

      a.index  b.index  matching
2363      952      745     False
5661      673      251     False
473       958       26     False
2315      409       95      True
1491      987      573     False
...       ...      ...       ...
4005      927      271     False
571       109      965     False
1847      110      101      True
499        78      880     False
2514      101      420     False

[75 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.3348312973976135,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 100
-- Random test --

      a.index  b.index  matching
3601      498      562     False
4693      443      427     False
3330      509      955     False
1462      470      506     False
3746      512      548     False
...       ...      ...       ...
5557      789      640     False
2069      546       21     False
3977      257      879     False
5394      249      320     False
4118      533      300     False

[100 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.5852051377296448,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 120
-- Random test --

      a.index  b.index  matching
777       742      774      True
3937      575      578     False
1865      573      710      True
4870      437      750      True
4373      638      885     False
...       ...      ...       ...
4186      662      621      True
4468      293       35     False
4900      669      587     False
3084      696      773     False
4810      574      631     False

[120 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.4301675977653631,
 'test_loss': 0.3808388411998749,
 'test_prec': 0.506578947368421,
 'test_recall': 0.3737864077669903}
--------------------------------------------------------------------------------

Test : 140
-- Random test --

      a.index  b.index  matching
3276      807      538     False
3062      481      991     False
5405     1023      115     False
4781      932     1029     False
1763      654      610     False
...       ...      ...       ...
4499      402      678     False
1413      329      639     False
2566      577      629     False
5514      477      629     False
2189       64       48     False

[140 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.3361034095287323,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 160
-- Random test --

      a.index  b.index  matching
2322     1007      317     False
3925     1011      626     False
2620      505      558      True
2879      424      862     False
3950      146      300     False
...       ...      ...       ...
3944      999       50     False
1534      536     1048      True
1109       34       36      True
4177      737      839     False
139      1071      103      True

[160 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.29722005128860474,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 180
-- Random test --

      a.index  b.index  matching
5514      477      629     False
1764       61       76     False
2486      530      351     False
13        719      798     False
5254      154       63     False
...       ...      ...       ...
3880       32      300     False
2443      329      335     False
4148     1003        4     False
1033      252      210     False
3654      520      727     False

[180 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.22222222222222224,
 'test_loss': 0.5246449112892151,
 'test_prec': 0.4246575342465753,
 'test_recall': 0.15048543689320387}
--------------------------------------------------------------------------------

Test : 200
-- Random test --

      a.index  b.index  matching
289        13       58     False
518       568      696     False
4249      905      582     False
3868      521      727     False
3556       32      641     False
...       ...      ...       ...
2350      298      423     False
4825      885      926     False
113       986      649     False
2915     1053      936     False
4197      359       46     False

[200 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0631578947368421,
 'test_loss': 0.3913453221321106,
 'test_prec': 0.11392405063291139,
 'test_recall': 0.043689320388349516}
--------------------------------------------------------------------------------

Test : 250
-- Random test --

      a.index  b.index  matching
3896      432       87     False
910       585      263     False
1345      915     1010     False
4181      997      961     False
3114      131      174     False
...       ...      ...       ...
356       664      139     False
984      1020       11     False
4709      273      963     False
3991      665      584     False
1331      579      694     False

[250 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.4356435643564357,
 'test_loss': 0.37379467487335205,
 'test_prec': 0.6804123711340206,
 'test_recall': 0.32038834951456313}
--------------------------------------------------------------------------------

Test : 300
-- Random test --

      a.index  b.index  matching
5075      669      588      True
958       102      167     False
2307      544      742     False
2094      608      675     False
4712      903      846     False
...       ...      ...       ...
573       667       87     False
5256      650      719     False
1158      363      238     False
1067      143       64     False
1284      586      205     False

[300 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.09803921568627451,
 'test_loss': 0.455384224653244,
 'test_prec': 0.15,
 'test_recall': 0.07281553398058252}
--------------------------------------------------------------------------------

Test : 400
-- Random test --

      a.index  b.index  matching
3320       25      639     False
3739      914     1011     False
2026      256      335     False
1564      448     1022     False
3576      801      259     False
...       ...      ...       ...
2857      190      641     False
4229      804      691     False
5562      575      581     False
3445      920     1005     False
718        65       74      True

[400 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8074866310160428,
 'test_loss': 0.18928274512290955,
 'test_prec': 0.8988095238095238,
 'test_recall': 0.7330097087378641}
--------------------------------------------------------------------------------

Test : 500
-- Random test --

      a.index  b.index  matching
2896      319      854     False
1156       59       16      True
4151      543      864     False
4975      736     1077     False
1180      687      574     False
...       ...      ...       ...
76        935      859     False
163       946     1000     False
2724      890      100     False
1166      532      665     False
927       644     1075     False

[500 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7949367088607596,
 'test_loss': 0.1485034078359604,
 'test_prec': 0.8306878306878307,
 'test_recall': 0.7621359223300971}
--------------------------------------------------------------------------------

Test : 600
-- Random test --

      a.index  b.index  matching
1737      586      148     False
2842      521      475     False
2828      903      654     False
608        77      346     False
2865      985     1012     False
...       ...      ...       ...
556       683      893      True
1077     1039      965     False
3985       15      138     False
3081      477      579     False
562      1015      654     False

[600 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5325779036827196,
 'test_loss': 0.2995074987411499,
 'test_prec': 0.6394557823129252,
 'test_recall': 0.4563106796116505}
--------------------------------------------------------------------------------

Test : 700
-- Random test --

      a.index  b.index  matching
5252      496      563      True
3765      785      669     False
267       447      412      True
4575      462       10     False
2099     1039      101     False
...       ...      ...       ...
1357      252      351     False
937       650      675     False
488        94      101     False
2913       87      569     False
1113      495      619     False

[700 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8436724565756824,
 'test_loss': 0.15228641033172607,
 'test_prec': 0.8629441624365483,
 'test_recall': 0.8252427184466019}
--------------------------------------------------------------------------------

Test : 800
-- Random test --

      a.index  b.index  matching
2243      226       80     False
3793      140      871     False
4706      964      974     False
2609      825      586     False
5373      489      880     False
...       ...      ...       ...
3527      462       11      True
4167      636      886     False
3564       11      716     False
1834      559      557     False
4696      691      785     False

[800 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8,
 'test_loss': 0.16043546795845032,
 'test_prec': 0.8735632183908046,
 'test_recall': 0.7378640776699029}
--------------------------------------------------------------------------------

Test : 900
-- Random test --

      a.index  b.index  matching
5473      638      893     False
4229      804      691     False
2439      115      297     False
5035      674      839     False
863      1025        8      True
...       ...      ...       ...
4592      900      446     False
415       164      160     False
1663      148      246      True
1219      914     1007     False
2840      426      287      True

[900 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8253164556962025,
 'test_loss': 0.18251602351665497,
 'test_prec': 0.8624338624338624,
 'test_recall': 0.7912621359223301}
--------------------------------------------------------------------------------

Test : 1000
-- Random test --

      a.index  b.index  matching
1417      190      637     False
698       350      880     False
2371      420      303      True
3209      570      971     False
220       536      972     False
...       ...      ...       ...
4066       10      639     False
3968      986      675     False
5634      577      654      True
1738      842      826     False
287      1036     1055      True

[1000 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.835820895522388,
 'test_loss': 0.19057929515838623,
 'test_prec': 0.8571428571428571,
 'test_recall': 0.8155339805825242}
--------------------------------------------------------------------------------

Test : 5743
-- Random test --

      a.index  b.index  matching
4590      481      793     False
245       481      630     False
3436      670      826     False
2202      197      502     False
4367      631      760     False
...       ...      ...       ...
5047      109       85     False
3062      481      991     False
1835       64      158     False
5590      109       83     False
2545      688      617     False

[5743 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8972431077694234,
 'test_loss': 0.1083647608757019,
 'test_prec': 0.927461139896373,
 'test_recall': 0.8689320388349514}
--------------------------------------------------------------------------------
New cross validation 4

Test : 50
-- Random test --

      a.index  b.index  matching
1475      296      424     False
4989      488      228     False
4868      979      239     False
3940      510      592      True
4492      413      568     False
351       485      271     False
3296      766      167     False
5725      550      593     False
780       884      986     False
2346      458      505     False
3908      839      815     False
437       181     1012     False
5702      613      729      True
174       419      395     False
380       644      515     False
2663      328      637     False
1539      790      584     False
2354      452      583     False
1264      145       34     False
2780      596     1012     False
4965      545      759     False
4113      941      419     False
4026      788      732     False
2425      764      632     False
5093      454      449      True
3374      960      272     False
1116       94       97     False
5041      850      818     False
2204      489      511     False
4651      483      607     False
231       641       37     False
5200      217      145     False
3963      682      891     False
1176     1021       11     False
2860      564      762     False
220       536      972     False
1214      931     1031      True
30        919     1004     False
500       625      831     False
2608      580      988     False
3022      510      590     False
4827      348      238     False
4580      198      100     False
819        20       48     False
4875      495      936     False
4215      885      880     False
4623      755      563     False
1647      596      732     False
804       718      799     False
279       738      835      True
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.3622276186943054,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 75
-- Random test --

      a.index  b.index  matching
5413      427      632     False
4828      188      869      True
2624      773      808      True
936       463      568     False
3947      543      831     False
...       ...      ...       ...
4596      901      510     False
113       986      649     False
6         671      817     False
5303      494      530      True
835       619      887     False

[75 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.3279978036880493,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 100
-- Random test --

      a.index  b.index  matching
2775     1017      553     False
3141      503      683     False
5686      645      888     False
3491      567      675     False
2391      406      487      True
...       ...      ...       ...
2991      563      723      True
1047      635      971     False
3762       11      758     False
849       267      348      True
1819      683      892     False

[100 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.319691926240921,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 120
-- Random test --

      a.index  b.index  matching
5252      496      563      True
90        554      122     False
226       790      629     False
523       584      680     False
2960      990     1041      True
...       ...      ...       ...
1253      749      626     False
1852      257      866     False
5355       96       87     False
5061      795      826     False
3025       33     1044     False

[120 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.009615384615384614,
 'test_loss': 0.3520944118499756,
 'test_prec': 0.5,
 'test_recall': 0.0048543689320388345}
--------------------------------------------------------------------------------

Test : 140
-- Random test --

      a.index  b.index  matching
5625      922     1006     False
2136      179      295     False
3887      813      830     False
1206      687      573     False
4486      332      389      True
...       ...      ...       ...
2813      450      978     False
422       631      742     False
3979      569     1083     False
4598      306      118      True
2167      806      130     False

[140 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.3430100083351135,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 160
-- Random test --

      a.index  b.index  matching
4536      657       34     False
470       128       27     False
3166      256      638     False
161       486      511     False
2775     1017      553     False
...       ...      ...       ...
1744     1060      653     False
4091      535      626     False
3785      566      663     False
5089     1060      991     False
5218      167       71     False

[160 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.2745098039215686,
 'test_loss': 0.45401039719581604,
 'test_prec': 0.7142857142857143,
 'test_recall': 0.16990291262135923}
--------------------------------------------------------------------------------

Test : 180
-- Random test --

      a.index  b.index  matching
1132      484      294     False
147       296      453     False
4885      840      823     False
2406      611      697     False
3525      675      839     False
...       ...      ...       ...
2732      747      619     False
2114      371      289      True
3425      760      501     False
4955       43      108     False
3551      408      716     False

[180 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.4407954514026642,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 200
-- Random test --

      a.index  b.index  matching
3720      918     1006     False
2015      373      180     False
3473      452      585     False
1462      470      506     False
4593      427      177     False
...       ...      ...       ...
3687      290      800     False
1447      940      543     False
3429      547      595     False
977      1015     1081      True
3140     1022      439     False

[200 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.2857142857142857,
 'test_loss': 0.5173943638801575,
 'test_prec': 0.3291139240506329,
 'test_recall': 0.2524271844660194}
--------------------------------------------------------------------------------

Test : 250
-- Random test --

      a.index  b.index  matching
362       559      843     False
1875      110       85     False
1968      999      301     False
985       400      140     False
4441      771      734     False
...       ...      ...       ...
78        235      772     False
3530      712      320     False
1483       71      178     False
820       614      636     False
5157      733     1064     False

[250 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.38567498326301575,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 300
-- Random test --

      a.index  b.index  matching
205       850      527     False
1830      594      139     False
573       667       87     False
2354      452      583     False
5065      476      629     False
...       ...      ...       ...
4473      764      140     False
4629      511      762     False
4570      937      580     False
338       786      311      True
2903       27       59     False

[300 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7715736040609138,
 'test_loss': 0.1939374953508377,
 'test_prec': 0.8085106382978723,
 'test_recall': 0.7378640776699029}
--------------------------------------------------------------------------------

Test : 400
-- Random test --

      a.index  b.index  matching
2825      348      272     False
2650      432      366     False
2698      680      900     False
1256      990      512     False
3552      873      684     False
...       ...      ...       ...
1047      635      971     False
1855      427      635     False
3250      328     1075     False
5741      621      737     False
893        54       64      True

[400 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6958762886597939,
 'test_loss': 0.23783543705940247,
 'test_prec': 0.7417582417582418,
 'test_recall': 0.6553398058252428}
--------------------------------------------------------------------------------

Test : 500
-- Random test --

      a.index  b.index  matching
746       615      641     False
1545      269      346     False
911       532      762     False
1251      863      487     False
4464      570      686     False
...       ...      ...       ...
1395      919     1010     False
122       910      401     False
4160      834      439     False
2046      838      527     False
5339      858      563     False

[500 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7572383073496659,
 'test_loss': 0.1842229813337326,
 'test_prec': 0.6995884773662552,
 'test_recall': 0.8252427184466019}
--------------------------------------------------------------------------------

Test : 600
-- Random test --

      a.index  b.index  matching
1275      295      489     False
1648     1003       26     False
1508       71      340     False
3955       43      345     False
541       533      140     False
...       ...      ...       ...
1743     1020      485     False
748       134        0     False
4886      290      170     False
686       529      665     False
3046       41      800     False

[600 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
slurmstepd: error: *** JOB 106692 ON idun-04-12 CANCELLED AT 2021-03-29T16:00:53 DUE TO TIME LIMIT ***
slurmstepd: error: *** JOB 106692 STEPD TERMINATED ON idun-04-12 AT 2021-03-29T16:02:55 DUE TO JOB NOT ENDING WITH SIGNALS ***
