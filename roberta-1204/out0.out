We are running from this directory: /cluster/work/oyvinsam
The name of the job is: alt-0
The job ID is 175442
The job was run on these nodes: idun-05-09
Number of nodes: 1
We are using 1 cores
We are using 1 cores per node
Total of 1 cores
Mon Apr 12 09:12:39 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.27.04    Driver Version: 460.27.04    CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-PCIE...  Off  | 00000000:3B:00.0 Off |                    0 |
| N/A   26C    P0    33W / 250W |      0MiB / 16160MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
Launch Python
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
Could not create dir out, File exists
[0, 20, 40, 60, 80, 100, 120, 140, 160, 180, 200, 240, 280, 320, 360, 400, 440, 480, 520, 560, 600, 640, 680, 720, 760, 800, 840, 880, 920, 960, 1000]




    ###########  New Dataset: <function deepmatcher_structured_amazon_google at 0x151a22caf310>
New cross validation 0, for  <function deepmatcher_structured_amazon_google at 0x151a22caf310>
| ID | GPU | MEM |
------------------
|  0 |  0% |  0% |

Test : 0
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.22832460701465607, 'test_f1': 0.7297297297297296, 'test_prec': 0.7714285714285715, 'test_recall': 0.6923076923076923, 'labeled_instances': 0, 'train_positive_rate': 0.1016875181844632, 'pool_positive_rate': 0.1016875181844632, 'iteration_time': 414.09050130844116}
| ID | GPU | MEM |
------------------
|  0 |  5% | 21% |

Test : 20
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.34070074558258057, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 20, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10169244236941932, 'iteration_time': 115.05562233924866}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 40
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.31152620911598206, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 40, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10169739537606087, 'iteration_time': 124.87285876274109}
| ID | GPU | MEM |
------------------
|  0 |  6% | 21% |

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3333081901073456, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.08333333333333333, 'pool_positive_rate': 0.10184913413560318, 'iteration_time': 125.34145951271057}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2677842676639557, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 80, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.1017073888725346, 'iteration_time': 126.65977144241333}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3027178943157196, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 100, 'train_positive_rate': 0.11, 'pool_positive_rate': 0.1015648066135223, 'iteration_time': 134.3534471988678}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3423134386539459, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 120, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10171750074030204, 'iteration_time': 133.43305349349976}
| ID | GPU | MEM |
------------------
|  0 |  5% | 21% |

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.31626003980636597, 'test_f1': 0.4999999999999999, 'test_prec': 0.4699248120300752, 'test_recall': 0.5341880341880342, 'labeled_instances': 140, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10172260172260172, 'iteration_time': 145.35617184638977}
| ID | GPU | MEM |
------------------
|  0 |  5% | 21% |

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.31968584656715393, 'test_f1': 0.45478036175710596, 'test_prec': 0.5751633986928104, 'test_recall': 0.37606837606837606, 'labeled_instances': 160, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.10187667560321716, 'iteration_time': 147.84616112709045}
| ID | GPU | MEM |
------------------
|  0 |  5% | 21% |

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.47141116857528687, 'test_f1': 0.5147540983606558, 'test_prec': 0.4175531914893617, 'test_recall': 0.6709401709401709, 'labeled_instances': 180, 'train_positive_rate': 0.09444444444444444, 'pool_positive_rate': 0.1018822826411712, 'iteration_time': 149.90984463691711}
| ID | GPU | MEM |
------------------
|  0 |  5% | 21% |

Test : 200
-- Random test --

[4179 3838 3534 4052 1831 1669 1168 1941 3791 3578 4480 5048 3132 3151
 4123  170 1087 4002 1977 6493 2729 6808 4084 5542 3885 3732 5136 6256
 2285 5243 6226 2790 1815  938 4665 1555 5667 4993 1237 6870 4203 2134
 5093 4527 2635 3634 1564 3411 5553 2270 4398   42 4995  499 5034  840
 2955 1122 3927 3093 4341  875 2527 1811 2006 1043 4741 2551 2406  559
 6451 3367 6562 2103 5092 1014  311  684 5495 2568  864  526 4608 2644
 4999 2653 2795  202 1940 1520  224  541 6728 6262 6283 5955 6595  119
 4172 3691 4227 1597  147 5581 6096 3803 2207  479 1216 4952 2425 1259
 1189 5384 6807 5645  495  578 6690 6821 5484 2193  444 1136 4429 1722
 3071 6252 3595 1881 3154 3428  558 2529  217 1855 6677  751 2836 4068
 5773 3643 1315 5261 3964 1526 4379 2587 5949 1982 5929 5790 3836 6556
 1984  521 6785  862 5066 1284  991 5845 4459 1783 2570  475 2149  528
  773  287   98 5135  148 6352 3892 2478 3939 4631 6528 2217 3714 5925
 2760 4627  296  629  733 2030 4563 1826 2211 6553 3491 5813 2420 2500
 6433 5883 1001 3619]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2615225911140442, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 200, 'train_positive_rate': 0.085, 'pool_positive_rate': 0.10218759364698832, 'iteration_time': 150.57584762573242}
| ID | GPU | MEM |
------------------
|  0 |  5% | 21% |

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3986571133136749, 'test_f1': 0.42051282051282046, 'test_prec': 0.5256410256410257, 'test_recall': 0.3504273504273504, 'labeled_instances': 240, 'train_positive_rate': 0.09583333333333334, 'pool_positive_rate': 0.10189930660235152, 'iteration_time': 154.26205682754517}
| ID | GPU | MEM |
------------------
|  0 | 37% | 22% |

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.5254429578781128, 'test_f1': 0.4933333333333333, 'test_prec': 0.5138888888888888, 'test_recall': 0.47435897435897434, 'labeled_instances': 280, 'train_positive_rate': 0.10714285714285714, 'pool_positive_rate': 0.10145586897179254, 'iteration_time': 156.33607387542725}
| ID | GPU | MEM |
------------------
|  0 |  2% | 21% |

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.444021612405777, 'test_f1': 0.21086261980830673, 'test_prec': 0.4177215189873418, 'test_recall': 0.14102564102564102, 'labeled_instances': 320, 'train_positive_rate': 0.109375, 'pool_positive_rate': 0.10131217577052182, 'iteration_time': 164.9282467365265}
| ID | GPU | MEM |
------------------
|  0 |  5% | 21% |

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3846258223056793, 'test_f1': 0.5123595505617977, 'test_prec': 0.5402843601895735, 'test_recall': 0.48717948717948717, 'labeled_instances': 360, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10178077985876574, 'iteration_time': 166.09969663619995}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4076218008995056, 'test_f1': 0.5211581291759466, 'test_prec': 0.5441860465116279, 'test_recall': 0.5, 'labeled_instances': 400, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10179178251467408, 'iteration_time': 167.90319800376892}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3371751606464386, 'test_f1': 0.5258215962441315, 'test_prec': 0.5833333333333334, 'test_recall': 0.47863247863247865, 'labeled_instances': 440, 'train_positive_rate': 0.09545454545454546, 'pool_positive_rate': 0.10211377059372086, 'iteration_time': 177.86894750595093}
| ID | GPU | MEM |
------------------
|  0 |  5% | 21% |

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.24807009100914001, 'test_f1': 0.5378590078328982, 'test_prec': 0.6912751677852349, 'test_recall': 0.44017094017094016, 'labeled_instances': 480, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.10228339067876134, 'iteration_time': 181.83671879768372}
| ID | GPU | MEM |
------------------
|  0 |  5% | 21% |

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4542059004306793, 'test_f1': 0.24861878453038677, 'test_prec': 0.3515625, 'test_recall': 0.19230769230769232, 'labeled_instances': 520, 'train_positive_rate': 0.09038461538461538, 'pool_positive_rate': 0.10261252754170601, 'iteration_time': 186.38516640663147}
| ID | GPU | MEM |
------------------
|  0 |  6% | 21% |

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3614961504936218, 'test_f1': 0.28501228501228504, 'test_prec': 0.3352601156069364, 'test_recall': 0.24786324786324787, 'labeled_instances': 560, 'train_positive_rate': 0.0875, 'pool_positive_rate': 0.10294583465315173, 'iteration_time': 175.2167570590973}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.36626264452934265, 'test_f1': 0.5648148148148148, 'test_prec': 0.6161616161616161, 'test_recall': 0.5213675213675214, 'labeled_instances': 600, 'train_positive_rate': 0.08666666666666667, 'pool_positive_rate': 0.10312400382531081, 'iteration_time': 192.0725221633911}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.350556880235672, 'test_f1': 0.3247863247863248, 'test_prec': 0.48717948717948717, 'test_recall': 0.24358974358974358, 'labeled_instances': 640, 'train_positive_rate': 0.0859375, 'pool_positive_rate': 0.10330445941610523, 'iteration_time': 183.36784601211548}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3810056149959564, 'test_f1': 0.5601851851851852, 'test_prec': 0.6111111111111112, 'test_recall': 0.5170940170940171, 'labeled_instances': 680, 'train_positive_rate': 0.08676470588235294, 'pool_positive_rate': 0.10332579916047788, 'iteration_time': 177.42705607414246}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.34092214703559875, 'test_f1': 0.5927601809954751, 'test_prec': 0.6298076923076923, 'test_recall': 0.5598290598290598, 'labeled_instances': 720, 'train_positive_rate': 0.09166666666666666, 'pool_positive_rate': 0.10285992850178746, 'iteration_time': 194.05594205856323}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2781480550765991, 'test_f1': 0.494279176201373, 'test_prec': 0.5320197044334976, 'test_recall': 0.46153846153846156, 'labeled_instances': 760, 'train_positive_rate': 0.09210526315789473, 'pool_positive_rate': 0.10287863918874714, 'iteration_time': 189.10963487625122}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.35646960139274597, 'test_f1': 0.5714285714285715, 'test_prec': 0.6086956521739131, 'test_recall': 0.5384615384615384, 'labeled_instances': 800, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.10273296015805071, 'iteration_time': 183.83186650276184}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3706381320953369, 'test_f1': 0.5139949109414759, 'test_prec': 0.6352201257861635, 'test_recall': 0.43162393162393164, 'labeled_instances': 840, 'train_positive_rate': 0.09285714285714286, 'pool_positive_rate': 0.10291680477295327, 'iteration_time': 191.88216042518616}
| ID | GPU | MEM |
------------------
|  0 |  6% | 33% |

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4310545325279236, 'test_f1': 0.5893719806763286, 'test_prec': 0.6777777777777778, 'test_recall': 0.5213675213675214, 'labeled_instances': 880, 'train_positive_rate': 0.09431818181818181, 'pool_positive_rate': 0.10276943610276944, 'iteration_time': 184.12825679779053}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3335545063018799, 'test_f1': 0.6008583690987124, 'test_prec': 0.603448275862069, 'test_recall': 0.5982905982905983, 'labeled_instances': 920, 'train_positive_rate': 0.09565217391304348, 'pool_positive_rate': 0.10262008733624454, 'iteration_time': 193.62007927894592}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.37254753708839417, 'test_f1': 0.255952380952381, 'test_prec': 0.4215686274509804, 'test_recall': 0.18376068376068377, 'labeled_instances': 960, 'train_positive_rate': 0.09479166666666666, 'pool_positive_rate': 0.10280689888400406, 'iteration_time': 185.91238284111023}
| ID | GPU | MEM |
------------------
|  0 |  5% | 21% |

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3278610110282898, 'test_f1': 0.5692695214105793, 'test_prec': 0.6932515337423313, 'test_recall': 0.4829059829059829, 'labeled_instances': 1000, 'train_positive_rate': 0.094, 'pool_positive_rate': 0.10299625468164794, 'iteration_time': 195.82932710647583}
| ID | GPU | MEM |
------------------
|  0 |  6% | 21% |

Test : 6874
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.24448788166046143, 'test_f1': 0.7179487179487178, 'test_prec': 0.7897435897435897, 'test_recall': 0.6581196581196581, 'labeled_instances': 6874, 'train_positive_rate': 0.1016875181844632, 'pool_positive_rate': 0.1016875181844632, 'iteration_time': 466.8261525630951}
New cross validation 1, for  <function deepmatcher_structured_amazon_google at 0x151a22caf310>
| ID | GPU | MEM |
------------------
|  0 |  5% | 21% |

Test : 0
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.24296724796295166, 'test_f1': 0.7139689578713969, 'test_prec': 0.7419354838709677, 'test_recall': 0.688034188034188, 'labeled_instances': 0, 'train_positive_rate': 0.1016875181844632, 'pool_positive_rate': 0.1016875181844632, 'iteration_time': 461.96156120300293}
| ID | GPU | MEM |
------------------
|  0 |  5% | 21% |

Test : 20
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.344891756772995, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 20, 'train_positive_rate': 0.25, 'pool_positive_rate': 0.10125474175663846, 'iteration_time': 161.74092030525208}
| ID | GPU | MEM |
------------------
|  0 |  6% | 21% |

Test : 40
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3069489598274231, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 40, 'train_positive_rate': 0.175, 'pool_positive_rate': 0.10125841381328651, 'iteration_time': 158.15188646316528}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.29941585659980774, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.13333333333333333, 'pool_positive_rate': 0.1014088641033167, 'iteration_time': 162.18738341331482}
| ID | GPU | MEM |
------------------
|  0 |  5% | 21% |

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.33914560079574585, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 80, 'train_positive_rate': 0.15, 'pool_positive_rate': 0.10111863408890197, 'iteration_time': 168.0875279903412}
| ID | GPU | MEM |
------------------
|  0 |  5% | 21% |

Test : 100
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2764342725276947, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 100, 'train_positive_rate': 0.13, 'pool_positive_rate': 0.10126956008266903, 'iteration_time': 167.26243209838867}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.29743295907974243, 'test_f1': 0.43683083511777304, 'test_prec': 0.43776824034334766, 'test_recall': 0.4358974358974359, 'labeled_instances': 120, 'train_positive_rate': 0.11666666666666667, 'pool_positive_rate': 0.10142137992300859, 'iteration_time': 172.89439916610718}
| ID | GPU | MEM |
------------------
|  0 |  5% | 21% |

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2778785526752472, 'test_f1': 0.35260115606936415, 'test_prec': 0.5446428571428571, 'test_recall': 0.2606837606837607, 'labeled_instances': 140, 'train_positive_rate': 0.10714285714285714, 'pool_positive_rate': 0.10157410157410157, 'iteration_time': 167.89657640457153}
| ID | GPU | MEM |
------------------
|  0 |  5% | 21% |

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2918555438518524, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 160, 'train_positive_rate': 0.1125, 'pool_positive_rate': 0.10142984807864164, 'iteration_time': 170.14847922325134}
| ID | GPU | MEM |
------------------
|  0 |  5% | 21% |

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3549339473247528, 'test_f1': 0.43911439114391143, 'test_prec': 0.38636363636363635, 'test_recall': 0.5085470085470085, 'labeled_instances': 180, 'train_positive_rate': 0.1111111111111111, 'pool_positive_rate': 0.101434120107559, 'iteration_time': 156.82897901535034}
| ID | GPU | MEM |
------------------
|  0 |  6% | 33% |

Test : 200
-- Random test --

[5401 2934 6005 3251 2134 1915 4427 1475 4514 1392 5641 4390 6349 1287
 2800 4431 3132 4942 2717 1528 5289 1328 6324 4821 2098 4615 2398 4291
 1793 5249 1373 5756 4889 5927  119  413 5358 4668 2632 4982 4757 3243
  784 3808 2146  929  767 4702 2338 6724 4002 5584  503 2271  248  553
 2623 3194 1719 4919 5865 1785 2233 2900 4945 2167 5488 1684 5937 1435
 3668 3741 6080 5727  834 2646 1064 3777 5787 1503 6027 6284  234 1777
 5888 5737 6529  951  218  200 6303 5783 5142 2065 2819 5277 2963 6719
 1954 3267 1534 4044 5207 1159 5612 4499  313 5216 2965 6384 4309  545
 1899 6153 1355 6060 1256  927 5492 6249  325 5744 3737 4770 5039 4177
  544 1073 3862 2193 5351 5642 1038 2823  724  161 3144 5946 5752 4252
 3396 6403 2666 2378 2899 4301  955 3072 3293 4304 1652 5790 2011 4856
 6578  984 5281 6136 2228 4579  787  147 4850 6567 4543 3514 3746 5225
 4089 4451 2246 3369 3282 3722 4534 3707 2987 4537 5523 1169 1271 2635
 3942 3660 2080  714  169 6061 6772 2320  407 4685 6539 4794 1309 2441
 3438 6574 2202 1508]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.5959012508392334, 'test_f1': 0.39144736842105265, 'test_prec': 0.3181818181818182, 'test_recall': 0.5085470085470085, 'labeled_instances': 200, 'train_positive_rate': 0.115, 'pool_positive_rate': 0.1012885825591849, 'iteration_time': 177.84298968315125}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.42097070813179016, 'test_f1': 0.5239005736137667, 'test_prec': 0.4740484429065744, 'test_recall': 0.5854700854700855, 'labeled_instances': 240, 'train_positive_rate': 0.125, 'pool_positive_rate': 0.10084413626771178, 'iteration_time': 172.9550335407257}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.49279725551605225, 'test_f1': 0.5017182130584192, 'test_prec': 0.41954022988505746, 'test_recall': 0.6239316239316239, 'labeled_instances': 280, 'train_positive_rate': 0.11428571428571428, 'pool_positive_rate': 0.10115256293600243, 'iteration_time': 171.24278450012207}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4844846725463867, 'test_f1': 0.47286821705426363, 'test_prec': 0.4326241134751773, 'test_recall': 0.5213675213675214, 'labeled_instances': 320, 'train_positive_rate': 0.10625, 'pool_positive_rate': 0.10146475434848948, 'iteration_time': 178.44212818145752}
| ID | GPU | MEM |
------------------
|  0 |  6% | 21% |

Test : 360
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.5020663142204285, 'test_f1': 0.49129593810444877, 'test_prec': 0.44876325088339225, 'test_recall': 0.5427350427350427, 'labeled_instances': 360, 'train_positive_rate': 0.09722222222222222, 'pool_positive_rate': 0.10193429536383175, 'iteration_time': 179.75272870063782}
| ID | GPU | MEM |
------------------
|  0 |  5% | 21% |

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.46167242527008057, 'test_f1': 0.25790754257907544, 'test_prec': 0.2994350282485876, 'test_recall': 0.2264957264957265, 'labeled_instances': 400, 'train_positive_rate': 0.105, 'pool_positive_rate': 0.10148285449490269, 'iteration_time': 174.90062880516052}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.40129730105400085, 'test_f1': 0.44075829383886256, 'test_prec': 0.4946808510638298, 'test_recall': 0.3974358974358974, 'labeled_instances': 440, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.1018029219769972, 'iteration_time': 184.61107563972473}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.34732240438461304, 'test_f1': 0.5221238938053097, 'test_prec': 0.5412844036697247, 'test_recall': 0.5042735042735043, 'labeled_instances': 480, 'train_positive_rate': 0.09583333333333334, 'pool_positive_rate': 0.10212699405692836, 'iteration_time': 175.5634160041809}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.5084614753723145, 'test_f1': 0.22994652406417113, 'test_prec': 0.30714285714285716, 'test_recall': 0.18376068376068377, 'labeled_instances': 520, 'train_positive_rate': 0.09423076923076923, 'pool_positive_rate': 0.1022977651872836, 'iteration_time': 176.2763271331787}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4153854548931122, 'test_f1': 0.5055432372505543, 'test_prec': 0.5253456221198156, 'test_recall': 0.48717948717948717, 'labeled_instances': 560, 'train_positive_rate': 0.09464285714285714, 'pool_positive_rate': 0.10231232182451695, 'iteration_time': 178.33118081092834}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4359675943851471, 'test_f1': 0.3824884792626728, 'test_prec': 0.415, 'test_recall': 0.3547008547008547, 'labeled_instances': 600, 'train_positive_rate': 0.095, 'pool_positive_rate': 0.102327064073956, 'iteration_time': 181.24031519889832}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.43454521894454956, 'test_f1': 0.507795100222717, 'test_prec': 0.5302325581395348, 'test_recall': 0.48717948717948717, 'labeled_instances': 640, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.10250240615976901, 'iteration_time': 180.51073122024536}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3585026264190674, 'test_f1': 0.5789473684210528, 'test_prec': 0.5945945945945946, 'test_recall': 0.5641025641025641, 'labeled_instances': 680, 'train_positive_rate': 0.09264705882352942, 'pool_positive_rate': 0.1026800129157249, 'iteration_time': 181.7444031238556}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3946053981781006, 'test_f1': 0.5450121654501217, 'test_prec': 0.632768361581921, 'test_recall': 0.47863247863247865, 'labeled_instances': 720, 'train_positive_rate': 0.09305555555555556, 'pool_positive_rate': 0.1026974325641859, 'iteration_time': 198.31029391288757}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4735359251499176, 'test_f1': 0.5105263157894737, 'test_prec': 0.6643835616438356, 'test_recall': 0.41452991452991456, 'labeled_instances': 760, 'train_positive_rate': 0.09210526315789473, 'pool_positive_rate': 0.10287863918874714, 'iteration_time': 191.67658376693726}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.38672930002212524, 'test_f1': 0.5565217391304349, 'test_prec': 0.5663716814159292, 'test_recall': 0.5470085470085471, 'labeled_instances': 800, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.10273296015805071, 'iteration_time': 197.77468752861023}
| ID | GPU | MEM |
------------------
|  0 |  4% | 21% |

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4043012857437134, 'test_f1': 0.5322997416020672, 'test_prec': 0.673202614379085, 'test_recall': 0.44017094017094016, 'labeled_instances': 840, 'train_positive_rate': 0.09642857142857143, 'pool_positive_rate': 0.10241962214119987, 'iteration_time': 194.20075750350952}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3951296806335449, 'test_f1': 0.5132275132275133, 'test_prec': 0.6736111111111112, 'test_recall': 0.41452991452991456, 'labeled_instances': 880, 'train_positive_rate': 0.09659090909090909, 'pool_positive_rate': 0.10243576910243576, 'iteration_time': 206.36305594444275}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.41721728444099426, 'test_f1': 0.5441860465116278, 'test_prec': 0.5969387755102041, 'test_recall': 0.5, 'labeled_instances': 920, 'train_positive_rate': 0.09565217391304348, 'pool_positive_rate': 0.10262008733624454, 'iteration_time': 205.88779759407043}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.37191540002822876, 'test_f1': 0.5444743935309972, 'test_prec': 0.7372262773722628, 'test_recall': 0.43162393162393164, 'labeled_instances': 960, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.10297598917822116, 'iteration_time': 200.81640577316284}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4073134958744049, 'test_f1': 0.6123348017621145, 'test_prec': 0.6318181818181818, 'test_recall': 0.594017094017094, 'labeled_instances': 1000, 'train_positive_rate': 0.096, 'pool_positive_rate': 0.10265577119509704, 'iteration_time': 227.75700879096985}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 6874
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2697973847389221, 'test_f1': 0.701834862385321, 'test_prec': 0.7574257425742574, 'test_recall': 0.6538461538461539, 'labeled_instances': 6874, 'train_positive_rate': 0.1016875181844632, 'pool_positive_rate': 0.1016875181844632, 'iteration_time': 507.5074691772461}
New cross validation 2, for  <function deepmatcher_structured_amazon_google at 0x151a22caf310>
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 0
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.27132993936538696, 'test_f1': 0.7192575406032483, 'test_prec': 0.7868020304568528, 'test_recall': 0.6623931623931624, 'labeled_instances': 0, 'train_positive_rate': 0.1016875181844632, 'pool_positive_rate': 0.1016875181844632, 'iteration_time': 518.8541643619537}
| ID | GPU | MEM |
------------------
|  0 |  5% | 21% |

Test : 20
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4904099404811859, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 20, 'train_positive_rate': 0.0, 'pool_positive_rate': 0.1019842427779399, 'iteration_time': 165.85900592803955}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 40
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.7379128336906433, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 40, 'train_positive_rate': 0.0, 'pool_positive_rate': 0.10228270412642669, 'iteration_time': 174.37506008148193}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.42515408992767334, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.03333333333333333, 'pool_positive_rate': 0.10228940416788963, 'iteration_time': 192.64088559150696}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3675515651702881, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 80, 'train_positive_rate': 0.0375, 'pool_positive_rate': 0.10244333235207537, 'iteration_time': 170.31046175956726}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4275008738040924, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 100, 'train_positive_rate': 0.04, 'pool_positive_rate': 0.10259816947150871, 'iteration_time': 180.4748513698578}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3900076448917389, 'test_f1': 0.1254355400696864, 'test_prec': 0.33962264150943394, 'test_recall': 0.07692307692307693, 'labeled_instances': 120, 'train_positive_rate': 0.05, 'pool_positive_rate': 0.10260586319218241, 'iteration_time': 196.58738088607788}
| ID | GPU | MEM |
------------------
|  0 |  5% | 21% |

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.45587438344955444, 'test_f1': 0.23569023569023567, 'test_prec': 0.5555555555555556, 'test_recall': 0.14957264957264957, 'labeled_instances': 140, 'train_positive_rate': 0.07142857142857142, 'pool_positive_rate': 0.10231660231660232, 'iteration_time': 188.98051476478577}
| ID | GPU | MEM |
------------------
|  0 |  6% | 21% |

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3911183476448059, 'test_f1': 0.024096385542168672, 'test_prec': 0.2, 'test_recall': 0.01282051282051282, 'labeled_instances': 160, 'train_positive_rate': 0.06875, 'pool_positive_rate': 0.10247244563598451, 'iteration_time': 199.54096055030823}
| ID | GPU | MEM |
------------------
|  0 |  5% | 21% |

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.5491002798080444, 'test_f1': 0.25396825396825395, 'test_prec': 0.49382716049382713, 'test_recall': 0.17094017094017094, 'labeled_instances': 180, 'train_positive_rate': 0.07222222222222222, 'pool_positive_rate': 0.10247983268598745, 'iteration_time': 180.19251489639282}
| ID | GPU | MEM |
------------------
|  0 |  5% | 21% |

Test : 200
-- Random test --

[ 810  862 2909 4208 4207 2627 5737 2098 2992 3026 5770 3281  866 4401
 6617 1160 4533 1758 3522  291 5559  338 1156 2793 1797 5845 5327 2283
  336 6287  565  942 4069 4471 3198  380  489 2512 6872  626 5322 3555
 3045 6482  595 4372 4795 6251 2051 1221 4557 1873 1446 1080 3553 3225
 1999 5066 5617 1737 5866 3821 6616 3408 1752 5713 6229 4250 1638 5349
 1664 3952 3455 1557 5139 3938 5333 3570 2391 6667  849   37 5689 1228
 2803 3174 5907 5123 1434 4063 3909 5457  186 2824 4511 2962 3475 2871
 3098 4952 1558 2444 4944 3566 2405 3612 5585  625  738  959  145 5376
 3481 1695 5679 3676 4554 4865 2951 5117 6064  256 5627 5158  887 3917
 1811 5256   62 3303 4204 1428 6022  103 4584 4047 2859 6634 5101 3997
 1067 1300 4820 3113   88 2714 4761 3580  661 3299 3524 1153 3734 5610
 4857 1176 2352 1987 5072 6101 5277 1263  814 3976 1082 1894 1395 3684
 5867 3320 1754 2927 4000 1294 5036 2187 6855 6091 2978 3926 3846 5863
 4233 5218 5478 6602 6525 6080 3896 5972  948 1494 1783 5534 3770 3349
 5976 3615 6088 3906]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3529094159603119, 'test_f1': 0.3565459610027855, 'test_prec': 0.512, 'test_recall': 0.27350427350427353, 'labeled_instances': 200, 'train_positive_rate': 0.08, 'pool_positive_rate': 0.10233742882828888, 'iteration_time': 172.78693008422852}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.42821139097213745, 'test_f1': 0.2738095238095238, 'test_prec': 0.45098039215686275, 'test_recall': 0.19658119658119658, 'labeled_instances': 240, 'train_positive_rate': 0.07916666666666666, 'pool_positive_rate': 0.10250226107928852, 'iteration_time': 197.6733376979828}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.26997658610343933, 'test_f1': 0.43434343434343436, 'test_prec': 0.5308641975308642, 'test_recall': 0.36752136752136755, 'labeled_instances': 280, 'train_positive_rate': 0.08928571428571429, 'pool_positive_rate': 0.10221413406126782, 'iteration_time': 189.99667596817017}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.35189127922058105, 'test_f1': 0.4965197215777262, 'test_prec': 0.5431472081218274, 'test_recall': 0.45726495726495725, 'labeled_instances': 320, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.10207506866036009, 'iteration_time': 183.85387110710144}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.32005447149276733, 'test_f1': 0.45812807881773393, 'test_prec': 0.5406976744186046, 'test_recall': 0.3974358974358974, 'labeled_instances': 360, 'train_positive_rate': 0.09166666666666666, 'pool_positive_rate': 0.10224132637396377, 'iteration_time': 191.51887440681458}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.423629492521286, 'test_f1': 0.49532710280373826, 'test_prec': 0.5463917525773195, 'test_recall': 0.452991452991453, 'labeled_instances': 400, 'train_positive_rate': 0.0875, 'pool_positive_rate': 0.10256410256410256, 'iteration_time': 193.2722418308258}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3675988018512726, 'test_f1': 0.5411764705882353, 'test_prec': 0.6020942408376964, 'test_recall': 0.49145299145299143, 'labeled_instances': 440, 'train_positive_rate': 0.08863636363636364, 'pool_positive_rate': 0.10258004351880634, 'iteration_time': 197.66563630104065}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4172707200050354, 'test_f1': 0.4935622317596567, 'test_prec': 0.4956896551724138, 'test_recall': 0.49145299145299143, 'labeled_instances': 480, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.10228339067876134, 'iteration_time': 198.8924684524536}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3959329426288605, 'test_f1': 0.5038560411311055, 'test_prec': 0.632258064516129, 'test_recall': 0.4188034188034188, 'labeled_instances': 520, 'train_positive_rate': 0.09423076923076923, 'pool_positive_rate': 0.1022977651872836, 'iteration_time': 196.18520259857178}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.44942817091941833, 'test_f1': 0.5474137931034483, 'test_prec': 0.5521739130434783, 'test_recall': 0.5427350427350427, 'labeled_instances': 560, 'train_positive_rate': 0.09285714285714286, 'pool_positive_rate': 0.10247070003167565, 'iteration_time': 197.46026849746704}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.44447216391563416, 'test_f1': 0.5465346534653466, 'test_prec': 0.5092250922509225, 'test_recall': 0.5897435897435898, 'labeled_instances': 600, 'train_positive_rate': 0.09166666666666666, 'pool_positive_rate': 0.10264583997449793, 'iteration_time': 200.46559309959412}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4173201322555542, 'test_f1': 0.44019138755980863, 'test_prec': 0.5, 'test_recall': 0.39316239316239315, 'labeled_instances': 640, 'train_positive_rate': 0.0890625, 'pool_positive_rate': 0.10298363811357074, 'iteration_time': 209.42031836509705}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.42484796047210693, 'test_f1': 0.49148418491484186, 'test_prec': 0.5706214689265536, 'test_recall': 0.43162393162393164, 'labeled_instances': 680, 'train_positive_rate': 0.09264705882352942, 'pool_positive_rate': 0.1026800129157249, 'iteration_time': 208.05310463905334}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4593048691749573, 'test_f1': 0.4676616915422886, 'test_prec': 0.5595238095238095, 'test_recall': 0.4017094017094017, 'labeled_instances': 720, 'train_positive_rate': 0.09444444444444444, 'pool_positive_rate': 0.10253493662658433, 'iteration_time': 209.94117784500122}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.5050844550132751, 'test_f1': 0.49746192893401014, 'test_prec': 0.6125, 'test_recall': 0.4188034188034188, 'labeled_instances': 760, 'train_positive_rate': 0.09868421052631579, 'pool_positive_rate': 0.10206084396467124, 'iteration_time': 217.92168831825256}
| ID | GPU | MEM |
------------------
|  0 |  5% | 21% |

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.5264636278152466, 'test_f1': 0.5390070921985816, 'test_prec': 0.6031746031746031, 'test_recall': 0.48717948717948717, 'labeled_instances': 800, 'train_positive_rate': 0.0975, 'pool_positive_rate': 0.10223905169575238, 'iteration_time': 225.3310706615448}
| ID | GPU | MEM |
------------------
|  0 |  5% | 21% |

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4218854606151581, 'test_f1': 0.5450346420323325, 'test_prec': 0.592964824120603, 'test_recall': 0.5042735042735043, 'labeled_instances': 840, 'train_positive_rate': 0.0988095238095238, 'pool_positive_rate': 0.10208816705336426, 'iteration_time': 219.7056369781494}
| ID | GPU | MEM |
------------------
|  0 |  5% | 21% |

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.48987844586372375, 'test_f1': 0.501240694789082, 'test_prec': 0.5976331360946746, 'test_recall': 0.43162393162393164, 'labeled_instances': 880, 'train_positive_rate': 0.09886363636363636, 'pool_positive_rate': 0.1021021021021021, 'iteration_time': 234.99132680892944}
| ID | GPU | MEM |
------------------
|  0 |  5% | 21% |

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4275510907173157, 'test_f1': 0.5154639175257731, 'test_prec': 0.6493506493506493, 'test_recall': 0.42735042735042733, 'labeled_instances': 920, 'train_positive_rate': 0.09782608695652174, 'pool_positive_rate': 0.10228417870339268, 'iteration_time': 247.40897226333618}
| ID | GPU | MEM |
------------------
|  0 |  5% | 21% |

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.41664326190948486, 'test_f1': 0.358974358974359, 'test_prec': 0.44871794871794873, 'test_recall': 0.29914529914529914, 'labeled_instances': 960, 'train_positive_rate': 0.09479166666666666, 'pool_positive_rate': 0.10280689888400406, 'iteration_time': 227.90366339683533}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3933073580265045, 'test_f1': 0.5907172995780591, 'test_prec': 0.5833333333333334, 'test_recall': 0.5982905982905983, 'labeled_instances': 1000, 'train_positive_rate': 0.094, 'pool_positive_rate': 0.10299625468164794, 'iteration_time': 261.2073369026184}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 6874
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2608796954154968, 'test_f1': 0.7077625570776256, 'test_prec': 0.7598039215686274, 'test_recall': 0.6623931623931624, 'labeled_instances': 6874, 'train_positive_rate': 0.1016875181844632, 'pool_positive_rate': 0.1016875181844632, 'iteration_time': 559.34415102005}
New cross validation 3, for  <function deepmatcher_structured_amazon_google at 0x151a22caf310>
| ID | GPU | MEM |
------------------
|  0 |  5% | 21% |

Test : 0
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.22851498425006866, 'test_f1': 0.7321428571428571, 'test_prec': 0.7663551401869159, 'test_recall': 0.7008547008547008, 'labeled_instances': 0, 'train_positive_rate': 0.1016875181844632, 'pool_positive_rate': 0.1016875181844632, 'iteration_time': 579.722505569458}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 20
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.40522506833076477, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 20, 'train_positive_rate': 0.05, 'pool_positive_rate': 0.1018383425736796, 'iteration_time': 187.80694317817688}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 40
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2716885209083557, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 40, 'train_positive_rate': 0.125, 'pool_positive_rate': 0.10155106818846941, 'iteration_time': 210.04357957839966}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2903447449207306, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.11666666666666667, 'pool_positive_rate': 0.10155562078074552, 'iteration_time': 221.96673226356506}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.37862342596054077, 'test_f1': 0.2636655948553055, 'test_prec': 0.5324675324675324, 'test_recall': 0.1752136752136752, 'labeled_instances': 80, 'train_positive_rate': 0.0875, 'pool_positive_rate': 0.10185457756844274, 'iteration_time': 203.21664714813232}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.39684197306632996, 'test_f1': 0.423076923076923, 'test_prec': 0.4835164835164835, 'test_recall': 0.37606837606837606, 'labeled_instances': 100, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10171242987894892, 'iteration_time': 200.82920289039612}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.38054147362709045, 'test_f1': 0.31545741324921134, 'test_prec': 0.6024096385542169, 'test_recall': 0.21367521367521367, 'labeled_instances': 120, 'train_positive_rate': 0.09166666666666666, 'pool_positive_rate': 0.10186556114894878, 'iteration_time': 219.11344194412231}
| ID | GPU | MEM |
------------------
|  0 |  5% | 21% |

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4804050326347351, 'test_f1': 0.35260115606936415, 'test_prec': 0.5446428571428571, 'test_recall': 0.2606837606837607, 'labeled_instances': 140, 'train_positive_rate': 0.08571428571428572, 'pool_positive_rate': 0.10201960201960202, 'iteration_time': 218.73863220214844}
| ID | GPU | MEM |
------------------
|  0 |  6% | 21% |

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3137145936489105, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 160, 'train_positive_rate': 0.0875, 'pool_positive_rate': 0.10202561811140899, 'iteration_time': 228.38186597824097}
| ID | GPU | MEM |
------------------
|  0 |  5% | 21% |

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.34504029154777527, 'test_f1': 0.40229885057471265, 'test_prec': 0.6140350877192983, 'test_recall': 0.29914529914529914, 'labeled_instances': 180, 'train_positive_rate': 0.08888888888888889, 'pool_positive_rate': 0.10203167015237526, 'iteration_time': 206.2739589214325}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 200
-- Random test --

[3078 2963 1942 1965 1622 6724 5933  125 4037  873 1964 1404 1548  202
 5638 3818  529 4539 4632 2991 6545 2633 2416 4920 5068 1123 3445 2139
 3476 2850 5984 1041 3820 3579  660 2896 1466 2800 2717 5184 1675 6185
 4452 4695 2364 6200  371 3032   41 4518 4825 6158 6401 3968 4136 4042
 1176 2251  317  163  447 4418 3578 1204 1571 4447  445 3807 5065 2919
 1129 1470 1663 3107 4227 1862 3279 6006   94 5892  281 1388 3540  515
 5589 1136 4246 1638 4186 1934 4209  375 4083 1646 3647 2894 2866 3972
 5156 2831 6300 1187 6571 1735 2861 6205 4276 3340 1316 4643 6461 1091
 3384  997  292 4068 1627 5150 1564 2115 5321 1866 1440   20 1491 3954
 5277 4727 1755 2021 6228 3213  575 3017 4859  232 6384 1784  510  273
 4284 2455 3747 5036 6762 5482 3517 5315 3702 1871  747  367 6590 4544
 4696 1124 2840 4745 3104 5453 1395 1878  991 6526 2581 2577 2366 4854
 1795 2208 4865 1364  404 6003  368  521 4788 2541  330 3452 4293 3682
 4796 6034 3925  454 2865 5739 3605 2367 5985 3123 6573 3358 2205 1008
 1206 5147 2296 6149]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.40010178089141846, 'test_f1': 0.12734082397003746, 'test_prec': 0.5151515151515151, 'test_recall': 0.07264957264957266, 'labeled_instances': 200, 'train_positive_rate': 0.085, 'pool_positive_rate': 0.10218759364698832, 'iteration_time': 225.70980620384216}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3787963390350342, 'test_f1': 0.2546583850931677, 'test_prec': 0.4659090909090909, 'test_recall': 0.1752136752136752, 'labeled_instances': 240, 'train_positive_rate': 0.07916666666666666, 'pool_positive_rate': 0.10250226107928852, 'iteration_time': 242.74948048591614}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.5049602389335632, 'test_f1': 0.34857142857142853, 'test_prec': 0.5258620689655172, 'test_recall': 0.2606837606837607, 'labeled_instances': 280, 'train_positive_rate': 0.075, 'pool_positive_rate': 0.10282074613284804, 'iteration_time': 216.5081822872162}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4254624545574188, 'test_f1': 0.4383561643835617, 'test_prec': 0.6106870229007634, 'test_recall': 0.3418803418803419, 'labeled_instances': 320, 'train_positive_rate': 0.078125, 'pool_positive_rate': 0.10283796155019835, 'iteration_time': 235.3138084411621}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 360
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4150454103946686, 'test_f1': 0.2678062678062678, 'test_prec': 0.4017094017094017, 'test_recall': 0.20085470085470086, 'labeled_instances': 360, 'train_positive_rate': 0.09166666666666666, 'pool_positive_rate': 0.10224132637396377, 'iteration_time': 230.08739852905273}
| ID | GPU | MEM |
------------------
|  0 |  5% | 21% |

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.5246923565864563, 'test_f1': 0.44619422572178474, 'test_prec': 0.5782312925170068, 'test_recall': 0.36324786324786323, 'labeled_instances': 400, 'train_positive_rate': 0.085, 'pool_positive_rate': 0.10271856657398826, 'iteration_time': 235.76777029037476}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4543396234512329, 'test_f1': 0.4235294117647059, 'test_prec': 0.6792452830188679, 'test_recall': 0.3076923076923077, 'labeled_instances': 440, 'train_positive_rate': 0.08863636363636364, 'pool_positive_rate': 0.10258004351880634, 'iteration_time': 239.33665251731873}
| ID | GPU | MEM |
------------------
|  0 |  5% | 21% |

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3570913076400757, 'test_f1': 0.5084745762711864, 'test_prec': 0.5865921787709497, 'test_recall': 0.44871794871794873, 'labeled_instances': 480, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10181420081326244, 'iteration_time': 247.11976981163025}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.33633682131767273, 'test_f1': 0.4988235294117648, 'test_prec': 0.5549738219895288, 'test_recall': 0.452991452991453, 'labeled_instances': 520, 'train_positive_rate': 0.09807692307692308, 'pool_positive_rate': 0.10198300283286119, 'iteration_time': 242.89121770858765}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3906773626804352, 'test_f1': 0.5242290748898678, 'test_prec': 0.5409090909090909, 'test_recall': 0.5085470085470085, 'labeled_instances': 560, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10183718720304086, 'iteration_time': 255.79126524925232}
| ID | GPU | MEM |
------------------
|  0 |  5% | 21% |

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.41905492544174194, 'test_f1': 0.523489932885906, 'test_prec': 0.5492957746478874, 'test_recall': 0.5, 'labeled_instances': 600, 'train_positive_rate': 0.09833333333333333, 'pool_positive_rate': 0.10200828817341409, 'iteration_time': 252.29348397254944}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.30391988158226013, 'test_f1': 0.564885496183206, 'test_prec': 0.6981132075471698, 'test_recall': 0.47435897435897434, 'labeled_instances': 640, 'train_positive_rate': 0.096875, 'pool_positive_rate': 0.10218158485723453, 'iteration_time': 261.75285720825195}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.37587860226631165, 'test_f1': 0.5558194774346794, 'test_prec': 0.6256684491978609, 'test_recall': 0.5, 'labeled_instances': 680, 'train_positive_rate': 0.09852941176470588, 'pool_positive_rate': 0.10203422667097191, 'iteration_time': 241.1022071838379}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.46224406361579895, 'test_f1': 0.2973760932944607, 'test_prec': 0.46788990825688076, 'test_recall': 0.21794871794871795, 'labeled_instances': 720, 'train_positive_rate': 0.09861111111111111, 'pool_positive_rate': 0.10204744881377965, 'iteration_time': 255.33095502853394}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3477819263935089, 'test_f1': 0.625531914893617, 'test_prec': 0.6228813559322034, 'test_recall': 0.6282051282051282, 'labeled_instances': 760, 'train_positive_rate': 0.09342105263157895, 'pool_positive_rate': 0.10271508014393196, 'iteration_time': 274.0965847969055}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.35945558547973633, 'test_f1': 0.5870020964360587, 'test_prec': 0.5761316872427984, 'test_recall': 0.5982905982905983, 'labeled_instances': 800, 'train_positive_rate': 0.095, 'pool_positive_rate': 0.10256832400395127, 'iteration_time': 255.53983068466187}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.39731982350349426, 'test_f1': 0.349570200573066, 'test_prec': 0.5304347826086957, 'test_recall': 0.2606837606837607, 'labeled_instances': 840, 'train_positive_rate': 0.09166666666666666, 'pool_positive_rate': 0.10308253231687106, 'iteration_time': 267.799521446228}
| ID | GPU | MEM |
------------------
|  0 |  2% | 33% |

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.36149266362190247, 'test_f1': 0.5871964679911699, 'test_prec': 0.6073059360730594, 'test_recall': 0.5683760683760684, 'labeled_instances': 880, 'train_positive_rate': 0.09431818181818181, 'pool_positive_rate': 0.10276943610276944, 'iteration_time': 277.21176052093506}
| ID | GPU | MEM |
------------------
|  0 |  6% | 33% |

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4437941908836365, 'test_f1': 0.44052863436123346, 'test_prec': 0.45454545454545453, 'test_recall': 0.42735042735042733, 'labeled_instances': 920, 'train_positive_rate': 0.09891304347826087, 'pool_positive_rate': 0.10211622438696674, 'iteration_time': 255.6081838607788}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.43592047691345215, 'test_f1': 0.4585987261146497, 'test_prec': 0.45569620253164556, 'test_recall': 0.46153846153846156, 'labeled_instances': 960, 'train_positive_rate': 0.09895833333333333, 'pool_positive_rate': 0.10213053770713561, 'iteration_time': 269.95754289627075}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.37614870071411133, 'test_f1': 0.5369127516778522, 'test_prec': 0.5633802816901409, 'test_recall': 0.5128205128205128, 'labeled_instances': 1000, 'train_positive_rate': 0.105, 'pool_positive_rate': 0.10112359550561797, 'iteration_time': 303.28240513801575}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 6874
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.26431804895401, 'test_f1': 0.7251732101616627, 'test_prec': 0.7889447236180904, 'test_recall': 0.6709401709401709, 'labeled_instances': 6874, 'train_positive_rate': 0.1016875181844632, 'pool_positive_rate': 0.1016875181844632, 'iteration_time': 611.007297039032}
New cross validation 4, for  <function deepmatcher_structured_amazon_google at 0x151a22caf310>
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 0
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2404407411813736, 'test_f1': 0.7400881057268722, 'test_prec': 0.7636363636363637, 'test_recall': 0.717948717948718, 'labeled_instances': 0, 'train_positive_rate': 0.1016875181844632, 'pool_positive_rate': 0.1016875181844632, 'iteration_time': 648.7935910224915}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 20
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3232877552509308, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 20, 'train_positive_rate': 0.25, 'pool_positive_rate': 0.10125474175663846, 'iteration_time': 201.51663875579834}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 40
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.30507558584213257, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 40, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.10111208662569506, 'iteration_time': 210.30102372169495}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2547142803668976, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.15, 'pool_positive_rate': 0.10126210742588788, 'iteration_time': 229.2247064113617}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.27952104806900024, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 80, 'train_positive_rate': 0.15, 'pool_positive_rate': 0.10111863408890197, 'iteration_time': 208.8809404373169}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.23882846534252167, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 100, 'train_positive_rate': 0.14, 'pool_positive_rate': 0.1011219368172424, 'iteration_time': 254.43350100517273}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.27536267042160034, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 120, 'train_positive_rate': 0.14166666666666666, 'pool_positive_rate': 0.10097719869706841, 'iteration_time': 248.85387325286865}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2357483059167862, 'test_f1': 0.5325443786982248, 'test_prec': 0.4945054945054945, 'test_recall': 0.5769230769230769, 'labeled_instances': 140, 'train_positive_rate': 0.12142857142857143, 'pool_positive_rate': 0.10127710127710128, 'iteration_time': 214.42682719230652}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.38547536730766296, 'test_f1': 0.4133738601823708, 'test_prec': 0.7157894736842105, 'test_recall': 0.2905982905982906, 'labeled_instances': 160, 'train_positive_rate': 0.10625, 'pool_positive_rate': 0.10157879058683349, 'iteration_time': 232.97713017463684}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.29817354679107666, 'test_f1': 0.31683168316831684, 'test_prec': 0.6956521739130435, 'test_recall': 0.20512820512820512, 'labeled_instances': 180, 'train_positive_rate': 0.09444444444444444, 'pool_positive_rate': 0.1018822826411712, 'iteration_time': 237.62399888038635}
| ID | GPU | MEM |
------------------
|  0 |  5% | 21% |

Test : 200
-- Random test --

[3451  203 6247  111 1397 3889 6530 3035 4666 4507 3405 3123  519 5379
 3901 5317 4466   41  473 6867   20 3485 5321 6039 2418  441 4352 1849
 5900 3944 3477 4167 5879 3173 5922 6276 1106 1185 1939 5844 4972 3685
 4997 2145 1905 2375 3425 4125 2315 4478 2525 6839 1256 3043 4785 3024
 1797 5332 6859 2079  158  621 2373 4207 3100 5684 4398 6411 3913 2016
 2243  387 4371 1374 5641 1318 5052 2994 3213  423 4084 5298 2440 1940
 3852 3054 4320 5409 5990 6645 2141 6841 3225 4235 5244 3332 4771 3050
 1691 2342 3491 3279 3206 6772 6153 5940 3121 1862 1488 2501 2218 4039
 5454 1858 1766 4321 2764 4559 6560 1746 5963 3196 4337 1028 3898 5101
 6727 4450 1105 4539 4428 1536 1859 5528 4285 1549 3869  945  920  923
 3664 4549 1618 3150 6004 5796 1117   13 6361 5776 6781 5223 1437 2257
  577 1005 2659 3314 5584  525 5887 4894 6399 3928  841 3571 5255  510
 3817 3228 4323 3602 1529 6060  908 2743 2582 5376 2565 4779 4116 1929
  537 6166 5462 4012 3422 1142 4411 6152 5857 3380  635 1152 3455 3902
 1429 2166 3864 5754]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3910766839981079, 'test_f1': 0.1646341463414634, 'test_prec': 0.2872340425531915, 'test_recall': 0.11538461538461539, 'labeled_instances': 200, 'train_positive_rate': 0.09, 'pool_positive_rate': 0.10203775846568774, 'iteration_time': 215.38839197158813}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3473345935344696, 'test_f1': 0.4658823529411765, 'test_prec': 0.518324607329843, 'test_recall': 0.4230769230769231, 'labeled_instances': 240, 'train_positive_rate': 0.07916666666666666, 'pool_positive_rate': 0.10250226107928852, 'iteration_time': 244.66958141326904}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.46477124094963074, 'test_f1': 0.36024844720496896, 'test_prec': 0.6590909090909091, 'test_recall': 0.24786324786324787, 'labeled_instances': 280, 'train_positive_rate': 0.08928571428571429, 'pool_positive_rate': 0.10221413406126782, 'iteration_time': 235.59274888038635}
| ID | GPU | MEM |
------------------
|  0 |  5% | 21% |

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2940676808357239, 'test_f1': 0.48958333333333326, 'test_prec': 0.6266666666666667, 'test_recall': 0.4017094017094017, 'labeled_instances': 320, 'train_positive_rate': 0.090625, 'pool_positive_rate': 0.10222764723832774, 'iteration_time': 239.29910588264465}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.27823370695114136, 'test_f1': 0.591375770020534, 'test_prec': 0.5691699604743083, 'test_recall': 0.6153846153846154, 'labeled_instances': 360, 'train_positive_rate': 0.08888888888888889, 'pool_positive_rate': 0.10239484187902978, 'iteration_time': 237.63100719451904}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.30696743726730347, 'test_f1': 0.5196850393700787, 'test_prec': 0.673469387755102, 'test_recall': 0.4230769230769231, 'labeled_instances': 400, 'train_positive_rate': 0.095, 'pool_positive_rate': 0.10210071053444547, 'iteration_time': 255.8447082042694}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.28845587372779846, 'test_f1': 0.5601965601965602, 'test_prec': 0.6589595375722543, 'test_recall': 0.48717948717948717, 'labeled_instances': 440, 'train_positive_rate': 0.09545454545454546, 'pool_positive_rate': 0.10211377059372086, 'iteration_time': 235.45547890663147}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4134368896484375, 'test_f1': 0.5053191489361701, 'test_prec': 0.6690140845070423, 'test_recall': 0.405982905982906, 'labeled_instances': 480, 'train_positive_rate': 0.09583333333333334, 'pool_positive_rate': 0.10212699405692836, 'iteration_time': 256.3050961494446}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.36407241225242615, 'test_f1': 0.4734042553191489, 'test_prec': 0.6267605633802817, 'test_recall': 0.3803418803418803, 'labeled_instances': 520, 'train_positive_rate': 0.09423076923076923, 'pool_positive_rate': 0.1022977651872836, 'iteration_time': 263.3316864967346}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.32183587551116943, 'test_f1': 0.5721649484536082, 'test_prec': 0.7207792207792207, 'test_recall': 0.47435897435897434, 'labeled_instances': 560, 'train_positive_rate': 0.09642857142857143, 'pool_positive_rate': 0.10215394361735824, 'iteration_time': 261.04855966567993}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.32565557956695557, 'test_f1': 0.6059113300492611, 'test_prec': 0.7151162790697675, 'test_recall': 0.5256410256410257, 'labeled_instances': 600, 'train_positive_rate': 0.09666666666666666, 'pool_positive_rate': 0.10216767612368505, 'iteration_time': 276.4172537326813}
| ID | GPU | MEM |
------------------
|  0 |  3% | 33% |

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3699154257774353, 'test_f1': 0.5853658536585366, 'test_prec': 0.5581395348837209, 'test_recall': 0.6153846153846154, 'labeled_instances': 640, 'train_positive_rate': 0.103125, 'pool_positive_rate': 0.10153994225216555, 'iteration_time': 278.0670909881592}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 680
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.29018619656562805, 'test_f1': 0.6213151927437643, 'test_prec': 0.6618357487922706, 'test_recall': 0.5854700854700855, 'labeled_instances': 680, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10187278010978366, 'iteration_time': 295.16908264160156}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3334197402000427, 'test_f1': 0.6008064516129031, 'test_prec': 0.5687022900763359, 'test_recall': 0.6367521367521367, 'labeled_instances': 720, 'train_positive_rate': 0.10416666666666667, 'pool_positive_rate': 0.10139746506337341, 'iteration_time': 298.80648159980774}
| ID | GPU | MEM |
------------------
|  0 |  5% | 33% |

Test : 760
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.35735687613487244, 'test_f1': 0.5904761904761905, 'test_prec': 0.6666666666666666, 'test_recall': 0.5299145299145299, 'labeled_instances': 760, 'train_positive_rate': 0.10394736842105264, 'pool_positive_rate': 0.10140660778541054, 'iteration_time': 297.80647110939026}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.34664273262023926, 'test_f1': 0.62882096069869, 'test_prec': 0.6428571428571429, 'test_recall': 0.6153846153846154, 'labeled_instances': 800, 'train_positive_rate': 0.105, 'pool_positive_rate': 0.10125123477115575, 'iteration_time': 274.2760212421417}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.28648853302001953, 'test_f1': 0.48106904231625836, 'test_prec': 0.5023255813953489, 'test_recall': 0.46153846153846156, 'labeled_instances': 840, 'train_positive_rate': 0.10595238095238095, 'pool_positive_rate': 0.10109380178985747, 'iteration_time': 278.37019634246826}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3233603835105896, 'test_f1': 0.6255924170616114, 'test_prec': 0.7021276595744681, 'test_recall': 0.5641025641025641, 'labeled_instances': 880, 'train_positive_rate': 0.10568181818181818, 'pool_positive_rate': 0.1011011011011011, 'iteration_time': 298.87919998168945}
| ID | GPU | MEM |
------------------
|  0 |  0% | 22% |

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.30694255232810974, 'test_f1': 0.5995893223819302, 'test_prec': 0.5770750988142292, 'test_recall': 0.6239316239316239, 'labeled_instances': 920, 'train_positive_rate': 0.10869565217391304, 'pool_positive_rate': 0.10060463553913336, 'iteration_time': 314.06123876571655}
| ID | GPU | MEM |
------------------
|  0 |  5% | 21% |

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.32563456892967224, 'test_f1': 0.6331877729257642, 'test_prec': 0.6473214285714286, 'test_recall': 0.6196581196581197, 'labeled_instances': 960, 'train_positive_rate': 0.10520833333333333, 'pool_positive_rate': 0.10111599594183295, 'iteration_time': 280.3693346977234}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3314162790775299, 'test_f1': 0.641255605381166, 'test_prec': 0.6745283018867925, 'test_recall': 0.6111111111111112, 'labeled_instances': 1000, 'train_positive_rate': 0.105, 'pool_positive_rate': 0.10112359550561797, 'iteration_time': 283.7607500553131}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 6874
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.22240842878818512, 'test_f1': 0.7139588100686499, 'test_prec': 0.7684729064039408, 'test_recall': 0.6666666666666666, 'labeled_instances': 6874, 'train_positive_rate': 0.1016875181844632, 'pool_positive_rate': 0.1016875181844632, 'iteration_time': 667.7451827526093}
Could not create dir out, File exists




    ###########  New Dataset: <function deepmatcher_structured_dblp_acm at 0x1519b4516160>
New cross validation 0, for  <function deepmatcher_structured_dblp_acm at 0x1519b4516160>
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 0
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.009595317766070366, 'test_f1': 0.9887133182844244, 'test_prec': 0.9909502262443439, 'test_recall': 0.9864864864864865, 'labeled_instances': 0, 'train_positive_rate': 0.17958743427261697, 'pool_positive_rate': 0.17958743427261697, 'iteration_time': 809.5180747509003}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 20
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3149318993091583, 'test_f1': 0.14990138067061143, 'test_prec': 0.6031746031746031, 'test_recall': 0.08558558558558559, 'labeled_instances': 20, 'train_positive_rate': 0.3, 'pool_positive_rate': 0.17926186291739896, 'iteration_time': 300.12834429740906}
| ID | GPU | MEM |
------------------
|  0 | 19% | 21% |

Test : 40
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.19071587920188904, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 40, 'train_positive_rate': 0.25, 'pool_positive_rate': 0.17920563914870544, 'iteration_time': 330.71596360206604}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.10349774360656738, 'test_f1': 0.9017951425554382, 'test_prec': 0.8489065606361829, 'test_recall': 0.9617117117117117, 'labeled_instances': 60, 'train_positive_rate': 0.21666666666666667, 'pool_positive_rate': 0.1792850346608672, 'iteration_time': 322.6143469810486}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.09765273332595825, 'test_f1': 0.8936605316973416, 'test_prec': 0.8183520599250936, 'test_recall': 0.9842342342342343, 'labeled_instances': 80, 'train_positive_rate': 0.1875, 'pool_positive_rate': 0.17950115851165327, 'iteration_time': 332.773206949234}
| ID | GPU | MEM |
------------------
|  0 | 19% | 21% |

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.07281126081943512, 'test_f1': 0.9392624728850326, 'test_prec': 0.9058577405857741, 'test_recall': 0.9752252252252253, 'labeled_instances': 100, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.1793084597512642, 'iteration_time': 302.85374903678894}
| ID | GPU | MEM |
------------------
|  0 | 16% | 21% |

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.08296676725149155, 'test_f1': 0.921793534932221, 'test_prec': 0.858252427184466, 'test_recall': 0.9954954954954955, 'labeled_instances': 120, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.17925174729340826, 'iteration_time': 320.66402888298035}
| ID | GPU | MEM |
------------------
|  0 | 13% | 21% |

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.05538557842373848, 'test_f1': 0.9617977528089887, 'test_prec': 0.9596412556053812, 'test_recall': 0.963963963963964, 'labeled_instances': 140, 'train_positive_rate': 0.2357142857142857, 'pool_positive_rate': 0.17850762676927306, 'iteration_time': 319.9666028022766}
| ID | GPU | MEM |
------------------
|  0 | 19% | 21% |

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.11605001986026764, 'test_f1': 0.9243697478991598, 'test_prec': 0.8661417322834646, 'test_recall': 0.990990990990991, 'labeled_instances': 160, 'train_positive_rate': 0.225, 'pool_positive_rate': 0.17858619264158743, 'iteration_time': 357.0825481414795}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.09046954661607742, 'test_f1': 0.9496717724288839, 'test_prec': 0.9234042553191489, 'test_recall': 0.9774774774774775, 'labeled_instances': 180, 'train_positive_rate': 0.2222222222222222, 'pool_positive_rate': 0.17852701395605913, 'iteration_time': 328.26484990119934}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 200
-- Random test --

[4194 6909  454 6712  152 4554 1953 3503  347 2475 1142 5686  842 1399
 3608 1361   39 6785 7224 3326 6290 5328 1060 1022 5455  773 5054 5329
 3286 5318 1590 1551 1624 4405 4582 5397 5108 6054  528 1984 1741 2909
 3374 2242 4341 4076  719 5609 1715 1035 5635 2090  462 4664  233 5248
 2585 2247 1235 5413 4992 1380 2027 5464 6998 2519  722  295 4979 6381
 2329 6211 3634 4793 5870 1750 4895 5143  971 1454  916 1830 2182 1568
 2293 5579 4797 3615 6071 2831 2235 3937 3162  444 2708 3617 5180 2111
 7389 3519 6954 4364 2095 6700 6765 6342 5688   49 6581 2076 6238 3035
 1722 6044 5234 4340 6988 4064 1284 3490 7310 3673 7362   72  304 5482
 1051 4136 3874 3943 4410  978 2265 4001 2865 3073 4932  158 5407 3803
 6417  144 7397 1812 3697 6730 1696 6968 4847 6564 4160 6050 6562 5067
  147 2868 2306 7327 4399 4590 5224 4714   38 3916  217 2369 6524 6622
 2630  987 3660  548 1386 3021  704 2447 3710 6979 7410 6361 1785 4521
 6713 1933 4540  176   98 1448 5191  878 5520 1824 1983 5916 4952  526
 2806 3687 5079 6670]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.05380810424685478, 'test_f1': 0.957095709570957, 'test_prec': 0.9354838709677419, 'test_recall': 0.9797297297297297, 'labeled_instances': 200, 'train_positive_rate': 0.23, 'pool_positive_rate': 0.17819038381599003, 'iteration_time': 335.59822130203247}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.15888725221157074, 'test_f1': 0.901639344262295, 'test_prec': 0.8270676691729323, 'test_recall': 0.990990990990991, 'labeled_instances': 240, 'train_positive_rate': 0.2125, 'pool_positive_rate': 0.17848683293855372, 'iteration_time': 324.4370286464691}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.10329361259937286, 'test_f1': 0.9340425531914893, 'test_prec': 0.8850806451612904, 'test_recall': 0.9887387387387387, 'labeled_instances': 280, 'train_positive_rate': 0.21071428571428572, 'pool_positive_rate': 0.17836626033347344, 'iteration_time': 318.056921005249}
| ID | GPU | MEM |
------------------
|  0 | 18% | 33% |

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.0555887445807457, 'test_f1': 0.9622222222222223, 'test_prec': 0.9495614035087719, 'test_recall': 0.9752252252252253, 'labeled_instances': 320, 'train_positive_rate': 0.203125, 'pool_positive_rate': 0.17852613780470622, 'iteration_time': 343.19402623176575}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.03658067062497139, 'test_f1': 0.9732739420935412, 'test_prec': 0.9625550660792952, 'test_recall': 0.9842342342342343, 'labeled_instances': 360, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.178546124415474, 'iteration_time': 335.9104919433594}
| ID | GPU | MEM |
------------------
|  0 | 19% | 33% |

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.055352333933115005, 'test_f1': 0.9705882352941176, 'test_prec': 0.975, 'test_recall': 0.9662162162162162, 'labeled_instances': 400, 'train_positive_rate': 0.1925, 'pool_positive_rate': 0.178851360980476, 'iteration_time': 344.544939994812}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.030808981508016586, 'test_f1': 0.976324689966178, 'test_prec': 0.9774266365688488, 'test_recall': 0.9752252252252253, 'labeled_instances': 440, 'train_positive_rate': 0.19545454545454546, 'pool_positive_rate': 0.17858678515121112, 'iteration_time': 374.4098753929138}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.04506424441933632, 'test_f1': 0.9643652561247216, 'test_prec': 0.9537444933920705, 'test_recall': 0.9752252252252253, 'labeled_instances': 480, 'train_positive_rate': 0.19375, 'pool_positive_rate': 0.17860746720484358, 'iteration_time': 370.0930485725403}
| ID | GPU | MEM |
------------------
|  0 | 19% | 33% |

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.05188244953751564, 'test_f1': 0.9623059866962307, 'test_prec': 0.9475982532751092, 'test_recall': 0.9774774774774775, 'labeled_instances': 520, 'train_positive_rate': 0.18269230769230768, 'pool_positive_rate': 0.17935334203276787, 'iteration_time': 366.85979890823364}
| ID | GPU | MEM |
------------------
|  0 | 19% | 33% |

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.02548128366470337, 'test_f1': 0.9840182648401826, 'test_prec': 0.9976851851851852, 'test_recall': 0.9707207207207207, 'labeled_instances': 560, 'train_positive_rate': 0.18928571428571428, 'pool_positive_rate': 0.1787953915706577, 'iteration_time': 379.58357310295105}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 600
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.02899089641869068, 'test_f1': 0.9774774774774775, 'test_prec': 0.9774774774774775, 'test_recall': 0.9774774774774775, 'labeled_instances': 600, 'train_positive_rate': 0.19166666666666668, 'pool_positive_rate': 0.1785242775414405, 'iteration_time': 369.7069344520569}
| ID | GPU | MEM |
------------------
|  0 | 19% | 33% |

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.040501177310943604, 'test_f1': 0.9741863075196409, 'test_prec': 0.970917225950783, 'test_recall': 0.9774774774774775, 'labeled_instances': 640, 'train_positive_rate': 0.1953125, 'pool_positive_rate': 0.17810240519403867, 'iteration_time': 366.46091866493225}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.02866322547197342, 'test_f1': 0.9771689497716894, 'test_prec': 0.9907407407407407, 'test_recall': 0.963963963963964, 'labeled_instances': 680, 'train_positive_rate': 0.19117647058823528, 'pool_positive_rate': 0.17841769333531246, 'iteration_time': 372.7337303161621}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.01904279552400112, 'test_f1': 0.9875424688561721, 'test_prec': 0.9931662870159453, 'test_recall': 0.9819819819819819, 'labeled_instances': 720, 'train_positive_rate': 0.19444444444444445, 'pool_positive_rate': 0.17799014484097356, 'iteration_time': 371.81263542175293}
| ID | GPU | MEM |
------------------
|  0 | 19% | 33% |

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.052577145397663116, 'test_f1': 0.9714937286202965, 'test_prec': 0.9838337182448037, 'test_recall': 0.9594594594594594, 'labeled_instances': 760, 'train_positive_rate': 0.19342105263157894, 'pool_positive_rate': 0.17800811176205497, 'iteration_time': 362.63939571380615}
| ID | GPU | MEM |
------------------
|  0 |  0% | 22% |

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.03191925212740898, 'test_f1': 0.9818181818181818, 'test_prec': 0.9908256880733946, 'test_recall': 0.972972972972973, 'labeled_instances': 800, 'train_positive_rate': 0.18875, 'pool_positive_rate': 0.17847967356808223, 'iteration_time': 383.5345141887665}
| ID | GPU | MEM |
------------------
|  0 | 19% | 21% |

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.04735049605369568, 'test_f1': 0.9636363636363636, 'test_prec': 0.9724770642201835, 'test_recall': 0.954954954954955, 'labeled_instances': 840, 'train_positive_rate': 0.18333333333333332, 'pool_positive_rate': 0.17910901626881556, 'iteration_time': 380.89155864715576}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.0312981940805912, 'test_f1': 0.9727272727272728, 'test_prec': 0.981651376146789, 'test_recall': 0.963963963963964, 'labeled_instances': 880, 'train_positive_rate': 0.18295454545454545, 'pool_positive_rate': 0.17913415940033656, 'iteration_time': 383.88702297210693}
| ID | GPU | MEM |
------------------
|  0 | 19% | 21% |

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.04322601482272148, 'test_f1': 0.9710982658959538, 'test_prec': 0.997624703087886, 'test_recall': 0.9459459459459459, 'labeled_instances': 920, 'train_positive_rate': 0.18043478260869567, 'pool_positive_rate': 0.17946744651377558, 'iteration_time': 404.69872307777405}
| ID | GPU | MEM |
------------------
|  0 | 19% | 21% |

Test : 960
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.03568674623966217, 'test_f1': 0.9793577981651376, 'test_prec': 0.9976635514018691, 'test_recall': 0.9617117117117117, 'labeled_instances': 960, 'train_positive_rate': 0.17916666666666667, 'pool_positive_rate': 0.17964999225646586, 'iteration_time': 375.68052530288696}
| ID | GPU | MEM |
------------------
|  0 | 19% | 33% |

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.045495957136154175, 'test_f1': 0.9680365296803655, 'test_prec': 0.9814814814814815, 'test_recall': 0.954954954954955, 'labeled_instances': 1000, 'train_positive_rate': 0.183, 'pool_positive_rate': 0.1790556334735858, 'iteration_time': 377.3927092552185}
| ID | GPU | MEM |
------------------
|  0 | 19% | 21% |

Test : 7417
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.014883434399962425, 'test_f1': 0.9909502262443439, 'test_prec': 0.9954545454545455, 'test_recall': 0.9864864864864865, 'labeled_instances': 7417, 'train_positive_rate': 0.17958743427261697, 'pool_positive_rate': 0.17958743427261697, 'iteration_time': 894.5792288780212}
New cross validation 1, for  <function deepmatcher_structured_dblp_acm at 0x1519b4516160>
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 0
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.012485265731811523, 'test_f1': 0.990990990990991, 'test_prec': 0.990990990990991, 'test_recall': 0.990990990990991, 'labeled_instances': 0, 'train_positive_rate': 0.17958743427261697, 'pool_positive_rate': 0.17958743427261697, 'iteration_time': 906.492104768753}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 20
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.5856900811195374, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 20, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.17980262268487224, 'iteration_time': 345.9015049934387}
| ID | GPU | MEM |
------------------
|  0 |  6% | 33% |

Test : 40
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.14577345550060272, 'test_f1': 0.9349503858875412, 'test_prec': 0.9157667386609071, 'test_recall': 0.954954954954955, 'labeled_instances': 40, 'train_positive_rate': 0.225, 'pool_positive_rate': 0.1793411956079707, 'iteration_time': 333.06919264793396}
| ID | GPU | MEM |
------------------
|  0 | 19% | 33% |

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.12145719677209854, 'test_f1': 0.8868312757201646, 'test_prec': 0.8162878787878788, 'test_recall': 0.9707207207207207, 'labeled_instances': 60, 'train_positive_rate': 0.23333333333333334, 'pool_positive_rate': 0.17914910969145031, 'iteration_time': 334.54359579086304}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.14377592504024506, 'test_f1': 0.8877445932028837, 'test_prec': 0.8178368121442126, 'test_recall': 0.9707207207207207, 'labeled_instances': 80, 'train_positive_rate': 0.25, 'pool_positive_rate': 0.17881968106855664, 'iteration_time': 325.668319940567}
| ID | GPU | MEM |
------------------
|  0 | 19% | 21% |

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.11309394985437393, 'test_f1': 0.9030837004405287, 'test_prec': 0.8836206896551724, 'test_recall': 0.9234234234234234, 'labeled_instances': 100, 'train_positive_rate': 0.24, 'pool_positive_rate': 0.17876178761787617, 'iteration_time': 306.57036662101746}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.0866120308637619, 'test_f1': 0.9194414607948442, 'test_prec': 0.8788501026694046, 'test_recall': 0.963963963963964, 'labeled_instances': 120, 'train_positive_rate': 0.225, 'pool_positive_rate': 0.17884061943264354, 'iteration_time': 342.63255500793457}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.04582473635673523, 'test_f1': 0.960272417707151, 'test_prec': 0.9679633867276888, 'test_recall': 0.9527027027027027, 'labeled_instances': 140, 'train_positive_rate': 0.20714285714285716, 'pool_positive_rate': 0.17905730383399754, 'iteration_time': 332.198205947876}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.09457378834486008, 'test_f1': 0.9450056116722784, 'test_prec': 0.941834451901566, 'test_recall': 0.9481981981981982, 'labeled_instances': 160, 'train_positive_rate': 0.20625, 'pool_positive_rate': 0.17899958660603554, 'iteration_time': 327.63617181777954}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.09371311217546463, 'test_f1': 0.9401330376940134, 'test_prec': 0.925764192139738, 'test_recall': 0.954954954954955, 'labeled_instances': 180, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.1790797291695454, 'iteration_time': 337.43386793136597}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 200
-- Random test --

[7156 6644 5326 4857 3611  234 2098  161 7244 3798  691 3390 6299 3680
 6419 4803 5524 1837 6529 4304 3262 6811 1578 6381 6113 2181 2569  984
 4075  847 2229 7066 5887 5938 6615 6251 1592 3272 3402 3504 2411 2575
 5213 7352 3823 6445 4962 4315  444 3631 6142 5429 6115 1945 7036 6682
  103 2610 1518  324 4827  159 4063 1198 1953 5795 5916 3690 4516 3529
 1307 1379 3532 6039 4495 1936 3344 6015  975   99 4913  961 5123 3401
 4598 3112 5310 1406 7376 2262 3957 6826 2966 2093  254 4869 3463 5335
 1216 6131  186 3227 4835 5622 7402 6958 2505 4168 6996 6120 6049 3404
   39 2563 4973  994 7198 7247  442 3945  517 3108 2800 5486 4617 4821
 2588 6721  119 4589 6731 3761 6323 6744 7185 5746 5011 3132 2867 2174
 5077 2963 2134 6195 3304 2615 2860 2606 2031 3659 3801 6074 2706 5389
 2408  714 5497 2868 4510 7180 1851 5150 3085 3949 6694 6843 1253 2619
   74 6756 2919 6265 1331 2479 6233 5319 7259 6061 6954 1504  787 4230
 7163 2885 3998 3669 1206 4292 5090 2076 6810 4784 1947 5482 3336 2772
  599  299 6763 1410]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.09058422595262527, 'test_f1': 0.9492273730684326, 'test_prec': 0.9307359307359307, 'test_recall': 0.9684684684684685, 'labeled_instances': 200, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.1790217541914923, 'iteration_time': 352.60789823532104}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.0669965073466301, 'test_f1': 0.9617117117117117, 'test_prec': 0.9617117117117117, 'test_recall': 0.9617117117117117, 'labeled_instances': 240, 'train_positive_rate': 0.18333333333333332, 'pool_positive_rate': 0.17946217082346383, 'iteration_time': 365.3909010887146}
| ID | GPU | MEM |
------------------
|  0 |  8% | 33% |

Test : 280
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.051069680601358414, 'test_f1': 0.9658965896589659, 'test_prec': 0.9440860215053763, 'test_recall': 0.9887387387387387, 'labeled_instances': 280, 'train_positive_rate': 0.18214285714285713, 'pool_positive_rate': 0.1794871794871795, 'iteration_time': 392.8719289302826}
| ID | GPU | MEM |
------------------
|  0 | 19% | 33% |

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.06671986728906631, 'test_f1': 0.9681818181818181, 'test_prec': 0.9770642201834863, 'test_recall': 0.9594594594594594, 'labeled_instances': 320, 'train_positive_rate': 0.18125, 'pool_positive_rate': 0.17951247005777088, 'iteration_time': 378.88808608055115}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.05113980546593666, 'test_f1': 0.9705882352941176, 'test_prec': 0.975, 'test_recall': 0.9662162162162162, 'labeled_instances': 360, 'train_positive_rate': 0.175, 'pool_positive_rate': 0.1798214538755845, 'iteration_time': 363.3582329750061}
| ID | GPU | MEM |
------------------
|  0 | 19% | 33% |

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.05084633454680443, 'test_f1': 0.9763779527559054, 'test_prec': 0.9752808988764045, 'test_recall': 0.9774774774774775, 'labeled_instances': 400, 'train_positive_rate': 0.1775, 'pool_positive_rate': 0.17970642724811173, 'iteration_time': 371.32239866256714}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.05442800745368004, 'test_f1': 0.9725400457665903, 'test_prec': 0.9883720930232558, 'test_recall': 0.9572072072072072, 'labeled_instances': 440, 'train_positive_rate': 0.17954545454545454, 'pool_positive_rate': 0.17959008169700444, 'iteration_time': 367.80634927749634}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.03765743970870972, 'test_f1': 0.9807909604519773, 'test_prec': 0.9841269841269841, 'test_recall': 0.9774774774774775, 'labeled_instances': 480, 'train_positive_rate': 0.18541666666666667, 'pool_positive_rate': 0.17918408533948393, 'iteration_time': 365.6019902229309}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.05602671951055527, 'test_f1': 0.9634551495016611, 'test_prec': 0.9477124183006536, 'test_recall': 0.9797297297297297, 'labeled_instances': 520, 'train_positive_rate': 0.18653846153846154, 'pool_positive_rate': 0.1790633608815427, 'iteration_time': 396.12239384651184}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.043710969388484955, 'test_f1': 0.9783352337514253, 'test_prec': 0.9907621247113164, 'test_recall': 0.9662162162162162, 'labeled_instances': 560, 'train_positive_rate': 0.19285714285714287, 'pool_positive_rate': 0.17850371882747557, 'iteration_time': 378.2461483478546}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.05327136442065239, 'test_f1': 0.9784335981838819, 'test_prec': 0.9862700228832952, 'test_recall': 0.9707207207207207, 'labeled_instances': 600, 'train_positive_rate': 0.19333333333333333, 'pool_positive_rate': 0.17837758544814433, 'iteration_time': 380.00565361976624}
| ID | GPU | MEM |
------------------
|  0 | 19% | 33% |

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.06775205582380295, 'test_f1': 0.9572254335260116, 'test_prec': 0.9833729216152018, 'test_recall': 0.9324324324324325, 'labeled_instances': 640, 'train_positive_rate': 0.196875, 'pool_positive_rate': 0.17795484727755645, 'iteration_time': 381.3778212070465}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.03181808814406395, 'test_f1': 0.9819819819819819, 'test_prec': 0.9819819819819819, 'test_recall': 0.9819819819819819, 'labeled_instances': 680, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.17752708920884666, 'iteration_time': 376.6661014556885}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.019811520352959633, 'test_f1': 0.9909502262443439, 'test_prec': 0.9954545454545455, 'test_recall': 0.9864864864864865, 'labeled_instances': 720, 'train_positive_rate': 0.20694444444444443, 'pool_positive_rate': 0.1766462595191877, 'iteration_time': 372.911429643631}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.024479087442159653, 'test_f1': 0.987598647125141, 'test_prec': 0.9887133182844243, 'test_recall': 0.9864864864864865, 'labeled_instances': 760, 'train_positive_rate': 0.20789473684210527, 'pool_positive_rate': 0.17635571578789244, 'iteration_time': 386.5805313587189}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.05301397666335106, 'test_f1': 0.9732142857142857, 'test_prec': 0.9646017699115044, 'test_recall': 0.9819819819819819, 'labeled_instances': 800, 'train_positive_rate': 0.20875, 'pool_positive_rate': 0.17606165936224874, 'iteration_time': 371.14391136169434}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.03291698545217514, 'test_f1': 0.9816933638443935, 'test_prec': 0.9976744186046511, 'test_recall': 0.9662162162162162, 'labeled_instances': 840, 'train_positive_rate': 0.2119047619047619, 'pool_positive_rate': 0.17545993614109776, 'iteration_time': 433.4511067867279}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.032809462398290634, 'test_f1': 0.9733924611973392, 'test_prec': 0.9585152838427947, 'test_recall': 0.9887387387387387, 'labeled_instances': 880, 'train_positive_rate': 0.20681818181818182, 'pool_positive_rate': 0.17592167661006577, 'iteration_time': 404.2303276062012}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 920
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.022961661219596863, 'test_f1': 0.9841628959276018, 'test_prec': 0.9886363636363636, 'test_recall': 0.9797297297297297, 'labeled_instances': 920, 'train_positive_rate': 0.20869565217391303, 'pool_positive_rate': 0.175465599507465, 'iteration_time': 401.55461621284485}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.033416613936424255, 'test_f1': 0.976324689966178, 'test_prec': 0.9774266365688488, 'test_recall': 0.9752252252252253, 'labeled_instances': 960, 'train_positive_rate': 0.2125, 'pool_positive_rate': 0.17469413040111506, 'iteration_time': 423.0776753425598}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.027778569608926773, 'test_f1': 0.9852104664391355, 'test_prec': 0.9954022988505747, 'test_recall': 0.9752252252252253, 'labeled_instances': 1000, 'train_positive_rate': 0.207, 'pool_positive_rate': 0.1753155680224404, 'iteration_time': 434.4263036251068}
| ID | GPU | MEM |
------------------
|  0 | 19% | 21% |

Test : 7417
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.010712051764130592, 'test_f1': 0.992108229988726, 'test_prec': 0.9932279909706546, 'test_recall': 0.990990990990991, 'labeled_instances': 7417, 'train_positive_rate': 0.17958743427261697, 'pool_positive_rate': 0.17958743427261697, 'iteration_time': 874.327894449234}
New cross validation 2, for  <function deepmatcher_structured_dblp_acm at 0x1519b4516160>
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 0
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.013217921368777752, 'test_f1': 0.9875706214689265, 'test_prec': 0.9909297052154195, 'test_recall': 0.9842342342342343, 'labeled_instances': 0, 'train_positive_rate': 0.17958743427261697, 'pool_positive_rate': 0.17958743427261697, 'iteration_time': 894.7508454322815}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 20
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3510395288467407, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 20, 'train_positive_rate': 0.25, 'pool_positive_rate': 0.17939705285926727, 'iteration_time': 344.0373387336731}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 40
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.16597497463226318, 'test_f1': 0.7948717948717949, 'test_prec': 0.9226190476190477, 'test_recall': 0.6981981981981982, 'labeled_instances': 40, 'train_positive_rate': 0.25, 'pool_positive_rate': 0.17920563914870544, 'iteration_time': 334.9809832572937}
| ID | GPU | MEM |
------------------
|  0 | 17% | 33% |

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.09983237087726593, 'test_f1': 0.9139072847682119, 'test_prec': 0.8961038961038961, 'test_recall': 0.9324324324324325, 'labeled_instances': 60, 'train_positive_rate': 0.21666666666666667, 'pool_positive_rate': 0.1792850346608672, 'iteration_time': 318.99803495407104}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.09267434477806091, 'test_f1': 0.8984615384615384, 'test_prec': 0.8248587570621468, 'test_recall': 0.9864864864864865, 'labeled_instances': 80, 'train_positive_rate': 0.175, 'pool_positive_rate': 0.1796374540002726, 'iteration_time': 334.18907380104065}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.08782432228326797, 'test_f1': 0.9240506329113924, 'test_prec': 0.8690476190476191, 'test_recall': 0.9864864864864865, 'labeled_instances': 100, 'train_positive_rate': 0.16, 'pool_positive_rate': 0.1798551318846522, 'iteration_time': 335.02575421333313}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.06736587733030319, 'test_f1': 0.9396267837541163, 'test_prec': 0.9164882226980728, 'test_recall': 0.963963963963964, 'labeled_instances': 120, 'train_positive_rate': 0.14166666666666666, 'pool_positive_rate': 0.18021104563519255, 'iteration_time': 336.7785966396332}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.061298251152038574, 'test_f1': 0.947136563876652, 'test_prec': 0.9267241379310345, 'test_recall': 0.9684684684684685, 'labeled_instances': 140, 'train_positive_rate': 0.15, 'pool_positive_rate': 0.1801566579634465, 'iteration_time': 326.57865738868713}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.07380098104476929, 'test_f1': 0.9364908503767493, 'test_prec': 0.8969072164948454, 'test_recall': 0.9797297297297297, 'labeled_instances': 160, 'train_positive_rate': 0.14375, 'pool_positive_rate': 0.18037756648752928, 'iteration_time': 362.6955268383026}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 180
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.09645411372184753, 'test_f1': 0.9428891377379619, 'test_prec': 0.9376391982182628, 'test_recall': 0.9481981981981982, 'labeled_instances': 180, 'train_positive_rate': 0.16111111111111112, 'pool_positive_rate': 0.18004698079314632, 'iteration_time': 347.7884991168976}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 200
-- Random test --

[4595 1345 1344 3449 2614 4882 6971 6418 4065 3691 1400 4569  721 5678
 3358 2937  291 3723 7319 6060 5404 6663  500 3300 1563 5057 6952 7397
 1796 7278 1176 1336 1230 3905 3195 6585 4627 1434 7338  472 2517 6867
 6009 1104 5978 4104 1853 2138   37 5575  202  727 5533 4619 2628 4638
 3628 3267  891 1751 1669   88 6371 4451 7400 6285 5178 7291  128 2510
 5581 1936 4784 1594 1272 2961 5408 6957 2782 4467 1693 1755 4601 3746
 5937  649  793 1804 2805  866 2509  545  564 6480  194 6842 7342 2143
 4393 7159 5636 3339 1678 6350 3601 3488 7097 4538 1182 7108 2530 3500
 6864 3198 2377 2830 1160 6267 7203 4487 6524 2621 5732 2312 6729 3319
 4132 3133 3220 4055 4785 6266  689 4677 5765 3504  877 4749  837 1591
 2217 7329 5825 1812 7024 1932  179  577 1783 2898 1978  130 6613 4929
 3728 5007 5380 1500 6895 5551 5547 5745  288 1475 3029 3084 7124 4029
 7411 6313 5798 4753  595 1019 6270  186 7276 3437 1139 2714 6062 3234
 1409 4653 3049 3705 4256 3503 3225 3826 5929 1067 2612 3845 5536  521
 4308 4434 5350 7395]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.05998942628502846, 'test_f1': 0.955456570155902, 'test_prec': 0.9449339207048458, 'test_recall': 0.9662162162162162, 'labeled_instances': 200, 'train_positive_rate': 0.155, 'pool_positive_rate': 0.18026880975474574, 'iteration_time': 338.9346709251404}
| ID | GPU | MEM |
------------------
|  0 | 19% | 21% |

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.08810048550367355, 'test_f1': 0.9456159822419534, 'test_prec': 0.9321663019693655, 'test_recall': 0.9594594594594594, 'labeled_instances': 240, 'train_positive_rate': 0.1625, 'pool_positive_rate': 0.1801588407412568, 'iteration_time': 341.78813552856445}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.0734419897198677, 'test_f1': 0.9502762430939226, 'test_prec': 0.9327548806941431, 'test_recall': 0.9684684684684685, 'labeled_instances': 280, 'train_positive_rate': 0.15714285714285714, 'pool_positive_rate': 0.18046798374667228, 'iteration_time': 348.19931411743164}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.09616583585739136, 'test_f1': 0.9445676274944567, 'test_prec': 0.9301310043668122, 'test_recall': 0.9594594594594594, 'labeled_instances': 320, 'train_positive_rate': 0.16875, 'pool_positive_rate': 0.18007608848809356, 'iteration_time': 349.1475501060486}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.09253431111574173, 'test_f1': 0.9498327759197325, 'test_prec': 0.9403973509933775, 'test_recall': 0.9594594594594594, 'labeled_instances': 360, 'train_positive_rate': 0.1638888888888889, 'pool_positive_rate': 0.18038826696896698, 'iteration_time': 360.76162123680115}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.08108795434236526, 'test_f1': 0.9551569506726457, 'test_prec': 0.9508928571428571, 'test_recall': 0.9594594594594594, 'labeled_instances': 400, 'train_positive_rate': 0.155, 'pool_positive_rate': 0.18098902664956534, 'iteration_time': 392.58441734313965}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.09061602503061295, 'test_f1': 0.9407744874715264, 'test_prec': 0.9516129032258065, 'test_recall': 0.9301801801801802, 'labeled_instances': 440, 'train_positive_rate': 0.1590909090909091, 'pool_positive_rate': 0.1808800343987387, 'iteration_time': 362.39270401000977}
| ID | GPU | MEM |
------------------
|  0 | 19% | 33% |

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.06740245968103409, 'test_f1': 0.9575892857142857, 'test_prec': 0.9491150442477876, 'test_recall': 0.9662162162162162, 'labeled_instances': 480, 'train_positive_rate': 0.1625, 'pool_positive_rate': 0.18076978520974485, 'iteration_time': 385.5773310661316}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.07779451459646225, 'test_f1': 0.963882618510158, 'test_prec': 0.9660633484162896, 'test_recall': 0.9617117117117117, 'labeled_instances': 520, 'train_positive_rate': 0.16346153846153846, 'pool_positive_rate': 0.18080324778889373, 'iteration_time': 386.2700924873352}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.042604971677064896, 'test_f1': 0.9774266365688488, 'test_prec': 0.9796380090497737, 'test_recall': 0.9752252252252253, 'labeled_instances': 560, 'train_positive_rate': 0.16785714285714284, 'pool_positive_rate': 0.18054542802975063, 'iteration_time': 377.843514919281}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.08388887345790863, 'test_f1': 0.9603624009060023, 'test_prec': 0.9658314350797267, 'test_recall': 0.954954954954955, 'labeled_instances': 600, 'train_positive_rate': 0.16666666666666666, 'pool_positive_rate': 0.18072465894088308, 'iteration_time': 386.33112049102783}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.06367605179548264, 'test_f1': 0.9609810479375697, 'test_prec': 0.9514348785871964, 'test_recall': 0.9707207207207207, 'labeled_instances': 640, 'train_positive_rate': 0.175, 'pool_positive_rate': 0.1800206581083075, 'iteration_time': 379.40511202812195}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 680
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.06439386308193207, 'test_f1': 0.9650507328072153, 'test_prec': 0.9661399548532731, 'test_recall': 0.963963963963964, 'labeled_instances': 680, 'train_positive_rate': 0.175, 'pool_positive_rate': 0.1800504675671664, 'iteration_time': 381.0012059211731}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.06120486184954643, 'test_f1': 0.9627959413754228, 'test_prec': 0.963882618510158, 'test_recall': 0.9617117117117117, 'labeled_instances': 720, 'train_positive_rate': 0.1763888888888889, 'pool_positive_rate': 0.1799313125279976, 'iteration_time': 382.0663857460022}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.034320175647735596, 'test_f1': 0.9707865168539327, 'test_prec': 0.968609865470852, 'test_recall': 0.972972972972973, 'labeled_instances': 760, 'train_positive_rate': 0.1763157894736842, 'pool_positive_rate': 0.17996094336788343, 'iteration_time': 386.9395933151245}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 800
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.03470565378665924, 'test_f1': 0.9752808988764046, 'test_prec': 0.9730941704035875, 'test_recall': 0.9774774774774775, 'labeled_instances': 800, 'train_positive_rate': 0.1775, 'pool_positive_rate': 0.17983980655886353, 'iteration_time': 400.1949555873871}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.02718369849026203, 'test_f1': 0.9753363228699552, 'test_prec': 0.9709821428571429, 'test_recall': 0.9797297297297297, 'labeled_instances': 840, 'train_positive_rate': 0.17261904761904762, 'pool_positive_rate': 0.18047742131670974, 'iteration_time': 405.7478437423706}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.04717905819416046, 'test_f1': 0.9658213891951488, 'test_prec': 0.9460043196544277, 'test_recall': 0.9864864864864865, 'labeled_instances': 880, 'train_positive_rate': 0.17272727272727273, 'pool_positive_rate': 0.18051093773902402, 'iteration_time': 413.2584207057953}
| ID | GPU | MEM |
------------------
|  0 | 19% | 21% |

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.03299012407660484, 'test_f1': 0.9733924611973392, 'test_prec': 0.9585152838427947, 'test_recall': 0.9887387387387387, 'labeled_instances': 920, 'train_positive_rate': 0.16956521739130434, 'pool_positive_rate': 0.18100661843927968, 'iteration_time': 391.5642685890198}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.036270637065172195, 'test_f1': 0.9766925638179801, 'test_prec': 0.962800875273523, 'test_recall': 0.990990990990991, 'labeled_instances': 960, 'train_positive_rate': 0.17291666666666666, 'pool_positive_rate': 0.18057921635434412, 'iteration_time': 418.754727602005}
| ID | GPU | MEM |
------------------
|  0 | 19% | 33% |

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.04707628861069679, 'test_f1': 0.9775280898876404, 'test_prec': 0.9753363228699552, 'test_recall': 0.9797297297297297, 'labeled_instances': 1000, 'train_positive_rate': 0.174, 'pool_positive_rate': 0.18045815801776532, 'iteration_time': 431.0326120853424}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 7417
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.00933360680937767, 'test_f1': 0.9909502262443439, 'test_prec': 0.9954545454545455, 'test_recall': 0.9864864864864865, 'labeled_instances': 7417, 'train_positive_rate': 0.17958743427261697, 'pool_positive_rate': 0.17958743427261697, 'iteration_time': 893.8624804019928}
New cross validation 3, for  <function deepmatcher_structured_dblp_acm at 0x1519b4516160>
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 0
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.011090862564742565, 'test_f1': 0.9909706546275394, 'test_prec': 0.9932126696832579, 'test_recall': 0.9887387387387387, 'labeled_instances': 0, 'train_positive_rate': 0.17958743427261697, 'pool_positive_rate': 0.17958743427261697, 'iteration_time': 914.7102699279785}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 20
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.31436148285865784, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 20, 'train_positive_rate': 0.15, 'pool_positive_rate': 0.17966743274300392, 'iteration_time': 319.10385751724243}
| ID | GPU | MEM |
------------------
|  0 |  0% | 34% |

Test : 40
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.16915825009346008, 'test_f1': 0.7931488801054019, 'test_prec': 0.9555555555555556, 'test_recall': 0.6779279279279279, 'labeled_instances': 40, 'train_positive_rate': 0.125, 'pool_positive_rate': 0.17988342144503186, 'iteration_time': 337.67829990386963}
| ID | GPU | MEM |
------------------
|  0 |  2% | 33% |

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.21430747210979462, 'test_f1': 0.8349999999999999, 'test_prec': 0.9382022471910112, 'test_recall': 0.7522522522522522, 'labeled_instances': 60, 'train_positive_rate': 0.15, 'pool_positive_rate': 0.17982873453853473, 'iteration_time': 340.7919497489929}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.122835673391819, 'test_f1': 0.921875, 'test_prec': 0.9137168141592921, 'test_recall': 0.9301801801801802, 'labeled_instances': 80, 'train_positive_rate': 0.15, 'pool_positive_rate': 0.17991004497751126, 'iteration_time': 332.1396279335022}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.09968848526477814, 'test_f1': 0.9017199017199017, 'test_prec': 0.9918918918918919, 'test_recall': 0.8265765765765766, 'labeled_instances': 100, 'train_positive_rate': 0.13, 'pool_positive_rate': 0.18026513598469318, 'iteration_time': 353.1756603717804}
| ID | GPU | MEM |
------------------
|  0 |  0% | 34% |

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.04291193559765816, 'test_f1': 0.9575892857142857, 'test_prec': 0.9491150442477876, 'test_recall': 0.9662162162162162, 'labeled_instances': 120, 'train_positive_rate': 0.15, 'pool_positive_rate': 0.18007400301493764, 'iteration_time': 356.45496582984924}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.05404555797576904, 'test_f1': 0.9601820250284414, 'test_prec': 0.9701149425287356, 'test_recall': 0.9504504504504504, 'labeled_instances': 140, 'train_positive_rate': 0.17857142857142858, 'pool_positive_rate': 0.179606980898722, 'iteration_time': 361.48781538009644}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.0600387379527092, 'test_f1': 0.9524886877828055, 'test_prec': 0.9568181818181818, 'test_recall': 0.9481981981981982, 'labeled_instances': 160, 'train_positive_rate': 0.175, 'pool_positive_rate': 0.1796885765467824, 'iteration_time': 349.9450047016144}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.09234989434480667, 'test_f1': 0.92534174553102, 'test_prec': 0.8678500986193294, 'test_recall': 0.990990990990991, 'labeled_instances': 180, 'train_positive_rate': 0.18333333333333332, 'pool_positive_rate': 0.17949426557966008, 'iteration_time': 356.3634512424469}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 200
-- Random test --

[5942 2812 5177 4005 1420 4413 2043  591 2664 4505 1465 3368 1036 6138
 2726 1623 5163 1762 1767 4439 3815 3439 4489 3665 1142 3286 5765 7024
 5708 3102 6211 5308 6713 3420 3177 3881 4415 1918 4753 7356 7255 6898
 2639 1583 7157 6167 4166 6333 1621 7070  685 7198 2072 1506 4985 6685
 5207  513 6317 1295 5719 7270 6355 1863 5972 6899   41 4087 5673  445
 4603 4611 2909 5327 3629 3982 4256 4991 7385 7007 5439 1704  404 5752
  213  961 2115 3176 4984  467 2550  371 7118 3148 4153 1686 3267 4424
 5344 5578 7139  290  367 1831 3523 3959 2343 3370 2364 7084 5907 4354
 1125 2519 6864 5843 6066 4075 4368 6973 5833 5275 6769 3987 3691 3546
 6483 4480 2712 1822 7168 3704 2981 2831 5781 4484 1021 5738 5456 6942
 2377 3084 3922 6401 3887 6383 4315 6172 6748 1187 6633 3933 1044 6302
 4689 3736 2902  200 7050 6709 4288 2230 6056 5466 3514 2472  125 4357
 6989 3471 6470  240 3983 2209 2261 6717 2198 5584 6638 1776  850 3536
 5075  281  202  749 3659 5903 3786 4776 3850 1773 4086 6876 5065 4605
 3902 3583 7028 4381]
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.09643226116895676, 'test_f1': 0.9278131634819533, 'test_prec': 0.8775100401606426, 'test_recall': 0.9842342342342343, 'labeled_instances': 200, 'train_positive_rate': 0.175, 'pool_positive_rate': 0.1797145628377442, 'iteration_time': 380.73282742500305}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.06844748556613922, 'test_f1': 0.9473684210526315, 'test_prec': 0.9230769230769231, 'test_recall': 0.972972972972973, 'labeled_instances': 240, 'train_positive_rate': 0.17916666666666667, 'pool_positive_rate': 0.17960150480702244, 'iteration_time': 368.92923283576965}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.08036553114652634, 'test_f1': 0.95, 'test_prec': 0.9180672268907563, 'test_recall': 0.9842342342342343, 'labeled_instances': 280, 'train_positive_rate': 0.16785714285714284, 'pool_positive_rate': 0.1800476390640325, 'iteration_time': 361.4906210899353}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.03837580233812332, 'test_f1': 0.9710467706013363, 'test_prec': 0.960352422907489, 'test_recall': 0.9819819819819819, 'labeled_instances': 320, 'train_positive_rate': 0.171875, 'pool_positive_rate': 0.17993518388051288, 'iteration_time': 376.03882026672363}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.06411822885274887, 'test_f1': 0.9700996677740864, 'test_prec': 0.954248366013072, 'test_recall': 0.9864864864864865, 'labeled_instances': 360, 'train_positive_rate': 0.175, 'pool_positive_rate': 0.1798214538755845, 'iteration_time': 369.0030369758606}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.07155059278011322, 'test_f1': 0.9651293588301463, 'test_prec': 0.9640449438202248, 'test_recall': 0.9662162162162162, 'labeled_instances': 400, 'train_positive_rate': 0.1725, 'pool_positive_rate': 0.17999144933732364, 'iteration_time': 358.26565074920654}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.061191216111183167, 'test_f1': 0.9698996655518396, 'test_prec': 0.9602649006622517, 'test_recall': 0.9797297297297297, 'labeled_instances': 440, 'train_positive_rate': 0.17727272727272728, 'pool_positive_rate': 0.17973340977497493, 'iteration_time': 374.77234077453613}
| ID | GPU | MEM |
------------------
|  0 |  9% | 33% |

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.044586289674043655, 'test_f1': 0.9796839729119639, 'test_prec': 0.9819004524886877, 'test_recall': 0.9774774774774775, 'labeled_instances': 480, 'train_positive_rate': 0.17708333333333334, 'pool_positive_rate': 0.17976070347412426, 'iteration_time': 366.1726233959198}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 520
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.0657866895198822, 'test_f1': 0.9661399548532732, 'test_prec': 0.9683257918552036, 'test_recall': 0.963963963963964, 'labeled_instances': 520, 'train_positive_rate': 0.17692307692307693, 'pool_positive_rate': 0.17978831375960563, 'iteration_time': 389.1998133659363}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 560
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.06688880175352097, 'test_f1': 0.9664429530201343, 'test_prec': 0.96, 'test_recall': 0.972972972972973, 'labeled_instances': 560, 'train_positive_rate': 0.17857142857142858, 'pool_positive_rate': 0.17967040980020418, 'iteration_time': 385.8608605861664}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.05146070942282677, 'test_f1': 0.9660633484162895, 'test_prec': 0.9704545454545455, 'test_recall': 0.9617117117117117, 'labeled_instances': 600, 'train_positive_rate': 0.17833333333333334, 'pool_positive_rate': 0.1796978142878099, 'iteration_time': 380.3886721134186}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.04259498789906502, 'test_f1': 0.9796380090497738, 'test_prec': 0.9840909090909091, 'test_recall': 0.9752252252252253, 'labeled_instances': 640, 'train_positive_rate': 0.184375, 'pool_positive_rate': 0.1791353106094142, 'iteration_time': 402.6821436882019}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.03117259219288826, 'test_f1': 0.9808342728297633, 'test_prec': 0.981941309255079, 'test_recall': 0.9797297297297297, 'labeled_instances': 680, 'train_positive_rate': 0.18088235294117647, 'pool_positive_rate': 0.17945673148285587, 'iteration_time': 401.2201771736145}
| ID | GPU | MEM |
------------------
|  0 | 19% | 21% |

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.041751693934202194, 'test_f1': 0.9807909604519773, 'test_prec': 0.9841269841269841, 'test_recall': 0.9774774774774775, 'labeled_instances': 720, 'train_positive_rate': 0.1763888888888889, 'pool_positive_rate': 0.1799313125279976, 'iteration_time': 405.9097743034363}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.05353406444191933, 'test_f1': 0.9763779527559054, 'test_prec': 0.9752808988764045, 'test_recall': 0.9774774774774775, 'labeled_instances': 760, 'train_positive_rate': 0.175, 'pool_positive_rate': 0.1801111611837164, 'iteration_time': 409.59739780426025}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.0591433085501194, 'test_f1': 0.9718785151856018, 'test_prec': 0.9707865168539326, 'test_recall': 0.972972972972973, 'labeled_instances': 800, 'train_positive_rate': 0.17625, 'pool_positive_rate': 0.17999093244672812, 'iteration_time': 410.18350553512573}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.046273939311504364, 'test_f1': 0.9783845278725825, 'test_prec': 0.9885057471264368, 'test_recall': 0.9684684684684685, 'labeled_instances': 840, 'train_positive_rate': 0.17261904761904762, 'pool_positive_rate': 0.18047742131670974, 'iteration_time': 399.7903711795807}
| ID | GPU | MEM |
------------------
|  0 |  3% | 33% |

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.040902748703956604, 'test_f1': 0.9785794813979707, 'test_prec': 0.9796839729119639, 'test_recall': 0.9774774774774775, 'labeled_instances': 880, 'train_positive_rate': 0.17272727272727273, 'pool_positive_rate': 0.18051093773902402, 'iteration_time': 405.25101041793823}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.04022243246436119, 'test_f1': 0.9819413092550789, 'test_prec': 0.9841628959276018, 'test_recall': 0.9797297297297297, 'labeled_instances': 920, 'train_positive_rate': 0.17282608695652174, 'pool_positive_rate': 0.18054486686162843, 'iteration_time': 420.4306592941284}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.024030523374676704, 'test_f1': 0.9853438556933484, 'test_prec': 0.9864559819413092, 'test_recall': 0.9842342342342343, 'labeled_instances': 960, 'train_positive_rate': 0.171875, 'pool_positive_rate': 0.18073408703732383, 'iteration_time': 416.3989305496216}
| ID | GPU | MEM |
------------------
|  0 | 12% | 21% |

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.04610336571931839, 'test_f1': 0.9706546275395034, 'test_prec': 0.9728506787330317, 'test_recall': 0.9684684684684685, 'labeled_instances': 1000, 'train_positive_rate': 0.175, 'pool_positive_rate': 0.18030232195730092, 'iteration_time': 428.00772619247437}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 7417
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.01966629922389984, 'test_f1': 0.9887133182844244, 'test_prec': 0.9909502262443439, 'test_recall': 0.9864864864864865, 'labeled_instances': 7417, 'train_positive_rate': 0.17958743427261697, 'pool_positive_rate': 0.17958743427261697, 'iteration_time': 867.0505695343018}
New cross validation 4, for  <function deepmatcher_structured_dblp_acm at 0x1519b4516160>
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 0
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.01011141762137413, 'test_f1': 0.9909706546275394, 'test_prec': 0.9932126696832579, 'test_recall': 0.9887387387387387, 'labeled_instances': 0, 'train_positive_rate': 0.17958743427261697, 'pool_positive_rate': 0.17958743427261697, 'iteration_time': 902.113974571228}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 20
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.6683877110481262, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 20, 'train_positive_rate': 0.05, 'pool_positive_rate': 0.17993781262674058, 'iteration_time': 346.8666424751282}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 40
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1270313411951065, 'test_f1': 0.9115341545352743, 'test_prec': 0.9064587973273942, 'test_recall': 0.9166666666666666, 'labeled_instances': 40, 'train_positive_rate': 0.225, 'pool_positive_rate': 0.1793411956079707, 'iteration_time': 356.8483588695526}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.13625560700893402, 'test_f1': 0.9210526315789475, 'test_prec': 0.8974358974358975, 'test_recall': 0.9459459459459459, 'labeled_instances': 60, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.1794209596302841, 'iteration_time': 347.6013271808624}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.08748357743024826, 'test_f1': 0.9096705632306058, 'test_prec': 0.8611670020120724, 'test_recall': 0.963963963963964, 'labeled_instances': 80, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.17936486302303395, 'iteration_time': 349.26102232933044}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 100
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.10228606313467026, 'test_f1': 0.9041713641488163, 'test_prec': 0.9051918735891648, 'test_recall': 0.9031531531531531, 'labeled_instances': 100, 'train_positive_rate': 0.18, 'pool_positive_rate': 0.1795817958179582, 'iteration_time': 360.98592376708984}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.07706572115421295, 'test_f1': 0.9302832244008714, 'test_prec': 0.9008438818565401, 'test_recall': 0.9617117117117117, 'labeled_instances': 120, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.17925174729340826, 'iteration_time': 353.817419052124}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.07578042894601822, 'test_f1': 0.9383783783783786, 'test_prec': 0.9022869022869023, 'test_recall': 0.9774774774774775, 'labeled_instances': 140, 'train_positive_rate': 0.21428571428571427, 'pool_positive_rate': 0.1789198845678164, 'iteration_time': 360.579229593277}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.14865776896476746, 'test_f1': 0.9327548806941433, 'test_prec': 0.899581589958159, 'test_recall': 0.9684684684684685, 'labeled_instances': 160, 'train_positive_rate': 0.21875, 'pool_positive_rate': 0.17872399062973682, 'iteration_time': 369.6394522190094}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.07888560742139816, 'test_f1': 0.9620535714285715, 'test_prec': 0.9535398230088495, 'test_recall': 0.9707207207207207, 'labeled_instances': 180, 'train_positive_rate': 0.2111111111111111, 'pool_positive_rate': 0.17880337156280227, 'iteration_time': 366.5634596347809}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 200
-- Random test --

[2560  807 5587 5997 5450 4323  253 4931 2836 2992 5358 5801 3242 5494
 6836 1800 6761 4752 1624 5620 4173 3930 5770 5470 7310 6720 5614  158
 3895 4548 6598 1867 3210 1152 6328 5393 4449 4309 4280 2783 1329 4539
 2651 3395 7130 4349 1888 1930 2757 4707 5490 1714 5426 4163 1458 1692
 5103 4108 3745  379 3629 7205 5363 5721 1885 5394 4458 6561 7087 2112
  789  352 5307 4478 7158 6426 5644 5060  741  428 5539 2970  374 4495
 3213 2509  528 5135 3485 1838 2715 7199 5272 6975 2243 6236 4035 1940
 6288 2257 4635 1122 2486 2416 7346 3101 2006 1341 2025  196  682 6127
 6977 1399  269 5174 4649 7391 3852 4651 6448 3833 1666 1906 6789 4463
 4811 5752 4227 5531 4823 5296 5253 1579 2820 5232  754 4868  597 6185
 1425 7052 6076 3654 6927 3924 3220 4511 2949 1414 1039 1536 4607 3562
 4250  129 6655 2630 1594 6409 6375 7349  497 4063 5340   20 5905 4212
 4986 6873 5227 2312 2396 5679 6589  165 4765 6021 4480  943 1304 1575
 3855 2016 1301 4741 7324  295  596 4273 1170 6573 2789 6289  702 7225
   11 6818 6824 6013]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.08223243057727814, 'test_f1': 0.9415584415584415, 'test_prec': 0.90625, 'test_recall': 0.9797297297297297, 'labeled_instances': 200, 'train_positive_rate': 0.21, 'pool_positive_rate': 0.17874463073299154, 'iteration_time': 352.5738923549652}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 240
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.09327873587608337, 'test_f1': 0.948051948051948, 'test_prec': 0.9125, 'test_recall': 0.9864864864864865, 'labeled_instances': 240, 'train_positive_rate': 0.20416666666666666, 'pool_positive_rate': 0.1787655009056709, 'iteration_time': 370.17610001564026}
| ID | GPU | MEM |
------------------
|  0 | 19% | 21% |

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.12465733289718628, 'test_f1': 0.9406688241639698, 'test_prec': 0.9026915113871635, 'test_recall': 0.9819819819819819, 'labeled_instances': 280, 'train_positive_rate': 0.20357142857142857, 'pool_positive_rate': 0.17864649012189995, 'iteration_time': 370.3601396083832}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.06049414351582527, 'test_f1': 0.9659863945578231, 'test_prec': 0.9726027397260274, 'test_recall': 0.9594594594594594, 'labeled_instances': 320, 'train_positive_rate': 0.19375, 'pool_positive_rate': 0.17894885162744822, 'iteration_time': 367.604927778244}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.059477031230926514, 'test_f1': 0.9623717217787913, 'test_prec': 0.9745958429561201, 'test_recall': 0.9504504504504504, 'labeled_instances': 360, 'train_positive_rate': 0.19444444444444445, 'pool_positive_rate': 0.17882953096216522, 'iteration_time': 357.83146047592163}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.06406952440738678, 'test_f1': 0.9585666293393057, 'test_prec': 0.9532293986636972, 'test_recall': 0.963963963963964, 'labeled_instances': 400, 'train_positive_rate': 0.1925, 'pool_positive_rate': 0.178851360980476, 'iteration_time': 373.59375977516174}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.04493308067321777, 'test_f1': 0.9771689497716894, 'test_prec': 0.9907407407407407, 'test_recall': 0.963963963963964, 'labeled_instances': 440, 'train_positive_rate': 0.19318181818181818, 'pool_positive_rate': 0.1787301132291816, 'iteration_time': 358.4939315319061}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 480
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.039583802223205566, 'test_f1': 0.976054732041049, 'test_prec': 0.9884526558891455, 'test_recall': 0.963963963963964, 'labeled_instances': 480, 'train_positive_rate': 0.19791666666666666, 'pool_positive_rate': 0.17831915813752341, 'iteration_time': 377.4555757045746}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.04954051971435547, 'test_f1': 0.9644444444444443, 'test_prec': 0.9517543859649122, 'test_recall': 0.9774774774774775, 'labeled_instances': 520, 'train_positive_rate': 0.20384615384615384, 'pool_positive_rate': 0.17775844570102944, 'iteration_time': 403.29713201522827}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.039030227810144424, 'test_f1': 0.9817767653758542, 'test_prec': 0.9930875576036866, 'test_recall': 0.9707207207207207, 'labeled_instances': 560, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.17792037334111127, 'iteration_time': 411.19779562950134}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.03751948103308678, 'test_f1': 0.9764837625979844, 'test_prec': 0.9710467706013363, 'test_recall': 0.9819819819819819, 'labeled_instances': 600, 'train_positive_rate': 0.19833333333333333, 'pool_positive_rate': 0.17793750916825582, 'iteration_time': 446.4619998931885}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.034628044813871384, 'test_f1': 0.9761092150170648, 'test_prec': 0.9862068965517241, 'test_recall': 0.9662162162162162, 'labeled_instances': 640, 'train_positive_rate': 0.190625, 'pool_positive_rate': 0.1785450789434853, 'iteration_time': 395.6353840827942}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.027905279770493507, 'test_f1': 0.9761634506242906, 'test_prec': 0.9839816933638444, 'test_recall': 0.9684684684684685, 'labeled_instances': 680, 'train_positive_rate': 0.18970588235294117, 'pool_positive_rate': 0.17856612735639008, 'iteration_time': 396.9547350406647}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 720
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.04354953020811081, 'test_f1': 0.9784824462061155, 'test_prec': 0.9840546697038725, 'test_recall': 0.972972972972973, 'labeled_instances': 720, 'train_positive_rate': 0.19444444444444445, 'pool_positive_rate': 0.17799014484097356, 'iteration_time': 398.84191036224365}
| ID | GPU | MEM |
------------------
|  0 | 16% | 21% |

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.035122472792863846, 'test_f1': 0.9808342728297633, 'test_prec': 0.981941309255079, 'test_recall': 0.9797297297297297, 'labeled_instances': 760, 'train_positive_rate': 0.19078947368421054, 'pool_positive_rate': 0.1783085473937209, 'iteration_time': 398.49568724632263}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.024041149765253067, 'test_f1': 0.9830124575311437, 'test_prec': 0.9886104783599089, 'test_recall': 0.9774774774774775, 'labeled_instances': 800, 'train_positive_rate': 0.19125, 'pool_positive_rate': 0.17817742179235302, 'iteration_time': 418.2286865711212}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.032923728227615356, 'test_f1': 0.9818594104308391, 'test_prec': 0.9885844748858448, 'test_recall': 0.9752252252252253, 'labeled_instances': 840, 'train_positive_rate': 0.19166666666666668, 'pool_positive_rate': 0.17804470123156454, 'iteration_time': 437.44519901275635}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.046642884612083435, 'test_f1': 0.983050847457627, 'test_prec': 0.9863945578231292, 'test_recall': 0.9797297297297297, 'labeled_instances': 880, 'train_positive_rate': 0.19090909090909092, 'pool_positive_rate': 0.1780633318035796, 'iteration_time': 394.92203760147095}
| ID | GPU | MEM |
------------------
|  0 | 19% | 33% |

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.02071906439960003, 'test_f1': 0.9830890642615557, 'test_prec': 0.9841986455981941, 'test_recall': 0.9819819819819819, 'labeled_instances': 920, 'train_positive_rate': 0.19021739130434784, 'pool_positive_rate': 0.1780821917808219, 'iteration_time': 407.99142503738403}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.03054961934685707, 'test_f1': 0.9783352337514253, 'test_prec': 0.9907621247113164, 'test_recall': 0.9662162162162162, 'labeled_instances': 960, 'train_positive_rate': 0.190625, 'pool_positive_rate': 0.17794641474368902, 'iteration_time': 413.1212182044983}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.029687661677598953, 'test_f1': 0.9852774631936579, 'test_prec': 0.9908883826879271, 'test_recall': 0.9797297297297297, 'labeled_instances': 1000, 'train_positive_rate': 0.191, 'pool_positive_rate': 0.17780894498987065, 'iteration_time': 419.6423854827881}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 7417
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.016049381345510483, 'test_f1': 0.9886621315192743, 'test_prec': 0.9954337899543378, 'test_recall': 0.9819819819819819, 'labeled_instances': 7417, 'train_positive_rate': 0.17958743427261697, 'pool_positive_rate': 0.17958743427261697, 'iteration_time': 923.0400195121765}
Could not create dir out, File exists




    ###########  New Dataset: <function deepmatcher_structured_dblp_google_scholar at 0x1519b45161f0>
New cross validation 0, for  <function deepmatcher_structured_dblp_google_scholar at 0x1519b45161f0>
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 0
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.11055484414100647, 'test_f1': 0.9523368810735771, 'test_prec': 0.9431714023831348, 'test_recall': 0.9616822429906542, 'labeled_instances': 0, 'train_positive_rate': 0.18620449399059397, 'pool_positive_rate': 0.18620449399059397, 'iteration_time': 1678.9669907093048}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 20
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.459258109331131, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 20, 'train_positive_rate': 0.25, 'pool_positive_rate': 0.18613032610591176, 'iteration_time': 434.24914169311523}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 40
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.31579867005348206, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 40, 'train_positive_rate': 0.225, 'pool_positive_rate': 0.18611418262235932, 'iteration_time': 441.62454652786255}
| ID | GPU | MEM |
------------------
|  0 |  0% | 34% |

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.173606738448143, 'test_f1': 0.8546081813701331, 'test_prec': 0.9040667361835245, 'test_recall': 0.8102803738317756, 'labeled_instances': 60, 'train_positive_rate': 0.23333333333333334, 'pool_positive_rate': 0.18603973664277806, 'iteration_time': 457.9652626514435}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2039356529712677, 'test_f1': 0.831518921721099, 'test_prec': 0.9336437718277066, 'test_recall': 0.7495327102803738, 'labeled_instances': 80, 'train_positive_rate': 0.2125, 'pool_positive_rate': 0.18608178265181124, 'iteration_time': 452.2604134082794}
| ID | GPU | MEM |
------------------
|  0 | 13% | 21% |

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.12631553411483765, 'test_f1': 0.9088345864661654, 'test_prec': 0.9139886578449905, 'test_recall': 0.9037383177570093, 'labeled_instances': 100, 'train_positive_rate': 0.19, 'pool_positive_rate': 0.1861823278631081, 'iteration_time': 459.0980181694031}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.15224313735961914, 'test_f1': 0.8758285461776403, 'test_prec': 0.8306789606035205, 'test_recall': 0.9261682242990654, 'labeled_instances': 120, 'train_positive_rate': 0.18333333333333332, 'pool_positive_rate': 0.1862246389522306, 'iteration_time': 431.0889971256256}
| ID | GPU | MEM |
------------------
|  0 |  7% | 21% |

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.11433479189872742, 'test_f1': 0.9190411578471279, 'test_prec': 0.8904469763365469, 'test_recall': 0.9495327102803738, 'labeled_instances': 140, 'train_positive_rate': 0.16428571428571428, 'pool_positive_rate': 0.18638412456828427, 'iteration_time': 437.74956464767456}
| ID | GPU | MEM |
------------------
|  0 | 12% | 34% |

Test : 160
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.18742622435092926, 'test_f1': 0.8620331950207469, 'test_prec': 0.9685314685314685, 'test_recall': 0.7766355140186916, 'labeled_instances': 160, 'train_positive_rate': 0.16875, 'pool_positive_rate': 0.18636816503545683, 'iteration_time': 476.42358136177063}
| ID | GPU | MEM |
------------------
|  0 | 13% | 21% |

Test : 180
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.10966718941926956, 'test_f1': 0.9228624535315985, 'test_prec': 0.9177449168207024, 'test_recall': 0.9280373831775701, 'labeled_instances': 180, 'train_positive_rate': 0.16111111111111112, 'pool_positive_rate': 0.1864695182772986, 'iteration_time': 453.35738801956177}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 200
-- Random test --

[12609 16649 12858 14262 12586  9319  9206  6546  3008 16299 15379 14026
  7750  2280   159 10550  7352 14332  5782  3018 12173  6368 17097  8734
 16913  1298 10870   292  6912 14466 11967  8659 16808 12838   127 10029
 11483  9761 13435    74  6954  2724 16519  4069 10325 14990  8759 11512
  9074  2861 12860 15346  5307 13430  9165  8960 12307  5844   952 14237
 10528  4777 10158 15548   461  5488 10303  2509  5644  5466  5283  8256
  6935  6491 14002  7297  8906  2111  1143  7263  2054  2359  3657  1514
  1785  6784 16891  9432 17141  8518  9002   632 16751  7167  5507  2384
  9459 11589 11358  4908  4749   275 13808 16157  9377   624 15244 12086
 12963 13735  9310   379  3335 13284  5338  3951  8805  1543 13809  1534
  6226  2193  8275 11854  2959  5260  9755  6095  8935 10444  6593   142
  9091  4808   499 11406  7291  5472 15199   772    12  3948  4532  3824
  9505  3260 13806  1328  5813  6710 10082 13894  6597 16677   489  2917
   261  1569  6913  3184 14065  2192  6088   723  4374  9080 16199  6975
 11431  2618 14795  7529 15192 16670 12302 11156  7815  7346  3487 13108
  8735 12749 10760  3641   380 15405 10805 13050 12982 10850  7562  8346
 15766 10610 10288 16661  6977  7939 14200 17036]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.160226970911026, 'test_f1': 0.8929782082324454, 'test_prec': 0.9266331658291457, 'test_recall': 0.8616822429906542, 'labeled_instances': 200, 'train_positive_rate': 0.15, 'pool_positive_rate': 0.1866298537273101, 'iteration_time': 470.2901222705841}
| ID | GPU | MEM |
------------------
|  0 | 13% | 21% |

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.15137417614459991, 'test_f1': 0.8971962616822429, 'test_prec': 0.9470404984423676, 'test_recall': 0.8523364485981308, 'labeled_instances': 240, 'train_positive_rate': 0.15, 'pool_positive_rate': 0.18671612789259848, 'iteration_time': 446.41825890541077}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1512971669435501, 'test_f1': 0.8983543078412392, 'test_prec': 0.9317269076305221, 'test_recall': 0.8672897196261682, 'labeled_instances': 280, 'train_positive_rate': 0.16071428571428573, 'pool_positive_rate': 0.18662574514548783, 'iteration_time': 461.86673188209534}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.20662838220596313, 'test_f1': 0.8925541941564562, 'test_prec': 0.9001901140684411, 'test_recall': 0.8850467289719626, 'labeled_instances': 320, 'train_positive_rate': 0.159375, 'pool_positive_rate': 0.18671241791397977, 'iteration_time': 447.6328275203705}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 360
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.13799571990966797, 'test_f1': 0.9089156626506024, 'test_prec': 0.9383084577114428, 'test_recall': 0.8813084112149533, 'labeled_instances': 360, 'train_positive_rate': 0.18055555555555555, 'pool_positive_rate': 0.18632509043467949, 'iteration_time': 486.59240102767944}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1471582055091858, 'test_f1': 0.9056785370548605, 'test_prec': 0.933531746031746, 'test_recall': 0.8794392523364486, 'labeled_instances': 400, 'train_positive_rate': 0.195, 'pool_positive_rate': 0.1859953634904595, 'iteration_time': 495.73475885391235}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.14150480926036835, 'test_f1': 0.9116809116809117, 'test_prec': 0.9266409266409267, 'test_recall': 0.897196261682243, 'labeled_instances': 440, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.185842817136388, 'iteration_time': 522.3153142929077}
| ID | GPU | MEM |
------------------
|  0 | 12% | 21% |

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.12546662986278534, 'test_f1': 0.9262672811059909, 'test_prec': 0.9136363636363637, 'test_recall': 0.9392523364485982, 'labeled_instances': 480, 'train_positive_rate': 0.20416666666666666, 'pool_positive_rate': 0.18568954189810666, 'iteration_time': 515.9582300186157}
| ID | GPU | MEM |
------------------
|  0 | 12% | 21% |

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.16988563537597656, 'test_f1': 0.9111214518380641, 'test_prec': 0.907321594068582, 'test_recall': 0.9149532710280374, 'labeled_instances': 520, 'train_positive_rate': 0.20384615384615384, 'pool_positive_rate': 0.1856552715081123, 'iteration_time': 505.7399127483368}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.14046689867973328, 'test_f1': 0.9253034547152195, 'test_prec': 0.9244402985074627, 'test_recall': 0.9261682242990654, 'labeled_instances': 560, 'train_positive_rate': 0.1982142857142857, 'pool_positive_rate': 0.18580087619276242, 'iteration_time': 485.5248625278473}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.17510241270065308, 'test_f1': 0.9143380668804397, 'test_prec': 0.8966756513926325, 'test_recall': 0.9327102803738317, 'labeled_instances': 600, 'train_positive_rate': 0.19666666666666666, 'pool_positive_rate': 0.18582686638994164, 'iteration_time': 488.5002646446228}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 640
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.09761402010917664, 'test_f1': 0.9321394910461829, 'test_prec': 0.9401140684410646, 'test_recall': 0.9242990654205607, 'labeled_instances': 640, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.18567207381052886, 'iteration_time': 484.43213510513306}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.13728046417236328, 'test_f1': 0.9310829817158931, 'test_prec': 0.9341486359360301, 'test_recall': 0.9280373831775701, 'labeled_instances': 680, 'train_positive_rate': 0.19852941176470587, 'pool_positive_rate': 0.18569787825666445, 'iteration_time': 541.9224169254303}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.11082781106233597, 'test_f1': 0.935602575896964, 'test_prec': 0.9211956521739131, 'test_recall': 0.9504672897196261, 'labeled_instances': 720, 'train_positive_rate': 0.19166666666666668, 'pool_positive_rate': 0.1859661879658244, 'iteration_time': 502.7940616607666}
| ID | GPU | MEM |
------------------
|  0 | 12% | 21% |

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.12081778794527054, 'test_f1': 0.9375, 'test_prec': 0.9357541899441341, 'test_recall': 0.9392523364485982, 'labeled_instances': 760, 'train_positive_rate': 0.19605263157894737, 'pool_positive_rate': 0.18574986332989127, 'iteration_time': 508.1839129924774}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.12787088751792908, 'test_f1': 0.9271644525881814, 'test_prec': 0.9092542677448338, 'test_recall': 0.9457943925233645, 'labeled_instances': 800, 'train_positive_rate': 0.19375, 'pool_positive_rate': 0.18583693600438408, 'iteration_time': 522.2040610313416}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.13751320540905, 'test_f1': 0.9240384615384615, 'test_prec': 0.9514851485148514, 'test_recall': 0.8981308411214953, 'labeled_instances': 840, 'train_positive_rate': 0.19523809523809524, 'pool_positive_rate': 0.18574131721906856, 'iteration_time': 536.4030532836914}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.11999932676553726, 'test_f1': 0.9288071664309289, 'test_prec': 0.9372026641294006, 'test_recall': 0.9205607476635514, 'labeled_instances': 880, 'train_positive_rate': 0.19204545454545455, 'pool_positive_rate': 0.18588998347916538, 'iteration_time': 529.1058716773987}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.13435903191566467, 'test_f1': 0.9309701492537312, 'test_prec': 0.9292364990689013, 'test_recall': 0.9327102803738317, 'labeled_instances': 920, 'train_positive_rate': 0.18804347826086956, 'pool_positive_rate': 0.1861007176593265, 'iteration_time': 553.5402729511261}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.10291054844856262, 'test_f1': 0.9322671683913453, 'test_prec': 0.9384469696969697, 'test_recall': 0.9261682242990654, 'labeled_instances': 960, 'train_positive_rate': 0.18541666666666667, 'pool_positive_rate': 0.18625099920063948, 'iteration_time': 539.8968834877014}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1223125159740448, 'test_f1': 0.9305816135084428, 'test_prec': 0.9340866290018832, 'test_recall': 0.9271028037383178, 'labeled_instances': 1000, 'train_positive_rate': 0.189, 'pool_positive_rate': 0.18603217653948098, 'iteration_time': 553.4177484512329}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 17223
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.10487513244152069, 'test_f1': 0.9513108614232209, 'test_prec': 0.9530956848030019, 'test_recall': 0.9495327102803738, 'labeled_instances': 17223, 'train_positive_rate': 0.18620449399059397, 'pool_positive_rate': 0.18620449399059397, 'iteration_time': 1779.9980924129486}
New cross validation 1, for  <function deepmatcher_structured_dblp_google_scholar at 0x1519b45161f0>
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 0
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.10904639959335327, 'test_f1': 0.954001839926403, 'test_prec': 0.9393115942028986, 'test_recall': 0.9691588785046729, 'labeled_instances': 0, 'train_positive_rate': 0.18620449399059397, 'pool_positive_rate': 0.18620449399059397, 'iteration_time': 1769.2158663272858}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 20
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3384745419025421, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 20, 'train_positive_rate': 0.4, 'pool_positive_rate': 0.18595593791780504, 'iteration_time': 443.0189878940582}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 40
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.23827657103538513, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 40, 'train_positive_rate': 0.275, 'pool_positive_rate': 0.1859977885119013, 'iteration_time': 437.7763614654541}
| ID | GPU | MEM |
------------------
|  0 | 12% | 21% |

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.18801778554916382, 'test_f1': 0.8568815729309556, 'test_prec': 0.8388540734109221, 'test_recall': 0.8757009345794392, 'labeled_instances': 60, 'train_positive_rate': 0.26666666666666666, 'pool_positive_rate': 0.18592320689856084, 'iteration_time': 429.16044187545776}
| ID | GPU | MEM |
------------------
|  0 |  8% | 21% |

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.15847323834896088, 'test_f1': 0.8766637089618456, 'test_prec': 0.8344594594594594, 'test_recall': 0.9233644859813084, 'labeled_instances': 80, 'train_positive_rate': 0.2375, 'pool_positive_rate': 0.18596511695735868, 'iteration_time': 426.8748981952667}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.09981735050678253, 'test_f1': 0.907563025210084, 'test_prec': 0.8614609571788413, 'test_recall': 0.9588785046728971, 'labeled_instances': 100, 'train_positive_rate': 0.23, 'pool_positive_rate': 0.18594872393856215, 'iteration_time': 467.9390001296997}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.11431394517421722, 'test_f1': 0.9049531459170014, 'test_prec': 0.8659265584970111, 'test_recall': 0.9476635514018692, 'labeled_instances': 120, 'train_positive_rate': 0.23333333333333334, 'pool_positive_rate': 0.18587382330585278, 'iteration_time': 479.77019715309143}
| ID | GPU | MEM |
------------------
|  0 | 13% | 21% |

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.10752586275339127, 'test_f1': 0.9141274238227146, 'test_prec': 0.9032846715328468, 'test_recall': 0.9252336448598131, 'labeled_instances': 140, 'train_positive_rate': 0.21428571428571427, 'pool_positive_rate': 0.18597436047532634, 'iteration_time': 449.08335185050964}
| ID | GPU | MEM |
------------------
|  0 | 12% | 21% |

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1912016123533249, 'test_f1': 0.8793319415448853, 'test_prec': 0.7947169811320755, 'test_recall': 0.9841121495327103, 'labeled_instances': 160, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.18607513332942624, 'iteration_time': 448.61599707603455}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.0949576273560524, 'test_f1': 0.9144361562088635, 'test_prec': 0.8618693134822167, 'test_recall': 0.9738317757009346, 'labeled_instances': 180, 'train_positive_rate': 0.19444444444444445, 'pool_positive_rate': 0.18611746758199849, 'iteration_time': 442.3892295360565}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 200
-- Random test --

[ 9872  7239  6463  9157  9577 16668  6881 12196  8081 12428  1770  5669
 15789 12131 16905  4130  8605  7776  8453  3393 12559 10530 14407 15228
 10737  2521  8572 15902  9391  6485  9705  1818  3489  2377  2273 13687
 16809 13096  4607  3556 13048 11251  8888 15997  6246 15598  8900    22
  4403 14569  2712 16804 13367 14595 15098 10858  8211 10731  9736 12720
 12274 12805  1533 12047  2539 10006 10385 15196  1565 11567 16173  4622
  1297  4770  4424  5201 13619 10648 12678  3049 16095   108  3439 12749
 11245 17207  8426 16756  9748  4170 12071  9777  8214  3069 11464   800
  3860 13808 13281  3894 10021  3964  1148  3780 16335   345  7554 14084
    44  4395  7504 12695 17077  4784 13142 11868  1618  4933  8720 12917
  3169 11724 16584 15373 16257 16048 13157  3931 13246 11591 10137  7293
 12245  8781 12341 14076 15134  3933  9468  3867 16121 11879   110  2940
  3004 14460  4467  2518 17018  6896  3373 12498  5337  5111 16369 16579
   220  5442  7214  3563  4371  3729 16602 11719 12519 15575  8429  8652
  6353 13854  2378 14159  6731 11536 11550  6661  2856   466  9223 11561
  4352  5476 10386  7505 17189  2369  4173 12552  7170  8359  8470  7533
 10128 13439 16931  8743  7274 13600 12101 17043]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.12555868923664093, 'test_f1': 0.9086879432624114, 'test_prec': 0.8642495784148398, 'test_recall': 0.9579439252336449, 'labeled_instances': 200, 'train_positive_rate': 0.18, 'pool_positive_rate': 0.1862773894143218, 'iteration_time': 488.9124822616577}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.11315345019102097, 'test_f1': 0.9264229523368811, 'test_prec': 0.9175068744271311, 'test_recall': 0.9355140186915888, 'labeled_instances': 240, 'train_positive_rate': 0.20833333333333334, 'pool_positive_rate': 0.18589177412706825, 'iteration_time': 457.23890376091003}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.09281386435031891, 'test_f1': 0.9323447636700649, 'test_prec': 0.9246323529411765, 'test_recall': 0.9401869158878504, 'labeled_instances': 280, 'train_positive_rate': 0.21071428571428572, 'pool_positive_rate': 0.18579944519860708, 'iteration_time': 463.3524990081787}
| ID | GPU | MEM |
------------------
|  0 | 12% | 21% |

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1208578497171402, 'test_f1': 0.9229382604776927, 'test_prec': 0.8912097476066144, 'test_recall': 0.9570093457943926, 'labeled_instances': 320, 'train_positive_rate': 0.221875, 'pool_positive_rate': 0.18552919600070994, 'iteration_time': 465.61636114120483}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.11688634008169174, 'test_f1': 0.9225894069714802, 'test_prec': 0.8946444249341527, 'test_recall': 0.9523364485981308, 'labeled_instances': 360, 'train_positive_rate': 0.20833333333333334, 'pool_positive_rate': 0.18573207614303505, 'iteration_time': 448.32561016082764}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.13480138778686523, 'test_f1': 0.9204244031830238, 'test_prec': 0.8733221476510067, 'test_recall': 0.9728971962616823, 'labeled_instances': 400, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.1858764786304464, 'iteration_time': 449.16616916656494}
| ID | GPU | MEM |
------------------
|  0 | 13% | 33% |

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.12049264460802078, 'test_f1': 0.9215048769159313, 'test_prec': 0.9159741458910434, 'test_recall': 0.9271028037383178, 'labeled_instances': 440, 'train_positive_rate': 0.19772727272727272, 'pool_positive_rate': 0.18590240123934934, 'iteration_time': 496.116357088089}
| ID | GPU | MEM |
------------------
|  0 |  1% | 21% |

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1196652203798294, 'test_f1': 0.935862691960253, 'test_prec': 0.9055944055944056, 'test_recall': 0.9682242990654205, 'labeled_instances': 480, 'train_positive_rate': 0.19166666666666668, 'pool_positive_rate': 0.18604790061518248, 'iteration_time': 479.927565574646}
| ID | GPU | MEM |
------------------
|  0 | 13% | 21% |

Test : 520
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.10766244679689407, 'test_f1': 0.928735632183908, 'test_prec': 0.9140271493212669, 'test_recall': 0.9439252336448598, 'labeled_instances': 520, 'train_positive_rate': 0.19038461538461537, 'pool_positive_rate': 0.18607435789977847, 'iteration_time': 485.68876600265503}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.12119295448064804, 'test_f1': 0.926012098650535, 'test_prec': 0.9221501390176089, 'test_recall': 0.9299065420560748, 'labeled_instances': 560, 'train_positive_rate': 0.19285714285714287, 'pool_positive_rate': 0.18598091580147633, 'iteration_time': 475.98767924308777}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.11354544013738632, 'test_f1': 0.9397590361445785, 'test_prec': 0.9319852941176471, 'test_recall': 0.9476635514018692, 'labeled_instances': 600, 'train_positive_rate': 0.19166666666666668, 'pool_positive_rate': 0.1860073392287794, 'iteration_time': 481.7566695213318}
| ID | GPU | MEM |
------------------
|  0 | 13% | 21% |

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.11609693616628647, 'test_f1': 0.932963476652797, 'test_prec': 0.9231473010064044, 'test_recall': 0.9429906542056075, 'labeled_instances': 640, 'train_positive_rate': 0.1859375, 'pool_positive_rate': 0.18621479828740276, 'iteration_time': 483.6336295604706}
| ID | GPU | MEM |
------------------
|  0 | 10% | 21% |

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.12423215806484222, 'test_f1': 0.9337597076290544, 'test_prec': 0.9133154602323503, 'test_recall': 0.9551401869158879, 'labeled_instances': 680, 'train_positive_rate': 0.18235294117647058, 'pool_positive_rate': 0.1863628120655262, 'iteration_time': 484.0594234466553}
| ID | GPU | MEM |
------------------
|  0 | 13% | 33% |

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.11655498296022415, 'test_f1': 0.9319419237749547, 'test_prec': 0.9056437389770723, 'test_recall': 0.9598130841121495, 'labeled_instances': 720, 'train_positive_rate': 0.17916666666666667, 'pool_positive_rate': 0.1865115433557535, 'iteration_time': 483.4005265235901}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1327361762523651, 'test_f1': 0.9261926192619261, 'test_prec': 0.8932291666666666, 'test_recall': 0.9616822429906542, 'labeled_instances': 760, 'train_positive_rate': 0.1868421052631579, 'pool_positive_rate': 0.18617505922371377, 'iteration_time': 517.9683051109314}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.11254458874464035, 'test_f1': 0.9283054003724395, 'test_prec': 0.924860853432282, 'test_recall': 0.9317757009345794, 'labeled_instances': 800, 'train_positive_rate': 0.19, 'pool_positive_rate': 0.18601960664921147, 'iteration_time': 504.8360023498535}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.13325253129005432, 'test_f1': 0.9241050119331742, 'test_prec': 0.944390243902439, 'test_recall': 0.9046728971962616, 'labeled_instances': 840, 'train_positive_rate': 0.19166666666666668, 'pool_positive_rate': 0.1859244338643716, 'iteration_time': 505.0190932750702}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1026901826262474, 'test_f1': 0.9427516158818098, 'test_prec': 0.9315693430656934, 'test_recall': 0.9542056074766355, 'labeled_instances': 880, 'train_positive_rate': 0.19090909090909092, 'pool_positive_rate': 0.18595117175549164, 'iteration_time': 501.88583421707153}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.12764552235603333, 'test_f1': 0.9229314420803783, 'test_prec': 0.9339712918660287, 'test_recall': 0.9121495327102803, 'labeled_instances': 920, 'train_positive_rate': 0.19021739130434784, 'pool_positive_rate': 0.18597804085137704, 'iteration_time': 547.9235887527466}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.13024009764194489, 'test_f1': 0.924618320610687, 'test_prec': 0.9444444444444444, 'test_recall': 0.905607476635514, 'labeled_instances': 960, 'train_positive_rate': 0.19270833333333334, 'pool_positive_rate': 0.18582057430978294, 'iteration_time': 548.4640917778015}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 1000
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.10348866879940033, 'test_f1': 0.9434137291280148, 'test_prec': 0.93646408839779, 'test_recall': 0.9504672897196261, 'labeled_instances': 1000, 'train_positive_rate': 0.191, 'pool_positive_rate': 0.18590889477901745, 'iteration_time': 586.8086643218994}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 17223
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1013503298163414, 'test_f1': 0.9562790697674419, 'test_prec': 0.9518518518518518, 'test_recall': 0.9607476635514018, 'labeled_instances': 17223, 'train_positive_rate': 0.18620449399059397, 'pool_positive_rate': 0.18620449399059397, 'iteration_time': 1803.9430446624756}
New cross validation 2, for  <function deepmatcher_structured_dblp_google_scholar at 0x1519b45161f0>
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 0
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1119566336274147, 'test_f1': 0.9570494864612512, 'test_prec': 0.9561567164179104, 'test_recall': 0.9579439252336449, 'labeled_instances': 0, 'train_positive_rate': 0.18620449399059397, 'pool_positive_rate': 0.18620449399059397, 'iteration_time': 1837.305315732956}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 20
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4523698687553406, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 20, 'train_positive_rate': 0.15, 'pool_positive_rate': 0.1862465848979829, 'iteration_time': 503.3996286392212}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 40
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4988546073436737, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 40, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.18640516789850434, 'iteration_time': 497.38914227485657}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.26091906428337097, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.15, 'pool_positive_rate': 0.18633106100332109, 'iteration_time': 468.81161522865295}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.253461092710495, 'test_f1': 0.7844374342797057, 'test_prec': 0.8966346153846154, 'test_recall': 0.697196261682243, 'labeled_instances': 80, 'train_positive_rate': 0.1375, 'pool_positive_rate': 0.18643177973516886, 'iteration_time': 478.00021719932556}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 100
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.16303396224975586, 'test_f1': 0.8685927306616962, 'test_prec': 0.8661710037174721, 'test_recall': 0.8710280373831776, 'labeled_instances': 100, 'train_positive_rate': 0.16, 'pool_positive_rate': 0.18635753080651754, 'iteration_time': 509.8345606327057}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.12335589528083801, 'test_f1': 0.9074889867841409, 'test_prec': 0.8583333333333333, 'test_recall': 0.9626168224299065, 'labeled_instances': 120, 'train_positive_rate': 0.18333333333333332, 'pool_positive_rate': 0.1862246389522306, 'iteration_time': 511.91719937324524}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.14962707459926605, 'test_f1': 0.8913963328631876, 'test_prec': 0.8968779564806055, 'test_recall': 0.8859813084112149, 'labeled_instances': 140, 'train_positive_rate': 0.17142857142857143, 'pool_positive_rate': 0.18632558684071884, 'iteration_time': 498.219854593277}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.16049914062023163, 'test_f1': 0.9026387625113741, 'test_prec': 0.8794326241134752, 'test_recall': 0.9271028037383178, 'labeled_instances': 160, 'train_positive_rate': 0.1625, 'pool_positive_rate': 0.18642677137666294, 'iteration_time': 497.11997652053833}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.10732727497816086, 'test_f1': 0.903976721629486, 'test_prec': 0.9395161290322581, 'test_recall': 0.8710280373831776, 'labeled_instances': 180, 'train_positive_rate': 0.16666666666666666, 'pool_positive_rate': 0.18641084316141524, 'iteration_time': 504.24755096435547}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 200
-- Random test --

[ 8835  2436  2930  7329 11785  5693  2177 14577  7313  8607  3822  8948
  8953  3118  1082 13886  4172  7097  2652  4053 16171  1334  9078  5833
  3438 10151 14335  4888 13448  5556 10200  3132 16473 13931 15378 12980
 11600 15519 16329  1324  9386  9732 12295 12203 11643  8227  1920   855
 12565 16038 16232  4764 11982 12610  8809 12679 11270  4344  7360 10324
 14018 13372  6814  3628  7135 16638 11538  1656  5824  7051 15310  5382
 12605  7427  2933     4 16970  5640 10123  2887  3180 11291  9958  1253
  6763  6895 17219  6717  1879 11127 10293 14468  6489  1353 14923 12452
 11716  4908 16434  7754 16003  1254  1446  5787 15560 13315  9186 15415
  8548  4230  4226  5973 15041 12206  5157 13161   852  5076 12247   168
 11258  7280 14707 11398 16831  7270 12402 10540  1703 11894  7629 14469
 15090 10176  3948  3748 14053  5158  1749  6046  3298 11904  1164  9517
  2277  6906 13052  2125 11774   489 13546  2688  2095  7250  9354   130
  8623 13718  6022  5564 11500  5791 12529  6248  2112 14262 11996 16655
 11026 15195  9062 10285 11611 12376  7816  1988 14559 12657 12942    71
 10073  6262 14955  7027 14288 10776  8677 15912  8881  8570 12875  1760
 10028    42  8797  9567 11322 14881  1317 10959]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.14210832118988037, 'test_f1': 0.9087359687652513, 'test_prec': 0.95097037793667, 'test_recall': 0.8700934579439252, 'labeled_instances': 200, 'train_positive_rate': 0.175, 'pool_positive_rate': 0.18633613346648653, 'iteration_time': 534.5836365222931}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.13034382462501526, 'test_f1': 0.9228624535315985, 'test_prec': 0.9177449168207024, 'test_recall': 0.9280373831775701, 'labeled_instances': 240, 'train_positive_rate': 0.175, 'pool_positive_rate': 0.18636283342165696, 'iteration_time': 514.4871842861176}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.16599953174591064, 'test_f1': 0.9072527472527472, 'test_prec': 0.8564315352697095, 'test_recall': 0.9644859813084112, 'labeled_instances': 280, 'train_positive_rate': 0.175, 'pool_positive_rate': 0.18638965944637903, 'iteration_time': 524.9385948181152}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.11083409190177917, 'test_f1': 0.9273137697516929, 'test_prec': 0.896943231441048, 'test_recall': 0.9598130841121495, 'labeled_instances': 320, 'train_positive_rate': 0.171875, 'pool_positive_rate': 0.1864757735313258, 'iteration_time': 515.8249890804291}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.11436989158391953, 'test_f1': 0.9266514806378132, 'test_prec': 0.904, 'test_recall': 0.9504672897196261, 'labeled_instances': 360, 'train_positive_rate': 0.16944444444444445, 'pool_positive_rate': 0.18656229615133724, 'iteration_time': 492.57820224761963}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.08895489573478699, 'test_f1': 0.9361502347417839, 'test_prec': 0.940566037735849, 'test_recall': 0.9317757009345794, 'labeled_instances': 400, 'train_positive_rate': 0.17, 'pool_positive_rate': 0.18658978779052487, 'iteration_time': 546.6302785873413}
| ID | GPU | MEM |
------------------
|  0 | 12% | 21% |

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.11553427577018738, 'test_f1': 0.9309417040358744, 'test_prec': 0.8948275862068965, 'test_recall': 0.9700934579439252, 'labeled_instances': 440, 'train_positive_rate': 0.17045454545454544, 'pool_positive_rate': 0.1866174104748853, 'iteration_time': 545.8392286300659}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1286502629518509, 'test_f1': 0.9281234925229138, 'test_prec': 0.959122632103689, 'test_recall': 0.8990654205607477, 'labeled_instances': 480, 'train_positive_rate': 0.17083333333333334, 'pool_positive_rate': 0.18664516514364213, 'iteration_time': 537.4584152698517}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.10986098647117615, 'test_f1': 0.9309534992954438, 'test_prec': 0.9357884796978282, 'test_recall': 0.9261682242990654, 'labeled_instances': 520, 'train_positive_rate': 0.17692307692307693, 'pool_positive_rate': 0.18649344429144465, 'iteration_time': 529.1813402175903}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.10906495898962021, 'test_f1': 0.9338999055712938, 'test_prec': 0.9437022900763359, 'test_recall': 0.9242990654205607, 'labeled_instances': 560, 'train_positive_rate': 0.18035714285714285, 'pool_positive_rate': 0.1864010082218088, 'iteration_time': 543.9429023265839}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1341256946325302, 'test_f1': 0.933454876937101, 'test_prec': 0.9110320284697508, 'test_recall': 0.9570093457943926, 'labeled_instances': 600, 'train_positive_rate': 0.18666666666666668, 'pool_positive_rate': 0.18618781206761717, 'iteration_time': 553.0016939640045}
| ID | GPU | MEM |
------------------
|  0 | 12% | 21% |

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.10524832457304001, 'test_f1': 0.9382600561272217, 'test_prec': 0.9391385767790262, 'test_recall': 0.9373831775700935, 'labeled_instances': 640, 'train_positive_rate': 0.1890625, 'pool_positive_rate': 0.18609419284809744, 'iteration_time': 536.3772709369659}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1147928237915039, 'test_f1': 0.9377593360995851, 'test_prec': 0.9253867151956324, 'test_recall': 0.9504672897196261, 'labeled_instances': 680, 'train_positive_rate': 0.18529411764705883, 'pool_positive_rate': 0.1862419150093695, 'iteration_time': 548.1757292747498}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 720
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.16276724636554718, 'test_f1': 0.9293647267880941, 'test_prec': 0.8856900931414056, 'test_recall': 0.9775700934579439, 'labeled_instances': 720, 'train_positive_rate': 0.18194444444444444, 'pool_positive_rate': 0.18639035326910258, 'iteration_time': 538.1287305355072}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 760
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.10804358124732971, 'test_f1': 0.9271889400921659, 'test_prec': 0.9145454545454546, 'test_recall': 0.9401869158878504, 'labeled_instances': 760, 'train_positive_rate': 0.17763157894736842, 'pool_positive_rate': 0.1866002551175363, 'iteration_time': 604.2345669269562}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.12129416316747665, 'test_f1': 0.9281716417910447, 'test_prec': 0.9264432029795159, 'test_recall': 0.9299065420560748, 'labeled_instances': 800, 'train_positive_rate': 0.1775, 'pool_positive_rate': 0.18662850879863607, 'iteration_time': 579.9817671775818}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1044415682554245, 'test_f1': 0.929224843524314, 'test_prec': 0.958291956305859, 'test_recall': 0.9018691588785047, 'labeled_instances': 840, 'train_positive_rate': 0.17857142857142858, 'pool_positive_rate': 0.18659586156381616, 'iteration_time': 588.7396650314331}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1488742232322693, 'test_f1': 0.9293785310734464, 'test_prec': 0.9364326375711575, 'test_recall': 0.922429906542056, 'labeled_instances': 880, 'train_positive_rate': 0.1806818181818182, 'pool_positive_rate': 0.18650186624242795, 'iteration_time': 564.8622376918793}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.11502712219953537, 'test_f1': 0.9390414146114472, 'test_prec': 0.9351251158480074, 'test_recall': 0.9429906542056075, 'labeled_instances': 920, 'train_positive_rate': 0.18369565217391304, 'pool_positive_rate': 0.18634607127522543, 'iteration_time': 578.3116598129272}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.13830706477165222, 'test_f1': 0.931985294117647, 'test_prec': 0.9168173598553345, 'test_recall': 0.9476635514018692, 'labeled_instances': 960, 'train_positive_rate': 0.1875, 'pool_positive_rate': 0.18612802066039477, 'iteration_time': 560.2623937129974}
| ID | GPU | MEM |
------------------
|  0 | 12% | 21% |

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.11990565806627274, 'test_f1': 0.9403669724770642, 'test_prec': 0.9234234234234234, 'test_recall': 0.9579439252336449, 'labeled_instances': 1000, 'train_positive_rate': 0.185, 'pool_positive_rate': 0.18627874006040807, 'iteration_time': 573.3151206970215}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 17223
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.12072644382715225, 'test_f1': 0.9516279069767443, 'test_prec': 0.9472222222222222, 'test_recall': 0.9560747663551402, 'labeled_instances': 17223, 'train_positive_rate': 0.18620449399059397, 'pool_positive_rate': 0.18620449399059397, 'iteration_time': 1833.6099803447723}
New cross validation 3, for  <function deepmatcher_structured_dblp_google_scholar at 0x1519b45161f0>
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 0
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.10285329818725586, 'test_f1': 0.9569643683479871, 'test_prec': 0.9477543538038496, 'test_recall': 0.9663551401869159, 'labeled_instances': 0, 'train_positive_rate': 0.18620449399059397, 'pool_positive_rate': 0.18620449399059397, 'iteration_time': 1855.2890243530273}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 20
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.5699098706245422, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 20, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.1863047142940185, 'iteration_time': 515.6875596046448}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 40
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2435302734375, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 40, 'train_positive_rate': 0.225, 'pool_positive_rate': 0.18611418262235932, 'iteration_time': 503.4775199890137}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.29178428649902344, 'test_f1': 0.7371975239167134, 'test_prec': 0.9264497878359265, 'test_recall': 0.6121495327102804, 'labeled_instances': 60, 'train_positive_rate': 0.21666666666666667, 'pool_positive_rate': 0.18609800151488667, 'iteration_time': 483.28998851776123}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1697026938199997, 'test_f1': 0.869527524924144, 'test_prec': 0.8108326596604689, 'test_recall': 0.9373831775700935, 'labeled_instances': 80, 'train_positive_rate': 0.225, 'pool_positive_rate': 0.18602344980458496, 'iteration_time': 541.5397381782532}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.12914450466632843, 'test_f1': 0.8982142857142857, 'test_prec': 0.8598290598290599, 'test_recall': 0.9401869158878504, 'labeled_instances': 100, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.18612392688197163, 'iteration_time': 506.2151458263397}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.15711922943592072, 'test_f1': 0.8824330458465728, 'test_prec': 0.8578993821712269, 'test_recall': 0.908411214953271, 'labeled_instances': 120, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.186107700403438, 'iteration_time': 507.2664866447449}
| ID | GPU | MEM |
------------------
|  0 |  8% | 21% |

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.17039327323436737, 'test_f1': 0.8844361602982292, 'test_prec': 0.8819702602230484, 'test_recall': 0.8869158878504673, 'labeled_instances': 140, 'train_positive_rate': 0.19285714285714287, 'pool_positive_rate': 0.1861499736580226, 'iteration_time': 506.56172013282776}
| ID | GPU | MEM |
------------------
|  0 | 12% | 21% |

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.15141062438488007, 'test_f1': 0.8934772407320507, 'test_prec': 0.8972667295004713, 'test_recall': 0.8897196261682243, 'labeled_instances': 160, 'train_positive_rate': 0.19375, 'pool_positive_rate': 0.18613373967063238, 'iteration_time': 505.2347593307495}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.16518840193748474, 'test_f1': 0.9029038112522687, 'test_prec': 0.8774250440917107, 'test_recall': 0.9299065420560748, 'labeled_instances': 180, 'train_positive_rate': 0.19444444444444445, 'pool_positive_rate': 0.18611746758199849, 'iteration_time': 499.1091113090515}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 200
-- Random test --

[14194  7214  1245   795 11431  2117  5739  2764  9744  1373 12337 17153
 16705  3074   771  8558 11124 17180  9203  7893  9184  5356 12185  9871
  8433 14102  3710   473  6618  2127 17197 16671 10508 13224  9294  8439
  1165  4405 14699  2049  2605  9365  6108 12595 12411  9435  1352   849
 11283 12134  3986  5903  5098  5029 15341  6466  5624 15538 13353 15277
 13256 10077  7955 10587  5047  9002 11384 11226  8749  6674  8026  3259
  7192 13759  1968 15244  1524 14320 10593 16044 15227  5844 14179 15191
  1750  5228 15537 14682 10092 13692  9663  3113  9731 13779 16739  4427
   688  2802    49  4847  7913 12488  1854  5424 15156  1665 15289 15722
  5676  2634  4911   574  7201 10446  9380  8552 14862  6166  2296 16484
   676  4660  5832 16257 16826 15132  8370 17220 12853 13877  3403   778
  8885  3301    41 14706 14678 13077  2335  1604 16754  5375 16652  1509
  3258 15333 15469 15576 10371  3344  2400 11687 10693 13045  2916  3194
  7059  8003  4107 14781 14769  8730 14026 10322 11062   538  6774 13074
  7936 15659  1406 11373  1059 10908 16658 12623   607 12560  1409 12326
  1920 10179  7990  5501 16337  7808  4668 10093 15356 11584 10487 14952
  5332  4625  5475  1201 10709 16290  7135 11909]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2332911640405655, 'test_f1': 0.8698817106460419, 'test_prec': 0.8475177304964538, 'test_recall': 0.8934579439252337, 'labeled_instances': 200, 'train_positive_rate': 0.185, 'pool_positive_rate': 0.18621864536215707, 'iteration_time': 544.13467669487}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.16397584974765778, 'test_f1': 0.8951923076923077, 'test_prec': 0.9217821782178218, 'test_recall': 0.8700934579439252, 'labeled_instances': 240, 'train_positive_rate': 0.17083333333333334, 'pool_positive_rate': 0.18642171583348055, 'iteration_time': 531.6095142364502}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.13689030706882477, 'test_f1': 0.9095915557595227, 'test_prec': 0.8935978358881875, 'test_recall': 0.9261682242990654, 'labeled_instances': 280, 'train_positive_rate': 0.16428571428571428, 'pool_positive_rate': 0.18656672372071062, 'iteration_time': 530.0479364395142}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.15296731889247894, 'test_f1': 0.9083371718102257, 'test_prec': 0.8955495004541326, 'test_recall': 0.9214953271028037, 'labeled_instances': 320, 'train_positive_rate': 0.184375, 'pool_positive_rate': 0.18623912914867183, 'iteration_time': 527.2505853176117}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.17801369726657867, 'test_f1': 0.9099735216240071, 'test_prec': 0.8620401337792643, 'test_recall': 0.9635514018691589, 'labeled_instances': 360, 'train_positive_rate': 0.18055555555555555, 'pool_positive_rate': 0.18632509043467949, 'iteration_time': 506.1237139701843}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.14303049445152283, 'test_f1': 0.9178966789667896, 'test_prec': 0.9061930783242259, 'test_recall': 0.9299065420560748, 'labeled_instances': 400, 'train_positive_rate': 0.18, 'pool_positive_rate': 0.18635201807049873, 'iteration_time': 556.0453732013702}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 440
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.13191784918308258, 'test_f1': 0.9227889564810482, 'test_prec': 0.9240862230552952, 'test_recall': 0.9214953271028037, 'labeled_instances': 440, 'train_positive_rate': 0.18863636363636363, 'pool_positive_rate': 0.18614073765119465, 'iteration_time': 566.7724010944366}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1532488763332367, 'test_f1': 0.9160373167481118, 'test_prec': 0.8729889923793396, 'test_recall': 0.9635514018691589, 'labeled_instances': 480, 'train_positive_rate': 0.19375, 'pool_positive_rate': 0.1859881741623365, 'iteration_time': 562.6054563522339}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.13651427626609802, 'test_f1': 0.9096686336813437, 'test_prec': 0.884377758164166, 'test_recall': 0.9364485981308411, 'labeled_instances': 520, 'train_positive_rate': 0.19807692307692307, 'pool_positive_rate': 0.18583487996168352, 'iteration_time': 559.3983950614929}
| ID | GPU | MEM |
------------------
|  0 | 12% | 21% |

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1488822102546692, 'test_f1': 0.9219666215606676, 'test_prec': 0.8910200523103748, 'test_recall': 0.9551401869158879, 'labeled_instances': 560, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.18574086298985776, 'iteration_time': 534.7076587677002}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1467021256685257, 'test_f1': 0.9203222918531782, 'test_prec': 0.8831615120274914, 'test_recall': 0.9607476635514018, 'labeled_instances': 600, 'train_positive_rate': 0.19833333333333333, 'pool_positive_rate': 0.18576670877699572, 'iteration_time': 560.5247523784637}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.12222608178853989, 'test_f1': 0.9256047466910087, 'test_prec': 0.9045495093666369, 'test_recall': 0.9476635514018692, 'labeled_instances': 640, 'train_positive_rate': 0.19375, 'pool_positive_rate': 0.18591328468913948, 'iteration_time': 556.4704797267914}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.16343900561332703, 'test_f1': 0.9160777385159011, 'test_prec': 0.8685092127303182, 'test_recall': 0.9691588785046729, 'labeled_instances': 680, 'train_positive_rate': 0.19705882352941176, 'pool_positive_rate': 0.1857583267847428, 'iteration_time': 549.2767987251282}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.15258051455020905, 'test_f1': 0.928772258669166, 'test_prec': 0.931390977443609, 'test_recall': 0.9261682242990654, 'labeled_instances': 720, 'train_positive_rate': 0.19305555555555556, 'pool_positive_rate': 0.18590559292249895, 'iteration_time': 564.3104739189148}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.13021615147590637, 'test_f1': 0.9253055681303757, 'test_prec': 0.897278314310799, 'test_recall': 0.9551401869158879, 'labeled_instances': 760, 'train_positive_rate': 0.19078947368421054, 'pool_positive_rate': 0.18599283241207556, 'iteration_time': 564.0092284679413}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.14118924736976624, 'test_f1': 0.9198423127463864, 'test_prec': 0.8656224237427865, 'test_recall': 0.9813084112149533, 'labeled_instances': 800, 'train_positive_rate': 0.19, 'pool_positive_rate': 0.18601960664921147, 'iteration_time': 533.2340993881226}
| ID | GPU | MEM |
------------------
|  0 | 13% | 33% |

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.11398352682590485, 'test_f1': 0.9282075034738305, 'test_prec': 0.9201101928374655, 'test_recall': 0.9364485981308411, 'labeled_instances': 840, 'train_positive_rate': 0.19523809523809524, 'pool_positive_rate': 0.18574131721906856, 'iteration_time': 608.3185119628906}
| ID | GPU | MEM |
------------------
|  0 | 10% | 21% |

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1295308917760849, 'test_f1': 0.9300797747536368, 'test_prec': 0.9340245051837889, 'test_recall': 0.9261682242990654, 'labeled_instances': 880, 'train_positive_rate': 0.19545454545454546, 'pool_positive_rate': 0.1857064186501866, 'iteration_time': 576.3172223567963}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1216602474451065, 'test_f1': 0.9330922242314648, 'test_prec': 0.9036777583187391, 'test_recall': 0.9644859813084112, 'labeled_instances': 920, 'train_positive_rate': 0.1956521739130435, 'pool_positive_rate': 0.1856713488315034, 'iteration_time': 602.2336921691895}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 960
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.10213739424943924, 'test_f1': 0.9337717238139972, 'test_prec': 0.9386213408876298, 'test_recall': 0.9289719626168225, 'labeled_instances': 960, 'train_positive_rate': 0.19479166666666667, 'pool_positive_rate': 0.1856975957695382, 'iteration_time': 581.8239259719849}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.11226873099803925, 'test_f1': 0.9377593360995851, 'test_prec': 0.9253867151956324, 'test_recall': 0.9504672897196261, 'labeled_instances': 1000, 'train_positive_rate': 0.196, 'pool_positive_rate': 0.1856006903778586, 'iteration_time': 599.2095789909363}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 17223
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.09729265421628952, 'test_f1': 0.961591855622397, 'test_prec': 0.9523373052245646, 'test_recall': 0.9710280373831776, 'labeled_instances': 17223, 'train_positive_rate': 0.18620449399059397, 'pool_positive_rate': 0.18620449399059397, 'iteration_time': 1824.961903333664}
New cross validation 4, for  <function deepmatcher_structured_dblp_google_scholar at 0x1519b45161f0>
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 0
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.11539900302886963, 'test_f1': 0.953219082908754, 'test_prec': 0.9449035812672176, 'test_recall': 0.9616822429906542, 'labeled_instances': 0, 'train_positive_rate': 0.18620449399059397, 'pool_positive_rate': 0.18620449399059397, 'iteration_time': 1856.2793552875519}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 20
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4515560269355774, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 20, 'train_positive_rate': 0.15, 'pool_positive_rate': 0.1862465848979829, 'iteration_time': 519.149240732193}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 40
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2955566346645355, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 40, 'train_positive_rate': 0.175, 'pool_positive_rate': 0.18623057673281732, 'iteration_time': 503.30645775794983}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.21548403799533844, 'test_f1': 0.7616998386229156, 'test_prec': 0.8973384030418251, 'test_recall': 0.6616822429906543, 'labeled_instances': 60, 'train_positive_rate': 0.18333333333333332, 'pool_positive_rate': 0.1862145312591039, 'iteration_time': 486.3661699295044}
| ID | GPU | MEM |
------------------
|  0 | 11% | 33% |

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2537285089492798, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 80, 'train_positive_rate': 0.1875, 'pool_positive_rate': 0.18619844834626378, 'iteration_time': 544.7996275424957}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.18041643500328064, 'test_f1': 0.868131868131868, 'test_prec': 0.8509874326750448, 'test_recall': 0.8859813084112149, 'labeled_instances': 100, 'train_positive_rate': 0.17, 'pool_positive_rate': 0.18629912982538108, 'iteration_time': 531.6757338047028}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.17820970714092255, 'test_f1': 0.8673376029277218, 'test_prec': 0.8494623655913979, 'test_recall': 0.8859813084112149, 'labeled_instances': 120, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.186107700403438, 'iteration_time': 521.1109704971313}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.12705384194850922, 'test_f1': 0.9055404178019982, 'test_prec': 0.8807420494699647, 'test_recall': 0.9317757009345794, 'labeled_instances': 140, 'train_positive_rate': 0.21428571428571427, 'pool_positive_rate': 0.18597436047532634, 'iteration_time': 495.94287037849426}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.15244928002357483, 'test_f1': 0.9048034934497816, 'test_prec': 0.8491803278688524, 'test_recall': 0.9682242990654205, 'labeled_instances': 160, 'train_positive_rate': 0.21875, 'pool_positive_rate': 0.1858993143058079, 'iteration_time': 502.9282953739166}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.11897020787000656, 'test_f1': 0.9206773618538324, 'test_prec': 0.8798977853492334, 'test_recall': 0.9654205607476636, 'labeled_instances': 180, 'train_positive_rate': 0.21666666666666667, 'pool_positive_rate': 0.18588276711846505, 'iteration_time': 497.1074888706207}
| ID | GPU | MEM |
------------------
|  0 |  0% | 34% |

Test : 200
-- Random test --

[ 5585  1166  1404   702 12439 17134 12135 10956  6083  4743 10697 16622
  5914  7448  5187  2367  8874  8057  4517 17011 14637  6307  4215  5673
 13018  3394 16687  7662 15077   841 15940  7896  1854 15014 16507   629
  5993  6517  1348 11259 12136  7687 10421  3997 12010  1755  3934 10602
 11429  5298 11920  6360  5964 15272  9326  2943  9425  3024  6481  8274
  2444  7547   968  9184  7040  4324 12328  5106   284  3319  5771  7055
  6196 13485 11460 13529   535  1862 14383 15959  9773 10324   414   920
  1206 12933  5723  8320 13790  2119 10717 16545  1800  7019 14067 13684
  9065 15364 14918   714   208  9606  3019  2886 15990  4589  2960  7769
  7173  3070 14828 11981  9917 15558 10858 16199  2667 15871  4059  4005
 16809  2919 10508  6429 15672 14903  2192  7350  1129  9196  6789  4327
 15428  9559  5031 11642  2769   801  3444  3496  6119 10244  1897  9155
  2225 10987 16631  7162  5509  9251  1546  4412 13551 12550  9629  9154
 13977  2614 14573 15876  6790  9589  8324 12914  4723 10454 15266 13652
  8527 10230  9710  4748  1146  3457  5622 14446  3465  2427  2518  2568
 16473  2118 17181   459  2168  7471  2661  2056 10047  2226  1858  7970
 17065  8024 10878   913  4906  6961 12191 14397]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1107870563864708, 'test_f1': 0.9107385591300409, 'test_prec': 0.8839050131926122, 'test_recall': 0.9392523364485982, 'labeled_instances': 200, 'train_positive_rate': 0.22, 'pool_positive_rate': 0.18580743699700406, 'iteration_time': 544.3949637413025}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.10309118777513504, 'test_f1': 0.9256572982774253, 'test_prec': 0.8987676056338029, 'test_recall': 0.9542056074766355, 'labeled_instances': 240, 'train_positive_rate': 0.22083333333333333, 'pool_positive_rate': 0.18571512689159747, 'iteration_time': 521.1719129085541}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 280
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.10233872383832932, 'test_f1': 0.9201277955271566, 'test_prec': 0.8991971454058876, 'test_recall': 0.9420560747663551, 'labeled_instances': 280, 'train_positive_rate': 0.20714285714285716, 'pool_positive_rate': 0.1858584666233843, 'iteration_time': 518.3611488342285}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.14640764892101288, 'test_f1': 0.9125780553077609, 'test_prec': 0.8728668941979523, 'test_recall': 0.9560747663551402, 'labeled_instances': 320, 'train_positive_rate': 0.196875, 'pool_positive_rate': 0.18600248476601786, 'iteration_time': 515.344509601593}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.11904151737689972, 'test_f1': 0.9164086687306501, 'test_prec': 0.869857262804366, 'test_recall': 0.9682242990654205, 'labeled_instances': 360, 'train_positive_rate': 0.19444444444444445, 'pool_positive_rate': 0.18602858328885727, 'iteration_time': 527.6795227527618}
| ID | GPU | MEM |
------------------
|  0 |  0% | 34% |

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1469699740409851, 'test_f1': 0.9154051647373108, 'test_prec': 0.8741496598639455, 'test_recall': 0.9607476635514018, 'labeled_instances': 400, 'train_positive_rate': 0.1825, 'pool_positive_rate': 0.18629257564049218, 'iteration_time': 563.3822674751282}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 440
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.11605167388916016, 'test_f1': 0.929539295392954, 'test_prec': 0.8994755244755245, 'test_recall': 0.9616822429906542, 'labeled_instances': 440, 'train_positive_rate': 0.18181818181818182, 'pool_positive_rate': 0.18631948996007866, 'iteration_time': 588.5024337768555}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.11291610449552536, 'test_f1': 0.9287671232876712, 'test_prec': 0.9080357142857143, 'test_recall': 0.9504672897196261, 'labeled_instances': 480, 'train_positive_rate': 0.18125, 'pool_positive_rate': 0.1863465328794123, 'iteration_time': 566.9271275997162}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 520
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.14511911571025848, 'test_f1': 0.9292833412434741, 'test_prec': 0.944069431051109, 'test_recall': 0.9149532710280374, 'labeled_instances': 520, 'train_positive_rate': 0.175, 'pool_positive_rate': 0.1865533137759684, 'iteration_time': 545.7806134223938}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.11866014450788498, 'test_f1': 0.9257722452743199, 'test_prec': 0.913557779799818, 'test_recall': 0.9383177570093458, 'labeled_instances': 560, 'train_positive_rate': 0.18035714285714285, 'pool_positive_rate': 0.1864010082218088, 'iteration_time': 553.9400730133057}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1302512139081955, 'test_f1': 0.9274156264447527, 'test_prec': 0.9176578225068619, 'test_recall': 0.9373831775700935, 'labeled_instances': 600, 'train_positive_rate': 0.17833333333333334, 'pool_positive_rate': 0.18648860013234675, 'iteration_time': 545.0305187702179}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1012452095746994, 'test_f1': 0.9371271225332722, 'test_prec': 0.9206492335437331, 'test_recall': 0.9542056074766355, 'labeled_instances': 640, 'train_positive_rate': 0.184375, 'pool_positive_rate': 0.1862751010070554, 'iteration_time': 536.470132112503}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.11132083088159561, 'test_f1': 0.9336405529953917, 'test_prec': 0.9209090909090909, 'test_recall': 0.9467289719626168, 'labeled_instances': 680, 'train_positive_rate': 0.18235294117647058, 'pool_positive_rate': 0.1863628120655262, 'iteration_time': 578.156845331192}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1185009777545929, 'test_f1': 0.9265799256505577, 'test_prec': 0.9214417744916821, 'test_recall': 0.9317757009345794, 'labeled_instances': 720, 'train_positive_rate': 0.18333333333333332, 'pool_positive_rate': 0.18632975822577713, 'iteration_time': 570.5715885162354}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.12909793853759766, 'test_f1': 0.9289967934035731, 'test_prec': 0.9110512129380054, 'test_recall': 0.9476635514018692, 'labeled_instances': 760, 'train_positive_rate': 0.18157894736842106, 'pool_positive_rate': 0.18641802830589807, 'iteration_time': 576.9191734790802}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1166120171546936, 'test_f1': 0.9327651515151516, 'test_prec': 0.9452975047984645, 'test_recall': 0.9205607476635514, 'labeled_instances': 800, 'train_positive_rate': 0.17875, 'pool_positive_rate': 0.1865676185836936, 'iteration_time': 550.4183349609375}
| ID | GPU | MEM |
------------------
|  0 | 13% | 21% |

Test : 840
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.12363702803850174, 'test_f1': 0.9359513791491351, 'test_prec': 0.9363891487371375, 'test_recall': 0.9355140186915888, 'labeled_instances': 840, 'train_positive_rate': 0.1773809523809524, 'pool_positive_rate': 0.18665690044558383, 'iteration_time': 586.7950944900513}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.13602465391159058, 'test_f1': 0.9339491916859123, 'test_prec': 0.9232876712328767, 'test_recall': 0.9448598130841122, 'labeled_instances': 880, 'train_positive_rate': 0.18295454545454545, 'pool_positive_rate': 0.18637948968977544, 'iteration_time': 585.440309047699}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.13197718560695648, 'test_f1': 0.9309865678554886, 'test_prec': 0.9228650137741047, 'test_recall': 0.9392523364485982, 'labeled_instances': 920, 'train_positive_rate': 0.1858695652173913, 'pool_positive_rate': 0.18622339446727595, 'iteration_time': 588.4407212734222}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.10164013504981995, 'test_f1': 0.9322519083969465, 'test_prec': 0.9522417153996101, 'test_recall': 0.9130841121495327, 'labeled_instances': 960, 'train_positive_rate': 0.18333333333333332, 'pool_positive_rate': 0.1863739777408842, 'iteration_time': 587.4134967327118}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.11258456856012344, 'test_f1': 0.9365225390984362, 'test_prec': 0.9221014492753623, 'test_recall': 0.9514018691588785, 'labeled_instances': 1000, 'train_positive_rate': 0.189, 'pool_positive_rate': 0.18603217653948098, 'iteration_time': 593.8237085342407}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 17223
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.09940437227487564, 'test_f1': 0.9578117756142792, 'test_prec': 0.9503219871205152, 'test_recall': 0.9654205607476636, 'labeled_instances': 17223, 'train_positive_rate': 0.18620449399059397, 'pool_positive_rate': 0.18620449399059397, 'iteration_time': 1852.8358981609344}
Could not create dir out, File exists




    ###########  New Dataset: <function deepmatcher_structured_walmart_amazon at 0x1519b4516310>
New cross validation 0, for  <function deepmatcher_structured_walmart_amazon at 0x1519b4516310>
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 0
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.14324384927749634, 'test_f1': 0.8743455497382199, 'test_prec': 0.8835978835978836, 'test_recall': 0.8652849740932642, 'labeled_instances': 0, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.09375, 'iteration_time': 879.3695139884949}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 20
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.30704253911972046, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 20, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.09372958850424559, 'iteration_time': 407.0244109630585}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 40
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.32472509145736694, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 40, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.09370904325032765, 'iteration_time': 400.07573556900024}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.34298545122146606, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.06666666666666667, 'pool_positive_rate': 0.09401709401709402, 'iteration_time': 429.454154253006}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3335179090499878, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 80, 'train_positive_rate': 0.0875, 'pool_positive_rate': 0.09383245382585752, 'iteration_time': 429.5283064842224}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.31210988759994507, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 100, 'train_positive_rate': 0.08, 'pool_positive_rate': 0.09397749834546658, 'iteration_time': 423.4487314224243}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.28440210223197937, 'test_f1': 0.4154929577464788, 'test_prec': 0.6483516483516484, 'test_recall': 0.30569948186528495, 'labeled_instances': 120, 'train_positive_rate': 0.09166666666666666, 'pool_positive_rate': 0.09379150066401062, 'iteration_time': 410.81175327301025}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2903045117855072, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 140, 'train_positive_rate': 0.07857142857142857, 'pool_positive_rate': 0.0941039307128581, 'iteration_time': 429.5209858417511}
| ID | GPU | MEM |
------------------
|  0 |  1% | 33% |

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.30976784229278564, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 160, 'train_positive_rate': 0.075, 'pool_positive_rate': 0.09425133689839572, 'iteration_time': 454.01965379714966}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.29887282848358154, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 180, 'train_positive_rate': 0.07222222222222222, 'pool_positive_rate': 0.09439973172367538, 'iteration_time': 427.3750762939453}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 200
-- Random test --

[3464 4138 1540 5586 1593  878 2066 2378 4855 2943 1934 1156 4062 3007
 5869 5205 2152  247 5466  443 4584 2212 5685 4521 1180 3030 4200 5354
 3761 1051 5947 4117 4048 1940 5892 2106 4070  134 6102 6065  462 5561
 1362 2819  472 4889 6060 5401 1691 3067 1597 4810  214 2265 1642 3428
 2500 1465 1867 5463  938 1369 3723 4823 3040 2936 1314 2210 4175  519
   12  257  735 5975 2147   14 4319 1096  532 1142 2752  620  776 4556
 4234 3930 5542 4486 5884 5830 4509 5929 4053  202 2373 5651 5087 2379
  124 1139 1008 1513 5440 4179 5728 2657 3582  683  311 6038 3755 1035
 2653 5122  143 1840  843 5701 4434 2984  170  144 1772 5934 2747 1161
  842 4538 4456 3731 5735  263 1675  979 4700 2232 2266  641 2100  499
 1427 4788 3885 4084 2369 4101 2590 4292 1654 6079 4877 5536 4513 1837
 2920 4507 3843  287 1644 5423 4281 2262 2260 2588 4382 4973 4551 2806
 4570 1817 3343 5386 4188 5171 3431 3864 5948 2118 1083  768 4927 5013
 1343 4218 1606 2784 3141 4395 4311 2846 5498 5250 2537 1590  130 1752
 2579 2753 3473 5079]
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3610047399997711, 'test_f1': 0.32824427480916024, 'test_prec': 0.6231884057971014, 'test_recall': 0.22279792746113988, 'labeled_instances': 200, 'train_positive_rate': 0.075, 'pool_positive_rate': 0.09438088829071332, 'iteration_time': 441.54217433929443}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3281995952129364, 'test_f1': 0.5080385852090031, 'test_prec': 0.6694915254237288, 'test_recall': 0.40932642487046633, 'labeled_instances': 240, 'train_positive_rate': 0.07916666666666666, 'pool_positive_rate': 0.09434281842818429, 'iteration_time': 423.58596658706665}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 280
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3389962613582611, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 280, 'train_positive_rate': 0.07142857142857142, 'pool_positive_rate': 0.09481582537517053, 'iteration_time': 418.38304829597473}
| ID | GPU | MEM |
------------------
|  0 |  0% | 22% |

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2849079668521881, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 320, 'train_positive_rate': 0.065625, 'pool_positive_rate': 0.09529532967032966, 'iteration_time': 411.86161065101624}
| ID | GPU | MEM |
------------------
|  0 | 10% | 33% |

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.23004195094108582, 'test_f1': 0.6402439024390244, 'test_prec': 0.7777777777777778, 'test_recall': 0.5440414507772021, 'labeled_instances': 360, 'train_positive_rate': 0.075, 'pool_positive_rate': 0.09491701244813278, 'iteration_time': 425.41980934143066}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3342753052711487, 'test_f1': 0.5435540069686412, 'test_prec': 0.8297872340425532, 'test_recall': 0.40414507772020725, 'labeled_instances': 400, 'train_positive_rate': 0.075, 'pool_positive_rate': 0.09505571030640668, 'iteration_time': 451.0255253314972}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.27158254384994507, 'test_f1': 0.6369047619047619, 'test_prec': 0.7482517482517482, 'test_recall': 0.5544041450777202, 'labeled_instances': 440, 'train_positive_rate': 0.07727272727272727, 'pool_positive_rate': 0.0950210378681627, 'iteration_time': 433.55426836013794}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.18839752674102783, 'test_f1': 0.6770833333333335, 'test_prec': 0.680628272251309, 'test_recall': 0.6735751295336787, 'labeled_instances': 480, 'train_positive_rate': 0.07916666666666666, 'pool_positive_rate': 0.0949858757062147, 'iteration_time': 454.80256390571594}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.23435594141483307, 'test_f1': 0.696103896103896, 'test_prec': 0.6979166666666666, 'test_recall': 0.694300518134715, 'labeled_instances': 520, 'train_positive_rate': 0.08269230769230769, 'pool_positive_rate': 0.0947724039829303, 'iteration_time': 453.41025733947754}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 560
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3280205726623535, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 560, 'train_positive_rate': 0.07857142857142857, 'pool_positive_rate': 0.09527220630372493, 'iteration_time': 461.92147421836853}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 600
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.24131719768047333, 'test_f1': 0.6447761194029851, 'test_prec': 0.7605633802816901, 'test_recall': 0.5595854922279793, 'labeled_instances': 600, 'train_positive_rate': 0.07833333333333334, 'pool_positive_rate': 0.09541847041847042, 'iteration_time': 459.61702251434326}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3169540464878082, 'test_f1': 0.6114649681528662, 'test_prec': 0.7933884297520661, 'test_recall': 0.49740932642487046, 'labeled_instances': 640, 'train_positive_rate': 0.0828125, 'pool_positive_rate': 0.0950218023255814, 'iteration_time': 465.4315369129181}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 680
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.22823786735534668, 'test_f1': 0.6815642458100559, 'test_prec': 0.7393939393939394, 'test_recall': 0.6321243523316062, 'labeled_instances': 680, 'train_positive_rate': 0.08235294117647059, 'pool_positive_rate': 0.0951683748169839, 'iteration_time': 462.5681166648865}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.20219354331493378, 'test_f1': 0.6852367688022285, 'test_prec': 0.7409638554216867, 'test_recall': 0.6373056994818653, 'labeled_instances': 720, 'train_positive_rate': 0.08472222222222223, 'pool_positive_rate': 0.09494837758112094, 'iteration_time': 473.2172660827637}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2582307755947113, 'test_f1': 0.6827794561933535, 'test_prec': 0.8188405797101449, 'test_recall': 0.5854922279792746, 'labeled_instances': 760, 'train_positive_rate': 0.08289473684210526, 'pool_positive_rate': 0.09528231797919762, 'iteration_time': 456.69435954093933}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.24950042366981506, 'test_f1': 0.6703296703296704, 'test_prec': 0.7134502923976608, 'test_recall': 0.6321243523316062, 'labeled_instances': 800, 'train_positive_rate': 0.085, 'pool_positive_rate': 0.09505988023952096, 'iteration_time': 468.97359347343445}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.22372251749038696, 'test_f1': 0.7272727272727272, 'test_prec': 0.7291666666666666, 'test_recall': 0.7253886010362695, 'labeled_instances': 840, 'train_positive_rate': 0.08928571428571429, 'pool_positive_rate': 0.09445701357466063, 'iteration_time': 445.6675372123718}
| ID | GPU | MEM |
------------------
|  0 | 10% | 33% |

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.18380875885486603, 'test_f1': 0.8105263157894735, 'test_prec': 0.8235294117647058, 'test_recall': 0.7979274611398963, 'labeled_instances': 880, 'train_positive_rate': 0.08863636363636364, 'pool_positive_rate': 0.0946048632218845, 'iteration_time': 478.7292585372925}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4059138894081116, 'test_f1': 0.39628482972136225, 'test_prec': 0.49230769230769234, 'test_recall': 0.3316062176165803, 'labeled_instances': 920, 'train_positive_rate': 0.08804347826086957, 'pool_positive_rate': 0.09475497702909648, 'iteration_time': 465.121009349823}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.22945047914981842, 'test_f1': 0.6843657817109144, 'test_prec': 0.7945205479452054, 'test_recall': 0.6010362694300518, 'labeled_instances': 960, 'train_positive_rate': 0.084375, 'pool_positive_rate': 0.0954861111111111, 'iteration_time': 463.9266152381897}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.224781334400177, 'test_f1': 0.7458563535911602, 'test_prec': 0.7988165680473372, 'test_recall': 0.6994818652849741, 'labeled_instances': 1000, 'train_positive_rate': 0.084, 'pool_positive_rate': 0.09564541213063764, 'iteration_time': 477.73311257362366}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 6144
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.14450065791606903, 'test_f1': 0.8691099476439791, 'test_prec': 0.8783068783068783, 'test_recall': 0.8601036269430051, 'labeled_instances': 6144, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.09375, 'iteration_time': 871.5579900741577}
New cross validation 1, for  <function deepmatcher_structured_walmart_amazon at 0x1519b4516310>
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 0
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1671249121427536, 'test_f1': 0.8617021276595744, 'test_prec': 0.8852459016393442, 'test_recall': 0.8393782383419689, 'labeled_instances': 0, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.09375, 'iteration_time': 865.7817680835724}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 20
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4327561855316162, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 20, 'train_positive_rate': 0.05, 'pool_positive_rate': 0.09389288047028087, 'iteration_time': 393.5666923522949}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 40
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3007989525794983, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 40, 'train_positive_rate': 0.075, 'pool_positive_rate': 0.09387287024901704, 'iteration_time': 403.76475048065186}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3004680573940277, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.08333333333333333, 'pool_positive_rate': 0.09385272846811309, 'iteration_time': 402.7667751312256}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.30472105741500854, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 80, 'train_positive_rate': 0.1125, 'pool_positive_rate': 0.09350263852242745, 'iteration_time': 408.20029044151306}
| ID | GPU | MEM |
------------------
|  0 |  0% | 34% |

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.32396042346954346, 'test_f1': 0.28448275862068967, 'test_prec': 0.24354243542435425, 'test_recall': 0.34196891191709844, 'labeled_instances': 100, 'train_positive_rate': 0.12, 'pool_positive_rate': 0.09331568497683654, 'iteration_time': 428.6010468006134}
| ID | GPU | MEM |
------------------
|  0 | 10% | 33% |

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.27949604392051697, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 120, 'train_positive_rate': 0.10833333333333334, 'pool_positive_rate': 0.09345949535192563, 'iteration_time': 410.97049736976624}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3659062087535858, 'test_f1': 0.3649122807017544, 'test_prec': 0.5652173913043478, 'test_recall': 0.2694300518134715, 'labeled_instances': 140, 'train_positive_rate': 0.10714285714285714, 'pool_positive_rate': 0.09343770819453698, 'iteration_time': 413.8172962665558}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4741799831390381, 'test_f1': 0.21097046413502107, 'test_prec': 0.5681818181818182, 'test_recall': 0.12953367875647667, 'labeled_instances': 160, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.09375, 'iteration_time': 411.16648268699646}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4890510141849518, 'test_f1': 0.05555555555555555, 'test_prec': 0.2608695652173913, 'test_recall': 0.031088082901554404, 'labeled_instances': 180, 'train_positive_rate': 0.08888888888888889, 'pool_positive_rate': 0.09389671361502347, 'iteration_time': 412.13003301620483}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 200
-- Random test --

[3779 5769 2689 1621  366 4731 4966 1297 5644 4276  444 2983  642 2188
  115 3205 1971 4829  200 3683 1907 4948 3941 5147  147  724  767  573
 1038 3398 4936 2938 4127 2402 5457 3206  161 4778 5843  867 6023 4050
 3953 4152 5669 3279  169 1958 5187 6103  255 1966 2646 5325 5055 2196
  705 2098 5982 5150 4031 5939 2438  141   28 5526 5674 2889 3701 4886
  179 2353 5491 4715 3804 2320  684 5980 1023 5391 2784 2733 3560  368
 2340 3275  234  538 3974 2608 5936 6113  795 4178 2900 3181 3705  276
 2157   45 1056 3152 5342 3259 2541 3512 2861 1537  758 5379 5629 2397
 2934 1394 5426 3486 1796 1147 2711 4007 1540 4794 3137 3794 1377 4066
 5369 3774 4371 6046 2827 4993 5812 2164 3068 6009 2820  383 2217  544
 1735 2488 3230 3185 1247 4609 6143 2084 4956 3523  125 5777 5070 4652
 3095 4185   79 2929 1812 3076 2319 1169 2236  301  958  799 2928 5727
 3532 3509 2505 1034 2155  440 2355 4239  634 1989 3446  941 5401 2345
 2905 1916 1081 3128  784 1606 2031 5966  718 4972 4013 1227 2838 4659
 6052 1331 3392 1287]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.31172266602516174, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 200, 'train_positive_rate': 0.085, 'pool_positive_rate': 0.09404441453566621, 'iteration_time': 414.1813714504242}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.567465603351593, 'test_f1': 0.0502092050209205, 'test_prec': 0.13043478260869565, 'test_recall': 0.031088082901554404, 'labeled_instances': 240, 'train_positive_rate': 0.10833333333333334, 'pool_positive_rate': 0.09315718157181571, 'iteration_time': 434.33797669410706}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.447184294462204, 'test_f1': 0.23741007194244604, 'test_prec': 0.38823529411764707, 'test_recall': 0.17098445595854922, 'labeled_instances': 280, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.09345156889495225, 'iteration_time': 421.62673473358154}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.5639006495475769, 'test_f1': 0.058823529411764705, 'test_prec': 0.15555555555555556, 'test_recall': 0.03626943005181347, 'labeled_instances': 320, 'train_positive_rate': 0.090625, 'pool_positive_rate': 0.0939217032967033, 'iteration_time': 420.7921326160431}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4720515012741089, 'test_f1': 0.28178694158075607, 'test_prec': 0.41836734693877553, 'test_recall': 0.21243523316062177, 'labeled_instances': 360, 'train_positive_rate': 0.08888888888888889, 'pool_positive_rate': 0.09405255878284924, 'iteration_time': 427.564325094223}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.24344490468502045, 'test_f1': 0.6596306068601583, 'test_prec': 0.6720430107526881, 'test_recall': 0.6476683937823834, 'labeled_instances': 400, 'train_positive_rate': 0.0975, 'pool_positive_rate': 0.09348885793871867, 'iteration_time': 425.0979199409485}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.5272618532180786, 'test_f1': 0.009615384615384614, 'test_prec': 0.06666666666666667, 'test_recall': 0.0051813471502590676, 'labeled_instances': 440, 'train_positive_rate': 0.09318181818181819, 'pool_positive_rate': 0.0937938288920056, 'iteration_time': 409.8166790008545}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.40939027070999146, 'test_f1': 0.4492753623188406, 'test_prec': 0.7469879518072289, 'test_recall': 0.32124352331606215, 'labeled_instances': 480, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.09375, 'iteration_time': 439.7661521434784}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.24981117248535156, 'test_f1': 0.7023809523809524, 'test_prec': 0.8251748251748252, 'test_recall': 0.6113989637305699, 'labeled_instances': 520, 'train_positive_rate': 0.08846153846153847, 'pool_positive_rate': 0.09423897581792319, 'iteration_time': 440.08957505226135}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.31839269399642944, 'test_f1': 0.6035502958579881, 'test_prec': 0.7034482758620689, 'test_recall': 0.5284974093264249, 'labeled_instances': 560, 'train_positive_rate': 0.08571428571428572, 'pool_positive_rate': 0.09455587392550144, 'iteration_time': 444.04848551750183}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 600
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.30126556754112244, 'test_f1': 0.660919540229885, 'test_prec': 0.7419354838709677, 'test_recall': 0.5958549222797928, 'labeled_instances': 600, 'train_positive_rate': 0.09, 'pool_positive_rate': 0.09415584415584416, 'iteration_time': 444.82508087158203}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.30938640236854553, 'test_f1': 0.5572755417956655, 'test_prec': 0.6923076923076923, 'test_recall': 0.46632124352331605, 'labeled_instances': 640, 'train_positive_rate': 0.090625, 'pool_positive_rate': 0.09411337209302326, 'iteration_time': 450.9300775527954}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.5534348487854004, 'test_f1': 0.08097165991902834, 'test_prec': 0.18518518518518517, 'test_recall': 0.05181347150259067, 'labeled_instances': 680, 'train_positive_rate': 0.09117647058823529, 'pool_positive_rate': 0.09407027818448023, 'iteration_time': 462.44268131256104}
| ID | GPU | MEM |
------------------
|  0 | 10% | 34% |

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.25669562816619873, 'test_f1': 0.6888888888888888, 'test_prec': 0.7425149700598802, 'test_recall': 0.6424870466321243, 'labeled_instances': 720, 'train_positive_rate': 0.09166666666666666, 'pool_positive_rate': 0.09402654867256637, 'iteration_time': 475.52618861198425}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.44138339161872864, 'test_f1': 0.40892193308550184, 'test_prec': 0.7236842105263158, 'test_recall': 0.2849740932642487, 'labeled_instances': 760, 'train_positive_rate': 0.09078947368421053, 'pool_positive_rate': 0.09416790490341753, 'iteration_time': 474.9365336894989}
| ID | GPU | MEM |
------------------
|  0 |  1% | 33% |

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.5418533682823181, 'test_f1': 0.20202020202020202, 'test_prec': 0.28846153846153844, 'test_recall': 0.15544041450777202, 'labeled_instances': 800, 'train_positive_rate': 0.0925, 'pool_positive_rate': 0.09393712574850299, 'iteration_time': 464.013396024704}
| ID | GPU | MEM |
------------------
|  0 | 10% | 33% |

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.22764798998832703, 'test_f1': 0.6963788300835654, 'test_prec': 0.7530120481927711, 'test_recall': 0.6476683937823834, 'labeled_instances': 840, 'train_positive_rate': 0.09404761904761905, 'pool_positive_rate': 0.09370286576168929, 'iteration_time': 470.807936668396}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.23925985395908356, 'test_f1': 0.6932515337423313, 'test_prec': 0.849624060150376, 'test_recall': 0.5854922279792746, 'labeled_instances': 880, 'train_positive_rate': 0.09431818181818181, 'pool_positive_rate': 0.09365501519756839, 'iteration_time': 478.04749059677124}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.23118583858013153, 'test_f1': 0.7253333333333334, 'test_prec': 0.7472527472527473, 'test_recall': 0.7046632124352331, 'labeled_instances': 920, 'train_positive_rate': 0.0967391304347826, 'pool_positive_rate': 0.09322358346094946, 'iteration_time': 471.0121681690216}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.21596939861774445, 'test_f1': 0.7415143603133159, 'test_prec': 0.7473684210526316, 'test_recall': 0.7357512953367875, 'labeled_instances': 960, 'train_positive_rate': 0.09791666666666667, 'pool_positive_rate': 0.09297839506172839, 'iteration_time': 458.27030777931213}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.16510076820850372, 'test_f1': 0.8, 'test_prec': 0.89171974522293, 'test_recall': 0.7253886010362695, 'labeled_instances': 1000, 'train_positive_rate': 0.095, 'pool_positive_rate': 0.09350699844479005, 'iteration_time': 488.02848982810974}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 6144
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1635347455739975, 'test_f1': 0.8480000000000001, 'test_prec': 0.8736263736263736, 'test_recall': 0.8238341968911918, 'labeled_instances': 6144, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.09375, 'iteration_time': 854.1874434947968}
New cross validation 2, for  <function deepmatcher_structured_walmart_amazon at 0x1519b4516310>
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 0
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.18232446908950806, 'test_f1': 0.8453608247422681, 'test_prec': 0.841025641025641, 'test_recall': 0.8497409326424871, 'labeled_instances': 0, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.09375, 'iteration_time': 854.039849281311}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 20
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.39361992478370667, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 20, 'train_positive_rate': 0.05, 'pool_positive_rate': 0.09389288047028087, 'iteration_time': 416.3413770198822}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 40
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.31599560379981995, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 40, 'train_positive_rate': 0.075, 'pool_positive_rate': 0.09387287024901704, 'iteration_time': 401.63797545433044}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4113761782646179, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.05, 'pool_positive_rate': 0.09418145956607495, 'iteration_time': 413.2168838977814}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.33761823177337646, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 80, 'train_positive_rate': 0.05, 'pool_positive_rate': 0.09432717678100264, 'iteration_time': 429.15848898887634}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4748270511627197, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 100, 'train_positive_rate': 0.05, 'pool_positive_rate': 0.09447385837193911, 'iteration_time': 408.3453526496887}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.5097288489341736, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 120, 'train_positive_rate': 0.05, 'pool_positive_rate': 0.0946215139442231, 'iteration_time': 413.1141531467438}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.444123774766922, 'test_f1': 0.12444444444444441, 'test_prec': 0.4375, 'test_recall': 0.07253886010362694, 'labeled_instances': 140, 'train_positive_rate': 0.06428571428571428, 'pool_positive_rate': 0.09443704197201866, 'iteration_time': 430.6942181587219}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.40808403491973877, 'test_f1': 0.1412639405204461, 'test_prec': 0.25, 'test_recall': 0.09844559585492228, 'labeled_instances': 160, 'train_positive_rate': 0.075, 'pool_positive_rate': 0.09425133689839572, 'iteration_time': 430.3174226284027}
| ID | GPU | MEM |
------------------
|  0 |  0% | 46% |

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3131415843963623, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 180, 'train_positive_rate': 0.07777777777777778, 'pool_positive_rate': 0.09423205902079142, 'iteration_time': 413.61148476600647}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 200
-- Random test --

[3041 4032 2391 1387 1709 1664   27 5997 3733 2702 3488 1986 1557   15
 5712 1015 5386 5263 5200 5636 4049 3045 2444  230 5615 1748 2288 5685
 4043 6116 5949 4472 4158 4138  604 5060 3481 4454 4029 5312 1002 2718
  103 5870 1927 1019  537 1301 2183  811 2114 2185 2252   72 1109 4114
 2133  463 4706 3148  201 5370 3056 2055  411  248 4615 1606  798    3
 2966  640 1263 2908 4554 1162 3564 6046  793 4671 1302 2627 2328 4690
 3679 1153 6060  661 2327  521 6110 4432 1667 3726 1469 4013  344  377
 5462  777 3160 4572 1896 1177 5689 4968  826  256 4377 4749  744 5322
 2123  204 2220 2433 4886 3814 5937 3390 5020 1346  184 3659 1933 5566
 6090 6032 4384 6085 3209 4804 5439 2063  385 1195 2576 2112 4519 4180
  626  141 5080 3321 3925 4550 4654 4604 5945  768 1145  889  874 1379
 1303 1854 5839 5620 1527  541 4231 3845 5070  866 4616 5725 1230 5236
 3709 3569 3348 2621 1715 1671 2011 2761  799  577 4814 5633 3838 1290
 2344 5002 1400   88 2289 1970 4019 3109 1614 2509 2141 1069  273 4993
 2353 3833 4751 3455]
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.31232893466949463, 'test_f1': 0.44559585492227977, 'test_prec': 0.44559585492227977, 'test_recall': 0.44559585492227977, 'labeled_instances': 200, 'train_positive_rate': 0.09, 'pool_positive_rate': 0.09387617765814267, 'iteration_time': 407.9004740715027}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.32730337977409363, 'test_f1': 0.3680555555555556, 'test_prec': 0.5578947368421052, 'test_recall': 0.27461139896373055, 'labeled_instances': 240, 'train_positive_rate': 0.0875, 'pool_positive_rate': 0.09400406504065041, 'iteration_time': 418.8940439224243}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4116477966308594, 'test_f1': 0.380952380952381, 'test_prec': 0.5544554455445545, 'test_recall': 0.29015544041450775, 'labeled_instances': 280, 'train_positive_rate': 0.08214285714285714, 'pool_positive_rate': 0.09430422919508867, 'iteration_time': 427.72851610183716}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 320
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3311982750892639, 'test_f1': 0.3944636678200692, 'test_prec': 0.59375, 'test_recall': 0.29533678756476683, 'labeled_instances': 320, 'train_positive_rate': 0.078125, 'pool_positive_rate': 0.09460851648351648, 'iteration_time': 424.8950045108795}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3815670907497406, 'test_f1': 0.4269005847953216, 'test_prec': 0.4899328859060403, 'test_recall': 0.37823834196891193, 'labeled_instances': 360, 'train_positive_rate': 0.075, 'pool_positive_rate': 0.09491701244813278, 'iteration_time': 435.5915639400482}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.22296437621116638, 'test_f1': 0.6058823529411765, 'test_prec': 0.7006802721088435, 'test_recall': 0.533678756476684, 'labeled_instances': 400, 'train_positive_rate': 0.075, 'pool_positive_rate': 0.09505571030640668, 'iteration_time': 440.08982586860657}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.32203221321105957, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 440, 'train_positive_rate': 0.07272727272727272, 'pool_positive_rate': 0.09537166900420757, 'iteration_time': 463.8278908729553}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.36987340450286865, 'test_f1': 0.40816326530612246, 'test_prec': 0.594059405940594, 'test_recall': 0.31088082901554404, 'labeled_instances': 480, 'train_positive_rate': 0.07708333333333334, 'pool_positive_rate': 0.09516242937853107, 'iteration_time': 439.2374978065491}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4533774256706238, 'test_f1': 0.2565789473684211, 'test_prec': 0.35135135135135137, 'test_recall': 0.20207253886010362, 'labeled_instances': 520, 'train_positive_rate': 0.075, 'pool_positive_rate': 0.09548364153627312, 'iteration_time': 498.9269902706146}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.21244437992572784, 'test_f1': 0.6949152542372882, 'test_prec': 0.7639751552795031, 'test_recall': 0.6373056994818653, 'labeled_instances': 560, 'train_positive_rate': 0.06964285714285715, 'pool_positive_rate': 0.0961676217765043, 'iteration_time': 448.1930305957794}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 600
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1819663792848587, 'test_f1': 0.7413333333333334, 'test_prec': 0.7637362637362637, 'test_recall': 0.7202072538860104, 'labeled_instances': 600, 'train_positive_rate': 0.075, 'pool_positive_rate': 0.09577922077922078, 'iteration_time': 446.5768177509308}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1740555316209793, 'test_f1': 0.7761194029850746, 'test_prec': 0.9154929577464789, 'test_recall': 0.6735751295336787, 'labeled_instances': 640, 'train_positive_rate': 0.075, 'pool_positive_rate': 0.09593023255813954, 'iteration_time': 448.1176567077637}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2784497141838074, 'test_f1': 0.6367924528301886, 'test_prec': 0.5844155844155844, 'test_recall': 0.6994818652849741, 'labeled_instances': 680, 'train_positive_rate': 0.07941176470588235, 'pool_positive_rate': 0.09553440702781844, 'iteration_time': 457.87772369384766}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.25486063957214355, 'test_f1': 0.6046511627906977, 'test_prec': 0.8425925925925926, 'test_recall': 0.47150259067357514, 'labeled_instances': 720, 'train_positive_rate': 0.08194444444444444, 'pool_positive_rate': 0.09531710914454278, 'iteration_time': 492.88317131996155}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.19677427411079407, 'test_f1': 0.7268292682926828, 'test_prec': 0.6866359447004609, 'test_recall': 0.772020725388601, 'labeled_instances': 760, 'train_positive_rate': 0.08421052631578947, 'pool_positive_rate': 0.0950965824665676, 'iteration_time': 461.4166970252991}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.183303564786911, 'test_f1': 0.768361581920904, 'test_prec': 0.84472049689441, 'test_recall': 0.7046632124352331, 'labeled_instances': 800, 'train_positive_rate': 0.085, 'pool_positive_rate': 0.09505988023952096, 'iteration_time': 481.0636510848999}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.21938304603099823, 'test_f1': 0.6338797814207651, 'test_prec': 0.6705202312138728, 'test_recall': 0.6010362694300518, 'labeled_instances': 840, 'train_positive_rate': 0.0880952380952381, 'pool_positive_rate': 0.09464555052790347, 'iteration_time': 470.38765931129456}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.18997715413570404, 'test_f1': 0.7969151670951158, 'test_prec': 0.7908163265306123, 'test_recall': 0.8031088082901554, 'labeled_instances': 880, 'train_positive_rate': 0.08636363636363636, 'pool_positive_rate': 0.09498480243161095, 'iteration_time': 487.2806842327118}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 920
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.18336331844329834, 'test_f1': 0.7616279069767441, 'test_prec': 0.8675496688741722, 'test_recall': 0.6787564766839378, 'labeled_instances': 920, 'train_positive_rate': 0.08804347826086957, 'pool_positive_rate': 0.09475497702909648, 'iteration_time': 471.82262229919434}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.18550552427768707, 'test_f1': 0.7391304347826086, 'test_prec': 0.7771428571428571, 'test_recall': 0.7046632124352331, 'labeled_instances': 960, 'train_positive_rate': 0.08645833333333333, 'pool_positive_rate': 0.09510030864197531, 'iteration_time': 489.29147601127625}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1518794745206833, 'test_f1': 0.8324324324324325, 'test_prec': 0.8700564971751412, 'test_recall': 0.7979274611398963, 'labeled_instances': 1000, 'train_positive_rate': 0.086, 'pool_positive_rate': 0.0952566096423017, 'iteration_time': 490.3914170265198}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 6144
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1590808928012848, 'test_f1': 0.8609625668449197, 'test_prec': 0.8895027624309392, 'test_recall': 0.8341968911917098, 'labeled_instances': 6144, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.09375, 'iteration_time': 877.9417691230774}
New cross validation 3, for  <function deepmatcher_structured_walmart_amazon at 0x1519b4516310>
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 0
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.18365365266799927, 'test_f1': 0.8548387096774193, 'test_prec': 0.888268156424581, 'test_recall': 0.8238341968911918, 'labeled_instances': 0, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.09375, 'iteration_time': 861.624302148819}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 20
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.308917373418808, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 20, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.09372958850424559, 'iteration_time': 403.3953540325165}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 40
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3217375576496124, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 40, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.09370904325032765, 'iteration_time': 423.7170236110687}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.31227830052375793, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.09368836291913216, 'iteration_time': 415.9499521255493}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.31424298882484436, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 80, 'train_positive_rate': 0.0875, 'pool_positive_rate': 0.09383245382585752, 'iteration_time': 422.57210421562195}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.28786957263946533, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 100, 'train_positive_rate': 0.08, 'pool_positive_rate': 0.09397749834546658, 'iteration_time': 420.3628304004669}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2864030599594116, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 120, 'train_positive_rate': 0.09166666666666666, 'pool_positive_rate': 0.09379150066401062, 'iteration_time': 417.20131182670593}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3036867380142212, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 140, 'train_positive_rate': 0.07857142857142857, 'pool_positive_rate': 0.0941039307128581, 'iteration_time': 393.2561845779419}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.309476375579834, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 160, 'train_positive_rate': 0.08125, 'pool_positive_rate': 0.09408422459893048, 'iteration_time': 428.7920994758606}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.43325281143188477, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 180, 'train_positive_rate': 0.07777777777777778, 'pool_positive_rate': 0.09423205902079142, 'iteration_time': 425.3339834213257}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 200
-- Random test --

[5768   36 1947  719  349 1663 2174  115 4297 2472 4179 5423 1507 1972
 5983   17 4692 3678 4486 2422 4170 4603 4948 1120 1614 6088 1726 5330
 5621 4403 5207 4329 3455 4324 1504 3395 1777 4116 4426 3315  375 3621
 1257   62 5877  269 5110 1740 5738 5030 1357 5039 2964  893 2705  330
 4295 2115  368 2334 1993 5805 4640 3748 5226 3569 1349 3541 4323 1820
 3371 5301 3250 3749   24 5512 1410 3813 2516 5049 1316 1056 2740 5107
 4488 2788 2310  626 3921  743 3511 3378 1176 2403 5213 2865 5539 3665
 6091 4352 1914  317 4112 1771 1087 1822 1046 1315 5681  125  640  685
 1735 5800 1964 1444 4032 1203 2521 4987 5105 3336 1136 1526 3258 3563
 2959 1187   33 4406 1518  563  521 2719 4848 1235 1584 5984 2063 4548
 1681  281 2488  894 1749 4279 3999 3461 5934 3892 1721 1784  796 4592
 2139 2817 4301 3175 3332 4578 2230 4859 2021 3252 1968 3057 3559 5215
  544 4399 2931 2337 5140 1091 3105 2782 5723 4062 5018 4212 5713 1292
 4802 5457 3594 5576 4677 2510 1140 5633 2775 1119 1879 4028 2320 4146
 1212 4338 3232 5295]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.27546507120132446, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 200, 'train_positive_rate': 0.08, 'pool_positive_rate': 0.09421265141318977, 'iteration_time': 422.5304443836212}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.42899712920188904, 'test_f1': 0.3484848484848485, 'test_prec': 0.647887323943662, 'test_recall': 0.23834196891191708, 'labeled_instances': 240, 'train_positive_rate': 0.07083333333333333, 'pool_positive_rate': 0.09468157181571815, 'iteration_time': 411.3827042579651}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 280
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.40115925669670105, 'test_f1': 0.06422018348623852, 'test_prec': 0.28, 'test_recall': 0.03626943005181347, 'labeled_instances': 280, 'train_positive_rate': 0.08214285714285714, 'pool_positive_rate': 0.09430422919508867, 'iteration_time': 433.2973701953888}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4053027033805847, 'test_f1': 0.2835820895522388, 'test_prec': 0.5066666666666667, 'test_recall': 0.19689119170984457, 'labeled_instances': 320, 'train_positive_rate': 0.078125, 'pool_positive_rate': 0.09460851648351648, 'iteration_time': 435.4714689254761}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2851886451244354, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 360, 'train_positive_rate': 0.08333333333333333, 'pool_positive_rate': 0.09439834024896265, 'iteration_time': 431.07471799850464}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.514407753944397, 'test_f1': 0.11666666666666665, 'test_prec': 0.2978723404255319, 'test_recall': 0.07253886010362694, 'labeled_instances': 400, 'train_positive_rate': 0.085, 'pool_positive_rate': 0.09435933147632312, 'iteration_time': 429.8122880458832}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.33689114451408386, 'test_f1': 0.3737024221453287, 'test_prec': 0.5625, 'test_recall': 0.27979274611398963, 'labeled_instances': 440, 'train_positive_rate': 0.08409090909090909, 'pool_positive_rate': 0.09449509116409537, 'iteration_time': 438.47575330734253}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.23252080380916595, 'test_f1': 0.6971428571428572, 'test_prec': 0.7770700636942676, 'test_recall': 0.6321243523316062, 'labeled_instances': 480, 'train_positive_rate': 0.08333333333333333, 'pool_positive_rate': 0.09463276836158192, 'iteration_time': 432.30561447143555}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2376461625099182, 'test_f1': 0.6876790830945559, 'test_prec': 0.7692307692307693, 'test_recall': 0.6217616580310881, 'labeled_instances': 520, 'train_positive_rate': 0.08461538461538462, 'pool_positive_rate': 0.0945945945945946, 'iteration_time': 474.76883029937744}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.23380833864212036, 'test_f1': 0.7405541561712846, 'test_prec': 0.7205882352941176, 'test_recall': 0.7616580310880829, 'labeled_instances': 560, 'train_positive_rate': 0.08571428571428572, 'pool_positive_rate': 0.09455587392550144, 'iteration_time': 438.3061945438385}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.22899051010608673, 'test_f1': 0.6516290726817043, 'test_prec': 0.6310679611650486, 'test_recall': 0.6735751295336787, 'labeled_instances': 600, 'train_positive_rate': 0.085, 'pool_positive_rate': 0.0946969696969697, 'iteration_time': 427.9382469654083}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.22200460731983185, 'test_f1': 0.6685878962536024, 'test_prec': 0.7532467532467533, 'test_recall': 0.6010362694300518, 'labeled_instances': 640, 'train_positive_rate': 0.084375, 'pool_positive_rate': 0.09484011627906977, 'iteration_time': 426.39339804649353}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.22497089207172394, 'test_f1': 0.709090909090909, 'test_prec': 0.8540145985401459, 'test_recall': 0.6062176165803109, 'labeled_instances': 680, 'train_positive_rate': 0.0838235294117647, 'pool_positive_rate': 0.09498535871156662, 'iteration_time': 450.0344183444977}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.25027042627334595, 'test_f1': 0.6309523809523809, 'test_prec': 0.7412587412587412, 'test_recall': 0.5492227979274611, 'labeled_instances': 720, 'train_positive_rate': 0.08333333333333333, 'pool_positive_rate': 0.09513274336283185, 'iteration_time': 458.06141424179077}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.17967349290847778, 'test_f1': 0.7735368956743003, 'test_prec': 0.76, 'test_recall': 0.7875647668393783, 'labeled_instances': 760, 'train_positive_rate': 0.08421052631578947, 'pool_positive_rate': 0.0950965824665676, 'iteration_time': 452.1989185810089}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.19500860571861267, 'test_f1': 0.7454068241469817, 'test_prec': 0.7553191489361702, 'test_recall': 0.7357512953367875, 'labeled_instances': 800, 'train_positive_rate': 0.085, 'pool_positive_rate': 0.09505988023952096, 'iteration_time': 461.86011695861816}
| ID | GPU | MEM |
------------------
|  0 |  0% | 34% |

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.361172080039978, 'test_f1': 0.47686832740213525, 'test_prec': 0.7613636363636364, 'test_recall': 0.3471502590673575, 'labeled_instances': 840, 'train_positive_rate': 0.08452380952380953, 'pool_positive_rate': 0.09521116138763197, 'iteration_time': 473.44933438301086}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.43541407585144043, 'test_f1': 0.25806451612903225, 'test_prec': 0.3418803418803419, 'test_recall': 0.20725388601036268, 'labeled_instances': 880, 'train_positive_rate': 0.08295454545454546, 'pool_positive_rate': 0.0955547112462006, 'iteration_time': 487.54502534866333}
| ID | GPU | MEM |
------------------
|  0 |  0% | 34% |

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2034236192703247, 'test_f1': 0.7532467532467532, 'test_prec': 0.7552083333333334, 'test_recall': 0.7512953367875648, 'labeled_instances': 920, 'train_positive_rate': 0.08586956521739131, 'pool_positive_rate': 0.09513782542113323, 'iteration_time': 472.2175097465515}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.17595833539962769, 'test_f1': 0.7978436657681941, 'test_prec': 0.8314606741573034, 'test_recall': 0.7668393782383419, 'labeled_instances': 960, 'train_positive_rate': 0.08541666666666667, 'pool_positive_rate': 0.09529320987654322, 'iteration_time': 491.0140416622162}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.5025896430015564, 'test_f1': 0.14671814671814673, 'test_prec': 0.2878787878787879, 'test_recall': 0.09844559585492228, 'labeled_instances': 1000, 'train_positive_rate': 0.086, 'pool_positive_rate': 0.0952566096423017, 'iteration_time': 493.2383933067322}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 6144
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.19005613029003143, 'test_f1': 0.870712401055409, 'test_prec': 0.8870967741935484, 'test_recall': 0.8549222797927462, 'labeled_instances': 6144, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.09375, 'iteration_time': 857.1071982383728}
New cross validation 4, for  <function deepmatcher_structured_walmart_amazon at 0x1519b4516310>
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 0
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.17255815863609314, 'test_f1': 0.8601036269430051, 'test_prec': 0.8601036269430051, 'test_recall': 0.8601036269430051, 'labeled_instances': 0, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.09375, 'iteration_time': 857.7083389759064}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 20
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.31037768721580505, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 20, 'train_positive_rate': 0.05, 'pool_positive_rate': 0.09389288047028087, 'iteration_time': 406.30466747283936}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 40
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.36300721764564514, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 40, 'train_positive_rate': 0.025, 'pool_positive_rate': 0.0942005242463958, 'iteration_time': 428.05285692214966}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.42956897616386414, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.016666666666666666, 'pool_positive_rate': 0.09451019066403682, 'iteration_time': 414.9317855834961}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4769875705242157, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 80, 'train_positive_rate': 0.0125, 'pool_positive_rate': 0.09482189973614776, 'iteration_time': 404.2057406902313}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4936281442642212, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 100, 'train_positive_rate': 0.02, 'pool_positive_rate': 0.09497021839841165, 'iteration_time': 415.8574528694153}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.5048749446868896, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 120, 'train_positive_rate': 0.03333333333333333, 'pool_positive_rate': 0.0949535192563081, 'iteration_time': 437.632554769516}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 140
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3525133728981018, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 140, 'train_positive_rate': 0.03571428571428571, 'pool_positive_rate': 0.09510326449033978, 'iteration_time': 437.992947101593}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.640632152557373, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 160, 'train_positive_rate': 0.0375, 'pool_positive_rate': 0.09525401069518717, 'iteration_time': 434.76545691490173}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4602818787097931, 'test_f1': 0.0099009900990099, 'test_prec': 0.1111111111111111, 'test_recall': 0.0051813471502590676, 'labeled_instances': 180, 'train_positive_rate': 0.044444444444444446, 'pool_positive_rate': 0.09523809523809523, 'iteration_time': 400.786985874176}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 200
-- Random test --

[1189 4595 1160 5389 2991 1105 4883 3028 4431 2958 3432 2943 4426 2017
 2881 4503 3618 3551 4432 5024 4652 5476  397 2516 2375 4932 3840 5986
  356 4458 4059 3851 3835 3208 2840  497 5768 2373 3879  203 2740  949
 2111  374  859 3982 3400 2057 1414 1723  741 1659  480 5999  525 2882
 4120 3291   42 2666 2271 1116 3483 4963 5593 2180 2551 4436 3152 3669
 3247 2932  157 1909 3770 1185 3877 4953 4170 1061 4119 5772   38 2591
 3593 2515 1350 4103 3657 2121 3384 2903  753 3234 2009 1279 2343 3621
 5887 2139 2831 5659  510 1131  560 1020 6026  131 2446 3355 1551 3856
 1802 4386 3322 4833 3370 3629 3424 5579 1622 1675 1168  841 3817 4140
 1490 1579 3268 5741 3282 4926 5762 3639 1151 3834 4138 5746  423 4627
  379 1399 3614 4805 6105 2395 5690  927 3348 4198 4143 4019 3689 5354
 4531 5208 5763  457 3738  926 2203 6102 4494 4233 1179  500 3083 2985
  495 5817 1922 4525 3679  656 4345 2713  362 4112 1820 2232 1878 2185
 2532 5604 2342 4955 2644 4006 5807  828 2977 5216 1335 3960 1575 2409
 5550 3087  736 2109]
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4440503418445587, 'test_f1': 0.0861244019138756, 'test_prec': 0.5625, 'test_recall': 0.046632124352331605, 'labeled_instances': 200, 'train_positive_rate': 0.05, 'pool_positive_rate': 0.09522207267833109, 'iteration_time': 405.84635734558105}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.31855538487434387, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 240, 'train_positive_rate': 0.058333333333333334, 'pool_positive_rate': 0.09518970189701897, 'iteration_time': 420.29515290260315}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.5283216238021851, 'test_f1': 0.15447154471544716, 'test_prec': 0.3584905660377358, 'test_recall': 0.09844559585492228, 'labeled_instances': 280, 'train_positive_rate': 0.06785714285714285, 'pool_positive_rate': 0.09498635743519782, 'iteration_time': 435.2291090488434}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.46469277143478394, 'test_f1': 0.24489795918367346, 'test_prec': 0.5769230769230769, 'test_recall': 0.15544041450777202, 'labeled_instances': 320, 'train_positive_rate': 0.06875, 'pool_positive_rate': 0.09512362637362637, 'iteration_time': 400.88794016838074}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3305491507053375, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 360, 'train_positive_rate': 0.06111111111111111, 'pool_positive_rate': 0.09578146611341633, 'iteration_time': 430.59828996658325}
| ID | GPU | MEM |
------------------
|  0 |  3% | 21% |

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2843616008758545, 'test_f1': 0.3286713286713287, 'test_prec': 0.5053763440860215, 'test_recall': 0.24352331606217617, 'labeled_instances': 400, 'train_positive_rate': 0.0575, 'pool_positive_rate': 0.09627437325905293, 'iteration_time': 413.7035391330719}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4435264766216278, 'test_f1': 0.06034482758620689, 'test_prec': 0.1794871794871795, 'test_recall': 0.03626943005181347, 'labeled_instances': 440, 'train_positive_rate': 0.06363636363636363, 'pool_positive_rate': 0.09607293127629733, 'iteration_time': 430.0583062171936}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.45595601201057434, 'test_f1': 0.04464285714285714, 'test_prec': 0.16129032258064516, 'test_recall': 0.025906735751295335, 'labeled_instances': 480, 'train_positive_rate': 0.07291666666666667, 'pool_positive_rate': 0.09551553672316385, 'iteration_time': 410.29192876815796}
| ID | GPU | MEM |
------------------
|  0 | 10% | 21% |

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2100599706172943, 'test_f1': 0.6900584795321637, 'test_prec': 0.7919463087248322, 'test_recall': 0.6113989637305699, 'labeled_instances': 520, 'train_positive_rate': 0.07307692307692308, 'pool_positive_rate': 0.09566145092460882, 'iteration_time': 437.5997054576874}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3884814977645874, 'test_f1': 0.15037593984962405, 'test_prec': 0.273972602739726, 'test_recall': 0.10362694300518134, 'labeled_instances': 560, 'train_positive_rate': 0.07857142857142857, 'pool_positive_rate': 0.09527220630372493, 'iteration_time': 429.3407654762268}
| ID | GPU | MEM |
------------------
|  0 | 10% | 21% |

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1784045696258545, 'test_f1': 0.736842105263158, 'test_prec': 0.8456375838926175, 'test_recall': 0.6528497409326425, 'labeled_instances': 600, 'train_positive_rate': 0.08, 'pool_positive_rate': 0.09523809523809523, 'iteration_time': 421.64032554626465}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1813487857580185, 'test_f1': 0.7867036011080332, 'test_prec': 0.8452380952380952, 'test_recall': 0.7357512953367875, 'labeled_instances': 640, 'train_positive_rate': 0.0859375, 'pool_positive_rate': 0.09465843023255814, 'iteration_time': 432.73789381980896}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.24187909066677094, 'test_f1': 0.6914285714285714, 'test_prec': 0.7707006369426752, 'test_recall': 0.6269430051813472, 'labeled_instances': 680, 'train_positive_rate': 0.08529411764705883, 'pool_positive_rate': 0.09480234260614934, 'iteration_time': 432.1041910648346}
| ID | GPU | MEM |
------------------
|  0 | 10% | 33% |

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2364250272512436, 'test_f1': 0.7468030690537084, 'test_prec': 0.7373737373737373, 'test_recall': 0.7564766839378239, 'labeled_instances': 720, 'train_positive_rate': 0.08472222222222223, 'pool_positive_rate': 0.09494837758112094, 'iteration_time': 441.3350942134857}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 760
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.19329261779785156, 'test_f1': 0.7738095238095237, 'test_prec': 0.9090909090909091, 'test_recall': 0.6735751295336787, 'labeled_instances': 760, 'train_positive_rate': 0.08421052631578947, 'pool_positive_rate': 0.0950965824665676, 'iteration_time': 440.2042398452759}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.17435498535633087, 'test_f1': 0.7859078590785908, 'test_prec': 0.8238636363636364, 'test_recall': 0.7512953367875648, 'labeled_instances': 800, 'train_positive_rate': 0.08375, 'pool_positive_rate': 0.09524700598802395, 'iteration_time': 468.52793550491333}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 840
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.21554891765117645, 'test_f1': 0.7204301075268816, 'test_prec': 0.7486033519553073, 'test_recall': 0.694300518134715, 'labeled_instances': 840, 'train_positive_rate': 0.08452380952380953, 'pool_positive_rate': 0.09521116138763197, 'iteration_time': 457.28708267211914}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.16944941878318787, 'test_f1': 0.7932960893854748, 'test_prec': 0.8606060606060606, 'test_recall': 0.7357512953367875, 'labeled_instances': 880, 'train_positive_rate': 0.08409090909090909, 'pool_positive_rate': 0.09536474164133739, 'iteration_time': 483.8072657585144}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.16545715928077698, 'test_f1': 0.8135593220338984, 'test_prec': 0.8944099378881988, 'test_recall': 0.7461139896373057, 'labeled_instances': 920, 'train_positive_rate': 0.08478260869565217, 'pool_positive_rate': 0.09532924961715161, 'iteration_time': 461.3469657897949}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.16178159415721893, 'test_f1': 0.8314606741573033, 'test_prec': 0.9079754601226994, 'test_recall': 0.7668393782383419, 'labeled_instances': 960, 'train_positive_rate': 0.08333333333333333, 'pool_positive_rate': 0.09567901234567901, 'iteration_time': 459.9585950374603}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.38600558042526245, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 1000, 'train_positive_rate': 0.084, 'pool_positive_rate': 0.09564541213063764, 'iteration_time': 470.7769136428833}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 6144
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.15852881968021393, 'test_f1': 0.8624338624338624, 'test_prec': 0.8810810810810811, 'test_recall': 0.844559585492228, 'labeled_instances': 6144, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.09375, 'iteration_time': 824.2749445438385}
Could not create dir out, File exists




    ###########  New Dataset: <function deepmatcher_textual_abt_buy at 0x1519b4516670>
New cross validation 0, for  <function deepmatcher_textual_abt_buy at 0x1519b4516670>
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 0
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.12589897215366364, 'test_f1': 0.8823529411764707, 'test_prec': 0.8910891089108911, 'test_recall': 0.8737864077669902, 'labeled_instances': 0, 'train_positive_rate': 0.10726101340762667, 'pool_positive_rate': 0.10726101340762667, 'iteration_time': 915.9065103530884}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 20
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.5779456496238708, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 20, 'train_positive_rate': 0.0, 'pool_positive_rate': 0.10763585532063603, 'iteration_time': 430.7145209312439}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 40
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3356981873512268, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 40, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10731194108364019, 'iteration_time': 466.988242149353}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.34161561727523804, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10733767376385711, 'iteration_time': 436.8709964752197}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.33014747500419617, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 80, 'train_positive_rate': 0.125, 'pool_positive_rate': 0.10701041850609218, 'iteration_time': 428.4407846927643}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3379960060119629, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 100, 'train_positive_rate': 0.11, 'pool_positive_rate': 0.10721247563352826, 'iteration_time': 444.04180574417114}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3749614655971527, 'test_f1': 0.07003891050583658, 'test_prec': 0.17647058823529413, 'test_recall': 0.043689320388349516, 'labeled_instances': 120, 'train_positive_rate': 0.10833333333333334, 'pool_positive_rate': 0.10723812911257335, 'iteration_time': 435.81473755836487}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 140
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.49607816338539124, 'test_f1': 0.11764705882352942, 'test_prec': 0.4375, 'test_recall': 0.06796116504854369, 'labeled_instances': 140, 'train_positive_rate': 0.10714285714285714, 'pool_positive_rate': 0.10726396573264323, 'iteration_time': 479.0490753650665}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.33483627438545227, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 160, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10746910263299302, 'iteration_time': 443.0173239707947}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.5227358937263489, 'test_f1': 0.07258064516129031, 'test_prec': 0.21428571428571427, 'test_recall': 0.043689320388349516, 'labeled_instances': 180, 'train_positive_rate': 0.1111111111111111, 'pool_positive_rate': 0.1071364371741866, 'iteration_time': 445.3272466659546}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 200
-- Random test --

[1625 4299 1824   29 1096  502 2588  499 3713 3083 2587 5315 1203 4189
  608 5594 3054 3439 4380 1722 4255  818 4483 4138  530 4601 4852 5712
 1029 5058 1001 3667 2729 3167  629 5013 2244 3502  965 3294 4399 5695
 2177  776 3916   15 5027 2818 1142 4125 3855 2661 3874 5674 4345  773
   98 4727 2513 2339 2920  472 1839  977 4322 4694 4411  286  751 2707
 3350 2730 1746 4928 3225 4805  531 5714 5187 1172 3417 3307  444 5373
 5511  142 4770 1519 2278 5546 4570 4386  144 1008  882 1833 4084  825
 5070 4899 4166 1710 2060 4504 3462 1505 3657 1332 5260 2285  949 4252
 2048 1411 2644 3312 3885 1982 4576 3326 5514 5007 5394 4282 1595 5211
 2553 2946 5376 1859 4224 1850 1715 2523 1855 1281 2381 5093 1095  642
 5322 1668 1687 3460 3698 1022 5584 4730  379 4185 3714  405 4913   14
 1829 2087  388 4228 1014 3653 2243 2760  202 2655  527 5380 2844 5228
 1108 3565 3497 4265 3390 2998 4653 4200  257  895 5561 4181 5173 4764
  311 1593 4514  143 3327 4401 1421 4291 5640 2027 1515   39 3629 5619
 2913 2972 4842 5646]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.37219586968421936, 'test_f1': 0.15172413793103448, 'test_prec': 0.2619047619047619, 'test_recall': 0.10679611650485436, 'labeled_instances': 200, 'train_positive_rate': 0.115, 'pool_positive_rate': 0.1069817788201335, 'iteration_time': 422.80613112449646}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3430751860141754, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 240, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10757768489914592, 'iteration_time': 440.8585832118988}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4044666588306427, 'test_f1': 0.38526912181303113, 'test_prec': 0.46258503401360546, 'test_recall': 0.3300970873786408, 'labeled_instances': 280, 'train_positive_rate': 0.11071428571428571, 'pool_positive_rate': 0.1070840197693575, 'iteration_time': 456.38751006126404}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.24387742578983307, 'test_f1': 0.654054054054054, 'test_prec': 0.7378048780487805, 'test_recall': 0.587378640776699, 'labeled_instances': 320, 'train_positive_rate': 0.1125, 'pool_positive_rate': 0.10695187165775401, 'iteration_time': 445.89291977882385}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.21236000955104828, 'test_f1': 0.6927374301675977, 'test_prec': 0.8157894736842105, 'test_recall': 0.6019417475728155, 'labeled_instances': 360, 'train_positive_rate': 0.11388888888888889, 'pool_positive_rate': 0.10681775961359836, 'iteration_time': 445.3033788204193}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.25270876288414, 'test_f1': 0.6648351648351648, 'test_prec': 0.7658227848101266, 'test_recall': 0.587378640776699, 'labeled_instances': 400, 'train_positive_rate': 0.1075, 'pool_positive_rate': 0.10724312184166199, 'iteration_time': 461.3303258419037}
| ID | GPU | MEM |
------------------
|  0 |  4% | 21% |

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2778312563896179, 'test_f1': 0.6702702702702702, 'test_prec': 0.7560975609756098, 'test_recall': 0.6019417475728155, 'labeled_instances': 440, 'train_positive_rate': 0.10909090909090909, 'pool_positive_rate': 0.10710918348104846, 'iteration_time': 476.3947215080261}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3833063244819641, 'test_f1': 0.44931506849315067, 'test_prec': 0.5157232704402516, 'test_recall': 0.39805825242718446, 'labeled_instances': 480, 'train_positive_rate': 0.10208333333333333, 'pool_positive_rate': 0.1077332319969599, 'iteration_time': 473.1757047176361}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.23459620773792267, 'test_f1': 0.7741935483870968, 'test_prec': 0.7918781725888325, 'test_recall': 0.7572815533980582, 'labeled_instances': 520, 'train_positive_rate': 0.1076923076923077, 'pool_positive_rate': 0.10721807390388666, 'iteration_time': 459.7579598426819}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2341277152299881, 'test_f1': 0.7121212121212122, 'test_prec': 0.7421052631578947, 'test_recall': 0.6844660194174758, 'labeled_instances': 560, 'train_positive_rate': 0.1125, 'pool_positive_rate': 0.10669496430638627, 'iteration_time': 510.42729568481445}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2343396097421646, 'test_f1': 0.7205882352941176, 'test_prec': 0.7277227722772277, 'test_recall': 0.7135922330097088, 'labeled_instances': 600, 'train_positive_rate': 0.11, 'pool_positive_rate': 0.10694147384794866, 'iteration_time': 490.0866515636444}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 640
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.25965791940689087, 'test_f1': 0.7785888077858881, 'test_prec': 0.7804878048780488, 'test_recall': 0.7766990291262136, 'labeled_instances': 640, 'train_positive_rate': 0.109375, 'pool_positive_rate': 0.10699588477366255, 'iteration_time': 489.4695448875427}
| ID | GPU | MEM |
------------------
|  0 | 25% | 21% |

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.19490888714790344, 'test_f1': 0.7823960880195598, 'test_prec': 0.7881773399014779, 'test_recall': 0.7766990291262136, 'labeled_instances': 680, 'train_positive_rate': 0.11029411764705882, 'pool_positive_rate': 0.10685364408453486, 'iteration_time': 472.94094228744507}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.17520801723003387, 'test_f1': 0.8103896103896103, 'test_prec': 0.8715083798882681, 'test_recall': 0.7572815533980582, 'labeled_instances': 720, 'train_positive_rate': 0.10972222222222222, 'pool_positive_rate': 0.10690822217798128, 'iteration_time': 485.12829089164734}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.21155275404453278, 'test_f1': 0.7885117493472584, 'test_prec': 0.8531073446327684, 'test_recall': 0.7330097087378641, 'labeled_instances': 760, 'train_positive_rate': 0.11315789473684211, 'pool_positive_rate': 0.10636162954043749, 'iteration_time': 483.03835940361023}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 800
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.21103346347808838, 'test_f1': 0.7896103896103895, 'test_prec': 0.8491620111731844, 'test_recall': 0.7378640776699029, 'labeled_instances': 800, 'train_positive_rate': 0.11625, 'pool_positive_rate': 0.10580619057252681, 'iteration_time': 494.73360657691956}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2238706797361374, 'test_f1': 0.797979797979798, 'test_prec': 0.8315789473684211, 'test_recall': 0.7669902912621359, 'labeled_instances': 840, 'train_positive_rate': 0.11666666666666667, 'pool_positive_rate': 0.10564960228431572, 'iteration_time': 483.7034845352173}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2056402862071991, 'test_f1': 0.7760416666666666, 'test_prec': 0.8370786516853933, 'test_recall': 0.7233009708737864, 'labeled_instances': 880, 'train_positive_rate': 0.1159090909090909, 'pool_positive_rate': 0.10569607238330249, 'iteration_time': 500.85764241218567}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 920
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.19635722041130066, 'test_f1': 0.7960199004975125, 'test_prec': 0.8163265306122449, 'test_recall': 0.7766990291262136, 'labeled_instances': 920, 'train_positive_rate': 0.11847826086956521, 'pool_positive_rate': 0.10512129380053908, 'iteration_time': 490.38974690437317}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.18598884344100952, 'test_f1': 0.8232323232323232, 'test_prec': 0.8578947368421053, 'test_recall': 0.7912621359223301, 'labeled_instances': 960, 'train_positive_rate': 0.11770833333333333, 'pool_positive_rate': 0.10516412293539619, 'iteration_time': 509.2022006511688}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 1000
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.13021951913833618, 'test_f1': 0.8467532467532468, 'test_prec': 0.9106145251396648, 'test_recall': 0.7912621359223301, 'labeled_instances': 1000, 'train_positive_rate': 0.115, 'pool_positive_rate': 0.105629348513599, 'iteration_time': 503.9603371620178}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 5743
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1152629554271698, 'test_f1': 0.8921568627450982, 'test_prec': 0.900990099009901, 'test_recall': 0.883495145631068, 'labeled_instances': 5743, 'train_positive_rate': 0.10726101340762667, 'pool_positive_rate': 0.10726101340762667, 'iteration_time': 928.1175055503845}
New cross validation 1, for  <function deepmatcher_textual_abt_buy at 0x1519b4516670>
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 0
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.11788787692785263, 'test_f1': 0.8953771289537714, 'test_prec': 0.8975609756097561, 'test_recall': 0.8932038834951457, 'labeled_instances': 0, 'train_positive_rate': 0.10726101340762667, 'pool_positive_rate': 0.10726101340762667, 'iteration_time': 919.1934149265289}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 20
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.38589707016944885, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 20, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10728638825790669, 'iteration_time': 420.9912896156311}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 40
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.33238211274147034, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 40, 'train_positive_rate': 0.125, 'pool_positive_rate': 0.10713659477467999, 'iteration_time': 426.785724401474}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4195164144039154, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.11666666666666667, 'pool_positive_rate': 0.10716171036424424, 'iteration_time': 430.5132808685303}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4611234664916992, 'test_f1': 0.009174311926605505, 'test_prec': 0.08333333333333333, 'test_recall': 0.0048543689320388345, 'labeled_instances': 80, 'train_positive_rate': 0.0875, 'pool_positive_rate': 0.10754017305315204, 'iteration_time': 421.08372807502747}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.341320276260376, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 100, 'train_positive_rate': 0.11, 'pool_positive_rate': 0.10721247563352826, 'iteration_time': 434.6304728984833}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3679325580596924, 'test_f1': 0.05882352941176471, 'test_prec': 0.21875, 'test_recall': 0.03398058252427184, 'labeled_instances': 120, 'train_positive_rate': 0.10833333333333334, 'pool_positive_rate': 0.10723812911257335, 'iteration_time': 443.3516426086426}
| ID | GPU | MEM |
------------------
|  0 | 10% | 21% |

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4871261417865753, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 140, 'train_positive_rate': 0.11428571428571428, 'pool_positive_rate': 0.10708548991611637, 'iteration_time': 418.1780409812927}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3110273778438568, 'test_f1': 0.3745819397993311, 'test_prec': 0.6021505376344086, 'test_recall': 0.27184466019417475, 'labeled_instances': 160, 'train_positive_rate': 0.125, 'pool_positive_rate': 0.10675264194877306, 'iteration_time': 435.22557067871094}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.36121153831481934, 'test_f1': 0.5609756097560975, 'test_prec': 0.7540983606557377, 'test_recall': 0.44660194174757284, 'labeled_instances': 180, 'train_positive_rate': 0.1111111111111111, 'pool_positive_rate': 0.1071364371741866, 'iteration_time': 428.4503798484802}
| ID | GPU | MEM |
------------------
|  0 |  9% | 33% |

Test : 200
-- Random test --

[2667 5575 4388 1078 3771  301 1271 1079 3286  573  141 3032 1412 5036
 2796  503 5347 3423 1637  147 1370 3662 3602 1387  233 3073 2537  428
  958 3924 4728 5584 2678 2429 2076 3768 3839 1016  259  169 3243 2781
 3016 4479 4515 5089 4475 5110  314 1988 4639   21 2228 3414  386  116
 4741 2921 4538 4038 1437 1321  496  354 2450  899 4721 1296 4632  200
 5263 3503  840 1232 4573 3067 5082 3003 1519 4579  940 4040  407 1073
 5295 2624 4577 3017 4746 1289 4706 2787 2353 2246 5093 4408 3220  383
 2019 4820 5409 5008 2726 2360 2708 1723 4966 3387  255 2706  784 2103
 4826 5447 2036 3447 3603 3586 4897 4476 2874 3818  359 2973 4213 4989
 5401 5356 3972  820 4652 1913  545 4283  285 2226 2970 3446 3619 3583
  222  943 4100 4197 3006 1300 4786 2253  895 3686 1666 2987 1256 2204
 5705  308 1122  634 3964   44 3883 4221 1494 5629 1960 3610 3803 5197
 1735 2993 2389 1926 1897    4 2441 4499 5259 2295 4796 1413 5310  795
  343  927 1131 2838 3593 3679 4461 3618  447 5605 1435 1710  745 3917
 5463  101 3687 4929]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.29973259568214417, 'test_f1': 0.6699751861042182, 'test_prec': 0.6852791878172588, 'test_recall': 0.6553398058252428, 'labeled_instances': 200, 'train_positive_rate': 0.105, 'pool_positive_rate': 0.10734259426303445, 'iteration_time': 473.02807235717773}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3172580599784851, 'test_f1': 0.6422535211267606, 'test_prec': 0.7651006711409396, 'test_recall': 0.5533980582524272, 'labeled_instances': 240, 'train_positive_rate': 0.10833333333333334, 'pool_positive_rate': 0.10721424677448664, 'iteration_time': 468.021516084671}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.32642844319343567, 'test_f1': 0.5362776025236593, 'test_prec': 0.7657657657657657, 'test_recall': 0.41262135922330095, 'labeled_instances': 280, 'train_positive_rate': 0.09642857142857143, 'pool_positive_rate': 0.10781621819513088, 'iteration_time': 451.75155687332153}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3861961364746094, 'test_f1': 0.5856697819314642, 'test_prec': 0.8173913043478261, 'test_recall': 0.4563106796116505, 'labeled_instances': 320, 'train_positive_rate': 0.096875, 'pool_positive_rate': 0.10787387055135533, 'iteration_time': 464.3577468395233}
| ID | GPU | MEM |
------------------
|  0 |  1% | 21% |

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.23221218585968018, 'test_f1': 0.74934036939314, 'test_prec': 0.8208092485549133, 'test_recall': 0.6893203883495146, 'labeled_instances': 360, 'train_positive_rate': 0.09722222222222222, 'pool_positive_rate': 0.10793237971391417, 'iteration_time': 460.2558536529541}
| ID | GPU | MEM |
------------------
|  0 | 16% | 21% |

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3651454448699951, 'test_f1': 0.4620462046204621, 'test_prec': 0.7216494845360825, 'test_recall': 0.33980582524271846, 'labeled_instances': 400, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10780460415496912, 'iteration_time': 459.3944809436798}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.23302341997623444, 'test_f1': 0.6970509383378016, 'test_prec': 0.7784431137724551, 'test_recall': 0.6310679611650486, 'labeled_instances': 440, 'train_positive_rate': 0.10227272727272728, 'pool_positive_rate': 0.10767490099943429, 'iteration_time': 467.3840436935425}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.18910914659500122, 'test_f1': 0.7645569620253165, 'test_prec': 0.798941798941799, 'test_recall': 0.7330097087378641, 'labeled_instances': 480, 'train_positive_rate': 0.09791666666666667, 'pool_positive_rate': 0.10811324339730193, 'iteration_time': 467.76571226119995}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.21690917015075684, 'test_f1': 0.7626262626262628, 'test_prec': 0.7947368421052632, 'test_recall': 0.7330097087378641, 'labeled_instances': 520, 'train_positive_rate': 0.09807692307692308, 'pool_positive_rate': 0.10817537813517136, 'iteration_time': 489.97778034210205}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 560
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.22039839625358582, 'test_f1': 0.7213930348258706, 'test_prec': 0.7397959183673469, 'test_recall': 0.7038834951456311, 'labeled_instances': 560, 'train_positive_rate': 0.09821428571428571, 'pool_positive_rate': 0.10823847192745514, 'iteration_time': 501.0786464214325}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.20791231095790863, 'test_f1': 0.7407407407407407, 'test_prec': 0.896551724137931, 'test_recall': 0.6310679611650486, 'labeled_instances': 600, 'train_positive_rate': 0.09333333333333334, 'pool_positive_rate': 0.10888586428154773, 'iteration_time': 469.7810175418854}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3368093967437744, 'test_f1': 0.45079365079365086, 'test_prec': 0.6513761467889908, 'test_recall': 0.3446601941747573, 'labeled_instances': 640, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.10895551636292378, 'iteration_time': 459.68848991394043}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.23102045059204102, 'test_f1': 0.7347826086956522, 'test_prec': 0.6653543307086615, 'test_recall': 0.8203883495145631, 'labeled_instances': 680, 'train_positive_rate': 0.09558823529411764, 'pool_positive_rate': 0.10882875765356508, 'iteration_time': 476.0202236175537}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2171160876750946, 'test_f1': 0.7712765957446809, 'test_prec': 0.8529411764705882, 'test_recall': 0.7038834951456311, 'labeled_instances': 720, 'train_positive_rate': 0.10138888888888889, 'pool_positive_rate': 0.10810272745371292, 'iteration_time': 501.266149520874}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.20788848400115967, 'test_f1': 0.7425742574257427, 'test_prec': 0.7575757575757576, 'test_recall': 0.7281553398058253, 'labeled_instances': 760, 'train_positive_rate': 0.10394736842105264, 'pool_positive_rate': 0.10776640577965081, 'iteration_time': 493.01126170158386}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.20937488973140717, 'test_f1': 0.7796610169491525, 'test_prec': 0.7777777777777778, 'test_recall': 0.7815533980582524, 'labeled_instances': 800, 'train_positive_rate': 0.10375, 'pool_positive_rate': 0.10782925348978353, 'iteration_time': 518.2561256885529}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3511587381362915, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 840, 'train_positive_rate': 0.10357142857142858, 'pool_positive_rate': 0.10789312665714869, 'iteration_time': 499.91762948036194}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.19374924898147583, 'test_f1': 0.8118811881188118, 'test_prec': 0.8282828282828283, 'test_recall': 0.7961165048543689, 'labeled_instances': 880, 'train_positive_rate': 0.10340909090909091, 'pool_positive_rate': 0.107958050586058, 'iteration_time': 533.3011643886566}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.15005110204219818, 'test_f1': 0.8091603053435115, 'test_prec': 0.8502673796791443, 'test_recall': 0.7718446601941747, 'labeled_instances': 920, 'train_positive_rate': 0.10108695652173913, 'pool_positive_rate': 0.10843873108024052, 'iteration_time': 533.4757537841797}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.19819073379039764, 'test_f1': 0.8089330024813897, 'test_prec': 0.8274111675126904, 'test_recall': 0.7912621359223301, 'labeled_instances': 960, 'train_positive_rate': 0.10208333333333333, 'pool_positive_rate': 0.10830022998118335, 'iteration_time': 531.1804735660553}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 1000
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.15608304738998413, 'test_f1': 0.8333333333333333, 'test_prec': 0.8177570093457944, 'test_recall': 0.8495145631067961, 'labeled_instances': 1000, 'train_positive_rate': 0.101, 'pool_positive_rate': 0.10858106683533629, 'iteration_time': 523.058212518692}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 5743
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1188846156001091, 'test_f1': 0.8872549019607844, 'test_prec': 0.8960396039603961, 'test_recall': 0.8786407766990292, 'labeled_instances': 5743, 'train_positive_rate': 0.10726101340762667, 'pool_positive_rate': 0.10726101340762667, 'iteration_time': 910.9516723155975}
New cross validation 2, for  <function deepmatcher_textual_abt_buy at 0x1519b4516670>
| ID | GPU | MEM |
------------------
|  0 |  6% | 21% |

Test : 0
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.0859093889594078, 'test_f1': 0.92, 'test_prec': 0.9484536082474226, 'test_recall': 0.8932038834951457, 'labeled_instances': 0, 'train_positive_rate': 0.10726101340762667, 'pool_positive_rate': 0.10726101340762667, 'iteration_time': 902.3137392997742}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 20
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.33725881576538086, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 20, 'train_positive_rate': 0.15, 'pool_positive_rate': 0.10711165472654202, 'iteration_time': 425.27569556236267}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 40
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3656158447265625, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 40, 'train_positive_rate': 0.075, 'pool_positive_rate': 0.10748728739260038, 'iteration_time': 475.3210816383362}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.34187307953834534, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.08333333333333333, 'pool_positive_rate': 0.10751363716347, 'iteration_time': 443.7195670604706}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4348655641078949, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 80, 'train_positive_rate': 0.075, 'pool_positive_rate': 0.107716757902172, 'iteration_time': 433.3275818824768}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.468796968460083, 'test_f1': 0.1391304347826087, 'test_prec': 0.6666666666666666, 'test_recall': 0.07766990291262135, 'labeled_instances': 100, 'train_positive_rate': 0.09, 'pool_positive_rate': 0.10756689704058126, 'iteration_time': 451.74328660964966}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3490995168685913, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 120, 'train_positive_rate': 0.075, 'pool_positive_rate': 0.1079494931531211, 'iteration_time': 450.98735666275024}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 140
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.46708598732948303, 'test_f1': 0.35877862595419846, 'test_prec': 0.8392857142857143, 'test_recall': 0.22815533980582525, 'labeled_instances': 140, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10744244154917008, 'iteration_time': 459.8144226074219}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 160
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.275247722864151, 'test_f1': 0.5796178343949044, 'test_prec': 0.8425925925925926, 'test_recall': 0.441747572815534, 'labeled_instances': 160, 'train_positive_rate': 0.10625, 'pool_positive_rate': 0.10728998746193803, 'iteration_time': 436.09239745140076}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3389839828014374, 'test_f1': 0.37735849056603776, 'test_prec': 0.847457627118644, 'test_recall': 0.24271844660194175, 'labeled_instances': 180, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10749595541973755, 'iteration_time': 434.69187784194946}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 200
-- Random test --

[2264 3677  839 5264 5437  277 4238 4505   88 2729 3170 5635 1069 3126
 3676 5695  989  619 4750 1156 5326 3331 5661 1082 4404  257 3467 5636
  213 5057 4970 4464 2906 2926 5121 4773  811 1807 2414   72 2106    3
 3950 4433 1836 1619 1135 4302 4927 2900 3166  922 3952 3659 3793 1972
 1291 2479 3656 4226 5447 4171 2224 5319 3187  463 3499 5492 1146 1304
 3427   15 3672 4809 3937 1379 3701 2922 2118 1794 1706 4952  380  683
 4820 1279 2601 1744 2726 1558 2425 2387 2714 4001 1614  809  696  587
 2072 3179 2057 2532 2975   27 4173 1894 2995 4503 4082 4108  721 4725
 4104 3946 1760  963 1821 3815 2183 3209  338 3292 3409  582  936 2958
 5734 4429 5476 4308  112 1560  385 3245 3303 1746 2917 5314 3249 3712
  925 4957 3084 1838 5137 2253 1996 3036 5486 3481 5054 3533  938 1599
 4272 2641 4454 4328 5354 2398 1561 2184 4863  273 3813 4541 4172 5475
  399 1017 1650 5460 2296 4878 3081  705 5235 4609 1840 5639 1395 3178
 3896 5614  921  887 3045 5540 1187 1608 1597 5052 2046  562  207 4823
  489  499 5563 1945]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.28700685501098633, 'test_f1': 0.6686567164179104, 'test_prec': 0.8682170542635659, 'test_recall': 0.5436893203883495, 'labeled_instances': 200, 'train_positive_rate': 0.09, 'pool_positive_rate': 0.1078838174273859, 'iteration_time': 442.8300359249115}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.40272945165634155, 'test_f1': 0.42, 'test_prec': 0.6702127659574468, 'test_recall': 0.3058252427184466, 'labeled_instances': 240, 'train_positive_rate': 0.09166666666666666, 'pool_positive_rate': 0.1079411230238052, 'iteration_time': 489.3447675704956}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
502 Server Error: Bad Gateway for url: https://huggingface.co/roberta-base/resolve/main/config.json
{'test_loss': 0.3824443519115448, 'test_f1': 0.4090909090909091, 'test_prec': 0.9310344827586207, 'test_recall': 0.2621359223300971, 'labeled_instances': 280, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10763316858868753, 'iteration_time': 616.5753397941589}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/transformers/configuration_utils.py", line 417, in get_config_dict
    resolved_config_file = cached_path(
  File "/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/transformers/file_utils.py", line 1078, in cached_path
    output_path = get_from_cache(
  File "/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/transformers/file_utils.py", line 1216, in get_from_cache
    r.raise_for_status()
  File "/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/requests/models.py", line 943, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 502 Server Error: Bad Gateway for url: https://huggingface.co/roberta-base/resolve/main/config.json

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "script-experiment-0.py", line 599, in <module>
    run()
  File "script-experiment-0.py", line 555, in run
    result = do_transformer(d, bert_model, train_batch_size, max_epochs)
  File "script-experiment-0.py", line 482, in do_transformer
    data_module.setup()
  File "/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py", line 92, in wrapped_fn
    return fn(*args, **kwargs)
  File "script-experiment-0.py", line 349, in setup
    self._train = BertEntityMatchingDataset(self._dataset.records_a, self._dataset.records_b, self._dataset.matches_train, self.bert_model)
  File "script-experiment-0.py", line 309, in __init__
    self.tokenizer = AutoTokenizer.from_pretrained(bert_model, use_fast=True)
  File "/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py", line 362, in from_pretrained
    config = AutoConfig.from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py", line 368, in from_pretrained
    config_dict, _ = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/transformers/configuration_utils.py", line 436, in get_config_dict
    raise EnvironmentError(msg)
OSError: Can't load config for 'roberta-base'. Make sure that:

- 'roberta-base' is a correct model identifier listed on 'https://huggingface.co/models'

- or 'roberta-base' is the correct path to a directory containing a config.json file


Python crashed
End of job!
