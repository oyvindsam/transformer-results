We are running from this directory: /cluster/work/oyvinsam
The name of the job is: alt-0
The job ID is 179637
The job was run on these nodes: idun-05-06
Number of nodes: 1
We are using 1 cores
We are using 1 cores per node
Total of 1 cores
Fri Apr 16 09:57:24 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.27.04    Driver Version: 460.27.04    CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-PCIE...  Off  | 00000000:D8:00.0 Off |                    0 |
| N/A   41C    P0    35W / 250W |      0MiB / 16160MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
Launch Python
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
Could not create dir out, File exists
[0, 20, 40, 60, 80, 100, 120, 140, 160, 180, 200, 240, 280, 320, 360, 400, 440, 480, 520, 560, 600, 640, 680, 720, 760, 800, 840, 880, 920, 960, 1000]




    ###########  New Dataset: <function deepmatcher_textual_abt_buy at 0x1470b7e35670>
New cross validation 0, for  <function deepmatcher_textual_abt_buy at 0x1470b7e35670>
| ID | GPU | MEM |
------------------
|  0 |  3% |  0% |

Test : 0
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.12589897215366364, 'test_f1': 0.8823529411764707, 'test_prec': 0.8910891089108911, 'test_recall': 0.8737864077669902, 'labeled_instances': 0, 'train_positive_rate': 0.10726101340762667, 'pool_positive_rate': 0.10726101340762667, 'iteration_time': 611.0084154605865}
| ID | GPU | MEM |
------------------
|  0 |  8% | 21% |

Test : 20
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.5779456496238708, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 20, 'train_positive_rate': 0.0, 'pool_positive_rate': 0.10763585532063603, 'iteration_time': 179.16636061668396}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 40
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3356981873512268, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 40, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10731194108364019, 'iteration_time': 197.1780924797058}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.34161561727523804, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10733767376385711, 'iteration_time': 193.16591691970825}
| ID | GPU | MEM |
------------------
|  0 | 19% | 21% |

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.33014747500419617, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 80, 'train_positive_rate': 0.125, 'pool_positive_rate': 0.10701041850609218, 'iteration_time': 193.98579668998718}
| ID | GPU | MEM |
------------------
|  0 | 14% | 21% |

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3379960060119629, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 100, 'train_positive_rate': 0.11, 'pool_positive_rate': 0.10721247563352826, 'iteration_time': 200.8518466949463}
| ID | GPU | MEM |
------------------
|  0 | 25% | 33% |

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3749614655971527, 'test_f1': 0.07003891050583658, 'test_prec': 0.17647058823529413, 'test_recall': 0.043689320388349516, 'labeled_instances': 120, 'train_positive_rate': 0.10833333333333334, 'pool_positive_rate': 0.10723812911257335, 'iteration_time': 209.95773482322693}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.49607816338539124, 'test_f1': 0.11764705882352942, 'test_prec': 0.4375, 'test_recall': 0.06796116504854369, 'labeled_instances': 140, 'train_positive_rate': 0.10714285714285714, 'pool_positive_rate': 0.10726396573264323, 'iteration_time': 215.59874939918518}
| ID | GPU | MEM |
------------------
|  0 | 24% | 21% |

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.33483627438545227, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 160, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10746910263299302, 'iteration_time': 217.59292101860046}
| ID | GPU | MEM |
------------------
|  0 | 25% | 21% |

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.5227358937263489, 'test_f1': 0.07258064516129031, 'test_prec': 0.21428571428571427, 'test_recall': 0.043689320388349516, 'labeled_instances': 180, 'train_positive_rate': 0.1111111111111111, 'pool_positive_rate': 0.1071364371741866, 'iteration_time': 217.26250910758972}
| ID | GPU | MEM |
------------------
|  0 | 25% | 21% |

Test : 200
-- Random test --

[1625 4299 1824   29 1096  502 2588  499 3713 3083 2587 5315 1203 4189
  608 5594 3054 3439 4380 1722 4255  818 4483 4138  530 4601 4852 5712
 1029 5058 1001 3667 2729 3167  629 5013 2244 3502  965 3294 4399 5695
 2177  776 3916   15 5027 2818 1142 4125 3855 2661 3874 5674 4345  773
   98 4727 2513 2339 2920  472 1839  977 4322 4694 4411  286  751 2707
 3350 2730 1746 4928 3225 4805  531 5714 5187 1172 3417 3307  444 5373
 5511  142 4770 1519 2278 5546 4570 4386  144 1008  882 1833 4084  825
 5070 4899 4166 1710 2060 4504 3462 1505 3657 1332 5260 2285  949 4252
 2048 1411 2644 3312 3885 1982 4576 3326 5514 5007 5394 4282 1595 5211
 2553 2946 5376 1859 4224 1850 1715 2523 1855 1281 2381 5093 1095  642
 5322 1668 1687 3460 3698 1022 5584 4730  379 4185 3714  405 4913   14
 1829 2087  388 4228 1014 3653 2243 2760  202 2655  527 5380 2844 5228
 1108 3565 3497 4265 3390 2998 4653 4200  257  895 5561 4181 5173 4764
  311 1593 4514  143 3327 4401 1421 4291 5640 2027 1515   39 3629 5619
 2913 2972 4842 5646]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.37219586968421936, 'test_f1': 0.15172413793103448, 'test_prec': 0.2619047619047619, 'test_recall': 0.10679611650485436, 'labeled_instances': 200, 'train_positive_rate': 0.115, 'pool_positive_rate': 0.1069817788201335, 'iteration_time': 213.23909211158752}
| ID | GPU | MEM |
------------------
|  0 | 25% | 21% |

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3430751860141754, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 240, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10757768489914592, 'iteration_time': 217.81488251686096}
| ID | GPU | MEM |
------------------
|  0 | 24% | 33% |

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4044666588306427, 'test_f1': 0.38526912181303113, 'test_prec': 0.46258503401360546, 'test_recall': 0.3300970873786408, 'labeled_instances': 280, 'train_positive_rate': 0.11071428571428571, 'pool_positive_rate': 0.1070840197693575, 'iteration_time': 219.63114976882935}
| ID | GPU | MEM |
------------------
|  0 | 19% | 33% |

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.24387742578983307, 'test_f1': 0.654054054054054, 'test_prec': 0.7378048780487805, 'test_recall': 0.587378640776699, 'labeled_instances': 320, 'train_positive_rate': 0.1125, 'pool_positive_rate': 0.10695187165775401, 'iteration_time': 227.3320128917694}
| ID | GPU | MEM |
------------------
|  0 | 25% | 33% |

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.21236000955104828, 'test_f1': 0.6927374301675977, 'test_prec': 0.8157894736842105, 'test_recall': 0.6019417475728155, 'labeled_instances': 360, 'train_positive_rate': 0.11388888888888889, 'pool_positive_rate': 0.10681775961359836, 'iteration_time': 242.89640641212463}
| ID | GPU | MEM |
------------------
|  0 | 17% | 21% |

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.25270876288414, 'test_f1': 0.6648351648351648, 'test_prec': 0.7658227848101266, 'test_recall': 0.587378640776699, 'labeled_instances': 400, 'train_positive_rate': 0.1075, 'pool_positive_rate': 0.10724312184166199, 'iteration_time': 239.4941349029541}
| ID | GPU | MEM |
------------------
|  0 | 24% | 21% |

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2778312563896179, 'test_f1': 0.6702702702702702, 'test_prec': 0.7560975609756098, 'test_recall': 0.6019417475728155, 'labeled_instances': 440, 'train_positive_rate': 0.10909090909090909, 'pool_positive_rate': 0.10710918348104846, 'iteration_time': 241.59776782989502}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3833063244819641, 'test_f1': 0.44931506849315067, 'test_prec': 0.5157232704402516, 'test_recall': 0.39805825242718446, 'labeled_instances': 480, 'train_positive_rate': 0.10208333333333333, 'pool_positive_rate': 0.1077332319969599, 'iteration_time': 235.4535129070282}
| ID | GPU | MEM |
------------------
|  0 | 25% | 33% |

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.23459620773792267, 'test_f1': 0.7741935483870968, 'test_prec': 0.7918781725888325, 'test_recall': 0.7572815533980582, 'labeled_instances': 520, 'train_positive_rate': 0.1076923076923077, 'pool_positive_rate': 0.10721807390388666, 'iteration_time': 248.85926985740662}
| ID | GPU | MEM |
------------------
|  0 | 25% | 33% |

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2341277152299881, 'test_f1': 0.7121212121212122, 'test_prec': 0.7421052631578947, 'test_recall': 0.6844660194174758, 'labeled_instances': 560, 'train_positive_rate': 0.1125, 'pool_positive_rate': 0.10669496430638627, 'iteration_time': 251.83830857276917}
| ID | GPU | MEM |
------------------
|  0 | 19% | 33% |

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2343396097421646, 'test_f1': 0.7205882352941176, 'test_prec': 0.7277227722772277, 'test_recall': 0.7135922330097088, 'labeled_instances': 600, 'train_positive_rate': 0.11, 'pool_positive_rate': 0.10694147384794866, 'iteration_time': 253.613911151886}
| ID | GPU | MEM |
------------------
|  0 | 25% | 33% |

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.25965791940689087, 'test_f1': 0.7785888077858881, 'test_prec': 0.7804878048780488, 'test_recall': 0.7766990291262136, 'labeled_instances': 640, 'train_positive_rate': 0.109375, 'pool_positive_rate': 0.10699588477366255, 'iteration_time': 255.69820928573608}
| ID | GPU | MEM |
------------------
|  0 | 24% | 33% |

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.19490888714790344, 'test_f1': 0.7823960880195598, 'test_prec': 0.7881773399014779, 'test_recall': 0.7766990291262136, 'labeled_instances': 680, 'train_positive_rate': 0.11029411764705882, 'pool_positive_rate': 0.10685364408453486, 'iteration_time': 269.72172355651855}
| ID | GPU | MEM |
------------------
|  0 | 24% | 33% |

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.17520801723003387, 'test_f1': 0.8103896103896103, 'test_prec': 0.8715083798882681, 'test_recall': 0.7572815533980582, 'labeled_instances': 720, 'train_positive_rate': 0.10972222222222222, 'pool_positive_rate': 0.10690822217798128, 'iteration_time': 275.80998277664185}
| ID | GPU | MEM |
------------------
|  0 | 25% | 21% |

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.21155275404453278, 'test_f1': 0.7885117493472584, 'test_prec': 0.8531073446327684, 'test_recall': 0.7330097087378641, 'labeled_instances': 760, 'train_positive_rate': 0.11315789473684211, 'pool_positive_rate': 0.10636162954043749, 'iteration_time': 281.0600564479828}
| ID | GPU | MEM |
------------------
|  0 | 24% | 21% |

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.21103346347808838, 'test_f1': 0.7896103896103895, 'test_prec': 0.8491620111731844, 'test_recall': 0.7378640776699029, 'labeled_instances': 800, 'train_positive_rate': 0.11625, 'pool_positive_rate': 0.10580619057252681, 'iteration_time': 286.07017493247986}
| ID | GPU | MEM |
------------------
|  0 | 25% | 21% |

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2238706797361374, 'test_f1': 0.797979797979798, 'test_prec': 0.8315789473684211, 'test_recall': 0.7669902912621359, 'labeled_instances': 840, 'train_positive_rate': 0.11666666666666667, 'pool_positive_rate': 0.10564960228431572, 'iteration_time': 281.4982810020447}
| ID | GPU | MEM |
------------------
|  0 | 24% | 21% |

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2056402862071991, 'test_f1': 0.7760416666666666, 'test_prec': 0.8370786516853933, 'test_recall': 0.7233009708737864, 'labeled_instances': 880, 'train_positive_rate': 0.1159090909090909, 'pool_positive_rate': 0.10569607238330249, 'iteration_time': 282.5398006439209}
| ID | GPU | MEM |
------------------
|  0 | 24% | 21% |

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.19635722041130066, 'test_f1': 0.7960199004975125, 'test_prec': 0.8163265306122449, 'test_recall': 0.7766990291262136, 'labeled_instances': 920, 'train_positive_rate': 0.11847826086956521, 'pool_positive_rate': 0.10512129380053908, 'iteration_time': 291.41181778907776}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.18598884344100952, 'test_f1': 0.8232323232323232, 'test_prec': 0.8578947368421053, 'test_recall': 0.7912621359223301, 'labeled_instances': 960, 'train_positive_rate': 0.11770833333333333, 'pool_positive_rate': 0.10516412293539619, 'iteration_time': 297.0689437389374}
| ID | GPU | MEM |
------------------
|  0 | 24% | 21% |

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.13021951913833618, 'test_f1': 0.8467532467532468, 'test_prec': 0.9106145251396648, 'test_recall': 0.7912621359223301, 'labeled_instances': 1000, 'train_positive_rate': 0.115, 'pool_positive_rate': 0.105629348513599, 'iteration_time': 282.6022901535034}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 5743
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1152629554271698, 'test_f1': 0.8921568627450982, 'test_prec': 0.900990099009901, 'test_recall': 0.883495145631068, 'labeled_instances': 5743, 'train_positive_rate': 0.10726101340762667, 'pool_positive_rate': 0.10726101340762667, 'iteration_time': 656.8894627094269}
New cross validation 1, for  <function deepmatcher_textual_abt_buy at 0x1470b7e35670>
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 0
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.11788787692785263, 'test_f1': 0.8953771289537714, 'test_prec': 0.8975609756097561, 'test_recall': 0.8932038834951457, 'labeled_instances': 0, 'train_positive_rate': 0.10726101340762667, 'pool_positive_rate': 0.10726101340762667, 'iteration_time': 643.4302537441254}
| ID | GPU | MEM |
------------------
|  0 | 25% | 21% |

Test : 20
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.38589707016944885, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 20, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10728638825790669, 'iteration_time': 206.95928931236267}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 40
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.33238211274147034, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 40, 'train_positive_rate': 0.125, 'pool_positive_rate': 0.10713659477467999, 'iteration_time': 229.37671208381653}
| ID | GPU | MEM |
------------------
|  0 | 24% | 21% |

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4195164144039154, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.11666666666666667, 'pool_positive_rate': 0.10716171036424424, 'iteration_time': 210.79908514022827}
| ID | GPU | MEM |
------------------
|  0 | 24% | 21% |

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4611234664916992, 'test_f1': 0.009174311926605505, 'test_prec': 0.08333333333333333, 'test_recall': 0.0048543689320388345, 'labeled_instances': 80, 'train_positive_rate': 0.0875, 'pool_positive_rate': 0.10754017305315204, 'iteration_time': 211.60517501831055}
| ID | GPU | MEM |
------------------
|  0 | 24% | 33% |

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.341320276260376, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 100, 'train_positive_rate': 0.11, 'pool_positive_rate': 0.10721247563352826, 'iteration_time': 219.64339327812195}
| ID | GPU | MEM |
------------------
|  0 | 25% | 33% |

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3679325580596924, 'test_f1': 0.05882352941176471, 'test_prec': 0.21875, 'test_recall': 0.03398058252427184, 'labeled_instances': 120, 'train_positive_rate': 0.10833333333333334, 'pool_positive_rate': 0.10723812911257335, 'iteration_time': 227.2549159526825}
| ID | GPU | MEM |
------------------
|  0 | 25% | 33% |

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4871261417865753, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 140, 'train_positive_rate': 0.11428571428571428, 'pool_positive_rate': 0.10708548991611637, 'iteration_time': 230.93458080291748}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3110273778438568, 'test_f1': 0.3745819397993311, 'test_prec': 0.6021505376344086, 'test_recall': 0.27184466019417475, 'labeled_instances': 160, 'train_positive_rate': 0.125, 'pool_positive_rate': 0.10675264194877306, 'iteration_time': 229.91248178482056}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.36121153831481934, 'test_f1': 0.5609756097560975, 'test_prec': 0.7540983606557377, 'test_recall': 0.44660194174757284, 'labeled_instances': 180, 'train_positive_rate': 0.1111111111111111, 'pool_positive_rate': 0.1071364371741866, 'iteration_time': 243.32514309883118}
| ID | GPU | MEM |
------------------
|  0 | 25% | 21% |

Test : 200
-- Random test --

[2667 5575 4388 1078 3771  301 1271 1079 3286  573  141 3032 1412 5036
 2796  503 5347 3423 1637  147 1370 3662 3602 1387  233 3073 2537  428
  958 3924 4728 5584 2678 2429 2076 3768 3839 1016  259  169 3243 2781
 3016 4479 4515 5089 4475 5110  314 1988 4639   21 2228 3414  386  116
 4741 2921 4538 4038 1437 1321  496  354 2450  899 4721 1296 4632  200
 5263 3503  840 1232 4573 3067 5082 3003 1519 4579  940 4040  407 1073
 5295 2624 4577 3017 4746 1289 4706 2787 2353 2246 5093 4408 3220  383
 2019 4820 5409 5008 2726 2360 2708 1723 4966 3387  255 2706  784 2103
 4826 5447 2036 3447 3603 3586 4897 4476 2874 3818  359 2973 4213 4989
 5401 5356 3972  820 4652 1913  545 4283  285 2226 2970 3446 3619 3583
  222  943 4100 4197 3006 1300 4786 2253  895 3686 1666 2987 1256 2204
 5705  308 1122  634 3964   44 3883 4221 1494 5629 1960 3610 3803 5197
 1735 2993 2389 1926 1897    4 2441 4499 5259 2295 4796 1413 5310  795
  343  927 1131 2838 3593 3679 4461 3618  447 5605 1435 1710  745 3917
 5463  101 3687 4929]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.29973259568214417, 'test_f1': 0.6699751861042182, 'test_prec': 0.6852791878172588, 'test_recall': 0.6553398058252428, 'labeled_instances': 200, 'train_positive_rate': 0.105, 'pool_positive_rate': 0.10734259426303445, 'iteration_time': 241.0724105834961}
| ID | GPU | MEM |
------------------
|  0 | 24% | 21% |

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3172580599784851, 'test_f1': 0.6422535211267606, 'test_prec': 0.7651006711409396, 'test_recall': 0.5533980582524272, 'labeled_instances': 240, 'train_positive_rate': 0.10833333333333334, 'pool_positive_rate': 0.10721424677448664, 'iteration_time': 240.31028723716736}
| ID | GPU | MEM |
------------------
|  0 | 10% | 33% |

Test : 280
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.32642844319343567, 'test_f1': 0.5362776025236593, 'test_prec': 0.7657657657657657, 'test_recall': 0.41262135922330095, 'labeled_instances': 280, 'train_positive_rate': 0.09642857142857143, 'pool_positive_rate': 0.10781621819513088, 'iteration_time': 249.62125849723816}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3861961364746094, 'test_f1': 0.5856697819314642, 'test_prec': 0.8173913043478261, 'test_recall': 0.4563106796116505, 'labeled_instances': 320, 'train_positive_rate': 0.096875, 'pool_positive_rate': 0.10787387055135533, 'iteration_time': 257.7010066509247}
| ID | GPU | MEM |
------------------
|  0 | 10% | 33% |

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.23221218585968018, 'test_f1': 0.74934036939314, 'test_prec': 0.8208092485549133, 'test_recall': 0.6893203883495146, 'labeled_instances': 360, 'train_positive_rate': 0.09722222222222222, 'pool_positive_rate': 0.10793237971391417, 'iteration_time': 271.36284255981445}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3651454448699951, 'test_f1': 0.4620462046204621, 'test_prec': 0.7216494845360825, 'test_recall': 0.33980582524271846, 'labeled_instances': 400, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10780460415496912, 'iteration_time': 280.1667513847351}
| ID | GPU | MEM |
------------------
|  0 | 23% | 33% |

Test : 440
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.23302341997623444, 'test_f1': 0.6970509383378016, 'test_prec': 0.7784431137724551, 'test_recall': 0.6310679611650486, 'labeled_instances': 440, 'train_positive_rate': 0.10227272727272728, 'pool_positive_rate': 0.10767490099943429, 'iteration_time': 274.5210211277008}
| ID | GPU | MEM |
------------------
|  0 | 24% | 21% |

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.18910914659500122, 'test_f1': 0.7645569620253165, 'test_prec': 0.798941798941799, 'test_recall': 0.7330097087378641, 'labeled_instances': 480, 'train_positive_rate': 0.09791666666666667, 'pool_positive_rate': 0.10811324339730193, 'iteration_time': 277.0181140899658}
| ID | GPU | MEM |
------------------
|  0 | 24% | 21% |

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.21690917015075684, 'test_f1': 0.7626262626262628, 'test_prec': 0.7947368421052632, 'test_recall': 0.7330097087378641, 'labeled_instances': 520, 'train_positive_rate': 0.09807692307692308, 'pool_positive_rate': 0.10817537813517136, 'iteration_time': 282.11934781074524}
| ID | GPU | MEM |
------------------
|  0 |  2% | 21% |

Test : 560
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.22039839625358582, 'test_f1': 0.7213930348258706, 'test_prec': 0.7397959183673469, 'test_recall': 0.7038834951456311, 'labeled_instances': 560, 'train_positive_rate': 0.09821428571428571, 'pool_positive_rate': 0.10823847192745514, 'iteration_time': 276.19502663612366}
| ID | GPU | MEM |
------------------
|  0 |  9% | 21% |

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.20791231095790863, 'test_f1': 0.7407407407407407, 'test_prec': 0.896551724137931, 'test_recall': 0.6310679611650486, 'labeled_instances': 600, 'train_positive_rate': 0.09333333333333334, 'pool_positive_rate': 0.10888586428154773, 'iteration_time': 278.8898072242737}
| ID | GPU | MEM |
------------------
|  0 | 25% | 21% |

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3368093967437744, 'test_f1': 0.45079365079365086, 'test_prec': 0.6513761467889908, 'test_recall': 0.3446601941747573, 'labeled_instances': 640, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.10895551636292378, 'iteration_time': 282.3559715747833}
| ID | GPU | MEM |
------------------
|  0 | 25% | 21% |

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.23102045059204102, 'test_f1': 0.7347826086956522, 'test_prec': 0.6653543307086615, 'test_recall': 0.8203883495145631, 'labeled_instances': 680, 'train_positive_rate': 0.09558823529411764, 'pool_positive_rate': 0.10882875765356508, 'iteration_time': 295.78433203697205}
| ID | GPU | MEM |
------------------
|  0 | 23% | 21% |

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2171160876750946, 'test_f1': 0.7712765957446809, 'test_prec': 0.8529411764705882, 'test_recall': 0.7038834951456311, 'labeled_instances': 720, 'train_positive_rate': 0.10138888888888889, 'pool_positive_rate': 0.10810272745371292, 'iteration_time': 300.9627730846405}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.20788848400115967, 'test_f1': 0.7425742574257427, 'test_prec': 0.7575757575757576, 'test_recall': 0.7281553398058253, 'labeled_instances': 760, 'train_positive_rate': 0.10394736842105264, 'pool_positive_rate': 0.10776640577965081, 'iteration_time': 301.44538855552673}
| ID | GPU | MEM |
------------------
|  0 | 25% | 21% |

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.20937488973140717, 'test_f1': 0.7796610169491525, 'test_prec': 0.7777777777777778, 'test_recall': 0.7815533980582524, 'labeled_instances': 800, 'train_positive_rate': 0.10375, 'pool_positive_rate': 0.10782925348978353, 'iteration_time': 299.0897879600525}
| ID | GPU | MEM |
------------------
|  0 | 16% | 21% |

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3511587381362915, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 840, 'train_positive_rate': 0.10357142857142858, 'pool_positive_rate': 0.10789312665714869, 'iteration_time': 314.4240708351135}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 880
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.19374924898147583, 'test_f1': 0.8118811881188118, 'test_prec': 0.8282828282828283, 'test_recall': 0.7961165048543689, 'labeled_instances': 880, 'train_positive_rate': 0.10340909090909091, 'pool_positive_rate': 0.107958050586058, 'iteration_time': 317.20269894599915}
| ID | GPU | MEM |
------------------
|  0 | 24% | 21% |

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.15005110204219818, 'test_f1': 0.8091603053435115, 'test_prec': 0.8502673796791443, 'test_recall': 0.7718446601941747, 'labeled_instances': 920, 'train_positive_rate': 0.10108695652173913, 'pool_positive_rate': 0.10843873108024052, 'iteration_time': 327.56035804748535}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.19819073379039764, 'test_f1': 0.8089330024813897, 'test_prec': 0.8274111675126904, 'test_recall': 0.7912621359223301, 'labeled_instances': 960, 'train_positive_rate': 0.10208333333333333, 'pool_positive_rate': 0.10830022998118335, 'iteration_time': 328.156290769577}
| ID | GPU | MEM |
------------------
|  0 | 23% | 21% |

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.15608304738998413, 'test_f1': 0.8333333333333333, 'test_prec': 0.8177570093457944, 'test_recall': 0.8495145631067961, 'labeled_instances': 1000, 'train_positive_rate': 0.101, 'pool_positive_rate': 0.10858106683533629, 'iteration_time': 341.3266272544861}
| ID | GPU | MEM |
------------------
|  0 | 15% | 21% |

Test : 5743
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1188846156001091, 'test_f1': 0.8872549019607844, 'test_prec': 0.8960396039603961, 'test_recall': 0.8786407766990292, 'labeled_instances': 5743, 'train_positive_rate': 0.10726101340762667, 'pool_positive_rate': 0.10726101340762667, 'iteration_time': 679.201103925705}
New cross validation 2, for  <function deepmatcher_textual_abt_buy at 0x1470b7e35670>
| ID | GPU | MEM |
------------------
|  0 | 12% | 21% |

Test : 0
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.0859093889594078, 'test_f1': 0.92, 'test_prec': 0.9484536082474226, 'test_recall': 0.8932038834951457, 'labeled_instances': 0, 'train_positive_rate': 0.10726101340762667, 'pool_positive_rate': 0.10726101340762667, 'iteration_time': 695.0077052116394}
| ID | GPU | MEM |
------------------
|  0 | 24% | 21% |

Test : 20
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.33725881576538086, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 20, 'train_positive_rate': 0.15, 'pool_positive_rate': 0.10711165472654202, 'iteration_time': 250.99482607841492}
| ID | GPU | MEM |
------------------
|  0 | 19% | 21% |

Test : 40
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3656158447265625, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 40, 'train_positive_rate': 0.075, 'pool_positive_rate': 0.10748728739260038, 'iteration_time': 253.28684830665588}
| ID | GPU | MEM |
------------------
|  0 | 19% | 21% |

Test : 60
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.34187307953834534, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.08333333333333333, 'pool_positive_rate': 0.10751363716347, 'iteration_time': 247.231764793396}
| ID | GPU | MEM |
------------------
|  0 | 25% | 33% |

Test : 80
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4348655641078949, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 80, 'train_positive_rate': 0.075, 'pool_positive_rate': 0.107716757902172, 'iteration_time': 255.04353618621826}
| ID | GPU | MEM |
------------------
|  0 | 24% | 33% |

Test : 100
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.468796968460083, 'test_f1': 0.1391304347826087, 'test_prec': 0.6666666666666666, 'test_recall': 0.07766990291262135, 'labeled_instances': 100, 'train_positive_rate': 0.09, 'pool_positive_rate': 0.10756689704058126, 'iteration_time': 250.44883751869202}
| ID | GPU | MEM |
------------------
|  0 | 25% | 33% |

Test : 120
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3490995168685913, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 120, 'train_positive_rate': 0.075, 'pool_positive_rate': 0.1079494931531211, 'iteration_time': 275.82528829574585}
| ID | GPU | MEM |
------------------
|  0 | 25% | 33% |

Test : 140
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.46708598732948303, 'test_f1': 0.35877862595419846, 'test_prec': 0.8392857142857143, 'test_recall': 0.22815533980582525, 'labeled_instances': 140, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10744244154917008, 'iteration_time': 281.943888425827}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 160
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.275247722864151, 'test_f1': 0.5796178343949044, 'test_prec': 0.8425925925925926, 'test_recall': 0.441747572815534, 'labeled_instances': 160, 'train_positive_rate': 0.10625, 'pool_positive_rate': 0.10728998746193803, 'iteration_time': 278.16066122055054}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 180
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3389839828014374, 'test_f1': 0.37735849056603776, 'test_prec': 0.847457627118644, 'test_recall': 0.24271844660194175, 'labeled_instances': 180, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10749595541973755, 'iteration_time': 274.4448461532593}
| ID | GPU | MEM |
------------------
|  0 | 25% | 21% |

Test : 200
-- Random test --

[2264 3677  839 5264 5437  277 4238 4505   88 2729 3170 5635 1069 3126
 3676 5695  989  619 4750 1156 5326 3331 5661 1082 4404  257 3467 5636
  213 5057 4970 4464 2906 2926 5121 4773  811 1807 2414   72 2106    3
 3950 4433 1836 1619 1135 4302 4927 2900 3166  922 3952 3659 3793 1972
 1291 2479 3656 4226 5447 4171 2224 5319 3187  463 3499 5492 1146 1304
 3427   15 3672 4809 3937 1379 3701 2922 2118 1794 1706 4952  380  683
 4820 1279 2601 1744 2726 1558 2425 2387 2714 4001 1614  809  696  587
 2072 3179 2057 2532 2975   27 4173 1894 2995 4503 4082 4108  721 4725
 4104 3946 1760  963 1821 3815 2183 3209  338 3292 3409  582  936 2958
 5734 4429 5476 4308  112 1560  385 3245 3303 1746 2917 5314 3249 3712
  925 4957 3084 1838 5137 2253 1996 3036 5486 3481 5054 3533  938 1599
 4272 2641 4454 4328 5354 2398 1561 2184 4863  273 3813 4541 4172 5475
  399 1017 1650 5460 2296 4878 3081  705 5235 4609 1840 5639 1395 3178
 3896 5614  921  887 3045 5540 1187 1608 1597 5052 2046  562  207 4823
  489  499 5563 1945]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.28700685501098633, 'test_f1': 0.6686567164179104, 'test_prec': 0.8682170542635659, 'test_recall': 0.5436893203883495, 'labeled_instances': 200, 'train_positive_rate': 0.09, 'pool_positive_rate': 0.1078838174273859, 'iteration_time': 263.1272268295288}
| ID | GPU | MEM |
------------------
|  0 | 10% | 33% |

Test : 240
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.40272945165634155, 'test_f1': 0.42, 'test_prec': 0.6702127659574468, 'test_recall': 0.3058252427184466, 'labeled_instances': 240, 'train_positive_rate': 0.09166666666666666, 'pool_positive_rate': 0.1079411230238052, 'iteration_time': 270.35780477523804}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 280
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3824443519115448, 'test_f1': 0.4090909090909091, 'test_prec': 0.9310344827586207, 'test_recall': 0.2621359223300971, 'labeled_instances': 280, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10763316858868753, 'iteration_time': 296.0739622116089}
| ID | GPU | MEM |
------------------
|  0 | 20% | 33% |

Test : 320
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.18636947870254517, 'test_f1': 0.6648199445983379, 'test_prec': 0.7741935483870968, 'test_recall': 0.5825242718446602, 'labeled_instances': 320, 'train_positive_rate': 0.096875, 'pool_positive_rate': 0.10787387055135533, 'iteration_time': 306.833548784256}
| ID | GPU | MEM |
------------------
|  0 |  9% | 33% |

Test : 360
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.17935091257095337, 'test_f1': 0.7696202531645568, 'test_prec': 0.8042328042328042, 'test_recall': 0.7378640776699029, 'labeled_instances': 360, 'train_positive_rate': 0.10555555555555556, 'pool_positive_rate': 0.10737506966375628, 'iteration_time': 303.69457721710205}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 400
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.21924172341823578, 'test_f1': 0.7473118279569892, 'test_prec': 0.8373493975903614, 'test_recall': 0.6747572815533981, 'labeled_instances': 400, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10780460415496912, 'iteration_time': 325.38243651390076}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 440
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.20706884562969208, 'test_f1': 0.7422096317280454, 'test_prec': 0.891156462585034, 'test_recall': 0.6359223300970874, 'labeled_instances': 440, 'train_positive_rate': 0.09545454545454546, 'pool_positive_rate': 0.1082406185178201, 'iteration_time': 309.21435499191284}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 480
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.19111515581607819, 'test_f1': 0.7929292929292929, 'test_prec': 0.8263157894736842, 'test_recall': 0.7621359223300971, 'labeled_instances': 480, 'train_positive_rate': 0.09375, 'pool_positive_rate': 0.10849325479764393, 'iteration_time': 328.3045175075531}
| ID | GPU | MEM |
------------------
|  0 | 18% | 21% |

Test : 520
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.17899824678897858, 'test_f1': 0.7569060773480665, 'test_prec': 0.8782051282051282, 'test_recall': 0.6650485436893204, 'labeled_instances': 520, 'train_positive_rate': 0.09038461538461538, 'pool_positive_rate': 0.10894122152019912, 'iteration_time': 318.82147240638733}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 560
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.20338831841945648, 'test_f1': 0.8040712468193385, 'test_prec': 0.8449197860962567, 'test_recall': 0.7669902912621359, 'labeled_instances': 560, 'train_positive_rate': 0.09821428571428571, 'pool_positive_rate': 0.10823847192745514, 'iteration_time': 314.6774854660034}
| ID | GPU | MEM |
------------------
|  0 | 25% | 21% |

Test : 600
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.19709645211696625, 'test_f1': 0.8270676691729323, 'test_prec': 0.8549222797927462, 'test_recall': 0.8009708737864077, 'labeled_instances': 600, 'train_positive_rate': 0.105, 'pool_positive_rate': 0.10752479097802839, 'iteration_time': 309.9573595523834}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 640
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.22663576900959015, 'test_f1': 0.7700534759358288, 'test_prec': 0.8571428571428571, 'test_recall': 0.6990291262135923, 'labeled_instances': 640, 'train_positive_rate': 0.103125, 'pool_positive_rate': 0.10777973740936704, 'iteration_time': 314.27606081962585}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 680
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2326362133026123, 'test_f1': 0.7595628415300546, 'test_prec': 0.86875, 'test_recall': 0.6747572815533981, 'labeled_instances': 680, 'train_positive_rate': 0.10294117647058823, 'pool_positive_rate': 0.10784120086904997, 'iteration_time': 325.56112694740295}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 720
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.19637230038642883, 'test_f1': 0.6634146341463415, 'test_prec': 0.6666666666666666, 'test_recall': 0.6601941747572816, 'labeled_instances': 720, 'train_positive_rate': 0.1, 'pool_positive_rate': 0.10830181166633486, 'iteration_time': 315.4358379840851}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 760
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.182742640376091, 'test_f1': 0.7890818858560793, 'test_prec': 0.8071065989847716, 'test_recall': 0.7718446601941747, 'labeled_instances': 760, 'train_positive_rate': 0.09605263157894736, 'pool_positive_rate': 0.10897049969897651, 'iteration_time': 325.71686363220215}
| ID | GPU | MEM |
------------------
|  0 | 19% | 33% |

Test : 800
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1753850281238556, 'test_f1': 0.8345323741007193, 'test_prec': 0.8246445497630331, 'test_recall': 0.8446601941747572, 'labeled_instances': 800, 'train_positive_rate': 0.09875, 'pool_positive_rate': 0.10863847865668623, 'iteration_time': 331.2534291744232}
| ID | GPU | MEM |
------------------
|  0 | 25% | 33% |

Test : 840
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1658024787902832, 'test_f1': 0.7989556135770236, 'test_prec': 0.864406779661017, 'test_recall': 0.7427184466019418, 'labeled_instances': 840, 'train_positive_rate': 0.09523809523809523, 'pool_positive_rate': 0.10932082398531512, 'iteration_time': 346.4169223308563}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 880
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.19534441828727722, 'test_f1': 0.8303797468354431, 'test_prec': 0.8677248677248677, 'test_recall': 0.7961165048543689, 'labeled_instances': 880, 'train_positive_rate': 0.09545454545454546, 'pool_positive_rate': 0.10939749126053876, 'iteration_time': 361.15002250671387}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 920
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.16687582433223724, 'test_f1': 0.8350000000000001, 'test_prec': 0.8608247422680413, 'test_recall': 0.8106796116504854, 'labeled_instances': 920, 'train_positive_rate': 0.0967391304347826, 'pool_positive_rate': 0.10926809040016587, 'iteration_time': 335.1192214488983}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 960
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.16624341905117035, 'test_f1': 0.8374384236453202, 'test_prec': 0.85, 'test_recall': 0.8252427184466019, 'labeled_instances': 960, 'train_positive_rate': 0.09895833333333333, 'pool_positive_rate': 0.1089274513903408, 'iteration_time': 355.0081946849823}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 1000
-- Random test --

Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.17453816533088684, 'test_f1': 0.8177083333333334, 'test_prec': 0.8820224719101124, 'test_recall': 0.7621359223300971, 'labeled_instances': 1000, 'train_positive_rate': 0.102, 'pool_positive_rate': 0.10837022981235504, 'iteration_time': 356.7904086112976}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 5743
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.10629215091466904, 'test_f1': 0.9024390243902438, 'test_prec': 0.9068627450980392, 'test_recall': 0.8980582524271845, 'labeled_instances': 5743, 'train_positive_rate': 0.10726101340762667, 'pool_positive_rate': 0.10726101340762667, 'iteration_time': 737.0132303237915}
Could not create dir out, File exists




    ###########  New Dataset: <function deepmatcher_structured_itunes_amazon at 0x1470b7e353a0>
New cross validation 0, for  <function deepmatcher_structured_itunes_amazon at 0x1470b7e353a0>
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 0
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.13471554219722748, 'test_f1': 0.9433962264150944, 'test_prec': 0.9615384615384616, 'test_recall': 0.9259259259259259, 'labeled_instances': 0, 'train_positive_rate': 0.24299065420560748, 'pool_positive_rate': 0.24299065420560748, 'iteration_time': 250.3898847103119}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 20
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.6372767686843872, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 20, 'train_positive_rate': 0.15, 'pool_positive_rate': 0.24916943521594684, 'iteration_time': 208.6739456653595}
| ID | GPU | MEM |
------------------
|  0 |  0% | 46% |

Test : 40
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.8128156661987305, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 40, 'train_positive_rate': 0.075, 'pool_positive_rate': 0.2669039145907473, 'iteration_time': 240.20916986465454}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 60
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4482761323451996, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.15, 'pool_positive_rate': 0.26436781609195403, 'iteration_time': 236.2229061126709}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 80
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2101755440235138, 'test_f1': 0.9433962264150944, 'test_prec': 0.9615384615384616, 'test_recall': 0.9259259259259259, 'labeled_instances': 80, 'train_positive_rate': 0.1625, 'pool_positive_rate': 0.2697095435684647, 'iteration_time': 238.07522797584534}
| ID | GPU | MEM |
------------------
|  0 |  0% | 46% |

Test : 100
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3021291196346283, 'test_f1': 0.8800000000000001, 'test_prec': 0.9565217391304348, 'test_recall': 0.8148148148148148, 'labeled_instances': 100, 'train_positive_rate': 0.17, 'pool_positive_rate': 0.27601809954751133, 'iteration_time': 249.60760307312012}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 120
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2549148201942444, 'test_f1': 0.8928571428571429, 'test_prec': 0.8620689655172413, 'test_recall': 0.9259259259259259, 'labeled_instances': 120, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.26865671641791045, 'iteration_time': 241.6333384513855}
| ID | GPU | MEM |
------------------
|  0 | 14% | 33% |

Test : 140
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.18020054697990417, 'test_f1': 0.9259259259259259, 'test_prec': 0.9259259259259259, 'test_recall': 0.9259259259259259, 'labeled_instances': 140, 'train_positive_rate': 0.22142857142857142, 'pool_positive_rate': 0.2596685082872928, 'iteration_time': 242.43532133102417}
| ID | GPU | MEM |
------------------
|  0 | 13% | 45% |

Test : 160
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.14375796914100647, 'test_f1': 0.9310344827586207, 'test_prec': 0.8709677419354839, 'test_recall': 1.0, 'labeled_instances': 160, 'train_positive_rate': 0.23125, 'pool_positive_rate': 0.2546583850931677, 'iteration_time': 260.4594783782959}
| ID | GPU | MEM |
------------------
|  0 | 13% | 33% |

Test : 180
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.10103687644004822, 'test_f1': 0.9629629629629629, 'test_prec': 0.9629629629629629, 'test_recall': 0.9629629629629629, 'labeled_instances': 180, 'train_positive_rate': 0.24444444444444444, 'pool_positive_rate': 0.24113475177304963, 'iteration_time': 251.75992512702942}
| ID | GPU | MEM |
------------------
|  0 |  0% | 45% |

Test : 200
-- Random test --

[181 258  15  65 216  63 240 228 167 156  64 103 124 316 311  60 122 271
  66  26 286 158 136 293 164 200 272   7   6 230 254  22 152  21  55 157
  12 108  68 144 170 278  59 134 231  92 175 267  74  81 289 259 264  52
 133 176  56  90 248  17   1   8 150 206 209 140 217 194   5  33 280  34
 212 215 263 137  45 101 266 126 198 238 199 222 120 245 135  73 314 305
 116 255  29  97  20  46 213 262 313  89 250  27 320 312  37  54 236 260
 142 132 184 190 304 239 159 161  35 102  76 106 171 225 282 160 179 173
 302  44 145 129 226 111 188 166  18 196  79  71 168 269 308 146 189  83
 310 118 153 300 110 220  16  75 109 208 191 139   4  96 234  61  67 154
 301 235 253 299  40 221  13 107 233   3 210 125  24  30  77 297 223 219
  19 273 275 182 284  80  51   2  11 104 214  86  10 229 306  58  41  14
 155  50]
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.20350439846515656, 'test_f1': 0.8928571428571429, 'test_prec': 0.8620689655172413, 'test_recall': 0.9259259259259259, 'labeled_instances': 200, 'train_positive_rate': 0.26, 'pool_positive_rate': 0.21487603305785125, 'iteration_time': 251.23745226860046}
| ID | GPU | MEM |
------------------
|  0 | 13% | 21% |

Test : 240
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.12499817460775375, 'test_f1': 0.9433962264150944, 'test_prec': 0.9615384615384616, 'test_recall': 0.9259259259259259, 'labeled_instances': 240, 'train_positive_rate': 0.26666666666666666, 'pool_positive_rate': 0.1728395061728395, 'iteration_time': 252.11840629577637}
| ID | GPU | MEM |
------------------
|  0 | 14% | 33% |

Test : 280
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.17289651930332184, 'test_f1': 0.923076923076923, 'test_prec': 0.96, 'test_recall': 0.8888888888888888, 'labeled_instances': 280, 'train_positive_rate': 0.25357142857142856, 'pool_positive_rate': 0.17073170731707318, 'iteration_time': 248.17142844200134}
| ID | GPU | MEM |
------------------
|  0 | 13% | 46% |

Test : 320
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1835707426071167, 'test_f1': 0.923076923076923, 'test_prec': 0.96, 'test_recall': 0.8888888888888888, 'labeled_instances': 320, 'train_positive_rate': 0.24375, 'pool_positive_rate': 0.0, 'iteration_time': 254.274188041687}
| ID | GPU | MEM |
------------------
|  0 | 13% | 21% |

Test : 360
-- Random test --

New cross validation 1, for  <function deepmatcher_structured_itunes_amazon at 0x1470b7e353a0>
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 0
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.18551215529441833, 'test_f1': 0.9433962264150944, 'test_prec': 0.9615384615384616, 'test_recall': 0.9259259259259259, 'labeled_instances': 0, 'train_positive_rate': 0.24299065420560748, 'pool_positive_rate': 0.24299065420560748, 'iteration_time': 259.0762710571289}
| ID | GPU | MEM |
------------------
|  0 |  4% | 33% |

Test : 20
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.5902292728424072, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 20, 'train_positive_rate': 0.3, 'pool_positive_rate': 0.23920265780730898, 'iteration_time': 226.1065788269043}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 40
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4766530692577362, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 40, 'train_positive_rate': 0.25, 'pool_positive_rate': 0.24199288256227758, 'iteration_time': 239.3147850036621}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 60
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3231160640716553, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.23333333333333334, 'pool_positive_rate': 0.24521072796934865, 'iteration_time': 234.08415365219116}
| ID | GPU | MEM |
------------------
|  0 |  0% | 46% |

Test : 80
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.19783006608486176, 'test_f1': 0.9019607843137256, 'test_prec': 0.9583333333333334, 'test_recall': 0.8518518518518519, 'labeled_instances': 80, 'train_positive_rate': 0.225, 'pool_positive_rate': 0.24896265560165975, 'iteration_time': 239.26738619804382}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 100
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1838293820619583, 'test_f1': 0.923076923076923, 'test_prec': 0.96, 'test_recall': 0.8888888888888888, 'labeled_instances': 100, 'train_positive_rate': 0.23, 'pool_positive_rate': 0.248868778280543, 'iteration_time': 238.99906992912292}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 120
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.08069566637277603, 'test_f1': 0.9642857142857143, 'test_prec': 0.9310344827586207, 'test_recall': 1.0, 'labeled_instances': 120, 'train_positive_rate': 0.26666666666666666, 'pool_positive_rate': 0.22885572139303484, 'iteration_time': 235.7519724369049}
| ID | GPU | MEM |
------------------
|  0 | 14% | 46% |

Test : 140
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.08305887132883072, 'test_f1': 0.9433962264150944, 'test_prec': 0.9615384615384616, 'test_recall': 0.9259259259259259, 'labeled_instances': 140, 'train_positive_rate': 0.2785714285714286, 'pool_positive_rate': 0.2154696132596685, 'iteration_time': 244.71896481513977}
| ID | GPU | MEM |
------------------
|  0 | 13% | 21% |

Test : 160
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.17818671464920044, 'test_f1': 0.9056603773584906, 'test_prec': 0.9230769230769231, 'test_recall': 0.8888888888888888, 'labeled_instances': 160, 'train_positive_rate': 0.28125, 'pool_positive_rate': 0.20496894409937888, 'iteration_time': 242.0941264629364}
| ID | GPU | MEM |
------------------
|  0 | 14% | 33% |

Test : 180
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.07385893166065216, 'test_f1': 0.9259259259259259, 'test_prec': 0.9259259259259259, 'test_recall': 0.9259259259259259, 'labeled_instances': 180, 'train_positive_rate': 0.2722222222222222, 'pool_positive_rate': 0.20567375886524822, 'iteration_time': 246.54680466651917}
| ID | GPU | MEM |
------------------
|  0 |  6% | 45% |

Test : 200
-- Random test --

[262 174 157 246 150 173  65 163 112 233  93  80 168 191  58  59 208 225
  92  85 256  89 296 250 187 317 307  18 313  11 301 248 232  95 311 117
 167  12  27 267 320  29 177 125  73 287 229 186 188 123 119  90 102 286
 275 165 120 227   4 184 207  51 179 318   9 274  16   0 158 308  62 132
 271 309  70 223  41 127 260 217 180  39 270  78 201 147 303  17 122  88
 154 139  42 105 159 258 131   5 111  38 302 146 306  67 192 224 269 100
  34 214 110 161 169 138 319 300 107 282  19 211  14  91 238 197  44 259
 106 162 171 108 279  79 304 185   8 172  99 310 266 261  28  31  55  32
 221  48 268 295  33  35 242  63 128  46  66 175 218 305 314 263 234  47
 113 244  40  21 101 164  69  53 137  24 272 134 240 116 189 142 277 257
 247  56  61 204 206  84 181 231 114 292 273 199 118 294 170 145 315 285
  54 176]
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.09170402586460114, 'test_f1': 0.9259259259259259, 'test_prec': 0.9259259259259259, 'test_recall': 0.9259259259259259, 'labeled_instances': 200, 'train_positive_rate': 0.28, 'pool_positive_rate': 0.18181818181818182, 'iteration_time': 256.3009843826294}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 240
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.09760724008083344, 'test_f1': 0.9433962264150944, 'test_prec': 0.9615384615384616, 'test_recall': 0.9259259259259259, 'labeled_instances': 240, 'train_positive_rate': 0.2625, 'pool_positive_rate': 0.18518518518518517, 'iteration_time': 244.50640106201172}
| ID | GPU | MEM |
------------------
|  0 |  0% | 45% |

Test : 280
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.0932188406586647, 'test_f1': 0.9433962264150944, 'test_prec': 0.9615384615384616, 'test_recall': 0.9259259259259259, 'labeled_instances': 280, 'train_positive_rate': 0.2642857142857143, 'pool_positive_rate': 0.0975609756097561, 'iteration_time': 263.4824550151825}
| ID | GPU | MEM |
------------------
|  0 | 13% | 21% |

Test : 320
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.10569191724061966, 'test_f1': 0.9433962264150944, 'test_prec': 0.9615384615384616, 'test_recall': 0.9259259259259259, 'labeled_instances': 320, 'train_positive_rate': 0.240625, 'pool_positive_rate': 1.0, 'iteration_time': 255.5806701183319}
| ID | GPU | MEM |
------------------
|  0 | 13% | 33% |

Test : 360
-- Random test --

New cross validation 2, for  <function deepmatcher_structured_itunes_amazon at 0x1470b7e353a0>
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 0
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1000816598534584, 'test_f1': 0.9629629629629629, 'test_prec': 0.9629629629629629, 'test_recall': 0.9629629629629629, 'labeled_instances': 0, 'train_positive_rate': 0.24299065420560748, 'pool_positive_rate': 0.24299065420560748, 'iteration_time': 256.23811411857605}
| ID | GPU | MEM |
------------------
|  0 | 14% | 45% |

Test : 20
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.6018016934394836, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 20, 'train_positive_rate': 0.35, 'pool_positive_rate': 0.23588039867109634, 'iteration_time': 241.24789762496948}
| ID | GPU | MEM |
------------------
|  0 | 13% | 33% |

Test : 40
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4631090462207794, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 40, 'train_positive_rate': 0.225, 'pool_positive_rate': 0.24555160142348753, 'iteration_time': 239.82823276519775}
| ID | GPU | MEM |
------------------
|  0 |  0% | 45% |

Test : 60
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.399618923664093, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'labeled_instances': 60, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.25287356321839083, 'iteration_time': 240.27887105941772}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 80
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.19578522443771362, 'test_f1': 0.9285714285714286, 'test_prec': 0.896551724137931, 'test_recall': 0.9629629629629629, 'labeled_instances': 80, 'train_positive_rate': 0.25, 'pool_positive_rate': 0.24066390041493776, 'iteration_time': 244.15794777870178}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 100
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.337921142578125, 'test_f1': 0.8363636363636364, 'test_prec': 0.8214285714285714, 'test_recall': 0.8518518518518519, 'labeled_instances': 100, 'train_positive_rate': 0.27, 'pool_positive_rate': 0.23076923076923078, 'iteration_time': 261.76971912384033}
| ID | GPU | MEM |
------------------
|  0 |  0% | 45% |

Test : 120
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.08224929869174957, 'test_f1': 0.9615384615384615, 'test_prec': 1.0, 'test_recall': 0.9259259259259259, 'labeled_instances': 120, 'train_positive_rate': 0.25, 'pool_positive_rate': 0.23880597014925373, 'iteration_time': 248.6470959186554}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 140
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.11533716320991516, 'test_f1': 0.9433962264150944, 'test_prec': 0.9615384615384616, 'test_recall': 0.9259259259259259, 'labeled_instances': 140, 'train_positive_rate': 0.2357142857142857, 'pool_positive_rate': 0.24861878453038674, 'iteration_time': 237.21236181259155}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 160
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1816018670797348, 'test_f1': 0.9090909090909091, 'test_prec': 0.8928571428571429, 'test_recall': 0.9259259259259259, 'labeled_instances': 160, 'train_positive_rate': 0.2375, 'pool_positive_rate': 0.2484472049689441, 'iteration_time': 236.66641545295715}
| ID | GPU | MEM |
------------------
|  0 | 13% | 21% |

Test : 180
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.12466537207365036, 'test_f1': 0.9056603773584906, 'test_prec': 0.9230769230769231, 'test_recall': 0.8888888888888888, 'labeled_instances': 180, 'train_positive_rate': 0.25, 'pool_positive_rate': 0.23404255319148937, 'iteration_time': 242.5309944152832}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 200
-- Random test --

[214 192   7  65  98 199 160 128 161  84 283  67  99 182 279  29  94 209
 169 140 257 198 240  13   3 142 261 228  30 232  68 302 106 305 275 304
  35 152 295  10  60 216 151 118 277 290 109 194 258  66 179  12 309  89
 127  77 217  74  41  11 181 197 114  53 144 153  91 173   2 180 259 303
 156 178  23 245 154 176 175 239 242 191 269 313  54   4 291 172 141 267
 310 164 237 104  24 298   6 170 222  20  28 265 112 203 272  71 155 297
 274 126  64  14 131 174  18  85 319 147  25 285 103 236 225 215 120 249
  69 190 134  44 113  93 101 133   5 244 130  79 115 183 206 117 306 281
 157 301 264 163  90 273 189   9  37 318  45 166 193 262 317 292  48  42
 266 159  57 231 145 122 184 105 289 226 210 230 188   1 139 111 294 314
 107   8 256 316 268 204  21 296 171 308 241 119  32 312 235  78 276 220
  46 108]
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.25408855080604553, 'test_f1': 0.896551724137931, 'test_prec': 0.8387096774193549, 'test_recall': 0.9629629629629629, 'labeled_instances': 200, 'train_positive_rate': 0.255, 'pool_positive_rate': 0.2231404958677686, 'iteration_time': 242.66516780853271}
| ID | GPU | MEM |
------------------
|  0 | 14% | 46% |

Test : 240
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.09771652519702911, 'test_f1': 0.9642857142857143, 'test_prec': 0.9310344827586207, 'test_recall': 1.0, 'labeled_instances': 240, 'train_positive_rate': 0.25, 'pool_positive_rate': 0.2222222222222222, 'iteration_time': 255.9098207950592}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 280
-- Random test --

GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.05757072940468788, 'test_f1': 0.9818181818181818, 'test_prec': 0.9642857142857143, 'test_recall': 1.0, 'labeled_instances': 280, 'train_positive_rate': 0.25357142857142856, 'pool_positive_rate': 0.17073170731707318, 'iteration_time': 252.5224893093109}
| ID | GPU | MEM |
------------------
|  0 | 13% | 33% |

Test : 320
-- Random test --

{'test_loss': 0.05715811252593994, 'test_f1': 0.9818181818181818, 'test_prec': 0.9642857142857143, 'test_recall': 1.0, 'labeled_instances': 320, 'train_positive_rate': 0.24375, 'pool_positive_rate': 0.0, 'iteration_time': 247.73614954948425}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 360
-- Random test --

Could not create dir out, File exists
End of job!
