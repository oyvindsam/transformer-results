We are running from this directory: /cluster/work/oyvinsam
The name of the job is: alt-3
The job ID is 179638
The job was run on these nodes: idun-05-10
Number of nodes: 1
We are using 1 cores
We are using 1 cores per node
Total of 1 cores
Fri Apr 16 10:14:46 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.27.04    Driver Version: 460.27.04    CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-PCIE...  Off  | 00000000:3B:00.0 Off |                    0 |
| N/A   39C    P0    38W / 250W |      0MiB / 16160MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
fatal: destination path 'experiment-data' already exists and is not an empty directory.
Launch Python
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
Could not create dir out, File exists
[0, 20, 40, 60, 80, 100, 120, 140, 160, 180, 200, 240, 280, 320, 360, 400, 440, 480, 520, 560, 600, 640, 680, 720, 760, 800, 840, 880, 920, 960, 1000]
    ########### 



New Dataset: <function deepmatcher_textual_abt_buy at 0x14891c5ca670>
New cross validation 0 <function deepmatcher_textual_abt_buy at 0x14891c5ca670>
| ID | GPU | MEM |
------------------
|  0 |  3% |  0% |

Test : 0
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.12589897215366364, 'test_f1': 0.8823529411764707, 'test_prec': 0.8910891089108911, 'test_recall': 0.8737864077669902, 'train_positive_rate': 0.10726101340762667, 'pool_positive_rate': 0.10726101340762667, 'labeled_instances': 0, 'iteration_time': 622.3890604972839}
| ID | GPU | MEM |
------------------
|  0 | 25% | 21% |

Test : 20
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4819546937942505, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'train_positive_rate': 0.05, 'pool_positive_rate': 0.10746112178927136, 'labeled_instances': 20, 'iteration_time': 192.94421935081482}
| ID | GPU | MEM |
------------------
|  0 | 26% | 33% |

Test : 40
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.33157673478126526, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'train_positive_rate': 0.15, 'pool_positive_rate': 0.10696124846571979, 'labeled_instances': 40, 'iteration_time': 207.37265992164612}
| ID | GPU | MEM |
------------------
|  0 | 25% | 21% |

Test : 60
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.34699785709381104, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.10628189336617984, 'labeled_instances': 60, 'iteration_time': 208.34461998939514}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 80
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3253777027130127, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'train_positive_rate': 0.1625, 'pool_positive_rate': 0.10648066395903232, 'labeled_instances': 80, 'iteration_time': 207.67492270469666}
| ID | GPU | MEM |
------------------
|  0 | 26% | 21% |

Test : 100
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3886512815952301, 'test_f1': 0.09361702127659574, 'test_prec': 0.3793103448275862, 'test_recall': 0.05339805825242718, 'train_positive_rate': 0.19, 'pool_positive_rate': 0.10579479000531632, 'labeled_instances': 100, 'iteration_time': 208.32636785507202}
| ID | GPU | MEM |
------------------
|  0 | 25% | 21% |

Test : 120
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.39784374833106995, 'test_f1': 0.38709677419354843, 'test_prec': 0.43373493975903615, 'test_recall': 0.34951456310679613, 'train_positive_rate': 0.225, 'pool_positive_rate': 0.10474835497065624, 'labeled_instances': 120, 'iteration_time': 208.2421588897705}
| ID | GPU | MEM |
------------------
|  0 | 25% | 33% |

Test : 140
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.48606404662132263, 'test_f1': 0.2699386503067485, 'test_prec': 0.2332155477031802, 'test_recall': 0.32038834951456313, 'train_positive_rate': 0.2857142857142857, 'pool_positive_rate': 0.10280207031947171, 'labeled_instances': 140, 'iteration_time': 224.02902841567993}
| ID | GPU | MEM |
------------------
|  0 | 16% | 33% |

Test : 160
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.28611135482788086, 'test_f1': 0.5159420289855072, 'test_prec': 0.6402877697841727, 'test_recall': 0.4320388349514563, 'train_positive_rate': 0.31875, 'pool_positive_rate': 0.10120007164606842, 'labeled_instances': 160, 'iteration_time': 218.22865462303162}
| ID | GPU | MEM |
------------------
|  0 |  6% | 21% |

Test : 180
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2878468334674835, 'test_f1': 0.5390428211586902, 'test_prec': 0.5602094240837696, 'test_recall': 0.5194174757281553, 'train_positive_rate': 0.32222222222222224, 'pool_positive_rate': 0.10030559050871832, 'labeled_instances': 180, 'iteration_time': 221.0895435810089}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 200
[4557 5664  830 4239 4375 3550  191 3359 4908 3965 3928 1281    0 1002
 5742  945 2869 4914 2868 5120 2867  298 2611 4027 3787  818 2870 3993
 2875  133 2657 5711 1929 1581 3474 5565 4660 2831 3616 4476 2866 2059
 4257   89 2858 4436 1586 3727 2859 4038   91  195 1894 5640 1458 3595
 4285 5119 5503 4015 3594 5245 5607  419 1528 2260 1970 4216 4445 1885
   60 1897 2103 4363 3235 3334 1611 1750 4638 4928 4280 3438 4289  821
 2435 3048 4352 2289  313 3894 4792  228 1941  874 4053 4335 4615 5443
 1626 1106 2371 5215 2884  279  483 2541 2878 3115 5203 3774 5113 1991
  630 4499    1 1274 5396 1822 2395   43 3577 4414 2314 2391 2988 2114
 2472 5080 1645 4422 2876 2401  370 3138 4276  757  922 1795 2887  718
  839 4758 2886 2184 5057 5564 4313 3978 3844 2240 4388 3292 5421 2640
 2888 2507 4311 1245 1979 2655 1900 1100 2164 5365 2366 4696 4912 1128
  289 4330 2150  154 2249 1381 2124 1844 4950  539 4504  476 2814 2853
 2394 2376  143  290 2186  576 3037 1407 4932 5558  344 2504 1999  791
 3027 1710 2891 4146]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.18620246648788452, 'test_f1': 0.7205882352941176, 'test_prec': 0.7277227722772277, 'test_recall': 0.7135922330097088, 'train_positive_rate': 0.34, 'pool_positive_rate': 0.09886343135486199, 'labeled_instances': 200, 'iteration_time': 227.89040875434875}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 240
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.13514994084835052, 'test_f1': 0.8104265402843601, 'test_prec': 0.7916666666666666, 'test_recall': 0.8300970873786407, 'train_positive_rate': 0.35833333333333334, 'pool_positive_rate': 0.09631110303470834, 'labeled_instances': 240, 'iteration_time': 230.53692173957825}
| ID | GPU | MEM |
------------------
|  0 | 16% | 21% |

Test : 280
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.15266159176826477, 'test_f1': 0.7918552036199096, 'test_prec': 0.7415254237288136, 'test_recall': 0.8495145631067961, 'train_positive_rate': 0.38571428571428573, 'pool_positive_rate': 0.09298920007321984, 'labeled_instances': 280, 'iteration_time': 225.96425247192383}
| ID | GPU | MEM |
------------------
|  0 | 36% | 21% |

Test : 320
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.19570887088775635, 'test_f1': 0.7724867724867726, 'test_prec': 0.8488372093023255, 'test_recall': 0.7087378640776699, 'train_positive_rate': 0.390625, 'pool_positive_rate': 0.09054029135165038, 'labeled_instances': 320, 'iteration_time': 227.26530194282532}
| ID | GPU | MEM |
------------------
|  0 | 25% | 33% |

Test : 360
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1429280936717987, 'test_f1': 0.8112244897959183, 'test_prec': 0.8548387096774194, 'test_recall': 0.7718446601941747, 'train_positive_rate': 0.4111111111111111, 'pool_positive_rate': 0.0869403678246331, 'labeled_instances': 360, 'iteration_time': 247.99200534820557}
| ID | GPU | MEM |
------------------
|  0 |  7% | 33% |

Test : 400
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1474069356918335, 'test_f1': 0.8078817733990147, 'test_prec': 0.82, 'test_recall': 0.7961165048543689, 'train_positive_rate': 0.41, 'pool_positive_rate': 0.08459666853827438, 'labeled_instances': 400, 'iteration_time': 257.56723618507385}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 440
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.14449526369571686, 'test_f1': 0.8333333333333333, 'test_prec': 0.8415841584158416, 'test_recall': 0.8252427184466019, 'train_positive_rate': 0.425, 'pool_positive_rate': 0.08089760512917217, 'labeled_instances': 440, 'iteration_time': 271.02657675743103}
| ID | GPU | MEM |
------------------
|  0 | 26% | 33% |

Test : 480
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.14503277838230133, 'test_f1': 0.8448687350835321, 'test_prec': 0.8309859154929577, 'test_recall': 0.8592233009708737, 'train_positive_rate': 0.4270833333333333, 'pool_positive_rate': 0.07809234277028311, 'labeled_instances': 480, 'iteration_time': 264.7619171142578}
| ID | GPU | MEM |
------------------
|  0 | 25% | 21% |

Test : 520
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1413344293832779, 'test_f1': 0.8536585365853658, 'test_prec': 0.8578431372549019, 'test_recall': 0.8495145631067961, 'train_positive_rate': 0.4288461538461538, 'pool_positive_rate': 0.0752441125789776, 'labeled_instances': 520, 'iteration_time': 259.265917301178}
| ID | GPU | MEM |
------------------
|  0 | 24% | 21% |

Test : 560
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.15779249370098114, 'test_f1': 0.825, 'test_prec': 0.8505154639175257, 'test_recall': 0.8009708737864077, 'train_positive_rate': 0.42857142857142855, 'pool_positive_rate': 0.07272376543209877, 'labeled_instances': 560, 'iteration_time': 263.824835062027}
| ID | GPU | MEM |
------------------
|  0 | 12% | 21% |

Test : 600
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.13310986757278442, 'test_f1': 0.8571428571428571, 'test_prec': 0.87, 'test_recall': 0.8446601941747572, 'train_positive_rate': 0.42833333333333334, 'pool_positive_rate': 0.06997084548104957, 'labeled_instances': 600, 'iteration_time': 269.2947871685028}
| ID | GPU | MEM |
------------------
|  0 | 25% | 21% |

Test : 640
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.16750259697437286, 'test_f1': 0.8293838862559242, 'test_prec': 0.8101851851851852, 'test_recall': 0.8495145631067961, 'train_positive_rate': 0.41875, 'pool_positive_rate': 0.06835095965530748, 'labeled_instances': 640, 'iteration_time': 268.93642020225525}
| ID | GPU | MEM |
------------------
|  0 | 25% | 21% |

Test : 680
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.16584156453609467, 'test_f1': 0.8445475638051045, 'test_prec': 0.8088888888888889, 'test_recall': 0.883495145631068, 'train_positive_rate': 0.4176470588235294, 'pool_positive_rate': 0.06571936056838366, 'labeled_instances': 680, 'iteration_time': 267.6533451080322}
| ID | GPU | MEM |
------------------
|  0 | 11% | 21% |

Test : 720
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.15409554541110992, 'test_f1': 0.8483412322274881, 'test_prec': 0.8287037037037037, 'test_recall': 0.8689320388349514, 'train_positive_rate': 0.4041666666666667, 'pool_positive_rate': 0.06482402068005567, 'labeled_instances': 720, 'iteration_time': 272.53207421302795}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 760
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.125637486577034, 'test_f1': 0.8656716417910448, 'test_prec': 0.8877551020408163, 'test_recall': 0.8446601941747572, 'train_positive_rate': 0.3894736842105263, 'pool_positive_rate': 0.06434155141310884, 'labeled_instances': 760, 'iteration_time': 276.14000630378723}
| ID | GPU | MEM |
------------------
|  0 | 26% | 21% |

Test : 800
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.15705552697181702, 'test_f1': 0.8564705882352941, 'test_prec': 0.8310502283105022, 'test_recall': 0.883495145631068, 'train_positive_rate': 0.37625, 'pool_positive_rate': 0.06385128308749242, 'labeled_instances': 800, 'iteration_time': 282.1286880970001}
| ID | GPU | MEM |
------------------
|  0 | 25% | 21% |

Test : 840
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.14589272439479828, 'test_f1': 0.864321608040201, 'test_prec': 0.8958333333333334, 'test_recall': 0.8349514563106796, 'train_positive_rate': 0.36666666666666664, 'pool_positive_rate': 0.06294561010389081, 'labeled_instances': 840, 'iteration_time': 284.44165897369385}
| ID | GPU | MEM |
------------------
|  0 | 25% | 21% |

Test : 880
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.14024247229099274, 'test_f1': 0.8626506024096385, 'test_prec': 0.8564593301435407, 'test_recall': 0.8689320388349514, 'train_positive_rate': 0.3568181818181818, 'pool_positive_rate': 0.06223043746149107, 'labeled_instances': 880, 'iteration_time': 285.4942283630371}
| ID | GPU | MEM |
------------------
|  0 | 26% | 21% |

Test : 920
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.16532690823078156, 'test_f1': 0.8514851485148516, 'test_prec': 0.8686868686868687, 'test_recall': 0.8349514563106796, 'train_positive_rate': 0.34456521739130436, 'pool_positive_rate': 0.062124663491406086, 'labeled_instances': 920, 'iteration_time': 291.2571349143982}
| ID | GPU | MEM |
------------------
|  0 | 25% | 21% |

Test : 960
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.16478240489959717, 'test_f1': 0.8454106280193237, 'test_prec': 0.8413461538461539, 'test_recall': 0.8495145631067961, 'train_positive_rate': 0.3385416666666667, 'pool_positive_rate': 0.061169102296450936, 'labeled_instances': 960, 'iteration_time': 290.6444878578186}
| ID | GPU | MEM |
------------------
|  0 | 26% | 21% |

Test : 1000
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.12706635892391205, 'test_f1': 0.8704156479217603, 'test_prec': 0.8768472906403941, 'test_recall': 0.8640776699029126, 'train_positive_rate': 0.339, 'pool_positive_rate': 0.0589349610608293, 'labeled_instances': 1000, 'iteration_time': 309.2300901412964}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 5743
New cross validation 1 <function deepmatcher_textual_abt_buy at 0x14891c5ca670>
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 0
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.11788787692785263, 'test_f1': 0.8953771289537714, 'test_prec': 0.8975609756097561, 'test_recall': 0.8932038834951457, 'train_positive_rate': 0.10726101340762667, 'pool_positive_rate': 0.10726101340762667, 'labeled_instances': 0, 'iteration_time': 638.2774786949158}
| ID | GPU | MEM |
------------------
|  0 |  1% | 21% |

Test : 20
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4871416389942169, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'train_positive_rate': 0.05, 'pool_positive_rate': 0.10746112178927136, 'labeled_instances': 20, 'iteration_time': 222.52583050727844}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 40
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3341217637062073, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'train_positive_rate': 0.15, 'pool_positive_rate': 0.10696124846571979, 'labeled_instances': 40, 'iteration_time': 224.25452518463135}
| ID | GPU | MEM |
------------------
|  0 |  1% | 21% |

Test : 60
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3411962687969208, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.10628189336617984, 'labeled_instances': 60, 'iteration_time': 221.64934730529785}
| ID | GPU | MEM |
------------------
|  0 | 25% | 33% |

Test : 80
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3547086715698242, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'train_positive_rate': 0.1625, 'pool_positive_rate': 0.10648066395903232, 'labeled_instances': 80, 'iteration_time': 229.58370804786682}
| ID | GPU | MEM |
------------------
|  0 | 26% | 33% |

Test : 100
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.37108665704727173, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'train_positive_rate': 0.19, 'pool_positive_rate': 0.10579479000531632, 'labeled_instances': 100, 'iteration_time': 234.09892654418945}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 120
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.37916022539138794, 'test_f1': 0.19584569732937682, 'test_prec': 0.25190839694656486, 'test_recall': 0.16019417475728157, 'train_positive_rate': 0.225, 'pool_positive_rate': 0.10474835497065624, 'labeled_instances': 120, 'iteration_time': 230.33624053001404}
| ID | GPU | MEM |
------------------
|  0 | 26% | 21% |

Test : 140
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.504331111907959, 'test_f1': 0.3351158645276292, 'test_prec': 0.2647887323943662, 'test_recall': 0.4563106796116505, 'train_positive_rate': 0.2857142857142857, 'pool_positive_rate': 0.10280207031947171, 'labeled_instances': 140, 'iteration_time': 237.75374460220337}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 160
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1949787437915802, 'test_f1': 0.7088607594936709, 'test_prec': 0.7407407407407407, 'test_recall': 0.6796116504854369, 'train_positive_rate': 0.31875, 'pool_positive_rate': 0.10120007164606842, 'labeled_instances': 160, 'iteration_time': 239.1114263534546}
| ID | GPU | MEM |
------------------
|  0 | 25% | 21% |

Test : 180
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2267976999282837, 'test_f1': 0.6115702479338843, 'test_prec': 0.7070063694267515, 'test_recall': 0.5388349514563107, 'train_positive_rate': 0.32222222222222224, 'pool_positive_rate': 0.10030559050871832, 'labeled_instances': 180, 'iteration_time': 244.89425921440125}
| ID | GPU | MEM |
------------------
|  0 |  4% | 21% |

Test : 200
[4557 5664  830 4239 4375 3550  191 3359 4908 3965 3928 1281    0 1002
 5742  945 2869 4914 2868 5120 2867  298 2611 4027 3787  818 2870 3993
 2875  133 2657 5711 1929 1581 3474 5565 4660 2831 3616 4476 2866 2059
 4257   89 2858 4436 1586 3727 2859 4038   91  195 1894 5640 1458 3595
 4285 5119 5503 4015 3594 5245 5607  419 1528 2260 1970 4216 4445 1885
   60 1897 2103 4363 3235 3334 1611 1750 4638 4928 4280 3438 4289  821
 2435 3048 4352 2289  313 3894 4792  228 1941  874 4053 4335 4615 5443
 1626 1106 2371 5215 2884  279  483 2541 2878 3115 5203 3774 5113 1991
  630 4499    1 1274 5396 1822 2395   43 3577 4414 2314 2391 2988 2114
 2472 5080 1645 4422 2876 2401  370 3138 4276  757  922 1795 2887  718
  839 4758 2886 2184 5057 5564 4313 3978 3844 2240 4388 3292 5421 2640
 2888 2507 4311 1245 1979 2655 1900 1100 2164 5365 2366 4696 4912 1128
  289 4330 2150  154 2249 1381 2124 1844 4950  539 4504  476 2814 2853
 2394 2376  143  290 2186  576 3037 1407 4932 5558  344 2504 1999  791
 3027 1710 2891 4146]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.20111244916915894, 'test_f1': 0.683291770573566, 'test_prec': 0.7025641025641025, 'test_recall': 0.6650485436893204, 'train_positive_rate': 0.34, 'pool_positive_rate': 0.09886343135486199, 'labeled_instances': 200, 'iteration_time': 243.23532581329346}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 240
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2231239229440689, 'test_f1': 0.7331536388140161, 'test_prec': 0.8242424242424242, 'test_recall': 0.6601941747572816, 'train_positive_rate': 0.35833333333333334, 'pool_positive_rate': 0.09631110303470834, 'labeled_instances': 240, 'iteration_time': 250.77399897575378}
| ID | GPU | MEM |
------------------
|  0 | 25% | 21% |

Test : 280
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.14575344324111938, 'test_f1': 0.8146453089244851, 'test_prec': 0.7705627705627706, 'test_recall': 0.8640776699029126, 'train_positive_rate': 0.38571428571428573, 'pool_positive_rate': 0.09298920007321984, 'labeled_instances': 280, 'iteration_time': 251.00265383720398}
| ID | GPU | MEM |
------------------
|  0 | 25% | 21% |

Test : 320
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.13191531598567963, 'test_f1': 0.8241206030150753, 'test_prec': 0.8541666666666666, 'test_recall': 0.7961165048543689, 'train_positive_rate': 0.390625, 'pool_positive_rate': 0.09054029135165038, 'labeled_instances': 320, 'iteration_time': 257.5869324207306}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 360
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.16217796504497528, 'test_f1': 0.8102564102564102, 'test_prec': 0.8586956521739131, 'test_recall': 0.7669902912621359, 'train_positive_rate': 0.4111111111111111, 'pool_positive_rate': 0.0869403678246331, 'labeled_instances': 360, 'iteration_time': 258.2161774635315}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 400
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.13362674415111542, 'test_f1': 0.8070175438596492, 'test_prec': 0.8341968911917098, 'test_recall': 0.7815533980582524, 'train_positive_rate': 0.41, 'pool_positive_rate': 0.08459666853827438, 'labeled_instances': 400, 'iteration_time': 263.2405993938446}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 440
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.17759950459003448, 'test_f1': 0.8041237113402061, 'test_prec': 0.8571428571428571, 'test_recall': 0.7572815533980582, 'train_positive_rate': 0.425, 'pool_positive_rate': 0.08089760512917217, 'labeled_instances': 440, 'iteration_time': 271.84180641174316}
| ID | GPU | MEM |
------------------
|  0 | 26% | 33% |

Test : 480
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.15914538502693176, 'test_f1': 0.8175182481751825, 'test_prec': 0.8195121951219512, 'test_recall': 0.8155339805825242, 'train_positive_rate': 0.4270833333333333, 'pool_positive_rate': 0.07809234277028311, 'labeled_instances': 480, 'iteration_time': 271.4640326499939}
| ID | GPU | MEM |
------------------
|  0 | 26% | 33% |

Test : 520
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.12337307631969452, 'test_f1': 0.8564476885644768, 'test_prec': 0.8585365853658536, 'test_recall': 0.8543689320388349, 'train_positive_rate': 0.4288461538461538, 'pool_positive_rate': 0.0752441125789776, 'labeled_instances': 520, 'iteration_time': 294.95949959754944}
| ID | GPU | MEM |
------------------
|  0 | 26% | 33% |

Test : 560
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.14781774580478668, 'test_f1': 0.7899543378995434, 'test_prec': 0.7456896551724138, 'test_recall': 0.8398058252427184, 'train_positive_rate': 0.42857142857142855, 'pool_positive_rate': 0.07272376543209877, 'labeled_instances': 560, 'iteration_time': 288.6768479347229}
| ID | GPU | MEM |
------------------
|  0 | 13% | 33% |

Test : 600
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.16358667612075806, 'test_f1': 0.8496420047732696, 'test_prec': 0.8356807511737089, 'test_recall': 0.8640776699029126, 'train_positive_rate': 0.42833333333333334, 'pool_positive_rate': 0.06997084548104957, 'labeled_instances': 600, 'iteration_time': 280.8325662612915}
| ID | GPU | MEM |
------------------
|  0 | 26% | 33% |

Test : 640
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.21341316401958466, 'test_f1': 0.8230088495575221, 'test_prec': 0.7560975609756098, 'test_recall': 0.9029126213592233, 'train_positive_rate': 0.41875, 'pool_positive_rate': 0.06835095965530748, 'labeled_instances': 640, 'iteration_time': 294.49126291275024}
| ID | GPU | MEM |
------------------
|  0 | 26% | 33% |

Test : 680
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.16007669270038605, 'test_f1': 0.8372093023255814, 'test_prec': 0.8035714285714286, 'test_recall': 0.8737864077669902, 'train_positive_rate': 0.4176470588235294, 'pool_positive_rate': 0.06571936056838366, 'labeled_instances': 680, 'iteration_time': 294.022944688797}
| ID | GPU | MEM |
------------------
|  0 | 26% | 33% |

Test : 720
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.16421906650066376, 'test_f1': 0.8368794326241136, 'test_prec': 0.815668202764977, 'test_recall': 0.8592233009708737, 'train_positive_rate': 0.4041666666666667, 'pool_positive_rate': 0.06482402068005567, 'labeled_instances': 720, 'iteration_time': 307.6127152442932}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 760
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.19367317855358124, 'test_f1': 0.8181818181818181, 'test_prec': 0.7692307692307693, 'test_recall': 0.8737864077669902, 'train_positive_rate': 0.3894736842105263, 'pool_positive_rate': 0.06434155141310884, 'labeled_instances': 760, 'iteration_time': 303.46997833251953}
| ID | GPU | MEM |
------------------
|  0 | 26% | 21% |

Test : 800
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1583978831768036, 'test_f1': 0.8344988344988344, 'test_prec': 0.8026905829596412, 'test_recall': 0.8689320388349514, 'train_positive_rate': 0.37625, 'pool_positive_rate': 0.06385128308749242, 'labeled_instances': 800, 'iteration_time': 311.8587110042572}
| ID | GPU | MEM |
------------------
|  0 | 25% | 21% |

Test : 840
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.152634397149086, 'test_f1': 0.8226950354609929, 'test_prec': 0.8018433179723502, 'test_recall': 0.8446601941747572, 'train_positive_rate': 0.36666666666666664, 'pool_positive_rate': 0.06294561010389081, 'labeled_instances': 840, 'iteration_time': 318.9825670719147}
| ID | GPU | MEM |
------------------
|  0 | 25% | 21% |

Test : 880
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1623374968767166, 'test_f1': 0.8407960199004973, 'test_prec': 0.8622448979591837, 'test_recall': 0.8203883495145631, 'train_positive_rate': 0.3568181818181818, 'pool_positive_rate': 0.06223043746149107, 'labeled_instances': 880, 'iteration_time': 322.6361093521118}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 920
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.13151419162750244, 'test_f1': 0.8647342995169081, 'test_prec': 0.8605769230769231, 'test_recall': 0.8689320388349514, 'train_positive_rate': 0.34456521739130436, 'pool_positive_rate': 0.062124663491406086, 'labeled_instances': 920, 'iteration_time': 336.8574492931366}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 960
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1700059473514557, 'test_f1': 0.8368794326241136, 'test_prec': 0.815668202764977, 'test_recall': 0.8592233009708737, 'train_positive_rate': 0.3385416666666667, 'pool_positive_rate': 0.061169102296450936, 'labeled_instances': 960, 'iteration_time': 334.2881455421448}
| ID | GPU | MEM |
------------------
|  0 | 26% | 21% |

Test : 1000
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1843244880437851, 'test_f1': 0.8544600938967137, 'test_prec': 0.8272727272727273, 'test_recall': 0.883495145631068, 'train_positive_rate': 0.339, 'pool_positive_rate': 0.0589349610608293, 'labeled_instances': 1000, 'iteration_time': 317.6007273197174}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 5743
New cross validation 2 <function deepmatcher_textual_abt_buy at 0x14891c5ca670>
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 0
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.0859093889594078, 'test_f1': 0.92, 'test_prec': 0.9484536082474226, 'test_recall': 0.8932038834951457, 'train_positive_rate': 0.10726101340762667, 'pool_positive_rate': 0.10726101340762667, 'labeled_instances': 0, 'iteration_time': 707.0869450569153}
| ID | GPU | MEM |
------------------
|  0 | 26% | 21% |

Test : 20
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4515955150127411, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'train_positive_rate': 0.05, 'pool_positive_rate': 0.10746112178927136, 'labeled_instances': 20, 'iteration_time': 248.4150629043579}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 40
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.33425721526145935, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'train_positive_rate': 0.15, 'pool_positive_rate': 0.10696124846571979, 'labeled_instances': 40, 'iteration_time': 267.86682868003845}
| ID | GPU | MEM |
------------------
|  0 | 24% | 33% |

Test : 60
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.32772836089134216, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'train_positive_rate': 0.2, 'pool_positive_rate': 0.10628189336617984, 'labeled_instances': 60, 'iteration_time': 269.658812046051}
| ID | GPU | MEM |
------------------
|  0 | 26% | 21% |

Test : 80
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3278632164001465, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'train_positive_rate': 0.1625, 'pool_positive_rate': 0.10648066395903232, 'labeled_instances': 80, 'iteration_time': 261.587012052536}
| ID | GPU | MEM |
------------------
|  0 | 25% | 21% |

Test : 100
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.35888123512268066, 'test_f1': 0.21908127208480566, 'test_prec': 0.4025974025974026, 'test_recall': 0.15048543689320387, 'train_positive_rate': 0.19, 'pool_positive_rate': 0.10579479000531632, 'labeled_instances': 100, 'iteration_time': 272.87695932388306}
| ID | GPU | MEM |
------------------
|  0 | 25% | 21% |

Test : 120
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.23799338936805725, 'test_f1': 0.5348837209302325, 'test_prec': 0.6666666666666666, 'test_recall': 0.44660194174757284, 'train_positive_rate': 0.225, 'pool_positive_rate': 0.10474835497065624, 'labeled_instances': 120, 'iteration_time': 263.3966872692108}
| ID | GPU | MEM |
------------------
|  0 | 25% | 21% |

Test : 140
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2635450065135956, 'test_f1': 0.5534246575342465, 'test_prec': 0.6352201257861635, 'test_recall': 0.49029126213592233, 'train_positive_rate': 0.2857142857142857, 'pool_positive_rate': 0.10280207031947171, 'labeled_instances': 140, 'iteration_time': 268.28471207618713}
| ID | GPU | MEM |
------------------
|  0 |  7% | 33% |

Test : 160
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.23063889145851135, 'test_f1': 0.5706371191135734, 'test_prec': 0.6645161290322581, 'test_recall': 0.5, 'train_positive_rate': 0.31875, 'pool_positive_rate': 0.10120007164606842, 'labeled_instances': 160, 'iteration_time': 279.60116744041443}
| ID | GPU | MEM |
------------------
|  0 | 26% | 33% |

Test : 180
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.26930031180381775, 'test_f1': 0.6778947368421053, 'test_prec': 0.5985130111524164, 'test_recall': 0.7815533980582524, 'train_positive_rate': 0.32222222222222224, 'pool_positive_rate': 0.10030559050871832, 'labeled_instances': 180, 'iteration_time': 295.0216290950775}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 200
[4557 5664  830 4239 4375 3550  191 3359 4908 3965 3928 1281    0 1002
 5742  945 2869 4914 2868 5120 2867  298 2611 4027 3787  818 2870 3993
 2875  133 2657 5711 1929 1581 3474 5565 4660 2831 3616 4476 2866 2059
 4257   89 2858 4436 1586 3727 2859 4038   91  195 1894 5640 1458 3595
 4285 5119 5503 4015 3594 5245 5607  419 1528 2260 1970 4216 4445 1885
   60 1897 2103 4363 3235 3334 1611 1750 4638 4928 4280 3438 4289  821
 2435 3048 4352 2289  313 3894 4792  228 1941  874 4053 4335 4615 5443
 1626 1106 2371 5215 2884  279  483 2541 2878 3115 5203 3774 5113 1991
  630 4499    1 1274 5396 1822 2395   43 3577 4414 2314 2391 2988 2114
 2472 5080 1645 4422 2876 2401  370 3138 4276  757  922 1795 2887  718
  839 4758 2886 2184 5057 5564 4313 3978 3844 2240 4388 3292 5421 2640
 2888 2507 4311 1245 1979 2655 1900 1100 2164 5365 2366 4696 4912 1128
  289 4330 2150  154 2249 1381 2124 1844 4950  539 4504  476 2814 2853
 2394 2376  143  290 2186  576 3037 1407 4932 5558  344 2504 1999  791
 3027 1710 2891 4146]
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2809502184391022, 'test_f1': 0.4895522388059701, 'test_prec': 0.6356589147286822, 'test_recall': 0.39805825242718446, 'train_positive_rate': 0.34, 'pool_positive_rate': 0.09886343135486199, 'labeled_instances': 200, 'iteration_time': 297.3211395740509}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 240
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.15367062389850616, 'test_f1': 0.7962085308056872, 'test_prec': 0.7777777777777778, 'test_recall': 0.8155339805825242, 'train_positive_rate': 0.35833333333333334, 'pool_positive_rate': 0.09631110303470834, 'labeled_instances': 240, 'iteration_time': 280.49493503570557}
| ID | GPU | MEM |
------------------
|  0 | 25% | 21% |

Test : 280
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.15063434839248657, 'test_f1': 0.8179551122194514, 'test_prec': 0.841025641025641, 'test_recall': 0.7961165048543689, 'train_positive_rate': 0.38571428571428573, 'pool_positive_rate': 0.09298920007321984, 'labeled_instances': 280, 'iteration_time': 305.0739450454712}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 320
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.13676247000694275, 'test_f1': 0.8492462311557789, 'test_prec': 0.8802083333333334, 'test_recall': 0.8203883495145631, 'train_positive_rate': 0.390625, 'pool_positive_rate': 0.09054029135165038, 'labeled_instances': 320, 'iteration_time': 301.00913739204407}
| ID | GPU | MEM |
------------------
|  0 | 26% | 21% |

Test : 360
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1345941722393036, 'test_f1': 0.8186046511627907, 'test_prec': 0.7857142857142857, 'test_recall': 0.8543689320388349, 'train_positive_rate': 0.4111111111111111, 'pool_positive_rate': 0.0869403678246331, 'labeled_instances': 360, 'iteration_time': 296.86678743362427}
| ID | GPU | MEM |
------------------
|  0 | 25% | 21% |

Test : 400
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.15636979043483734, 'test_f1': 0.8399999999999999, 'test_prec': 0.865979381443299, 'test_recall': 0.8155339805825242, 'train_positive_rate': 0.41, 'pool_positive_rate': 0.08459666853827438, 'labeled_instances': 400, 'iteration_time': 299.5909116268158}
| ID | GPU | MEM |
------------------
|  0 | 14% | 33% |

Test : 440
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.133759543299675, 'test_f1': 0.8564705882352941, 'test_prec': 0.8310502283105022, 'test_recall': 0.883495145631068, 'train_positive_rate': 0.425, 'pool_positive_rate': 0.08089760512917217, 'labeled_instances': 440, 'iteration_time': 310.1589958667755}
| ID | GPU | MEM |
------------------
|  0 | 25% | 33% |

Test : 480
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.17350147664546967, 'test_f1': 0.8305489260143198, 'test_prec': 0.8169014084507042, 'test_recall': 0.8446601941747572, 'train_positive_rate': 0.4270833333333333, 'pool_positive_rate': 0.07809234277028311, 'labeled_instances': 480, 'iteration_time': 316.0080831050873}
| ID | GPU | MEM |
------------------
|  0 | 24% | 33% |

Test : 520
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.17035889625549316, 'test_f1': 0.8310502283105023, 'test_prec': 0.7844827586206896, 'test_recall': 0.883495145631068, 'train_positive_rate': 0.4288461538461538, 'pool_positive_rate': 0.0752441125789776, 'labeled_instances': 520, 'iteration_time': 325.71004343032837}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 560
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.16370221972465515, 'test_f1': 0.8295165394402035, 'test_prec': 0.8716577540106952, 'test_recall': 0.7912621359223301, 'train_positive_rate': 0.42857142857142855, 'pool_positive_rate': 0.07272376543209877, 'labeled_instances': 560, 'iteration_time': 317.85190653800964}
| ID | GPU | MEM |
------------------
|  0 |  9% | 21% |

Test : 600
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.15077021718025208, 'test_f1': 0.8470588235294118, 'test_prec': 0.821917808219178, 'test_recall': 0.8737864077669902, 'train_positive_rate': 0.42833333333333334, 'pool_positive_rate': 0.06997084548104957, 'labeled_instances': 600, 'iteration_time': 314.09264636039734}
| ID | GPU | MEM |
------------------
|  0 | 25% | 21% |

Test : 640
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1583530157804489, 'test_f1': 0.8406466512702079, 'test_prec': 0.801762114537445, 'test_recall': 0.883495145631068, 'train_positive_rate': 0.41875, 'pool_positive_rate': 0.06835095965530748, 'labeled_instances': 640, 'iteration_time': 340.1522681713104}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 680
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.13353772461414337, 'test_f1': 0.8468899521531099, 'test_prec': 0.8349056603773585, 'test_recall': 0.8592233009708737, 'train_positive_rate': 0.4176470588235294, 'pool_positive_rate': 0.06571936056838366, 'labeled_instances': 680, 'iteration_time': 327.7624247074127}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 720
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.15364791452884674, 'test_f1': 0.8401826484018265, 'test_prec': 0.7931034482758621, 'test_recall': 0.8932038834951457, 'train_positive_rate': 0.4041666666666667, 'pool_positive_rate': 0.06482402068005567, 'labeled_instances': 720, 'iteration_time': 345.94749426841736}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 760
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.17111952602863312, 'test_f1': 0.8337236533957846, 'test_prec': 0.8054298642533937, 'test_recall': 0.8640776699029126, 'train_positive_rate': 0.3894736842105263, 'pool_positive_rate': 0.06434155141310884, 'labeled_instances': 760, 'iteration_time': 335.2904508113861}
| ID | GPU | MEM |
------------------
|  0 | 11% | 33% |

Test : 800
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1751108169555664, 'test_f1': 0.8274231678486996, 'test_prec': 0.8064516129032258, 'test_recall': 0.8495145631067961, 'train_positive_rate': 0.37625, 'pool_positive_rate': 0.06385128308749242, 'labeled_instances': 800, 'iteration_time': 345.43956661224365}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 840
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.15241947770118713, 'test_f1': 0.850356294536817, 'test_prec': 0.8325581395348837, 'test_recall': 0.8689320388349514, 'train_positive_rate': 0.36666666666666664, 'pool_positive_rate': 0.06294561010389081, 'labeled_instances': 840, 'iteration_time': 336.91040873527527}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 880
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1390983611345291, 'test_f1': 0.8571428571428571, 'test_prec': 0.8411214953271028, 'test_recall': 0.8737864077669902, 'train_positive_rate': 0.3568181818181818, 'pool_positive_rate': 0.06223043746149107, 'labeled_instances': 880, 'iteration_time': 346.5719118118286}
| ID | GPU | MEM |
------------------
|  0 | 10% | 33% |

Test : 920
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.17599667608737946, 'test_f1': 0.8524590163934426, 'test_prec': 0.8235294117647058, 'test_recall': 0.883495145631068, 'train_positive_rate': 0.34456521739130436, 'pool_positive_rate': 0.062124663491406086, 'labeled_instances': 920, 'iteration_time': 366.88509035110474}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 960
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.18018795549869537, 'test_f1': 0.8682926829268292, 'test_prec': 0.8725490196078431, 'test_recall': 0.8640776699029126, 'train_positive_rate': 0.3385416666666667, 'pool_positive_rate': 0.061169102296450936, 'labeled_instances': 960, 'iteration_time': 371.8541178703308}
| ID | GPU | MEM |
------------------
|  0 | 25% | 33% |

Test : 1000
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.16314350068569183, 'test_f1': 0.8657407407407406, 'test_prec': 0.827433628318584, 'test_recall': 0.9077669902912622, 'train_positive_rate': 0.339, 'pool_positive_rate': 0.0589349610608293, 'labeled_instances': 1000, 'iteration_time': 365.81071877479553}
| ID | GPU | MEM |
------------------
|  0 | 26% | 21% |

Test : 5743
Could not create dir out, File exists
    ########### 



New Dataset: <function deepmatcher_structured_itunes_amazon at 0x14891c5ca3a0>
New cross validation 0 <function deepmatcher_structured_itunes_amazon at 0x14891c5ca3a0>
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 0
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.13471554219722748, 'test_f1': 0.9433962264150944, 'test_prec': 0.9615384615384616, 'test_recall': 0.9259259259259259, 'train_positive_rate': 0.24299065420560748, 'pool_positive_rate': 0.24299065420560748, 'labeled_instances': 0, 'iteration_time': 230.52678298950195}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 20
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.5628898739814758, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'train_positive_rate': 0.4, 'pool_positive_rate': 0.23255813953488372, 'labeled_instances': 20, 'iteration_time': 203.63415837287903}
| ID | GPU | MEM |
------------------
|  0 |  0% | 46% |

Test : 40
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.3488292396068573, 'test_f1': 0.7037037037037037, 'test_prec': 0.7037037037037037, 'test_recall': 0.7037037037037037, 'train_positive_rate': 0.375, 'pool_positive_rate': 0.22419928825622776, 'labeled_instances': 40, 'iteration_time': 231.31879448890686}
| ID | GPU | MEM |
------------------
|  0 |  4% | 21% |

Test : 60
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.26632431149482727, 'test_f1': 0.8163265306122449, 'test_prec': 0.9090909090909091, 'test_recall': 0.7407407407407407, 'train_positive_rate': 0.36666666666666664, 'pool_positive_rate': 0.21455938697318008, 'labeled_instances': 60, 'iteration_time': 245.40270376205444}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 80
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.11656484752893448, 'test_f1': 0.8846153846153846, 'test_prec': 0.92, 'test_recall': 0.8518518518518519, 'train_positive_rate': 0.4, 'pool_positive_rate': 0.1908713692946058, 'labeled_instances': 80, 'iteration_time': 246.74725794792175}
| ID | GPU | MEM |
------------------
|  0 | 14% | 45% |

Test : 100
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.14630132913589478, 'test_f1': 0.912280701754386, 'test_prec': 0.8666666666666667, 'test_recall': 0.9629629629629629, 'train_positive_rate': 0.41, 'pool_positive_rate': 0.167420814479638, 'labeled_instances': 100, 'iteration_time': 249.97079157829285}
| ID | GPU | MEM |
------------------
|  0 | 13% | 21% |

Test : 120
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.08177103102207184, 'test_f1': 0.923076923076923, 'test_prec': 0.96, 'test_recall': 0.8888888888888888, 'train_positive_rate': 0.425, 'pool_positive_rate': 0.13432835820895522, 'labeled_instances': 120, 'iteration_time': 246.3211908340454}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 140
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.10750705003738403, 'test_f1': 0.9433962264150944, 'test_prec': 0.9615384615384616, 'test_recall': 0.9259259259259259, 'train_positive_rate': 0.4357142857142857, 'pool_positive_rate': 0.09392265193370165, 'labeled_instances': 140, 'iteration_time': 241.7695233821869}
| ID | GPU | MEM |
------------------
|  0 |  9% | 45% |

Test : 160
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1611730307340622, 'test_f1': 0.9285714285714286, 'test_prec': 0.896551724137931, 'test_recall': 0.9629629629629629, 'train_positive_rate': 0.44375, 'pool_positive_rate': 0.043478260869565216, 'labeled_instances': 160, 'iteration_time': 238.68700098991394}
| ID | GPU | MEM |
------------------
|  0 | 14% | 21% |

Test : 180
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1184566393494606, 'test_f1': 0.9629629629629629, 'test_prec': 0.9629629629629629, 'test_recall': 0.9629629629629629, 'train_positive_rate': 0.42777777777777776, 'pool_positive_rate': 0.0070921985815602835, 'labeled_instances': 180, 'iteration_time': 249.26035571098328}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 200
[207  66 204  10 288 309  29 235 316   7 222 170   0 159 108 155 160   2
 171  24 320  72 125 241 129 111  15 114 263 162  55 214  82 110  31  98
  89 166 315 126 285 100  57 158 127 169 186  99 121 256 314  53 236 261
  70 296 130 107 218  13 117  19 220  86 119 140 193 244 122 131 123  81
 242 178  90 176 293  97 112 278 135 279 232  96 292  84  78 149 251 246
 165 182 305 102 137 168 106 185  18 132 167 188 180 273 274  80 307 150
 163 191  87  54 105 271  33 192 249 310 287 225  92 301 219 175  91 173
  68  23 118  34  36 139 154  35 174 298 177  37 239 297 172  42 138 282
 300  46 152 268 299  48   1 253   3  62 179 243   4  69 151 238 184  77
 164 231 187  83  45 217 189 181 229 205 183 258 161 200 157 113 190 248
 156 294 319 260 148  58 318 153 147   5   6 289   8  60   9  74  11  64
  12 313]
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.12805628776550293, 'test_f1': 0.9433962264150944, 'test_prec': 0.9615384615384616, 'test_recall': 0.9259259259259259, 'train_positive_rate': 0.385, 'pool_positive_rate': 0.008264462809917356, 'labeled_instances': 200, 'iteration_time': 243.48758840560913}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 240
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1372339278459549, 'test_f1': 0.9433962264150944, 'test_prec': 0.9615384615384616, 'test_recall': 0.9259259259259259, 'train_positive_rate': 0.325, 'pool_positive_rate': 0.0, 'labeled_instances': 240, 'iteration_time': 249.04707074165344}
| ID | GPU | MEM |
------------------
|  0 |  4% | 33% |

Test : 280
New cross validation 1 <function deepmatcher_structured_itunes_amazon at 0x14891c5ca3a0>
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 0
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.18551215529441833, 'test_f1': 0.9433962264150944, 'test_prec': 0.9615384615384616, 'test_recall': 0.9259259259259259, 'train_positive_rate': 0.24299065420560748, 'pool_positive_rate': 0.24299065420560748, 'labeled_instances': 0, 'iteration_time': 260.922278881073}
| ID | GPU | MEM |
------------------
|  0 |  7% | 45% |

Test : 20
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.5829850435256958, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'train_positive_rate': 0.4, 'pool_positive_rate': 0.23255813953488372, 'labeled_instances': 20, 'iteration_time': 232.0059621334076}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 40
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.46381875872612, 'test_f1': 0.07142857142857142, 'test_prec': 1.0, 'test_recall': 0.037037037037037035, 'train_positive_rate': 0.375, 'pool_positive_rate': 0.22419928825622776, 'labeled_instances': 40, 'iteration_time': 234.64521431922913}
| ID | GPU | MEM |
------------------
|  0 | 10% | 33% |

Test : 60
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.21660982072353363, 'test_f1': 0.8846153846153846, 'test_prec': 0.92, 'test_recall': 0.8518518518518519, 'train_positive_rate': 0.36666666666666664, 'pool_positive_rate': 0.21455938697318008, 'labeled_instances': 60, 'iteration_time': 236.96558284759521}
| ID | GPU | MEM |
------------------
|  0 | 14% | 46% |

Test : 80
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.14682215452194214, 'test_f1': 0.923076923076923, 'test_prec': 0.96, 'test_recall': 0.8888888888888888, 'train_positive_rate': 0.4, 'pool_positive_rate': 0.1908713692946058, 'labeled_instances': 80, 'iteration_time': 241.48133993148804}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 100
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.08987008035182953, 'test_f1': 0.9473684210526316, 'test_prec': 0.9, 'test_recall': 1.0, 'train_positive_rate': 0.41, 'pool_positive_rate': 0.167420814479638, 'labeled_instances': 100, 'iteration_time': 240.0982151031494}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 120
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.10589372366666794, 'test_f1': 0.9285714285714286, 'test_prec': 0.896551724137931, 'test_recall': 0.9629629629629629, 'train_positive_rate': 0.425, 'pool_positive_rate': 0.13432835820895522, 'labeled_instances': 120, 'iteration_time': 243.78933715820312}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 140
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.09753458946943283, 'test_f1': 0.9629629629629629, 'test_prec': 0.9629629629629629, 'test_recall': 0.9629629629629629, 'train_positive_rate': 0.4357142857142857, 'pool_positive_rate': 0.09392265193370165, 'labeled_instances': 140, 'iteration_time': 243.21681380271912}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 160
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1957804411649704, 'test_f1': 0.912280701754386, 'test_prec': 0.8666666666666667, 'test_recall': 0.9629629629629629, 'train_positive_rate': 0.44375, 'pool_positive_rate': 0.043478260869565216, 'labeled_instances': 160, 'iteration_time': 237.7024257183075}
| ID | GPU | MEM |
------------------
|  0 |  0% | 46% |

Test : 180
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.12514528632164001, 'test_f1': 0.9433962264150944, 'test_prec': 0.9615384615384616, 'test_recall': 0.9259259259259259, 'train_positive_rate': 0.42777777777777776, 'pool_positive_rate': 0.0070921985815602835, 'labeled_instances': 180, 'iteration_time': 239.5198209285736}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 200
[207  66 204  10 288 309  29 235 316   7 222 170   0 159 108 155 160   2
 171  24 320  72 125 241 129 111  15 114 263 162  55 214  82 110  31  98
  89 166 315 126 285 100  57 158 127 169 186  99 121 256 314  53 236 261
  70 296 130 107 218  13 117  19 220  86 119 140 193 244 122 131 123  81
 242 178  90 176 293  97 112 278 135 279 232  96 292  84  78 149 251 246
 165 182 305 102 137 168 106 185  18 132 167 188 180 273 274  80 307 150
 163 191  87  54 105 271  33 192 249 310 287 225  92 301 219 175  91 173
  68  23 118  34  36 139 154  35 174 298 177  37 239 297 172  42 138 282
 300  46 152 268 299  48   1 253   3  62 179 243   4  69 151 238 184  77
 164 231 187  83  45 217 189 181 229 205 183 258 161 200 157 113 190 248
 156 294 319 260 148  58 318 153 147   5   6 289   8  60   9  74  11  64
  12 313]
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.12219129502773285, 'test_f1': 0.9285714285714286, 'test_prec': 0.896551724137931, 'test_recall': 0.9629629629629629, 'train_positive_rate': 0.385, 'pool_positive_rate': 0.008264462809917356, 'labeled_instances': 200, 'iteration_time': 251.57645320892334}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 240
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.05015537142753601, 'test_f1': 0.9629629629629629, 'test_prec': 0.9629629629629629, 'test_recall': 0.9629629629629629, 'train_positive_rate': 0.325, 'pool_positive_rate': 0.0, 'labeled_instances': 240, 'iteration_time': 260.4445629119873}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 280
New cross validation 2 <function deepmatcher_structured_itunes_amazon at 0x14891c5ca3a0>
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 0
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.1000816598534584, 'test_f1': 0.9629629629629629, 'test_prec': 0.9629629629629629, 'test_recall': 0.9629629629629629, 'train_positive_rate': 0.24299065420560748, 'pool_positive_rate': 0.24299065420560748, 'labeled_instances': 0, 'iteration_time': 261.90008878707886}
| ID | GPU | MEM |
------------------
|  0 |  1% | 33% |

Test : 20
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.5489481091499329, 'test_f1': 0.0, 'test_prec': 0.0, 'test_recall': 0.0, 'train_positive_rate': 0.4, 'pool_positive_rate': 0.23255813953488372, 'labeled_instances': 20, 'iteration_time': 227.64817190170288}
| ID | GPU | MEM |
------------------
|  0 | 14% | 46% |

Test : 40
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.40427833795547485, 'test_f1': 0.5, 'test_prec': 1.0, 'test_recall': 0.3333333333333333, 'train_positive_rate': 0.375, 'pool_positive_rate': 0.22419928825622776, 'labeled_instances': 40, 'iteration_time': 230.7168571949005}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 60
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.16861003637313843, 'test_f1': 0.8979591836734693, 'test_prec': 1.0, 'test_recall': 0.8148148148148148, 'train_positive_rate': 0.36666666666666664, 'pool_positive_rate': 0.21455938697318008, 'labeled_instances': 60, 'iteration_time': 241.49697303771973}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 80
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.22871838510036469, 'test_f1': 0.84, 'test_prec': 0.9130434782608695, 'test_recall': 0.7777777777777778, 'train_positive_rate': 0.4, 'pool_positive_rate': 0.1908713692946058, 'labeled_instances': 80, 'iteration_time': 240.94524788856506}
| ID | GPU | MEM |
------------------
|  0 |  3% | 45% |

Test : 100
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.0659470334649086, 'test_f1': 0.9642857142857143, 'test_prec': 0.9310344827586207, 'test_recall': 1.0, 'train_positive_rate': 0.41, 'pool_positive_rate': 0.167420814479638, 'labeled_instances': 100, 'iteration_time': 237.89780950546265}
| ID | GPU | MEM |
------------------
|  0 | 14% | 21% |

Test : 120
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.11784107983112335, 'test_f1': 0.9411764705882353, 'test_prec': 1.0, 'test_recall': 0.8888888888888888, 'train_positive_rate': 0.425, 'pool_positive_rate': 0.13432835820895522, 'labeled_instances': 120, 'iteration_time': 233.61372065544128}
| ID | GPU | MEM |
------------------
|  0 |  0% | 33% |

Test : 140
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.09314426779747009, 'test_f1': 0.9454545454545454, 'test_prec': 0.9285714285714286, 'test_recall': 0.9629629629629629, 'train_positive_rate': 0.4357142857142857, 'pool_positive_rate': 0.09392265193370165, 'labeled_instances': 140, 'iteration_time': 254.13887906074524}
| ID | GPU | MEM |
------------------
|  0 | 13% | 46% |

Test : 160
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.4117814600467682, 'test_f1': 0.8771929824561403, 'test_prec': 0.8333333333333334, 'test_recall': 0.9259259259259259, 'train_positive_rate': 0.44375, 'pool_positive_rate': 0.043478260869565216, 'labeled_instances': 160, 'iteration_time': 256.47590351104736}
| ID | GPU | MEM |
------------------
|  0 | 12% | 33% |

Test : 180
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.11283478885889053, 'test_f1': 0.9454545454545454, 'test_prec': 0.9285714285714286, 'test_recall': 0.9629629629629629, 'train_positive_rate': 0.42777777777777776, 'pool_positive_rate': 0.0070921985815602835, 'labeled_instances': 180, 'iteration_time': 266.03505182266235}
| ID | GPU | MEM |
------------------
|  0 | 14% | 46% |

Test : 200
[207  66 204  10 288 309  29 235 316   7 222 170   0 159 108 155 160   2
 171  24 320  72 125 241 129 111  15 114 263 162  55 214  82 110  31  98
  89 166 315 126 285 100  57 158 127 169 186  99 121 256 314  53 236 261
  70 296 130 107 218  13 117  19 220  86 119 140 193 244 122 131 123  81
 242 178  90 176 293  97 112 278 135 279 232  96 292  84  78 149 251 246
 165 182 305 102 137 168 106 185  18 132 167 188 180 273 274  80 307 150
 163 191  87  54 105 271  33 192 249 310 287 225  92 301 219 175  91 173
  68  23 118  34  36 139 154  35 174 298 177  37 239 297 172  42 138 282
 300  46 152 268 299  48   1 253   3  62 179 243   4  69 151 238 184  77
 164 231 187  83  45 217 189 181 229 205 183 258 161 200 157 113 190 248
 156 294 319 260 148  58 318 153 147   5   6 289   8  60   9  74  11  64
  12 313]
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
{'test_loss': 0.2431362420320511, 'test_f1': 0.9090909090909091, 'test_prec': 0.8928571428571429, 'test_recall': 0.9259259259259259, 'train_positive_rate': 0.385, 'pool_positive_rate': 0.008264462809917356, 'labeled_instances': 200, 'iteration_time': 262.6955142021179}
| ID | GPU | MEM |
------------------
|  0 |  0% | 21% |

Test : 240
{'test_loss': 0.16799314320087433, 'test_f1': 0.9433962264150944, 'test_prec': 0.9615384615384616, 'test_recall': 0.9259259259259259, 'train_positive_rate': 0.325, 'pool_positive_rate': 0.0, 'labeled_instances': 240, 'iteration_time': 255.00544810295105}
| ID | GPU | MEM |
------------------
|  0 | 14% | 33% |

Test : 280
Could not create dir out, File exists
End of job!
