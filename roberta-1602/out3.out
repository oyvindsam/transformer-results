We are running from this directory: /cluster/work/oyvinsam
The name of the job is: alt-3
The job ID is 35852
The job was run on these nodes: idun-05-06
Number of nodes: 1
We are using 1 cores
We are using 1 cores per node
Total of 1 cores
Tue Mar 16 17:10:17 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.27.04    Driver Version: 460.27.04    CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-PCIE...  Off  | 00000000:3B:00.0 Off |                    0 |
| N/A   30C    P0    36W / 250W |      0MiB / 16160MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
fatal: destination path 'experiment-data' already exists and is not an empty directory.
Launch Python
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
[50, 75, 100, 120, 140, 160, 180, 200, 250, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 2000]
    ########### 



New Dataset: <function deepmatcher_structured_amazon_google at 0x14962ea16280>

Test : 50
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.31141397356987,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------
{'test_loss': 0.31141397356987, 'test_prec': 0.0, 'test_recall': 0.0, 'test_f1': 0.0, 'positive_rate': 0.22, 'labeled_instances': 50, 'iteration_time': 122.13487935066223}
-- Random test --

      a.index  b.index  matching
2254      795     2594      True
4334      527     2199     False
3318     1198     1253     False
5233     1244     1256     False
6344      699      328     False
5857      751     2283     False
6647      644      330      True
2462       64     2826     False
3752     1362     3136     False
1657      578     3183     False
6296      208       69     False
4561       26      176     False
468      1174      946     False
2922      757      340      True
1979      817      400      True
2638      562      257     False
543       672     1432     False
1188      615     1853     False
1726     1290     2402     False
132      1055      243     False
5325      658     1579     False
2807      628      276      True
1672      316     2865     False
476       226     2466     False
5162      620      932     False
2155       76     3003     False
1921      737     3094     False
6477     1258     2399     False
5595      823     3029     False
2753      683     2986     False
4954      851     2752     False
3464      839      508     False
1056      604     2332     False
5783      518     2803     False
6276      645     1132     False
2057      465     1150     False
2858      271     2821     False
3611      140      345     False
5839      549     1897     False
1421      520     1307     False
3467      808      535      True
3722      382      957     False
503      1108     2763     False
1543      511     1162     False
1153      456     2550      True
4020      258     1852     False
2251     1353     3048     False
2751      312     3168     False
5426     1020      758     False
2845      536     1595     False
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.2687983512878418,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 75
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.28808864265927975,
 'test_loss': 0.3325880467891693,
 'test_prec': 0.4094488188976378,
 'test_recall': 0.2222222222222222}
--------------------------------------------------------------------------------
{'test_loss': 0.3325880467891693, 'test_prec': 0.4094488188976378, 'test_recall': 0.2222222222222222, 'test_f1': 0.28808864265927975, 'positive_rate': 0.24, 'labeled_instances': 75, 'iteration_time': 110.98058724403381}
-- Random test --

      a.index  b.index  matching
2254      795     2594      True
4334      527     2199     False
3318     1198     1253     False
5233     1244     1256     False
6344      699      328     False
...       ...      ...       ...
2202     1148     3214     False
4210     1198     1124     False
642       490      124     False
6553      511     1075     False
4239      420     3007     False

[75 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.008130081300813009,
 'test_loss': 0.33414971828460693,
 'test_prec': 0.08333333333333333,
 'test_recall': 0.004273504273504274}
--------------------------------------------------------------------------------

Test : 100
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.4555984555984556,
 'test_loss': 0.26709744334220886,
 'test_prec': 0.4154929577464789,
 'test_recall': 0.5042735042735043}
--------------------------------------------------------------------------------
{'test_loss': 0.26709744334220886, 'test_prec': 0.4154929577464789, 'test_recall': 0.5042735042735043, 'test_f1': 0.4555984555984556, 'positive_rate': 0.22, 'labeled_instances': 100, 'iteration_time': 116.52476000785828}
-- Random test --

      a.index  b.index  matching
2254      795     2594      True
4334      527     2199     False
3318     1198     1253     False
5233     1244     1256     False
6344      699      328     False
...       ...      ...       ...
496       827     2496     False
2900      852      312     False
1163      804     3024     False
4252      301     1181     False
3487      646     1475     False

[100 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.35332366824150085,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 120
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.175,
 'test_loss': 0.34588631987571716,
 'test_prec': 0.32558139534883723,
 'test_recall': 0.11965811965811966}
--------------------------------------------------------------------------------
{'test_loss': 0.34588631987571716, 'test_prec': 0.32558139534883723, 'test_recall': 0.11965811965811966, 'test_f1': 0.175, 'positive_rate': 0.20833333333333334, 'labeled_instances': 120, 'iteration_time': 119.74396467208862}
-- Random test --

      a.index  b.index  matching
2254      795     2594      True
4334      527     2199     False
3318     1198     1253     False
5233     1244     1256     False
6344      699      328     False
...       ...      ...       ...
3613     1177     2165     False
6655     1341     2996     False
586       212     3055     False
3025      139     1213     False
2916      146     2821     False

[120 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.20640569395017794,
 'test_loss': 0.30100691318511963,
 'test_prec': 0.6170212765957447,
 'test_recall': 0.12393162393162394}
--------------------------------------------------------------------------------

Test : 140
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.3361702127659575,
 'test_loss': 0.34012094140052795,
 'test_prec': 0.3347457627118644,
 'test_recall': 0.33760683760683763}
--------------------------------------------------------------------------------
{'test_loss': 0.34012094140052795, 'test_prec': 0.3347457627118644, 'test_recall': 0.33760683760683763, 'test_f1': 0.3361702127659575, 'positive_rate': 0.18571428571428572, 'labeled_instances': 140, 'iteration_time': 122.08040189743042}
-- Random test --

      a.index  b.index  matching
2254      795     2594      True
4334      527     2199     False
3318     1198     1253     False
5233     1244     1256     False
6344      699      328     False
...       ...      ...       ...
4586     1179     3107     False
1934     1061     2226     False
3552     1353      621      True
592       930      331     False
4030      504      176     False

[140 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.27439024390243905,
 'test_loss': 0.30412623286247253,
 'test_prec': 0.4787234042553192,
 'test_recall': 0.19230769230769232}
--------------------------------------------------------------------------------

Test : 160
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.41836734693877553,
 'test_loss': 0.3274012506008148,
 'test_prec': 0.5189873417721519,
 'test_recall': 0.3504273504273504}
--------------------------------------------------------------------------------
{'test_loss': 0.3274012506008148, 'test_prec': 0.5189873417721519, 'test_recall': 0.3504273504273504, 'test_f1': 0.41836734693877553, 'positive_rate': 0.2, 'labeled_instances': 160, 'iteration_time': 127.05197978019714}
-- Random test --

      a.index  b.index  matching
2254      795     2594      True
4334      527     2199     False
3318     1198     1253     False
5233     1244     1256     False
6344      699      328     False
...       ...      ...       ...
3109      971     3048     False
2815      225     1686     False
5137      531     1137     False
2596      225     3215     False
535       895     1118     False

[160 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.48165137614678905,
 'test_loss': 0.330917626619339,
 'test_prec': 0.5198019801980198,
 'test_recall': 0.44871794871794873}
--------------------------------------------------------------------------------

Test : 180
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.3534883720930233,
 'test_loss': 0.4016423225402832,
 'test_prec': 0.3877551020408163,
 'test_recall': 0.3247863247863248}
--------------------------------------------------------------------------------
{'test_loss': 0.4016423225402832, 'test_prec': 0.3877551020408163, 'test_recall': 0.3247863247863248, 'test_f1': 0.3534883720930233, 'positive_rate': 0.21666666666666667, 'labeled_instances': 180, 'iteration_time': 127.86313581466675}
-- Random test --

      a.index  b.index  matching
2254      795     2594      True
4334      527     2199     False
3318     1198     1253     False
5233     1244     1256     False
6344      699      328     False
...       ...      ...       ...
4941      522     1075     False
752       661     1150     False
1954      991     3023     False
5912      808      562     False
3494      236     2827     False

[180 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5342789598108747,
 'test_loss': 0.2934545874595642,
 'test_prec': 0.5978835978835979,
 'test_recall': 0.4829059829059829}
--------------------------------------------------------------------------------

Test : 200
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.4053452115812918,
 'test_loss': 0.34380418062210083,
 'test_prec': 0.4232558139534884,
 'test_recall': 0.3888888888888889}
--------------------------------------------------------------------------------
{'test_loss': 0.34380418062210083, 'test_prec': 0.4232558139534884, 'test_recall': 0.3888888888888889, 'test_f1': 0.4053452115812918, 'positive_rate': 0.245, 'labeled_instances': 200, 'iteration_time': 132.27909684181213}
-- Random test --

      a.index  b.index  matching
2254      795     2594      True
4334      527     2199     False
3318     1198     1253     False
5233     1244     1256     False
6344      699      328     False
...       ...      ...       ...
2276      274     3014     False
168        95     1630      True
6370      853     2503     False
429       823     1159     False
5481      753     1137     False

[200 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.548856548856549,
 'test_loss': 0.32736751437187195,
 'test_prec': 0.5344129554655871,
 'test_recall': 0.5641025641025641}
--------------------------------------------------------------------------------

Test : 250
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5441527446300717,
 'test_loss': 0.3338225781917572,
 'test_prec': 0.6162162162162163,
 'test_recall': 0.48717948717948717}
--------------------------------------------------------------------------------
{'test_loss': 0.3338225781917572, 'test_prec': 0.6162162162162163, 'test_recall': 0.48717948717948717, 'test_f1': 0.5441527446300717, 'positive_rate': 0.288, 'labeled_instances': 250, 'iteration_time': 136.2202844619751}
-- Random test --

      a.index  b.index  matching
2254      795     2594      True
4334      527     2199     False
3318     1198     1253     False
5233     1244     1256     False
6344      699      328     False
...       ...      ...       ...
4938      816     1864     False
6348     1330      639      True
6052      903      277     False
1740      799     2592      True
3016       99     1680      True

[250 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5330296127562641,
 'test_loss': 0.25609609484672546,
 'test_prec': 0.5707317073170731,
 'test_recall': 0.5}
--------------------------------------------------------------------------------

Test : 300
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5837651122625216,
 'test_loss': 0.38040831685066223,
 'test_prec': 0.48985507246376814,
 'test_recall': 0.7222222222222222}
--------------------------------------------------------------------------------
{'test_loss': 0.38040831685066223, 'test_prec': 0.48985507246376814, 'test_recall': 0.7222222222222222, 'test_f1': 0.5837651122625216, 'positive_rate': 0.30666666666666664, 'labeled_instances': 300, 'iteration_time': 138.9059443473816}
-- Random test --

      a.index  b.index  matching
2254      795     2594      True
4334      527     2199     False
3318     1198     1253     False
5233     1244     1256     False
6344      699      328     False
...       ...      ...       ...
6549      202     1517     False
61        975      734     False
2191      960      982     False
1055      231     1912     False
6160     1345     3221     False

[300 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5592417061611373,
 'test_loss': 0.3696691393852234,
 'test_prec': 0.6276595744680851,
 'test_recall': 0.5042735042735043}
--------------------------------------------------------------------------------

Test : 400
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5789473684210528,
 'test_loss': 0.2809315323829651,
 'test_prec': 0.5945945945945946,
 'test_recall': 0.5641025641025641}
--------------------------------------------------------------------------------
{'test_loss': 0.2809315323829651, 'test_prec': 0.5945945945945946, 'test_recall': 0.5641025641025641, 'test_f1': 0.5789473684210528, 'positive_rate': 0.3325, 'labeled_instances': 400, 'iteration_time': 145.22896337509155}
-- Random test --

      a.index  b.index  matching
2254      795     2594      True
4334      527     2199     False
3318     1198     1253     False
5233     1244     1256     False
6344      699      328     False
...       ...      ...       ...
2846      737      902     False
3575       35     1821     False
2650      145     2850     False
4962      606     1007     False
2303      490     2518     False

[400 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.555045871559633,
 'test_loss': 0.336448073387146,
 'test_prec': 0.599009900990099,
 'test_recall': 0.5170940170940171}
--------------------------------------------------------------------------------

Test : 500
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6143187066974597,
 'test_loss': 0.31688621640205383,
 'test_prec': 0.6683417085427136,
 'test_recall': 0.5683760683760684}
--------------------------------------------------------------------------------
{'test_loss': 0.31688621640205383, 'test_prec': 0.6683417085427136, 'test_recall': 0.5683760683760684, 'test_f1': 0.6143187066974597, 'positive_rate': 0.358, 'labeled_instances': 500, 'iteration_time': 140.98996996879578}
-- Random test --

      a.index  b.index  matching
2254      795     2594      True
4334      527     2199     False
3318     1198     1253     False
5233     1244     1256     False
6344      699      328     False
...       ...      ...       ...
6101      431      286     False
5943     1284     2926     False
6705      584     1715     False
2614     1334     1853     False
4393     1186     1146     False

[500 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.509009009009009,
 'test_loss': 0.3696042597293854,
 'test_prec': 0.5380952380952381,
 'test_recall': 0.4829059829059829}
--------------------------------------------------------------------------------

Test : 600
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6073059360730593,
 'test_loss': 0.30974873900413513,
 'test_prec': 0.6519607843137255,
 'test_recall': 0.5683760683760684}
--------------------------------------------------------------------------------
{'test_loss': 0.30974873900413513, 'test_prec': 0.6519607843137255, 'test_recall': 0.5683760683760684, 'test_f1': 0.6073059360730593, 'positive_rate': 0.38, 'labeled_instances': 600, 'iteration_time': 149.97245860099792}
-- Random test --

      a.index  b.index  matching
2254      795     2594      True
4334      527     2199     False
3318     1198     1253     False
5233     1244     1256     False
6344      699      328     False
...       ...      ...       ...
2417      892      580     False
3554      248     2419     False
4481      968     2656     False
620       662     1014     False
1079       93      904     False

[600 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.49532710280373826,
 'test_loss': 0.3493446111679077,
 'test_prec': 0.5463917525773195,
 'test_recall': 0.452991452991453}
--------------------------------------------------------------------------------

Test : 700
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6371681415929203,
 'test_loss': 0.319385826587677,
 'test_prec': 0.6605504587155964,
 'test_recall': 0.6153846153846154}
--------------------------------------------------------------------------------
{'test_loss': 0.319385826587677, 'test_prec': 0.6605504587155964, 'test_recall': 0.6153846153846154, 'test_f1': 0.6371681415929203, 'positive_rate': 0.38857142857142857, 'labeled_instances': 700, 'iteration_time': 156.22176861763}
-- Random test --

      a.index  b.index  matching
2254      795     2594      True
4334      527     2199     False
3318     1198     1253     False
5233     1244     1256     False
6344      699      328     False
...       ...      ...       ...
4416     1185     2402     False
4739      413     1216     False
5576     1257     1080     False
346       553      485     False
6550      512     1083     False

[700 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5625,
 'test_loss': 0.3801650106906891,
 'test_prec': 0.5487804878048781,
 'test_recall': 0.5769230769230769}
--------------------------------------------------------------------------------

Test : 800
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.647450110864745,
 'test_loss': 0.28799182176589966,
 'test_prec': 0.6728110599078341,
 'test_recall': 0.6239316239316239}
--------------------------------------------------------------------------------
{'test_loss': 0.28799182176589966, 'test_prec': 0.6728110599078341, 'test_recall': 0.6239316239316239, 'test_f1': 0.647450110864745, 'positive_rate': 0.36625, 'labeled_instances': 800, 'iteration_time': 170.34339046478271}
-- Random test --

      a.index  b.index  matching
2254      795     2594      True
4334      527     2199     False
3318     1198     1253     False
5233     1244     1256     False
6344      699      328     False
...       ...      ...       ...
5130     1264     1052     False
5626      251     2513     False
1606      258      137     False
5062     1330     2440     False
322       688      250      True

[800 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5525672371638142,
 'test_loss': 0.39408379793167114,
 'test_prec': 0.6457142857142857,
 'test_recall': 0.4829059829059829}
--------------------------------------------------------------------------------

Test : 900
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.647450110864745,
 'test_loss': 0.33910053968429565,
 'test_prec': 0.6728110599078341,
 'test_recall': 0.6239316239316239}
--------------------------------------------------------------------------------
{'test_loss': 0.33910053968429565, 'test_prec': 0.6728110599078341, 'test_recall': 0.6239316239316239, 'test_f1': 0.647450110864745, 'positive_rate': 0.34444444444444444, 'labeled_instances': 900, 'iteration_time': 161.57512259483337}
-- Random test --

      a.index  b.index  matching
2254      795     2594      True
4334      527     2199     False
3318     1198     1253     False
5233     1244     1256     False
6344      699      328     False
...       ...      ...       ...
6657      578     2877     False
196      1290     1048     False
3932      591      926     False
3258      993     3034     False
3058      145     1585     False

[900 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5631067961165049,
 'test_loss': 0.3080907166004181,
 'test_prec': 0.651685393258427,
 'test_recall': 0.49572649572649574}
--------------------------------------------------------------------------------

Test : 1000
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6434782608695652,
 'test_loss': 0.31171518564224243,
 'test_prec': 0.6548672566371682,
 'test_recall': 0.6324786324786325}
--------------------------------------------------------------------------------
{'test_loss': 0.31171518564224243, 'test_prec': 0.6548672566371682, 'test_recall': 0.6324786324786325, 'test_f1': 0.6434782608695652, 'positive_rate': 0.33, 'labeled_instances': 1000, 'iteration_time': 175.8693606853485}
-- Random test --

      a.index  b.index  matching
2254      795     2594      True
4334      527     2199     False
3318     1198     1253     False
5233     1244     1256     False
6344      699      328     False
...       ...      ...       ...
4325      350     1612     False
6827      740      427      True
1374      145     3029     False
221      1185      313     False
4907      644     2848     False

[1000 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5580246913580247,
 'test_loss': 0.3618967831134796,
 'test_prec': 0.6608187134502924,
 'test_recall': 0.4829059829059829}
--------------------------------------------------------------------------------

Test : 1100
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6666666666666666,
 'test_loss': 0.3148648142814636,
 'test_prec': 0.7333333333333333,
 'test_recall': 0.6111111111111112}
--------------------------------------------------------------------------------
{'test_loss': 0.3148648142814636, 'test_prec': 0.7333333333333333, 'test_recall': 0.6111111111111112, 'test_f1': 0.6666666666666666, 'positive_rate': 0.3109090909090909, 'labeled_instances': 1100, 'iteration_time': 171.72966861724854}
-- Random test --

      a.index  b.index  matching
2254      795     2594      True
4334      527     2199     False
3318     1198     1253     False
5233     1244     1256     False
6344      699      328     False
...       ...      ...       ...
3169      662       36     False
2997      335     2032     False
4559      686      353     False
5514      216      893     False
2704      316      793     False

[1100 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.542713567839196,
 'test_loss': 0.4260765016078949,
 'test_prec': 0.6585365853658537,
 'test_recall': 0.46153846153846156}
--------------------------------------------------------------------------------

Test : 1200
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6323185011709601,
 'test_loss': 0.30597034096717834,
 'test_prec': 0.6994818652849741,
 'test_recall': 0.5769230769230769}
--------------------------------------------------------------------------------
{'test_loss': 0.30597034096717834, 'test_prec': 0.6994818652849741, 'test_recall': 0.5769230769230769, 'test_f1': 0.6323185011709601, 'positive_rate': 0.30333333333333334, 'labeled_instances': 1200, 'iteration_time': 193.23563313484192}
-- Random test --

      a.index  b.index  matching
2254      795     2594      True
4334      527     2199     False
3318     1198     1253     False
5233     1244     1256     False
6344      699      328     False
...       ...      ...       ...
3505     1331     1668     False
3346      816     1170     False
1718      265      331      True
5198       93     2518     False
4463      844     2762     False

[1200 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6214442013129102,
 'test_loss': 0.3619605600833893,
 'test_prec': 0.6367713004484304,
 'test_recall': 0.6068376068376068}
--------------------------------------------------------------------------------

Test : 1300
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6589327146171694,
 'test_loss': 0.3056965470314026,
 'test_prec': 0.7208121827411168,
 'test_recall': 0.6068376068376068}
--------------------------------------------------------------------------------
{'test_loss': 0.3056965470314026, 'test_prec': 0.7208121827411168, 'test_recall': 0.6068376068376068, 'test_f1': 0.6589327146171694, 'positive_rate': 0.2946153846153846, 'labeled_instances': 1300, 'iteration_time': 195.62281036376953}
-- Random test --

      a.index  b.index  matching
2254      795     2594      True
4334      527     2199     False
3318     1198     1253     False
5233     1244     1256     False
6344      699      328     False
...       ...      ...       ...
315       364     3213     False
4731      319     3119      True
4883     1284     2400     False
1161      819     2527     False
4684      574     3183     False

[1300 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6017699115044248,
 'test_loss': 0.35581067204475403,
 'test_prec': 0.6238532110091743,
 'test_recall': 0.5811965811965812}
--------------------------------------------------------------------------------

Test : 1400
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6696629213483146,
 'test_loss': 0.28717997670173645,
 'test_prec': 0.7061611374407583,
 'test_recall': 0.6367521367521367}
--------------------------------------------------------------------------------
{'test_loss': 0.28717997670173645, 'test_prec': 0.7061611374407583, 'test_recall': 0.6367521367521367, 'test_f1': 0.6696629213483146, 'positive_rate': 0.2814285714285714, 'labeled_instances': 1400, 'iteration_time': 192.47816801071167}
-- Random test --

      a.index  b.index  matching
2254      795     2594      True
4334      527     2199     False
3318     1198     1253     False
5233     1244     1256     False
6344      699      328     False
...       ...      ...       ...
641       553      521     False
3442     1185      741     False
3705      917      163      True
5888      350      354     False
297      1196     2987     False

[1400 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6049661399548533,
 'test_loss': 0.37188535928726196,
 'test_prec': 0.6411483253588517,
 'test_recall': 0.5726495726495726}
--------------------------------------------------------------------------------

Test : 1500
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6772009029345373,
 'test_loss': 0.2651073932647705,
 'test_prec': 0.7177033492822966,
 'test_recall': 0.6410256410256411}
--------------------------------------------------------------------------------
{'test_loss': 0.2651073932647705, 'test_prec': 0.7177033492822966, 'test_recall': 0.6410256410256411, 'test_f1': 0.6772009029345373, 'positive_rate': 0.2713333333333333, 'labeled_instances': 1500, 'iteration_time': 210.4689211845398}
-- Random test --

      a.index  b.index  matching
2254      795     2594      True
4334      527     2199     False
3318     1198     1253     False
5233     1244     1256     False
6344      699      328     False
...       ...      ...       ...
3148      825     2871     False
4248     1021     2144     False
2181      808     2926     False
1599      584      924     False
4814      567     2532     False

[1500 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5204819277108435,
 'test_loss': 0.30780115723609924,
 'test_prec': 0.5966850828729282,
 'test_recall': 0.46153846153846156}
--------------------------------------------------------------------------------

Test : 2000
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.654292343387471,
 'test_loss': 0.2739578187465668,
 'test_prec': 0.7157360406091371,
 'test_recall': 0.6025641025641025}
--------------------------------------------------------------------------------
{'test_loss': 0.2739578187465668, 'test_prec': 0.7157360406091371, 'test_recall': 0.6025641025641025, 'test_f1': 0.654292343387471, 'positive_rate': 0.241, 'labeled_instances': 2000, 'iteration_time': 224.94288420677185}
-- Random test --

      a.index  b.index  matching
2254      795     2594      True
4334      527     2199     False
3318     1198     1253     False
5233     1244     1256     False
6344      699      328     False
...       ...      ...       ...
4827      981     2804     False
5830      319     3099     False
184      1244     1319     False
6463      605     3183     False
71        994      828      True

[2000 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6394557823129252,
 'test_loss': 0.30980759859085083,
 'test_prec': 0.6811594202898551,
 'test_recall': 0.6025641025641025}
--------------------------------------------------------------------------------
-- Full test test --

Positive rate: 0.1016875181844632
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7272727272727272,
 'test_loss': 0.22595560550689697,
 'test_prec': 0.8,
 'test_recall': 0.6666666666666666}
--------------------------------------------------------------------------------
    ########### 



New Dataset: <function deepmatcher_structured_dblp_acm at 0x1495c2d344c0>

Test : 50
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9034267912772586,
 'test_loss': 0.16506925225257874,
 'test_prec': 0.838150289017341,
 'test_recall': 0.9797297297297297}
--------------------------------------------------------------------------------
{'test_loss': 0.16506925225257874, 'test_prec': 0.838150289017341, 'test_recall': 0.9797297297297297, 'test_f1': 0.9034267912772586, 'positive_rate': 0.48, 'labeled_instances': 50, 'iteration_time': 197.5490016937256}
-- Random test --

      a.index  b.index  matching
5483     2005     1052     False
4556     1538       98     False
4056      144     2225     False
1811     2237     1472     False
763      1136     1148      True
3515     2179     1787     False
1142     2495     1632     False
5365      123      418     False
6608     1975       72     False
2478     2350     2261     False
6658      307     2159     False
4701     1439     1512     False
6343     2246     1953     False
1034      628     1462     False
7173       55      545     False
4631      466     2050     False
3666     1044     1042     False
5023     1181      455     False
3089      747      340     False
2034      445      239      True
5284     1287     1088     False
5840     2203      342     False
6384     2436      600      True
2908     1658      850     False
5820     2486     1160     False
965      1480      855     False
6334     1812     1138      True
1803      899      371     False
169       198      778     False
5277     2233     1304      True
1618     1616     1909     False
4247      778     1751      True
4318     1542      777     False
4525     1530      640     False
5371     2232      591     False
3001      987     1194     False
3379     2357      213     False
7362     2209     1827      True
4816      545     1448     False
4899     2307     1942      True
736       932      688     False
4604     2119     1987     False
877      1577     1596     False
2272     2246      258     False
3862      854     1046     False
101       507      443     False
6556     1132      181      True
1042     2115      190      True
7288     1231      923     False
7180     2402     1048     False
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.89648033126294,
 'test_loss': 0.1046125516295433,
 'test_prec': 0.8295019157088123,
 'test_recall': 0.9752252252252253}
--------------------------------------------------------------------------------

Test : 75
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9379014989293362,
 'test_loss': 0.08050059527158737,
 'test_prec': 0.8938775510204081,
 'test_recall': 0.9864864864864865}
--------------------------------------------------------------------------------
{'test_loss': 0.08050059527158737, 'test_prec': 0.8938775510204081, 'test_recall': 0.9864864864864865, 'test_f1': 0.9379014989293362, 'positive_rate': 0.48, 'labeled_instances': 75, 'iteration_time': 208.44514346122742}
-- Random test --

      a.index  b.index  matching
5483     2005     1052     False
4556     1538       98     False
4056      144     2225     False
1811     2237     1472     False
763      1136     1148      True
...       ...      ...       ...
7385      123     1992     False
4319     1689     1161     False
2133      720     1248      True
251       877      103      True
4638     2302     1534     False

[75 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9013761467889908,
 'test_loss': 0.12600886821746826,
 'test_prec': 0.9182242990654206,
 'test_recall': 0.8851351351351351}
--------------------------------------------------------------------------------

Test : 100
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9243697478991598,
 'test_loss': 0.08524512499570847,
 'test_prec': 0.8661417322834646,
 'test_recall': 0.990990990990991}
--------------------------------------------------------------------------------
{'test_loss': 0.08524512499570847, 'test_prec': 0.8661417322834646, 'test_recall': 0.990990990990991, 'test_f1': 0.9243697478991598, 'positive_rate': 0.46, 'labeled_instances': 100, 'iteration_time': 211.95205569267273}
-- Random test --

      a.index  b.index  matching
5483     2005     1052     False
4556     1538       98     False
4056      144     2225     False
1811     2237     1472     False
763      1136     1148      True
...       ...      ...       ...
7242     1779     1258      True
2138     1226     2008      True
2778     2244     1239     False
4671     1387     1672     False
4024     1415     1423     False

[100 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8898305084745762,
 'test_loss': 0.17828482389450073,
 'test_prec': 0.84,
 'test_recall': 0.9459459459459459}
--------------------------------------------------------------------------------

Test : 120
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9373650107991361,
 'test_loss': 0.08274015039205551,
 'test_prec': 0.9004149377593361,
 'test_recall': 0.9774774774774775}
--------------------------------------------------------------------------------
{'test_loss': 0.08274015039205551, 'test_prec': 0.9004149377593361, 'test_recall': 0.9774774774774775, 'test_f1': 0.9373650107991361, 'positive_rate': 0.4666666666666667, 'labeled_instances': 120, 'iteration_time': 217.2033679485321}
-- Random test --

      a.index  b.index  matching
5483     2005     1052     False
4556     1538       98     False
4056      144     2225     False
1811     2237     1472     False
763      1136     1148      True
...       ...      ...       ...
6412      361     1432     False
2799     2608      553     False
5061     1222      392      True
4570      267     1868     False
496       847      955     False

[120 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8987341772151899,
 'test_loss': 0.22489231824874878,
 'test_prec': 0.8452380952380952,
 'test_recall': 0.9594594594594594}
--------------------------------------------------------------------------------

Test : 140
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9463087248322148,
 'test_loss': 0.06955225020647049,
 'test_prec': 0.94,
 'test_recall': 0.9527027027027027}
--------------------------------------------------------------------------------
{'test_loss': 0.06955225020647049, 'test_prec': 0.94, 'test_recall': 0.9527027027027027, 'test_f1': 0.9463087248322148, 'positive_rate': 0.45714285714285713, 'labeled_instances': 140, 'iteration_time': 205.30648922920227}
-- Random test --

      a.index  b.index  matching
5483     2005     1052     False
4556     1538       98     False
4056      144     2225     False
1811     2237     1472     False
763      1136     1148      True
...       ...      ...       ...
3771      390      264      True
7126      103     1262     False
2986       58      881     False
6086     1310     1935     False
6578     2096     1437     False

[140 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9158679446219383,
 'test_loss': 0.17610229551792145,
 'test_prec': 0.8686868686868687,
 'test_recall': 0.9684684684684685}
--------------------------------------------------------------------------------

Test : 160
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9556756756756757,
 'test_loss': 0.054439760744571686,
 'test_prec': 0.918918918918919,
 'test_recall': 0.9954954954954955}
--------------------------------------------------------------------------------
{'test_loss': 0.054439760744571686, 'test_prec': 0.918918918918919, 'test_recall': 0.9954954954954955, 'test_f1': 0.9556756756756757, 'positive_rate': 0.46875, 'labeled_instances': 160, 'iteration_time': 233.07182145118713}
-- Random test --

      a.index  b.index  matching
5483     2005     1052     False
4556     1538       98     False
4056      144     2225     False
1811     2237     1472     False
763      1136     1148      True
...       ...      ...       ...
6582     2578      388     False
7012      372     1583     False
4207     2000     1117      True
1322     1837      427      True
5251     1860     1504      True

[160 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9278794402583422,
 'test_loss': 0.14293769001960754,
 'test_prec': 0.8886597938144329,
 'test_recall': 0.9707207207207207}
--------------------------------------------------------------------------------

Test : 180
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.974472807991121,
 'test_loss': 0.035766057670116425,
 'test_prec': 0.9606126914660832,
 'test_recall': 0.9887387387387387}
--------------------------------------------------------------------------------
{'test_loss': 0.035766057670116425, 'test_prec': 0.9606126914660832, 'test_recall': 0.9887387387387387, 'test_f1': 0.974472807991121, 'positive_rate': 0.4777777777777778, 'labeled_instances': 180, 'iteration_time': 229.3950490951538}
-- Random test --

      a.index  b.index  matching
5483     2005     1052     False
4556     1538       98     False
4056      144     2225     False
1811     2237     1472     False
763      1136     1148      True
...       ...      ...       ...
5457     2435     1565     False
3024     2603     1511     False
4934      931      530     False
79       1829     1915     False
4019     1818      194      True

[180 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.911550468262227,
 'test_loss': 0.15945352613925934,
 'test_prec': 0.8471953578336557,
 'test_recall': 0.9864864864864865}
--------------------------------------------------------------------------------

Test : 200
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9730941704035874,
 'test_loss': 0.04058035835623741,
 'test_prec': 0.96875,
 'test_recall': 0.9774774774774775}
--------------------------------------------------------------------------------
{'test_loss': 0.04058035835623741, 'test_prec': 0.96875, 'test_recall': 0.9774774774774775, 'test_f1': 0.9730941704035874, 'positive_rate': 0.49, 'labeled_instances': 200, 'iteration_time': 220.69774723052979}
-- Random test --

      a.index  b.index  matching
5483     2005     1052     False
4556     1538       98     False
4056      144     2225     False
1811     2237     1472     False
763      1136     1148      True
...       ...      ...       ...
576      1597     1360      True
1880     2151      379     False
3803      162     1600      True
1952     1869      302      True
2375     2377      484      True

[200 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9370165745856354,
 'test_loss': 0.1037462130188942,
 'test_prec': 0.9197396963123644,
 'test_recall': 0.954954954954955}
--------------------------------------------------------------------------------

Test : 250
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9733924611973392,
 'test_loss': 0.04370078444480896,
 'test_prec': 0.9585152838427947,
 'test_recall': 0.9887387387387387}
--------------------------------------------------------------------------------
{'test_loss': 0.04370078444480896, 'test_prec': 0.9585152838427947, 'test_recall': 0.9887387387387387, 'test_f1': 0.9733924611973392, 'positive_rate': 0.48, 'labeled_instances': 250, 'iteration_time': 224.51883673667908}
-- Random test --

      a.index  b.index  matching
5483     2005     1052     False
4556     1538       98     False
4056      144     2225     False
1811     2237     1472     False
763      1136     1148      True
...       ...      ...       ...
3617      350      233      True
5076      575      527      True
711       841      664     False
7255      210      465     False
6897     1119     1579     False

[250 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.951739618406285,
 'test_loss': 0.07004212588071823,
 'test_prec': 0.9485458612975392,
 'test_recall': 0.954954954954955}
--------------------------------------------------------------------------------

Test : 300
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9732739420935412,
 'test_loss': 0.04605090990662575,
 'test_prec': 0.9625550660792952,
 'test_recall': 0.9842342342342343}
--------------------------------------------------------------------------------
{'test_loss': 0.04605090990662575, 'test_prec': 0.9625550660792952, 'test_recall': 0.9842342342342343, 'test_f1': 0.9732739420935412, 'positive_rate': 0.4766666666666667, 'labeled_instances': 300, 'iteration_time': 235.75136709213257}
-- Random test --

      a.index  b.index  matching
5483     2005     1052     False
4556     1538       98     False
4056      144     2225     False
1811     2237     1472     False
763      1136     1148      True
...       ...      ...       ...
468        40     1848     False
2304     2186     2207     False
2697     1561      322      True
429      2435      755     False
1002     1086      533     False

[300 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9707865168539327,
 'test_loss': 0.05601002275943756,
 'test_prec': 0.968609865470852,
 'test_recall': 0.972972972972973}
--------------------------------------------------------------------------------

Test : 400
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9820627802690582,
 'test_loss': 0.03450049087405205,
 'test_prec': 0.9776785714285714,
 'test_recall': 0.9864864864864865}
--------------------------------------------------------------------------------
{'test_loss': 0.03450049087405205, 'test_prec': 0.9776785714285714, 'test_recall': 0.9864864864864865, 'test_f1': 0.9820627802690582, 'positive_rate': 0.465, 'labeled_instances': 400, 'iteration_time': 250.8348536491394}
-- Random test --

      a.index  b.index  matching
5483     2005     1052     False
4556     1538       98     False
4056      144     2225     False
1811     2237     1472     False
763      1136     1148      True
...       ...      ...       ...
1507      142     1866     False
960       817     2043     False
3194     1752     1183      True
4983     2201      164     False
6574      153     1234     False

[400 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9700332963374029,
 'test_loss': 0.06465806066989899,
 'test_prec': 0.9562363238512035,
 'test_recall': 0.9842342342342343}
--------------------------------------------------------------------------------

Test : 500
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9898074745186863,
 'test_loss': 0.017491159960627556,
 'test_prec': 0.9954441913439636,
 'test_recall': 0.9842342342342343}
--------------------------------------------------------------------------------
{'test_loss': 0.017491159960627556, 'test_prec': 0.9954441913439636, 'test_recall': 0.9842342342342343, 'test_f1': 0.9898074745186863, 'positive_rate': 0.46, 'labeled_instances': 500, 'iteration_time': 239.0264081954956}
-- Random test --

      a.index  b.index  matching
5483     2005     1052     False
4556     1538       98     False
4056      144     2225     False
1811     2237     1472     False
763      1136     1148      True
...       ...      ...       ...
786       857     1507     False
1467     1254      399     False
2973      973     1463     False
2676     1546     1898     False
1009     2099     1690     False

[500 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9765886287625419,
 'test_loss': 0.03863661363720894,
 'test_prec': 0.9668874172185431,
 'test_recall': 0.9864864864864865}
--------------------------------------------------------------------------------

Test : 600
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9799107142857142,
 'test_loss': 0.020156733691692352,
 'test_prec': 0.9712389380530974,
 'test_recall': 0.9887387387387387}
--------------------------------------------------------------------------------
{'test_loss': 0.020156733691692352, 'test_prec': 0.9712389380530974, 'test_recall': 0.9887387387387387, 'test_f1': 0.9799107142857142, 'positive_rate': 0.4633333333333333, 'labeled_instances': 600, 'iteration_time': 249.17344188690186}
-- Random test --

      a.index  b.index  matching
5483     2005     1052     False
4556     1538       98     False
4056      144     2225     False
1811     2237     1472     False
763      1136     1148      True
...       ...      ...       ...
4101     1808      184     False
4373     2139     1652     False
4771       24     1132     False
642      1028      339     False
4374     2186     1222     False

[600 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9755555555555556,
 'test_loss': 0.03678010031580925,
 'test_prec': 0.9627192982456141,
 'test_recall': 0.9887387387387387}
--------------------------------------------------------------------------------

Test : 700
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9810479375696767,
 'test_loss': 0.022924792021512985,
 'test_prec': 0.9713024282560706,
 'test_recall': 0.990990990990991}
--------------------------------------------------------------------------------
{'test_loss': 0.022924792021512985, 'test_prec': 0.9713024282560706, 'test_recall': 0.990990990990991, 'test_f1': 0.9810479375696767, 'positive_rate': 0.46285714285714286, 'labeled_instances': 700, 'iteration_time': 266.41259932518005}
-- Random test --

      a.index  b.index  matching
5483     2005     1052     False
4556     1538       98     False
4056      144     2225     False
1811     2237     1472     False
763      1136     1148      True
...       ...      ...       ...
858      2418     2100      True
3961      838      171     False
7266      467      536     False
1623     1848      512     False
4655     2524     1265     False

[700 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.966740576496674,
 'test_loss': 0.06844457983970642,
 'test_prec': 0.9519650655021834,
 'test_recall': 0.9819819819819819}
--------------------------------------------------------------------------------

Test : 800
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9821428571428571,
 'test_loss': 0.017104633152484894,
 'test_prec': 0.9734513274336283,
 'test_recall': 0.990990990990991}
--------------------------------------------------------------------------------
{'test_loss': 0.017104633152484894, 'test_prec': 0.9734513274336283, 'test_recall': 0.990990990990991, 'test_f1': 0.9821428571428571, 'positive_rate': 0.46375, 'labeled_instances': 800, 'iteration_time': 255.77229714393616}
-- Random test --

      a.index  b.index  matching
5483     2005     1052     False
4556     1538       98     False
4056      144     2225     False
1811     2237     1472     False
763      1136     1148      True
...       ...      ...       ...
4366     2119      591     False
5720     2308     1282     False
96        420      152     False
5641      390      671     False
6653     1850      883     False

[800 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9710467706013363,
 'test_loss': 0.048718661069869995,
 'test_prec': 0.960352422907489,
 'test_recall': 0.9819819819819819}
--------------------------------------------------------------------------------

Test : 900
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9898305084745763,
 'test_loss': 0.02006719447672367,
 'test_prec': 0.9931972789115646,
 'test_recall': 0.9864864864864865}
--------------------------------------------------------------------------------
{'test_loss': 0.02006719447672367, 'test_prec': 0.9931972789115646, 'test_recall': 0.9864864864864865, 'test_f1': 0.9898305084745763, 'positive_rate': 0.4622222222222222, 'labeled_instances': 900, 'iteration_time': 272.3291964530945}
-- Random test --

      a.index  b.index  matching
5483     2005     1052     False
4556     1538       98     False
4056      144     2225     False
1811     2237     1472     False
763      1136     1148      True
...       ...      ...       ...
5278     1452     2133     False
1720     1892     1878     False
2902      368      780     False
23       1118     1915     False
3558       78      903     False

[900 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9797752808988766,
 'test_loss': 0.051217176020145416,
 'test_prec': 0.9775784753363229,
 'test_recall': 0.9819819819819819}
--------------------------------------------------------------------------------

Test : 1000
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.974472807991121,
 'test_loss': 0.021499572321772575,
 'test_prec': 0.9606126914660832,
 'test_recall': 0.9887387387387387}
--------------------------------------------------------------------------------
{'test_loss': 0.021499572321772575, 'test_prec': 0.9606126914660832, 'test_recall': 0.9887387387387387, 'test_f1': 0.974472807991121, 'positive_rate': 0.459, 'labeled_instances': 1000, 'iteration_time': 302.0097334384918}
-- Random test --

      a.index  b.index  matching
5483     2005     1052     False
4556     1538       98     False
4056      144     2225     False
1811     2237     1472     False
763      1136     1148      True
...       ...      ...       ...
547        28     1176      True
4812      863     2259     False
1634      630     1777     False
3307     1377      580     False
4077      942      619     False

[1000 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9854096520763187,
 'test_loss': 0.03370125964283943,
 'test_prec': 0.9821029082774049,
 'test_recall': 0.9887387387387387}
--------------------------------------------------------------------------------

Test : 1100
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9865470852017937,
 'test_loss': 0.021311836317181587,
 'test_prec': 0.9821428571428571,
 'test_recall': 0.990990990990991}
--------------------------------------------------------------------------------
{'test_loss': 0.021311836317181587, 'test_prec': 0.9821428571428571, 'test_recall': 0.990990990990991, 'test_f1': 0.9865470852017937, 'positive_rate': 0.45545454545454545, 'labeled_instances': 1100, 'iteration_time': 292.86468863487244}
-- Random test --

      a.index  b.index  matching
5483     2005     1052     False
4556     1538       98     False
4056      144     2225     False
1811     2237     1472     False
763      1136     1148      True
...       ...      ...       ...
1883      386      512     False
3686      449      949     False
2603      368     1074     False
5101     1596     1240     False
2850     1123      259     False

[1100 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9863945578231292,
 'test_loss': 0.026534460484981537,
 'test_prec': 0.9931506849315068,
 'test_recall': 0.9797297297297297}
--------------------------------------------------------------------------------

Test : 1200
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9809203142536477,
 'test_loss': 0.02769431285560131,
 'test_prec': 0.9776286353467561,
 'test_recall': 0.9842342342342343}
--------------------------------------------------------------------------------
{'test_loss': 0.02769431285560131, 'test_prec': 0.9776286353467561, 'test_recall': 0.9842342342342343, 'test_f1': 0.9809203142536477, 'positive_rate': 0.45666666666666667, 'labeled_instances': 1200, 'iteration_time': 318.7256906032562}
-- Random test --

      a.index  b.index  matching
5483     2005     1052     False
4556     1538       98     False
4056      144     2225     False
1811     2237     1472     False
763      1136     1148      True
...       ...      ...       ...
3539     1892      589     False
1263      470     1252     False
373       291     1313      True
2526     1260      342     False
5349      752     1692     False

[1200 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9864864864864865,
 'test_loss': 0.03257231414318085,
 'test_prec': 0.9864864864864865,
 'test_recall': 0.9864864864864865}
--------------------------------------------------------------------------------

Test : 1300
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9886877828054299,
 'test_loss': 0.014746956527233124,
 'test_prec': 0.9931818181818182,
 'test_recall': 0.9842342342342343}
--------------------------------------------------------------------------------
{'test_loss': 0.014746956527233124, 'test_prec': 0.9931818181818182, 'test_recall': 0.9842342342342343, 'test_f1': 0.9886877828054299, 'positive_rate': 0.4546153846153846, 'labeled_instances': 1300, 'iteration_time': 311.5942678451538}
-- Random test --

      a.index  b.index  matching
5483     2005     1052     False
4556     1538       98     False
4056      144     2225     False
1811     2237     1472     False
763      1136     1148      True
...       ...      ...       ...
2484     2422     1505     False
3105     2329     1563      True
1108     1038     1933     False
5202     1901     1065     False
1872     1359      384     False

[1300 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9841986455981941,
 'test_loss': 0.040045011788606644,
 'test_prec': 0.9864253393665159,
 'test_recall': 0.9819819819819819}
--------------------------------------------------------------------------------

Test : 1400
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9887133182844244,
 'test_loss': 0.009878492914140224,
 'test_prec': 0.9909502262443439,
 'test_recall': 0.9864864864864865}
--------------------------------------------------------------------------------
{'test_loss': 0.009878492914140224, 'test_prec': 0.9909502262443439, 'test_recall': 0.9864864864864865, 'test_f1': 0.9887133182844244, 'positive_rate': 0.455, 'labeled_instances': 1400, 'iteration_time': 309.7547233104706}
-- Random test --

      a.index  b.index  matching
5483     2005     1052     False
4556     1538       98     False
4056      144     2225     False
1811     2237     1472     False
763      1136     1148      True
...       ...      ...       ...
5812     2591     1952     False
1192     1634     1084     False
3058     1611      631      True
4094     2241      711     False
216       957     1239     False

[1400 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9876265466816648,
 'test_loss': 0.023045208305120468,
 'test_prec': 0.9865168539325843,
 'test_recall': 0.9887387387387387}
--------------------------------------------------------------------------------

Test : 1500
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9854096520763187,
 'test_loss': 0.016505107283592224,
 'test_prec': 0.9821029082774049,
 'test_recall': 0.9887387387387387}
--------------------------------------------------------------------------------
{'test_loss': 0.016505107283592224, 'test_prec': 0.9821029082774049, 'test_recall': 0.9887387387387387, 'test_f1': 0.9854096520763187, 'positive_rate': 0.4553333333333333, 'labeled_instances': 1500, 'iteration_time': 343.73628425598145}
-- Random test --

      a.index  b.index  matching
5483     2005     1052     False
4556     1538       98     False
4056      144     2225     False
1811     2237     1472     False
763      1136     1148      True
...       ...      ...       ...
1109     1794      110     False
3774      189     1669     False
1511     1910     1516      True
4424     2571     1622     False
7091     1406     1824      True

[1500 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9853438556933484,
 'test_loss': 0.02673748880624771,
 'test_prec': 0.9864559819413092,
 'test_recall': 0.9842342342342343}
--------------------------------------------------------------------------------

Test : 2000
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9875141884222476,
 'test_loss': 0.013038339093327522,
 'test_prec': 0.9954233409610984,
 'test_recall': 0.9797297297297297}
--------------------------------------------------------------------------------
{'test_loss': 0.013038339093327522, 'test_prec': 0.9954233409610984, 'test_recall': 0.9797297297297297, 'test_f1': 0.9875141884222476, 'positive_rate': 0.45, 'labeled_instances': 2000, 'iteration_time': 383.5716984272003}
-- Random test --

      a.index  b.index  matching
5483     2005     1052     False
4556     1538       98     False
4056      144     2225     False
1811     2237     1472     False
763      1136     1148      True
...       ...      ...       ...
6547     2124     1720     False
2471     1771      240     False
4357     2037      418     False
6913     2244     2101     False
5318     1380     2125     False

[2000 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9875706214689265,
 'test_loss': 0.0286136195063591,
 'test_prec': 0.9909297052154195,
 'test_recall': 0.9842342342342343}
--------------------------------------------------------------------------------
-- Full test test --

Positive rate: 0.17958743427261697
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9909706546275394,
 'test_loss': 0.013093381188809872,
 'test_prec': 0.9932126696832579,
 'test_recall': 0.9887387387387387}
--------------------------------------------------------------------------------
    ########### 



New Dataset: <function deepmatcher_structured_dblp_google_scholar at 0x1495c2d34550>

Test : 50
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.875968992248062,
 'test_loss': 0.1430661678314209,
 'test_prec': 0.8123003194888179,
 'test_recall': 0.9504672897196261}
--------------------------------------------------------------------------------
{'test_loss': 0.1430661678314209, 'test_prec': 0.8123003194888179, 'test_recall': 0.9504672897196261, 'test_f1': 0.875968992248062, 'positive_rate': 0.4, 'labeled_instances': 50, 'iteration_time': 338.0399899482727}
-- Random test --

       a.index  b.index  matching
6886      1842    16179     False
744       2280    25749     False
9717      2342    52778     False
11937      593    46883     False
11357     1864    38562     False
101        563    43933     False
10654     1842    35825     False
5803      1529     1043     False
16911     1049    18168     False
10581      356    45288      True
2545       562    11541     False
123       2142     8018     False
19        2455    31743     False
16587      135    52470      True
5050       297    13830     False
13846     2577    61565      True
9899      1963    57134     False
7112      1148    31823     False
12006     2276    29530      True
7556      1749    30836     False
13135     2336    29138     False
6956       772    24387     False
11461     1262    45618      True
16247      630    26123     False
2300       566    44593     False
5332      2420    12829     False
828        601    13281     False
13441     2538    48032     False
3410       370    38935     False
13222      146     4967     False
5377      2479    30326      True
3745      1099    57120     False
3362      2040    17415     False
14744      452    55320     False
4990       687    38046     False
1086      2107    10139      True
3887      2466    48536     False
2009      1925    54393     False
169       1244    61006     False
3288      2277    28447     False
10514       18    10325     False
10363      997    28685      True
3682       568    42156     False
11398      254    22722     False
10133     2409     9194     False
16295      901    60624     False
14038       71    37725      True
9767       635     3598     False
971       1841    53356     False
5841      1466    19179     False
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8216658150229945,
 'test_loss': 0.1983633190393448,
 'test_prec': 0.9064261555806088,
 'test_recall': 0.7514018691588785}
--------------------------------------------------------------------------------

Test : 75
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8748778103616813,
 'test_loss': 0.12491921335458755,
 'test_prec': 0.9170081967213115,
 'test_recall': 0.8364485981308412}
--------------------------------------------------------------------------------
{'test_loss': 0.12491921335458755, 'test_prec': 0.9170081967213115, 'test_recall': 0.8364485981308412, 'test_f1': 0.8748778103616813, 'positive_rate': 0.41333333333333333, 'labeled_instances': 75, 'iteration_time': 326.9841570854187}
-- Random test --

       a.index  b.index  matching
6886      1842    16179     False
744       2280    25749     False
9717      2342    52778     False
11937      593    46883     False
11357     1864    38562     False
...        ...      ...       ...
2714       829    15303     False
3946       546    62331      True
5862       770     8744      True
1144       837    25574      True
13452      203    11426     False

[75 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8338249754178957,
 'test_loss': 0.2405463308095932,
 'test_prec': 0.8796680497925311,
 'test_recall': 0.7925233644859813}
--------------------------------------------------------------------------------

Test : 100
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.900405588102749,
 'test_loss': 0.12182074040174484,
 'test_prec': 0.8694516971279374,
 'test_recall': 0.9336448598130841}
--------------------------------------------------------------------------------
{'test_loss': 0.12182074040174484, 'test_prec': 0.8694516971279374, 'test_recall': 0.9336448598130841, 'test_f1': 0.900405588102749, 'positive_rate': 0.46, 'labeled_instances': 100, 'iteration_time': 315.47143936157227}
-- Random test --

       a.index  b.index  matching
6886      1842    16179     False
744       2280    25749     False
9717      2342    52778     False
11937      593    46883     False
11357     1864    38562     False
...        ...      ...       ...
4115      1845     4202     False
3194      2376    50062     False
6753      1840    43836     False
6220       844    49845     False
12725       42    33904     False

[100 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8725972284309343,
 'test_loss': 0.1985238790512085,
 'test_prec': 0.8363324764353042,
 'test_recall': 0.9121495327102803}
--------------------------------------------------------------------------------

Test : 120
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8945626477541371,
 'test_loss': 0.10990982502698898,
 'test_prec': 0.9052631578947369,
 'test_recall': 0.8841121495327103}
--------------------------------------------------------------------------------
{'test_loss': 0.10990982502698898, 'test_prec': 0.9052631578947369, 'test_recall': 0.8841121495327103, 'test_f1': 0.8945626477541371, 'positive_rate': 0.475, 'labeled_instances': 120, 'iteration_time': 360.2591633796692}
-- Random test --

       a.index  b.index  matching
6886      1842    16179     False
744       2280    25749     False
9717      2342    52778     False
11937      593    46883     False
11357     1864    38562     False
...        ...      ...       ...
12214     1288    21508     False
14650       19    63089     False
621       1829    15400     False
12724      758    20709     False
12205       19    55098     False

[120 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8786181139122317,
 'test_loss': 0.1614297479391098,
 'test_prec': 0.8777985074626866,
 'test_recall': 0.8794392523364486}
--------------------------------------------------------------------------------

Test : 140
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.90999099909991,
 'test_loss': 0.12678180634975433,
 'test_prec': 0.8776041666666666,
 'test_recall': 0.9448598130841122}
--------------------------------------------------------------------------------
{'test_loss': 0.12678180634975433, 'test_prec': 0.8776041666666666, 'test_recall': 0.9448598130841122, 'test_f1': 0.90999099909991, 'positive_rate': 0.4785714285714286, 'labeled_instances': 140, 'iteration_time': 345.386269569397}
-- Random test --

       a.index  b.index  matching
6886      1842    16179     False
744       2280    25749     False
9717      2342    52778     False
11937      593    46883     False
11357     1864    38562     False
...        ...      ...       ...
10819     1637    64061     False
5035      1875    25714     False
2848        42    61810     False
16815      547    13262     False
17051      752    48867      True

[140 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8860759493670886,
 'test_loss': 0.13036033511161804,
 'test_prec': 0.8581436077057794,
 'test_recall': 0.9158878504672897}
--------------------------------------------------------------------------------

Test : 160
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9054593874833554,
 'test_loss': 0.1322367638349533,
 'test_prec': 0.8622147083685545,
 'test_recall': 0.9532710280373832}
--------------------------------------------------------------------------------
{'test_loss': 0.1322367638349533, 'test_prec': 0.8622147083685545, 'test_recall': 0.9532710280373832, 'test_f1': 0.9054593874833554, 'positive_rate': 0.48125, 'labeled_instances': 160, 'iteration_time': 332.91405868530273}
-- Random test --

       a.index  b.index  matching
6886      1842    16179     False
744       2280    25749     False
9717      2342    52778     False
11937      593    46883     False
11357     1864    38562     False
...        ...      ...       ...
5479      1953    29603     False
17199     2561    10812     False
2937       492     5067     False
4772      2510    21479     False
12002      586    47596     False

[160 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8787446504992867,
 'test_loss': 0.19550766050815582,
 'test_prec': 0.8944820909970959,
 'test_recall': 0.8635514018691589}
--------------------------------------------------------------------------------

Test : 180
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9106302916274693,
 'test_loss': 0.15220607817173004,
 'test_prec': 0.9166666666666666,
 'test_recall': 0.9046728971962616}
--------------------------------------------------------------------------------
{'test_loss': 0.15220607817173004, 'test_prec': 0.9166666666666666, 'test_recall': 0.9046728971962616, 'test_f1': 0.9106302916274693, 'positive_rate': 0.4722222222222222, 'labeled_instances': 180, 'iteration_time': 379.0005798339844}
-- Random test --

       a.index  b.index  matching
6886      1842    16179     False
744       2280    25749     False
9717      2342    52778     False
11937      593    46883     False
11357     1864    38562     False
...        ...      ...       ...
5391       322     9291      True
12478     1288    30895     False
15405     2449    20618     False
6699      1925    30845     False
15571       41     7969     False

[180 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.89375,
 'test_loss': 0.1576448529958725,
 'test_prec': 0.8555555555555555,
 'test_recall': 0.9355140186915888}
--------------------------------------------------------------------------------

Test : 200
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9235639981908639,
 'test_loss': 0.11564690619707108,
 'test_prec': 0.894829097283085,
 'test_recall': 0.9542056074766355}
--------------------------------------------------------------------------------
{'test_loss': 0.11564690619707108, 'test_prec': 0.894829097283085, 'test_recall': 0.9542056074766355, 'test_f1': 0.9235639981908639, 'positive_rate': 0.485, 'labeled_instances': 200, 'iteration_time': 361.2809624671936}
-- Random test --

       a.index  b.index  matching
6886      1842    16179     False
744       2280    25749     False
9717      2342    52778     False
11937      593    46883     False
11357     1864    38562     False
...        ...      ...       ...
12648     2208     9403     False
2301      1826    34720     False
14962      177    42272     False
15426      365    41094     False
878        264    36520     False

[200 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9005145797598627,
 'test_loss': 0.1721094250679016,
 'test_prec': 0.8320126782884311,
 'test_recall': 0.9813084112149533}
--------------------------------------------------------------------------------

Test : 250
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9171679777880611,
 'test_loss': 0.15162873268127441,
 'test_prec': 0.9083409715857012,
 'test_recall': 0.9261682242990654}
--------------------------------------------------------------------------------
{'test_loss': 0.15162873268127441, 'test_prec': 0.9083409715857012, 'test_recall': 0.9261682242990654, 'test_f1': 0.9171679777880611, 'positive_rate': 0.496, 'labeled_instances': 250, 'iteration_time': 357.92017579078674}
-- Random test --

       a.index  b.index  matching
6886      1842    16179     False
744       2280    25749     False
9717      2342    52778     False
11937      593    46883     False
11357     1864    38562     False
...        ...      ...       ...
3938      2168    55061     False
10365     1129     8968     False
2562      2006    16576     False
1606       390    44696     False
3944       253    17892     False

[250 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.895644283121597,
 'test_loss': 0.2222009152173996,
 'test_prec': 0.8703703703703703,
 'test_recall': 0.922429906542056}
--------------------------------------------------------------------------------

Test : 300
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9153297682709446,
 'test_loss': 0.1452518254518509,
 'test_prec': 0.8747870528109029,
 'test_recall': 0.9598130841121495}
--------------------------------------------------------------------------------
{'test_loss': 0.1452518254518509, 'test_prec': 0.8747870528109029, 'test_recall': 0.9598130841121495, 'test_f1': 0.9153297682709446, 'positive_rate': 0.51, 'labeled_instances': 300, 'iteration_time': 358.3655309677124}
-- Random test --

       a.index  b.index  matching
6886      1842    16179     False
744       2280    25749     False
9717      2342    52778     False
11937      593    46883     False
11357     1864    38562     False
...        ...      ...       ...
6501      2538    43727     False
664       1962    59074     False
10226     1263    43195     False
16748     2374    55856     False
3013       554    64160     False

[300 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9074427480916031,
 'test_loss': 0.16596564650535583,
 'test_prec': 0.9269005847953217,
 'test_recall': 0.888785046728972}
--------------------------------------------------------------------------------

Test : 400
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8846503178928247,
 'test_loss': 0.14954718947410583,
 'test_prec': 0.8604240282685512,
 'test_recall': 0.9102803738317757}
--------------------------------------------------------------------------------
{'test_loss': 0.14954718947410583, 'test_prec': 0.8604240282685512, 'test_recall': 0.9102803738317757, 'test_f1': 0.8846503178928247, 'positive_rate': 0.5075, 'labeled_instances': 400, 'iteration_time': 396.7052481174469}
-- Random test --

       a.index  b.index  matching
6886      1842    16179     False
744       2280    25749     False
9717      2342    52778     False
11937      593    46883     False
11357     1864    38562     False
...        ...      ...       ...
11987      934    32858      True
5886       842    21956     False
1315       197    60992     False
47        2272     6326     False
14858      758    23457     False

[400 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9256820319849483,
 'test_loss': 0.10442519187927246,
 'test_prec': 0.9318181818181818,
 'test_recall': 0.9196261682242991}
--------------------------------------------------------------------------------

Test : 500
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9194756554307116,
 'test_loss': 0.1316411793231964,
 'test_prec': 0.9212007504690432,
 'test_recall': 0.9177570093457944}
--------------------------------------------------------------------------------
{'test_loss': 0.1316411793231964, 'test_prec': 0.9212007504690432, 'test_recall': 0.9177570093457944, 'test_f1': 0.9194756554307116, 'positive_rate': 0.494, 'labeled_instances': 500, 'iteration_time': 397.4864466190338}
-- Random test --

       a.index  b.index  matching
6886      1842    16179     False
744       2280    25749     False
9717      2342    52778     False
11937      593    46883     False
11357     1864    38562     False
...        ...      ...       ...
88         352    50155     False
16227      204    58021     False
6758      1433    11508     False
4860       842    44025     False
2026       156    12395     False

[500 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9110287303058388,
 'test_loss': 0.18391293287277222,
 'test_prec': 0.9034926470588235,
 'test_recall': 0.9186915887850468}
--------------------------------------------------------------------------------

Test : 600
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9312413474850022,
 'test_loss': 0.11662844568490982,
 'test_prec': 0.9197812215132178,
 'test_recall': 0.9429906542056075}
--------------------------------------------------------------------------------
{'test_loss': 0.11662844568490982, 'test_prec': 0.9197812215132178, 'test_recall': 0.9429906542056075, 'test_f1': 0.9312413474850022, 'positive_rate': 0.49, 'labeled_instances': 600, 'iteration_time': 390.3101816177368}
-- Random test --

       a.index  b.index  matching
6886      1842    16179     False
744       2280    25749     False
9717      2342    52778     False
11937      593    46883     False
11357     1864    38562     False
...        ...      ...       ...
327       1986    62583     False
50         874    24044     False
3669      1833    20944     False
15118     1841    20624     False
15634      132    38470     False

[600 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9193548387096774,
 'test_loss': 0.15013007819652557,
 'test_prec': 0.882960413080895,
 'test_recall': 0.9588785046728971}
--------------------------------------------------------------------------------

Test : 700
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9340196537201684,
 'test_loss': 0.12696883082389832,
 'test_prec': 0.9353327085285849,
 'test_recall': 0.9327102803738317}
--------------------------------------------------------------------------------
{'test_loss': 0.12696883082389832, 'test_prec': 0.9353327085285849, 'test_recall': 0.9327102803738317, 'test_f1': 0.9340196537201684, 'positive_rate': 0.49142857142857144, 'labeled_instances': 700, 'iteration_time': 374.7475588321686}
-- Random test --

       a.index  b.index  matching
6886      1842    16179     False
744       2280    25749     False
9717      2342    52778     False
11937      593    46883     False
11357     1864    38562     False
...        ...      ...       ...
10579     2333    31372     False
2141      2360    45165     False
9946      1914    57406     False
12143     1681     9803     False
11289     2300    19371     False

[700 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9312762973352035,
 'test_loss': 0.13419629633426666,
 'test_prec': 0.9317118802619271,
 'test_recall': 0.930841121495327}
--------------------------------------------------------------------------------

Test : 800
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9299303944315545,
 'test_loss': 0.12321837991476059,
 'test_prec': 0.9235023041474655,
 'test_recall': 0.9364485981308411}
--------------------------------------------------------------------------------
{'test_loss': 0.12321837991476059, 'test_prec': 0.9235023041474655, 'test_recall': 0.9364485981308411, 'test_f1': 0.9299303944315545, 'positive_rate': 0.4875, 'labeled_instances': 800, 'iteration_time': 410.8013770580292}
-- Random test --

       a.index  b.index  matching
6886      1842    16179     False
744       2280    25749     False
9717      2342    52778     False
11937      593    46883     False
11357     1864    38562     False
...        ...      ...       ...
3143      2161    33055     False
11343     2489    23100     False
1166      2161    28746     False
937         31    22508     False
7573      2568    17171      True

[800 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9285714285714286,
 'test_loss': 0.14021947979927063,
 'test_prec': 0.9338374291115312,
 'test_recall': 0.9233644859813084}
--------------------------------------------------------------------------------

Test : 900
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9342723004694835,
 'test_loss': 0.10448778420686722,
 'test_prec': 0.9386792452830188,
 'test_recall': 0.9299065420560748}
--------------------------------------------------------------------------------
{'test_loss': 0.10448778420686722, 'test_prec': 0.9386792452830188, 'test_recall': 0.9299065420560748, 'test_f1': 0.9342723004694835, 'positive_rate': 0.49, 'labeled_instances': 900, 'iteration_time': 410.0424633026123}
-- Random test --

       a.index  b.index  matching
6886      1842    16179     False
744       2280    25749     False
9717      2342    52778     False
11937      593    46883     False
11357     1864    38562     False
...        ...      ...       ...
7098      1374     6148     False
6202      1283    47720     False
13788      329    12540     False
6434       676    23614     False
2095      1109    31689     False

[900 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9316081330868762,
 'test_loss': 0.11888034641742706,
 'test_prec': 0.9213893967093236,
 'test_recall': 0.9420560747663551}
--------------------------------------------------------------------------------

Test : 1000
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9444444444444445,
 'test_loss': 0.10486704111099243,
 'test_prec': 0.9357798165137615,
 'test_recall': 0.9532710280373832}
--------------------------------------------------------------------------------
{'test_loss': 0.10486704111099243, 'test_prec': 0.9357798165137615, 'test_recall': 0.9532710280373832, 'test_f1': 0.9444444444444445, 'positive_rate': 0.491, 'labeled_instances': 1000, 'iteration_time': 441.192045211792}
-- Random test --

       a.index  b.index  matching
6886      1842    16179     False
744       2280    25749     False
9717      2342    52778     False
11937      593    46883     False
11357     1864    38562     False
...        ...      ...       ...
8443      2126    45648     False
3222      2249    63428     False
15613     2270    24733     False
13204     2208    28180      True
820        574    39128     False

[1000 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.928261916225325,
 'test_loss': 0.12654231488704681,
 'test_prec': 0.9572989076464746,
 'test_recall': 0.9009345794392524}
--------------------------------------------------------------------------------

Test : 1100
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9266697804764129,
 'test_loss': 0.14088097214698792,
 'test_prec': 0.9262371615312792,
 'test_recall': 0.9271028037383178}
--------------------------------------------------------------------------------
{'test_loss': 0.14088097214698792, 'test_prec': 0.9262371615312792, 'test_recall': 0.9271028037383178, 'test_f1': 0.9266697804764129, 'positive_rate': 0.4863636363636364, 'labeled_instances': 1100, 'iteration_time': 436.72388553619385}
-- Random test --

       a.index  b.index  matching
6886      1842    16179     False
744       2280    25749     False
9717      2342    52778     False
11937      593    46883     False
11357     1864    38562     False
...        ...      ...       ...
8158      2126    11823     False
6162      1960    16392     False
13903     1678    63918      True
5277      1794    61304     False
9719      1685     4585     False

[1100 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9275500476644423,
 'test_loss': 0.11842786520719528,
 'test_prec': 0.9464980544747081,
 'test_recall': 0.9093457943925234}
--------------------------------------------------------------------------------

Test : 1200
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9352720450281427,
 'test_loss': 0.12266182899475098,
 'test_prec': 0.9387947269303202,
 'test_recall': 0.9317757009345794}
--------------------------------------------------------------------------------
{'test_loss': 0.12266182899475098, 'test_prec': 0.9387947269303202, 'test_recall': 0.9317757009345794, 'test_f1': 0.9352720450281427, 'positive_rate': 0.49083333333333334, 'labeled_instances': 1200, 'iteration_time': 450.067182302475}
-- Random test --

       a.index  b.index  matching
6886      1842    16179     False
744       2280    25749     False
9717      2342    52778     False
11937      593    46883     False
11357     1864    38562     False
...        ...      ...       ...
5146      1700    39437     False
3429      2438    62767     False
8223       387     3234      True
6630       885    51866      True
6134       570    25877     False

[1200 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9306551889048303,
 'test_loss': 0.12897127866744995,
 'test_prec': 0.9529872673849168,
 'test_recall': 0.9093457943925234}
--------------------------------------------------------------------------------

Test : 1300
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9365671641791044,
 'test_loss': 0.13002410531044006,
 'test_prec': 0.9348230912476723,
 'test_recall': 0.9383177570093458}
--------------------------------------------------------------------------------
{'test_loss': 0.13002410531044006, 'test_prec': 0.9348230912476723, 'test_recall': 0.9383177570093458, 'test_f1': 0.9365671641791044, 'positive_rate': 0.4930769230769231, 'labeled_instances': 1300, 'iteration_time': 453.7772755622864}
-- Random test --

       a.index  b.index  matching
6886      1842    16179     False
744       2280    25749     False
9717      2342    52778     False
11937      593    46883     False
11357     1864    38562     False
...        ...      ...       ...
10885      788    32189     False
10727     2562    41031     False
1090      1361    35588     False
7636      1955    62491     False
11887     1968    16558     False

[1300 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9342167534311405,
 'test_loss': 0.1337619125843048,
 'test_prec': 0.9463087248322147,
 'test_recall': 0.922429906542056}
--------------------------------------------------------------------------------

Test : 1400
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9415584415584416,
 'test_loss': 0.120270274579525,
 'test_prec': 0.934622467771639,
 'test_recall': 0.9485981308411215}
--------------------------------------------------------------------------------
{'test_loss': 0.120270274579525, 'test_prec': 0.934622467771639, 'test_recall': 0.9485981308411215, 'test_f1': 0.9415584415584416, 'positive_rate': 0.495, 'labeled_instances': 1400, 'iteration_time': 465.5225329399109}
-- Random test --

       a.index  b.index  matching
6886      1842    16179     False
744       2280    25749     False
9717      2342    52778     False
11937      593    46883     False
11357     1864    38562     False
...        ...      ...       ...
9450      2030    62687     False
9376      1404    58415     False
85        2437    45096     False
4081      1957     6958     False
13874     2168    40205     False

[1400 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9349056603773584,
 'test_loss': 0.1326369047164917,
 'test_prec': 0.9438095238095238,
 'test_recall': 0.9261682242990654}
--------------------------------------------------------------------------------

Test : 1500
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.936768149882904,
 'test_loss': 0.11657387763261795,
 'test_prec': 0.9389671361502347,
 'test_recall': 0.9345794392523364}
--------------------------------------------------------------------------------
{'test_loss': 0.11657387763261795, 'test_prec': 0.9389671361502347, 'test_recall': 0.9345794392523364, 'test_f1': 0.936768149882904, 'positive_rate': 0.49666666666666665, 'labeled_instances': 1500, 'iteration_time': 471.56786704063416}
-- Random test --

       a.index  b.index  matching
6886      1842    16179     False
744       2280    25749     False
9717      2342    52778     False
11937      593    46883     False
11357     1864    38562     False
...        ...      ...       ...
15873      758    34555     False
6550      2428    42562     False
9855      2554    34075     False
12610     2354    42678     False
10486       66    21336     False

[1500 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9446254071661238,
 'test_loss': 0.09091390669345856,
 'test_prec': 0.9406858202038925,
 'test_recall': 0.9485981308411215}
--------------------------------------------------------------------------------

Test : 2000
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9422180801491147,
 'test_loss': 0.10668503493070602,
 'test_prec': 0.9395910780669146,
 'test_recall': 0.9448598130841122}
--------------------------------------------------------------------------------
{'test_loss': 0.10668503493070602, 'test_prec': 0.9395910780669146, 'test_recall': 0.9448598130841122, 'test_f1': 0.9422180801491147, 'positive_rate': 0.491, 'labeled_instances': 2000, 'iteration_time': 467.0016691684723}
-- Random test --

       a.index  b.index  matching
6886      1842    16179     False
744       2280    25749     False
9717      2342    52778     False
11937      593    46883     False
11357     1864    38562     False
...        ...      ...       ...
7735      2590     6664      True
11971     1478     3471     False
11391      519    32599     False
15750     2312    31919     False
11960     1701    41655     False

[2000 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9351724137931035,
 'test_loss': 0.11541516333818436,
 'test_prec': 0.9203619909502262,
 'test_recall': 0.9504672897196261}
--------------------------------------------------------------------------------
-- Full test test --

Positive rate: 0.18620449399059397
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9523809523809523,
 'test_loss': 0.12263064086437225,
 'test_prec': 0.9423604757548033,
 'test_recall': 0.9626168224299065}
--------------------------------------------------------------------------------
    ########### 



New Dataset: <function deepmatcher_structured_walmart_amazon at 0x1495c2d34670>

Test : 50
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.4158920645713806,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------
{'test_loss': 0.4158920645713806, 'test_prec': 0.0, 'test_recall': 0.0, 'test_f1': 0.0, 'positive_rate': 0.42, 'labeled_instances': 50, 'iteration_time': 299.4050598144531}
-- Random test --

      a.index  b.index  matching
4489      852    14707     False
4159      822     9734     False
2780      419     5216     False
2927     2160    15757     False
3142     1720    20522      True
3491     2085     6140     False
535      1269     7953     False
2836     1132    14707     False
2902       58    20807     False
544      2196    17366      True
3979     1262    12734      True
2197     1527     5049     False
1357     1631     6556     False
2860      612     4733     False
3960     2100      984     False
604      1699    17616     False
1144     1172    16301     False
2195     1581     6075     False
4772      327    20715     False
3039     1365    10473     False
2666     1761    21681     False
432      1098    11745     False
2406      822    21693     False
1186     2190    21661      True
2570     2143     8239     False
811       342    13307     False
2952     2546    21955     False
2552      419    13254     False
2535     1016    17235     False
4252      725    16800      True
4649     2220    17892     False
1022     2080    18134     False
1400     1296     9734     False
5745      792     6397     False
2574      582    11379     False
351       821      609     False
1760     1153    13245      True
2042     1694    20397      True
4512     1134     6753     False
5838     1502     7665     False
5741     2371     6949     False
1720      419       30     False
5004     1536     4044     False
5025      577     9160     False
2881      219    12694     False
4025     1861     6115     False
410      1879     8607     False
2728     1537    20635     False
4651      429    15215     False
5694      584     4868     False
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.30892255902290344,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 75
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.42984014209591476,
 'test_loss': 0.3624674379825592,
 'test_prec': 0.327027027027027,
 'test_recall': 0.6269430051813472}
--------------------------------------------------------------------------------
{'test_loss': 0.3624674379825592, 'test_prec': 0.327027027027027, 'test_recall': 0.6269430051813472, 'test_f1': 0.42984014209591476, 'positive_rate': 0.44, 'labeled_instances': 75, 'iteration_time': 285.32404112815857}
-- Random test --

      a.index  b.index  matching
4489      852    14707     False
4159      822     9734     False
2780      419     5216     False
2927     2160    15757     False
3142     1720    20522      True
...       ...      ...       ...
3668     1695    17274      True
263      2472      806     False
167      1511     4526     False
1101     1193      519     False
787      1784     8486     False

[75 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.44053930044174194,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 100
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.459915611814346,
 'test_loss': 0.2773243188858032,
 'test_prec': 0.3879003558718861,
 'test_recall': 0.5647668393782384}
--------------------------------------------------------------------------------
{'test_loss': 0.2773243188858032, 'test_prec': 0.3879003558718861, 'test_recall': 0.5647668393782384, 'test_f1': 0.459915611814346, 'positive_rate': 0.46, 'labeled_instances': 100, 'iteration_time': 272.63449144363403}
-- Random test --

      a.index  b.index  matching
4489      852    14707     False
4159      822     9734     False
2780      419     5216     False
2927     2160    15757     False
3142     1720    20522      True
...       ...      ...       ...
3626       10     2429     False
1046     1869    12573     False
3670     2223    19012     False
6045     1432    15920     False
1807      869    10504     False

[100 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.2712686061859131,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 120
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.4781704781704782,
 'test_loss': 0.3517305254936218,
 'test_prec': 0.3993055555555556,
 'test_recall': 0.5958549222797928}
--------------------------------------------------------------------------------
{'test_loss': 0.3517305254936218, 'test_prec': 0.3993055555555556, 'test_recall': 0.5958549222797928, 'test_f1': 0.4781704781704782, 'positive_rate': 0.475, 'labeled_instances': 120, 'iteration_time': 272.41200733184814}
-- Random test --

      a.index  b.index  matching
4489      852    14707     False
4159      822     9734     False
2780      419     5216     False
2927     2160    15757     False
3142     1720    20522      True
...       ...      ...       ...
1643       40    14686     False
681      2030    20736     False
683      1136    17380     False
3916      532     8070     False
3737      606     3327     False

[120 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.2993817627429962,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 140
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5714285714285714,
 'test_loss': 0.23041698336601257,
 'test_prec': 0.5955056179775281,
 'test_recall': 0.5492227979274611}
--------------------------------------------------------------------------------
{'test_loss': 0.23041698336601257, 'test_prec': 0.5955056179775281, 'test_recall': 0.5492227979274611, 'test_f1': 0.5714285714285714, 'positive_rate': 0.45714285714285713, 'labeled_instances': 140, 'iteration_time': 265.58859395980835}
-- Random test --

      a.index  b.index  matching
4489      852    14707     False
4159      822     9734     False
2780      419     5216     False
2927     2160    15757     False
3142     1720    20522      True
...       ...      ...       ...
319      2107     4292     False
3264     1927    14736     False
4814     2349    12226     False
4047      324      548     False
4235      187    19156     False

[140 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.15037593984962405,
 'test_loss': 0.4940614402294159,
 'test_prec': 0.273972602739726,
 'test_recall': 0.10362694300518134}
--------------------------------------------------------------------------------

Test : 160
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.546583850931677,
 'test_loss': 0.3674866855144501,
 'test_prec': 0.45517241379310347,
 'test_recall': 0.6839378238341969}
--------------------------------------------------------------------------------
{'test_loss': 0.3674866855144501, 'test_prec': 0.45517241379310347, 'test_recall': 0.6839378238341969, 'test_f1': 0.546583850931677, 'positive_rate': 0.45625, 'labeled_instances': 160, 'iteration_time': 260.82570910453796}
-- Random test --

      a.index  b.index  matching
4489      852    14707     False
4159      822     9734     False
2780      419     5216     False
2927     2160    15757     False
3142     1720    20522      True
...       ...      ...       ...
5227      382    19438     False
5533      900    20993     False
2298      896    12918     False
3470     1507    12714     False
6118     1959    18507     False

[160 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.06730769230769229,
 'test_loss': 0.48589786887168884,
 'test_prec': 0.4666666666666667,
 'test_recall': 0.03626943005181347}
--------------------------------------------------------------------------------

Test : 180
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6422976501305484,
 'test_loss': 0.24100255966186523,
 'test_prec': 0.6473684210526316,
 'test_recall': 0.6373056994818653}
--------------------------------------------------------------------------------
{'test_loss': 0.24100255966186523, 'test_prec': 0.6473684210526316, 'test_recall': 0.6373056994818653, 'test_f1': 0.6422976501305484, 'positive_rate': 0.45555555555555555, 'labeled_instances': 180, 'iteration_time': 268.18482661247253}
-- Random test --

      a.index  b.index  matching
4489      852    14707     False
4159      822     9734     False
2780      419     5216     False
2927     2160    15757     False
3142     1720    20522      True
...       ...      ...       ...
156      2149    10786     False
1451      627     4730     False
1788       58     7538     False
1220     2229      871     False
1425     1853    16450     False

[180 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.3440233236151603,
 'test_loss': 0.305075466632843,
 'test_prec': 0.3933333333333333,
 'test_recall': 0.30569948186528495}
--------------------------------------------------------------------------------

Test : 200
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5248226950354611,
 'test_loss': 0.331703245639801,
 'test_prec': 0.4826086956521739,
 'test_recall': 0.5751295336787565}
--------------------------------------------------------------------------------
{'test_loss': 0.331703245639801, 'test_prec': 0.4826086956521739, 'test_recall': 0.5751295336787565, 'test_f1': 0.5248226950354611, 'positive_rate': 0.455, 'labeled_instances': 200, 'iteration_time': 272.3702828884125}
-- Random test --

      a.index  b.index  matching
4489      852    14707     False
4159      822     9734     False
2780      419     5216     False
2927     2160    15757     False
3142     1720    20522      True
...       ...      ...       ...
84         16    15183     False
1370     1825     5339     False
3139      898    15335      True
4195     1529     1441      True
4386      326     1474     False

[200 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5781990521327014,
 'test_loss': 0.2710350453853607,
 'test_prec': 0.5327510917030568,
 'test_recall': 0.6321243523316062}
--------------------------------------------------------------------------------

Test : 250
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5970149253731343,
 'test_loss': 0.39334115386009216,
 'test_prec': 0.46647230320699706,
 'test_recall': 0.8290155440414507}
--------------------------------------------------------------------------------
{'test_loss': 0.39334115386009216, 'test_prec': 0.46647230320699706, 'test_recall': 0.8290155440414507, 'test_f1': 0.5970149253731343, 'positive_rate': 0.468, 'labeled_instances': 250, 'iteration_time': 277.2554953098297}
-- Random test --

      a.index  b.index  matching
4489      852    14707     False
4159      822     9734     False
2780      419     5216     False
2927     2160    15757     False
3142     1720    20522      True
...       ...      ...       ...
4918      166    21693     False
5690     2265     8468     False
2916     2507     1090     False
730      1228     5477     False
5687     2405     6980     False

[250 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5089820359281436,
 'test_loss': 0.3102068305015564,
 'test_prec': 0.6028368794326241,
 'test_recall': 0.44041450777202074}
--------------------------------------------------------------------------------

Test : 300
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6607142857142857,
 'test_loss': 0.31890925765037537,
 'test_prec': 0.5803921568627451,
 'test_recall': 0.7668393782383419}
--------------------------------------------------------------------------------
{'test_loss': 0.31890925765037537, 'test_prec': 0.5803921568627451, 'test_recall': 0.7668393782383419, 'test_f1': 0.6607142857142857, 'positive_rate': 0.47, 'labeled_instances': 300, 'iteration_time': 293.2527551651001}
-- Random test --

      a.index  b.index  matching
4489      852    14707     False
4159      822     9734     False
2780      419     5216     False
2927     2160    15757     False
3142     1720    20522      True
...       ...      ...       ...
5454     2504    17892     False
4998      228    18020     False
2388     2514     2644     False
3590      428     4979     False
4314     1718     6796     False

[300 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6271186440677966,
 'test_loss': 0.2934436798095703,
 'test_prec': 0.5304659498207885,
 'test_recall': 0.7668393782383419}
--------------------------------------------------------------------------------

Test : 400
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6682926829268292,
 'test_loss': 0.27400973439216614,
 'test_prec': 0.631336405529954,
 'test_recall': 0.7098445595854922}
--------------------------------------------------------------------------------
{'test_loss': 0.27400973439216614, 'test_prec': 0.631336405529954, 'test_recall': 0.7098445595854922, 'test_f1': 0.6682926829268292, 'positive_rate': 0.4875, 'labeled_instances': 400, 'iteration_time': 291.4347915649414}
-- Random test --

      a.index  b.index  matching
4489      852    14707     False
4159      822     9734     False
2780      419     5216     False
2927     2160    15757     False
3142     1720    20522      True
...       ...      ...       ...
2970      883     4974     False
5586      244    14686     False
5273     2389     8786     False
3275     1716     9715     False
3460      864    13133     False

[400 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5558441558441557,
 'test_loss': 0.3223634362220764,
 'test_prec': 0.5572916666666666,
 'test_recall': 0.5544041450777202}
--------------------------------------------------------------------------------

Test : 500
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7532467532467533,
 'test_loss': 0.23216107487678528,
 'test_prec': 0.6468401486988847,
 'test_recall': 0.9015544041450777}
--------------------------------------------------------------------------------
{'test_loss': 0.23216107487678528, 'test_prec': 0.6468401486988847, 'test_recall': 0.9015544041450777, 'test_f1': 0.7532467532467533, 'positive_rate': 0.508, 'labeled_instances': 500, 'iteration_time': 289.1115233898163}
-- Random test --

      a.index  b.index  matching
4489      852    14707     False
4159      822     9734     False
2780      419     5216     False
2927     2160    15757     False
3142     1720    20522      True
...       ...      ...       ...
1161     1026    12056     False
3708     1425     4733     False
14        417    17561     False
3782      582    13152     False
2002     1135    10745     False

[500 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6778846153846154,
 'test_loss': 0.231268510222435,
 'test_prec': 0.6322869955156951,
 'test_recall': 0.7305699481865285}
--------------------------------------------------------------------------------

Test : 600
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7337526205450733,
 'test_loss': 0.2459651231765747,
 'test_prec': 0.6161971830985915,
 'test_recall': 0.9067357512953368}
--------------------------------------------------------------------------------
{'test_loss': 0.2459651231765747, 'test_prec': 0.6161971830985915, 'test_recall': 0.9067357512953368, 'test_f1': 0.7337526205450733, 'positive_rate': 0.5183333333333333, 'labeled_instances': 600, 'iteration_time': 307.13524556159973}
-- Random test --

      a.index  b.index  matching
4489      852    14707     False
4159      822     9734     False
2780      419     5216     False
2927     2160    15757     False
3142     1720    20522      True
...       ...      ...       ...
1599     2472    21811     False
764      2397    10117      True
5184     1188     3878     False
4434     1695    17605     False
3289     1888     4209     False

[600 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6473684210526316,
 'test_loss': 0.2937360405921936,
 'test_prec': 0.6577540106951871,
 'test_recall': 0.6373056994818653}
--------------------------------------------------------------------------------

Test : 700
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7775280898876404,
 'test_loss': 0.18967393040657043,
 'test_prec': 0.6865079365079365,
 'test_recall': 0.8963730569948186}
--------------------------------------------------------------------------------
{'test_loss': 0.18967393040657043, 'test_prec': 0.6865079365079365, 'test_recall': 0.8963730569948186, 'test_f1': 0.7775280898876404, 'positive_rate': 0.5185714285714286, 'labeled_instances': 700, 'iteration_time': 302.05908370018005}
-- Random test --

      a.index  b.index  matching
4489      852    14707     False
4159      822     9734     False
2780      419     5216     False
2927     2160    15757     False
3142     1720    20522      True
...       ...      ...       ...
4888     2220     6750     False
5877      896     3099     False
5922     1713    17122     False
4522     1412    16818      True
4966     2371    10925     False

[700 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7360406091370559,
 'test_loss': 0.24724441766738892,
 'test_prec': 0.7213930348258707,
 'test_recall': 0.7512953367875648}
--------------------------------------------------------------------------------

Test : 800
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7130801687763713,
 'test_loss': 0.28557249903678894,
 'test_prec': 0.6014234875444839,
 'test_recall': 0.8756476683937824}
--------------------------------------------------------------------------------
{'test_loss': 0.28557249903678894, 'test_prec': 0.6014234875444839, 'test_recall': 0.8756476683937824, 'test_f1': 0.7130801687763713, 'positive_rate': 0.51875, 'labeled_instances': 800, 'iteration_time': 303.0416328907013}
-- Random test --

      a.index  b.index  matching
4489      852    14707     False
4159      822     9734     False
2780      419     5216     False
2927     2160    15757     False
3142     1720    20522      True
...       ...      ...       ...
6131      943    11353     False
5910      489      768     False
4039     1927    12918     False
5347      887    19779     False
3317      883     7140     False

[800 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7338501291989663,
 'test_loss': 0.2376827895641327,
 'test_prec': 0.7319587628865979,
 'test_recall': 0.7357512953367875}
--------------------------------------------------------------------------------

Test : 900
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.818401937046005,
 'test_loss': 0.16271653771400452,
 'test_prec': 0.7681818181818182,
 'test_recall': 0.8756476683937824}
--------------------------------------------------------------------------------
{'test_loss': 0.16271653771400452, 'test_prec': 0.7681818181818182, 'test_recall': 0.8756476683937824, 'test_f1': 0.818401937046005, 'positive_rate': 0.47, 'labeled_instances': 900, 'iteration_time': 298.4564094543457}
-- Random test --

      a.index  b.index  matching
4489      852    14707     False
4159      822     9734     False
2780      419     5216     False
2927     2160    15757     False
3142     1720    20522      True
...       ...      ...       ...
1002     1672     9026     False
5066     2305     8576     False
2377      973     6761     False
3718      166    18153     False
2164     1774    17453     False

[900 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.761904761904762,
 'test_loss': 0.22217892110347748,
 'test_prec': 0.7783783783783784,
 'test_recall': 0.7461139896373057}
--------------------------------------------------------------------------------

Test : 1000
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7813953488372093,
 'test_loss': 0.2137080878019333,
 'test_prec': 0.7088607594936709,
 'test_recall': 0.8704663212435233}
--------------------------------------------------------------------------------
{'test_loss': 0.2137080878019333, 'test_prec': 0.7088607594936709, 'test_recall': 0.8704663212435233, 'test_f1': 0.7813953488372093, 'positive_rate': 0.439, 'labeled_instances': 1000, 'iteration_time': 307.14835691452026}
-- Random test --

      a.index  b.index  matching
4489      852    14707     False
4159      822     9734     False
2780      419     5216     False
2927     2160    15757     False
3142     1720    20522      True
...       ...      ...       ...
2182      967      801     False
5632      968    15233     False
4868      428     4976     False
4032     1761     8642     False
2272      968    19351     False

[1000 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7969924812030076,
 'test_loss': 0.18887725472450256,
 'test_prec': 0.7718446601941747,
 'test_recall': 0.8238341968911918}
--------------------------------------------------------------------------------

Test : 1100
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7834101382488479,
 'test_loss': 0.1945674866437912,
 'test_prec': 0.7053941908713693,
 'test_recall': 0.8808290155440415}
--------------------------------------------------------------------------------
{'test_loss': 0.1945674866437912, 'test_prec': 0.7053941908713693, 'test_recall': 0.8808290155440415, 'test_f1': 0.7834101382488479, 'positive_rate': 0.4081818181818182, 'labeled_instances': 1100, 'iteration_time': 339.8976423740387}
-- Random test --

      a.index  b.index  matching
4489      852    14707     False
4159      822     9734     False
2780      419     5216     False
2927     2160    15757     False
3142     1720    20522      True
...       ...      ...       ...
1253      299     2727     False
5882     1688     1349     False
5157      759    14294     False
1671     1959    21693     False
5538     1699      289     False

[1100 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8032345013477089,
 'test_loss': 0.18637162446975708,
 'test_prec': 0.8370786516853933,
 'test_recall': 0.772020725388601}
--------------------------------------------------------------------------------

Test : 1200
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8284313725490197,
 'test_loss': 0.1457192301750183,
 'test_prec': 0.786046511627907,
 'test_recall': 0.8756476683937824}
--------------------------------------------------------------------------------
{'test_loss': 0.1457192301750183, 'test_prec': 0.786046511627907, 'test_recall': 0.8756476683937824, 'test_f1': 0.8284313725490197, 'positive_rate': 0.38166666666666665, 'labeled_instances': 1200, 'iteration_time': 300.277152299881}
-- Random test --

      a.index  b.index  matching
4489      852    14707     False
4159      822     9734     False
2780      419     5216     False
2927     2160    15757     False
3142     1720    20522      True
...       ...      ...       ...
3055        5    20932      True
71       1963     1019     False
2542     1135    10869     False
711      2293    14509     False
3891     2152    19230     False

[1200 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7584541062801933,
 'test_loss': 0.22074267268180847,
 'test_prec': 0.7104072398190046,
 'test_recall': 0.8134715025906736}
--------------------------------------------------------------------------------

Test : 1300
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8056206088992973,
 'test_loss': 0.18748216331005096,
 'test_prec': 0.7350427350427351,
 'test_recall': 0.8911917098445595}
--------------------------------------------------------------------------------
{'test_loss': 0.18748216331005096, 'test_prec': 0.7350427350427351, 'test_recall': 0.8911917098445595, 'test_f1': 0.8056206088992973, 'positive_rate': 0.35846153846153844, 'labeled_instances': 1300, 'iteration_time': 346.24814891815186}
-- Random test --

      a.index  b.index  matching
4489      852    14707     False
4159      822     9734     False
2780      419     5216     False
2927     2160    15757     False
3142     1720    20522      True
...       ...      ...       ...
3399     2201    11698     False
4927     1242     6398     False
6001     1606    18687      True
5571     1711    17898     False
2505     1626     6967     False

[1300 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.3087538778781891,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 1400
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8238095238095238,
 'test_loss': 0.17624340951442719,
 'test_prec': 0.762114537444934,
 'test_recall': 0.8963730569948186}
--------------------------------------------------------------------------------
{'test_loss': 0.17624340951442719, 'test_prec': 0.762114537444934, 'test_recall': 0.8963730569948186, 'test_f1': 0.8238095238095238, 'positive_rate': 0.34, 'labeled_instances': 1400, 'iteration_time': 328.17318391799927}
-- Random test --

      a.index  b.index  matching
4489      852    14707     False
4159      822     9734     False
2780      419     5216     False
2927     2160    15757     False
3142     1720    20522      True
...       ...      ...       ...
856      1824    15224     False
3901       15     8008     False
4342      597     4280     False
5834     1237    21921     False
2135     2462     4155     False

[1400 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8148148148148148,
 'test_loss': 0.15159021317958832,
 'test_prec': 0.8324324324324325,
 'test_recall': 0.7979274611398963}
--------------------------------------------------------------------------------

Test : 1500
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8349514563106796,
 'test_loss': 0.15313053131103516,
 'test_prec': 0.7853881278538812,
 'test_recall': 0.8911917098445595}
--------------------------------------------------------------------------------
{'test_loss': 0.15313053131103516, 'test_prec': 0.7853881278538812, 'test_recall': 0.8911917098445595, 'test_f1': 0.8349514563106796, 'positive_rate': 0.32466666666666666, 'labeled_instances': 1500, 'iteration_time': 346.00064754486084}
-- Random test --

      a.index  b.index  matching
4489      852    14707     False
4159      822     9734     False
2780      419     5216     False
2927     2160    15757     False
3142     1720    20522      True
...       ...      ...       ...
3208     1294    14246     False
4970      500    12544      True
6037       97    15904      True
3487      589     9328     False
203      1796     6590     False

[1500 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8229166666666667,
 'test_loss': 0.19024506211280823,
 'test_prec': 0.8272251308900523,
 'test_recall': 0.8186528497409327}
--------------------------------------------------------------------------------

Test : 2000
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8480000000000001,
 'test_loss': 0.13003040850162506,
 'test_prec': 0.8736263736263736,
 'test_recall': 0.8238341968911918}
--------------------------------------------------------------------------------
{'test_loss': 0.13003040850162506, 'test_prec': 0.8736263736263736, 'test_recall': 0.8238341968911918, 'test_f1': 0.8480000000000001, 'positive_rate': 0.2545, 'labeled_instances': 2000, 'iteration_time': 364.50063467025757}
-- Random test --

      a.index  b.index  matching
4489      852    14707     False
4159      822     9734     False
2780      419     5216     False
2927     2160    15757     False
3142     1720    20522      True
...       ...      ...       ...
2873     1342    15292     False
1189     1229    10854     False
175      2436     6692     False
2154      776    13713     False
2821     1153    13243     False

[2000 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8125,
 'test_loss': 0.16039490699768066,
 'test_prec': 0.8167539267015707,
 'test_recall': 0.8082901554404145}
--------------------------------------------------------------------------------
-- Full test test --

Positive rate: 0.09375
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8668407310704961,
 'test_loss': 0.13959312438964844,
 'test_prec': 0.8736842105263158,
 'test_recall': 0.8601036269430051}
--------------------------------------------------------------------------------
Could not create dir out, File exists
    ########### 



New Dataset: <function deepmatcher_textual_abt_buy at 0x1495c2d349d0>

Test : 50
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.3452046811580658,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------
{'test_loss': 0.3452046811580658, 'test_prec': 0.0, 'test_recall': 0.0, 'test_f1': 0.0, 'positive_rate': 0.18, 'labeled_instances': 50, 'iteration_time': 301.44286942481995}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
1586      612      616      True
4694      473      568     False
3095      764      648     False
199       852      821     False
3827      906      245     False
624       422      155     False
1393     1056       46     False
1454      631      716     False
3634       44      740     False
3323      661      671     False
3103      425      242     False
3787      636      758     False
3728      451      506     False
101      1076      526     False
2173      655      503     False
5065      476      629     False
576       194       81      True
3915      459      384     False
1315      715      567     False
132        55      102     False
4083      779      661     False
3066      489      736     False
1046      607      881     False
1954      785      121     False
808       496      561     False
1872      579      714     False
2794      257      194     False
4756      550      709     False
1779      482      415     False
1566      535      302     False
4472      912     1005     False
1370      337      183     False
3145      118      617     False
3783      617      988     False
1194      481      846     False
3892      901      961     False
907       921     1008     False
2063      665      641     False
2809      469      585     False
599       445      414     False
1477      383      483     False
5417      172      358     False
4153      906      294     False
5597      857      607     False
2522      402      391     False
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.3404536843299866,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 75
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.32630279660224915,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------
{'test_loss': 0.32630279660224915, 'test_prec': 0.0, 'test_recall': 0.0, 'test_f1': 0.0, 'positive_rate': 0.17333333333333334, 'labeled_instances': 75, 'iteration_time': 304.62339425086975}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
805       692      789     False
1084      502      553      True
896      1037      949     False
5539      176      688     False
4839      168      245     False

[75 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.4110661745071411,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 100
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.3523544371128082,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------
{'test_loss': 0.3523544371128082, 'test_prec': 0.0, 'test_recall': 0.0, 'test_f1': 0.0, 'positive_rate': 0.19, 'labeled_instances': 100, 'iteration_time': 288.636470079422}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
3286      708      742     False
2022      902      631     False
5072      443      585     False
4705      940      574     False
755      1019      172     False

[100 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.08064516129032259,
 'test_loss': 0.5562756657600403,
 'test_prec': 0.23809523809523808,
 'test_recall': 0.04854368932038835}
--------------------------------------------------------------------------------

Test : 120
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.39072847682119205,
 'test_loss': 0.27559101581573486,
 'test_prec': 0.6145833333333334,
 'test_recall': 0.28640776699029125}
--------------------------------------------------------------------------------
{'test_loss': 0.27559101581573486, 'test_prec': 0.6145833333333334, 'test_recall': 0.28640776699029125, 'test_f1': 0.39072847682119205, 'positive_rate': 0.225, 'labeled_instances': 120, 'iteration_time': 323.9353439807892}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
3237      750      405     False
3262      570      667     False
5379       64      307     False
911       532      762     False
1412      184      539     False

[120 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.08208955223880597,
 'test_loss': 0.6121570467948914,
 'test_prec': 0.1774193548387097,
 'test_recall': 0.05339805825242718}
--------------------------------------------------------------------------------

Test : 140
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.21874999999999997,
 'test_loss': 0.5428805351257324,
 'test_prec': 0.17027027027027028,
 'test_recall': 0.3058252427184466}
--------------------------------------------------------------------------------
{'test_loss': 0.5428805351257324, 'test_prec': 0.17027027027027028, 'test_recall': 0.3058252427184466, 'test_f1': 0.21874999999999997, 'positive_rate': 0.2857142857142857, 'labeled_instances': 140, 'iteration_time': 326.7314009666443}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
4192      660      621     False
5586      545      716     False
14        519      399     False
2402      578     1061     False
3768      903      399     False

[140 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.11228070175438597,
 'test_loss': 0.546666145324707,
 'test_prec': 0.20253164556962025,
 'test_recall': 0.07766990291262135}
--------------------------------------------------------------------------------

Test : 160
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5775401069518716,
 'test_loss': 0.23437969386577606,
 'test_prec': 0.6428571428571429,
 'test_recall': 0.5242718446601942}
--------------------------------------------------------------------------------
{'test_loss': 0.23437969386577606, 'test_prec': 0.6428571428571429, 'test_recall': 0.5242718446601942, 'test_f1': 0.5775401069518716, 'positive_rate': 0.31875, 'labeled_instances': 160, 'iteration_time': 310.515065908432}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
865       897      622     False
79        741     1077     False
5429       95       83     False
181       534      634     False
2932     1038      716     False

[160 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.08695652173913043,
 'test_loss': 0.6678985357284546,
 'test_prec': 0.23404255319148937,
 'test_recall': 0.05339805825242718}
--------------------------------------------------------------------------------

Test : 180
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7374005305039788,
 'test_loss': 0.178310826420784,
 'test_prec': 0.8128654970760234,
 'test_recall': 0.6747572815533981}
--------------------------------------------------------------------------------
{'test_loss': 0.178310826420784, 'test_prec': 0.8128654970760234, 'test_recall': 0.6747572815533981, 'test_f1': 0.7374005305039788, 'positive_rate': 0.32222222222222224, 'labeled_instances': 180, 'iteration_time': 302.5100636482239}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
4954      953      187     False
4596      901      510     False
2638      584      660     False
5275      136      234     False
915       892     1061     False

[180 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.4627462923526764,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 200
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6696230598669624,
 'test_loss': 0.2654646635055542,
 'test_prec': 0.6163265306122448,
 'test_recall': 0.7330097087378641}
--------------------------------------------------------------------------------
{'test_loss': 0.2654646635055542, 'test_prec': 0.6163265306122448, 'test_recall': 0.7330097087378641, 'test_f1': 0.6696230598669624, 'positive_rate': 0.34, 'labeled_instances': 200, 'iteration_time': 310.0046672821045}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
2607     1014      736     False
1988      869      987     False
2603      543      716     False
3143      716      800     False
1038      399       72     False

[200 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.09565217391304347,
 'test_loss': 0.6480404138565063,
 'test_prec': 0.4583333333333333,
 'test_recall': 0.05339805825242718}
--------------------------------------------------------------------------------

Test : 250
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.802784222737819,
 'test_loss': 0.15482459962368011,
 'test_prec': 0.7688888888888888,
 'test_recall': 0.8398058252427184}
--------------------------------------------------------------------------------
{'test_loss': 0.15482459962368011, 'test_prec': 0.7688888888888888, 'test_recall': 0.8398058252427184, 'test_f1': 0.802784222737819, 'positive_rate': 0.368, 'labeled_instances': 250, 'iteration_time': 327.43266701698303}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
4578      180      627     False
4797      471      476     False
2357     1039       98     False
5350      864      504     False
4584     1010      528     False

[250 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.3551015555858612,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 300
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8179551122194514,
 'test_loss': 0.14254464209079742,
 'test_prec': 0.841025641025641,
 'test_recall': 0.7961165048543689}
--------------------------------------------------------------------------------
{'test_loss': 0.14254464209079742, 'test_prec': 0.841025641025641, 'test_recall': 0.7961165048543689, 'test_f1': 0.8179551122194514, 'positive_rate': 0.38666666666666666, 'labeled_instances': 300, 'iteration_time': 339.0487926006317}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
1302      658      621     False
3866      649      663     False
932       489      629     False
1095      952      428     False
2018      194      480     False

[300 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.4391891891891892,
 'test_loss': 0.30566737055778503,
 'test_prec': 0.7222222222222222,
 'test_recall': 0.3155339805825243}
--------------------------------------------------------------------------------

Test : 400
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.817351598173516,
 'test_loss': 0.1786595731973648,
 'test_prec': 0.771551724137931,
 'test_recall': 0.8689320388349514}
--------------------------------------------------------------------------------
{'test_loss': 0.1786595731973648, 'test_prec': 0.771551724137931, 'test_recall': 0.8689320388349514, 'test_f1': 0.817351598173516, 'positive_rate': 0.41, 'labeled_instances': 400, 'iteration_time': 347.48605513572693}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
1745      780      484     False
1488      842      816     False
5367       14      302     False
5083      115       72     False
4141      915     1068     False

[400 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.3,
 'test_loss': 0.5067199468612671,
 'test_prec': 0.7222222222222222,
 'test_recall': 0.18932038834951456}
--------------------------------------------------------------------------------

Test : 500
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8467153284671532,
 'test_loss': 0.15883365273475647,
 'test_prec': 0.848780487804878,
 'test_recall': 0.8446601941747572}
--------------------------------------------------------------------------------
{'test_loss': 0.15883365273475647, 'test_prec': 0.848780487804878, 'test_recall': 0.8446601941747572, 'test_f1': 0.8467153284671532, 'positive_rate': 0.426, 'labeled_instances': 500, 'iteration_time': 343.56329798698425}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
5184      444     1000     False
2067      883      727     False
1197      667      100     False
1074      847      686     False
3872      484      475     False

[500 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.47781569965870313,
 'test_loss': 0.3385487496852875,
 'test_prec': 0.8045977011494253,
 'test_recall': 0.33980582524271846}
--------------------------------------------------------------------------------

Test : 600
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8306997742663658,
 'test_loss': 0.18344463407993317,
 'test_prec': 0.7763713080168776,
 'test_recall': 0.8932038834951457}
--------------------------------------------------------------------------------
{'test_loss': 0.18344463407993317, 'test_prec': 0.7763713080168776, 'test_recall': 0.8932038834951457, 'test_f1': 0.8306997742663658, 'positive_rate': 0.42833333333333334, 'labeled_instances': 600, 'iteration_time': 348.0872972011566}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
5339      858      563     False
367       875     1060     False
5540      650      694     False
4561      932      977     False
5687      473      650     False

[600 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7038123167155425,
 'test_loss': 0.2239203304052353,
 'test_prec': 0.8888888888888888,
 'test_recall': 0.5825242718446602}
--------------------------------------------------------------------------------

Test : 700
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8605200945626478,
 'test_loss': 0.15384621918201447,
 'test_prec': 0.8387096774193549,
 'test_recall': 0.883495145631068}
--------------------------------------------------------------------------------
{'test_loss': 0.15384621918201447, 'test_prec': 0.8387096774193549, 'test_recall': 0.883495145631068, 'test_f1': 0.8605200945626478, 'positive_rate': 0.41, 'labeled_instances': 700, 'iteration_time': 348.0674350261688}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
4640      941      966     False
106       280      633     False
4831      962      540     False
2272      693      772     False
4335      476      630     False

[700 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7520435967302452,
 'test_loss': 0.195504292845726,
 'test_prec': 0.8571428571428571,
 'test_recall': 0.6699029126213593}
--------------------------------------------------------------------------------

Test : 800
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8530805687203792,
 'test_loss': 0.16566993296146393,
 'test_prec': 0.8333333333333334,
 'test_recall': 0.8737864077669902}
--------------------------------------------------------------------------------
{'test_loss': 0.16566993296146393, 'test_prec': 0.8333333333333334, 'test_recall': 0.8737864077669902, 'test_f1': 0.8530805687203792, 'positive_rate': 0.37625, 'labeled_instances': 800, 'iteration_time': 364.0760974884033}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
5062      774      807      True
711       511      595     False
811       455      980     False
3429      547      595     False
4649      230      913     False

[800 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6148867313915858,
 'test_loss': 0.38412004709243774,
 'test_prec': 0.9223300970873787,
 'test_recall': 0.46116504854368934}
--------------------------------------------------------------------------------

Test : 900
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8425925925925926,
 'test_loss': 0.1773768961429596,
 'test_prec': 0.8053097345132744,
 'test_recall': 0.883495145631068}
--------------------------------------------------------------------------------
{'test_loss': 0.1773768961429596, 'test_prec': 0.8053097345132744, 'test_recall': 0.883495145631068, 'test_f1': 0.8425925925925926, 'positive_rate': 0.3511111111111111, 'labeled_instances': 900, 'iteration_time': 381.2159764766693}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
3260      529      879     False
30        919     1004     False
3439      885      846     False
1951      946      152     False
3481      843      676     False

[900 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7887323943661971,
 'test_loss': 0.19727224111557007,
 'test_prec': 0.9395973154362416,
 'test_recall': 0.6796116504854369}
--------------------------------------------------------------------------------

Test : 1000
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8543689320388349,
 'test_loss': 0.1665935218334198,
 'test_prec': 0.8543689320388349,
 'test_recall': 0.8543689320388349}
--------------------------------------------------------------------------------
{'test_loss': 0.1665935218334198, 'test_prec': 0.8543689320388349, 'test_recall': 0.8543689320388349, 'test_f1': 0.8543689320388349, 'positive_rate': 0.339, 'labeled_instances': 1000, 'iteration_time': 397.5127911567688}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
4414     1069      518      True
44        637      429     False
5709     1001      991     False
1652      267      347     False
746       615      641     False

[1000 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8290155440414507,
 'test_loss': 0.16486413776874542,
 'test_prec': 0.8888888888888888,
 'test_recall': 0.7766990291262136}
--------------------------------------------------------------------------------

Test : 1100
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8592592592592592,
 'test_loss': 0.13826106488704681,
 'test_prec': 0.8743718592964824,
 'test_recall': 0.8446601941747572}
--------------------------------------------------------------------------------
{'test_loss': 0.13826106488704681, 'test_prec': 0.8743718592964824, 'test_recall': 0.8446601941747572, 'test_f1': 0.8592592592592592, 'positive_rate': 0.31727272727272726, 'labeled_instances': 1100, 'iteration_time': 403.0617914199829}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
4147      484      419     False
2232      896      622     False
1919      722      800     False
3245      171       45      True
252       900      629     False

[1100 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8244680851063829,
 'test_loss': 0.15730208158493042,
 'test_prec': 0.9117647058823529,
 'test_recall': 0.7524271844660194}
--------------------------------------------------------------------------------

Test : 1200
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8851674641148326,
 'test_loss': 0.13137058913707733,
 'test_prec': 0.8726415094339622,
 'test_recall': 0.8980582524271845}
--------------------------------------------------------------------------------
{'test_loss': 0.13137058913707733, 'test_prec': 0.8726415094339622, 'test_recall': 0.8980582524271845, 'test_f1': 0.8851674641148326, 'positive_rate': 0.30416666666666664, 'labeled_instances': 1200, 'iteration_time': 395.65543723106384}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
4163      970      402     False
5492      325      596     False
670       540      665     False
3574      659      113     False
3786      885      475     False

[1200 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8564102564102564,
 'test_loss': 0.12612566351890564,
 'test_prec': 0.907608695652174,
 'test_recall': 0.8106796116504854}
--------------------------------------------------------------------------------

Test : 1300
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8634146341463416,
 'test_loss': 0.15684033930301666,
 'test_prec': 0.8676470588235294,
 'test_recall': 0.8592233009708737}
--------------------------------------------------------------------------------
{'test_loss': 0.15684033930301666, 'test_prec': 0.8676470588235294, 'test_recall': 0.8592233009708737, 'test_f1': 0.8634146341463416, 'positive_rate': 0.30153846153846153, 'labeled_instances': 1300, 'iteration_time': 402.84803771972656}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
3209      570      971     False
1620       73      870     False
957       528      835     False
3919      345      662     False
2536      482      907     False

[1300 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8069306930693069,
 'test_loss': 0.14902083575725555,
 'test_prec': 0.8232323232323232,
 'test_recall': 0.7912621359223301}
--------------------------------------------------------------------------------

Test : 1400
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8780487804878048,
 'test_loss': 0.12460611015558243,
 'test_prec': 0.8823529411764706,
 'test_recall': 0.8737864077669902}
--------------------------------------------------------------------------------
{'test_loss': 0.12460611015558243, 'test_prec': 0.8823529411764706, 'test_recall': 0.8737864077669902, 'test_f1': 0.8780487804878048, 'positive_rate': 0.2892857142857143, 'labeled_instances': 1400, 'iteration_time': 412.18764638900757}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
4267      491      574     False
120       615      637     False
2671      951      500     False
3612      174      182      True
5032      531      313     False

[1400 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8390243902439024,
 'test_loss': 0.14541032910346985,
 'test_prec': 0.8431372549019608,
 'test_recall': 0.8349514563106796}
--------------------------------------------------------------------------------

Test : 1500
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8676470588235294,
 'test_loss': 0.13403485715389252,
 'test_prec': 0.8762376237623762,
 'test_recall': 0.8592233009708737}
--------------------------------------------------------------------------------
{'test_loss': 0.13403485715389252, 'test_prec': 0.8762376237623762, 'test_recall': 0.8592233009708737, 'test_f1': 0.8676470588235294, 'positive_rate': 0.278, 'labeled_instances': 1500, 'iteration_time': 407.0734031200409}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
1694      699      774     False
5466      966     1068      True
4382      625     1064     False
3253      550      763     False
841       466      580     False

[1500 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8235294117647058,
 'test_loss': 0.16669252514839172,
 'test_prec': 0.9166666666666666,
 'test_recall': 0.7475728155339806}
--------------------------------------------------------------------------------

Test : 2000
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8855721393034826,
 'test_loss': 0.1238832101225853,
 'test_prec': 0.9081632653061225,
 'test_recall': 0.8640776699029126}
--------------------------------------------------------------------------------
{'test_loss': 0.1238832101225853, 'test_prec': 0.9081632653061225, 'test_recall': 0.8640776699029126, 'test_f1': 0.8855721393034826, 'positive_rate': 0.2355, 'labeled_instances': 2000, 'iteration_time': 462.94965648651123}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
3799      510      924     False
4741      438      751     False
618       615      633     False
4913      916     1004     False
4072      905      727     False

[2000 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8498727735368957,
 'test_loss': 0.1254524290561676,
 'test_prec': 0.893048128342246,
 'test_recall': 0.8106796116504854}
--------------------------------------------------------------------------------
-- Full test test --

Positive rate: 0.10726101340762667
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8938271604938272,
 'test_loss': 0.12149067223072052,
 'test_prec': 0.9095477386934674,
 'test_recall': 0.8786407766990292}
--------------------------------------------------------------------------------
Could not create dir out, File exists
    ########### 



New Dataset: <function deepmatcher_structured_itunes_amazon at 0x1495c2d34700>

Test : 50
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6153846153846153,
 'test_loss': 0.358628511428833,
 'test_prec': 1.0,
 'test_recall': 0.4444444444444444}
--------------------------------------------------------------------------------
{'test_loss': 0.358628511428833, 'test_prec': 1.0, 'test_recall': 0.4444444444444444, 'test_f1': 0.6153846153846153, 'positive_rate': 0.36, 'labeled_instances': 50, 'iteration_time': 229.88164734840393}
-- Random test --

     a.index  b.index  matching
173     1736    10938      True
132     3358    39320      True
197     1263    28025     False
9       2477     1222     False
104     5682    35056     False
119     3378     7377     False
250      311    22308     False
158     3255     4532     False
226     2962    22498     False
310     2394    29834      True
196     3414    34350     False
90      5806     6499      True
277     4743    41115     False
84       254    49104      True
185     6724    17069      True
268     3870    23901      True
126     5852    32665     False
78      1278    34912     False
25       303    22290     False
5       1303    34060     False
204     1759    27480     False
55      2841    52852     False
46      2749    17161      True
304     5161    34090     False
298     1069    11277      True
114     1579    41593     False
57      1183    34915     False
77      3093    22994      True
195     3450     7383     False
254     1570    27494     False
108     2729    17190     False
208     1784    11758     False
63      1159    28024     False
209     4733    31618     False
247     3499    54794     False
172     3450    34292     False
290     3312    34309     False
33      2694    17169     False
143     3327    34307     False
164     1314    34035     False
302     1263    34898     False
42      6234    13713      True
256     2375     3581      True
316     6282    47824     False
45      1625    27515     False
301     4587    26140      True
82      4761     6229     False
94      4047    37547     False
16      4236    27814     False
75      2987    37085     False
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8076923076923077,
 'test_loss': 0.256785124540329,
 'test_prec': 0.84,
 'test_recall': 0.7777777777777778}
--------------------------------------------------------------------------------

Test : 75
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.84,
 'test_loss': 0.16105617582798004,
 'test_prec': 0.9130434782608695,
 'test_recall': 0.7777777777777778}
--------------------------------------------------------------------------------
{'test_loss': 0.16105617582798004, 'test_prec': 0.9130434782608695, 'test_recall': 0.7777777777777778, 'test_f1': 0.84, 'positive_rate': 0.38666666666666666, 'labeled_instances': 75, 'iteration_time': 239.05683588981628}
-- Random test --

     a.index  b.index  matching
173     1736    10938      True
132     3358    39320      True
197     1263    28025     False
9       2477     1222     False
104     5682    35056     False
..       ...      ...       ...
73      5079    40453     False
101     1264    28000     False
137     1277    28012     False
281     6851    39325     False
294     3527    54789     False

[75 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9259259259259259,
 'test_loss': 0.10428684204816818,
 'test_prec': 0.9259259259259259,
 'test_recall': 0.9259259259259259}
--------------------------------------------------------------------------------

Test : 100
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9411764705882353,
 'test_loss': 0.10192830860614777,
 'test_prec': 1.0,
 'test_recall': 0.8888888888888888}
--------------------------------------------------------------------------------
{'test_loss': 0.10192830860614777, 'test_prec': 1.0, 'test_recall': 0.8888888888888888, 'test_f1': 0.9411764705882353, 'positive_rate': 0.41, 'labeled_instances': 100, 'iteration_time': 230.78698444366455}
-- Random test --

     a.index  b.index  matching
173     1736    10938      True
132     3358    39320      True
197     1263    28025     False
9       2477     1222     False
104     5682    35056     False
..       ...      ...       ...
167     6855     7373     False
145     1263    31287     False
206     1175    34891     False
81      6624      800     False
147     1542    41566     False

[100 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8800000000000001,
 'test_loss': 0.19837619364261627,
 'test_prec': 0.9565217391304348,
 'test_recall': 0.8148148148148148}
--------------------------------------------------------------------------------

Test : 120
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9285714285714286,
 'test_loss': 0.0893978476524353,
 'test_prec': 0.896551724137931,
 'test_recall': 0.9629629629629629}
--------------------------------------------------------------------------------
{'test_loss': 0.0893978476524353, 'test_prec': 0.896551724137931, 'test_recall': 0.9629629629629629, 'test_f1': 0.9285714285714286, 'positive_rate': 0.425, 'labeled_instances': 120, 'iteration_time': 238.10234189033508}
-- Random test --

     a.index  b.index  matching
173     1736    10938      True
132     3358    39320      True
197     1263    28025     False
9       2477     1222     False
104     5682    35056     False
..       ...      ...       ...
79      1343     6231     False
124     2020    28341     False
184     3564    19787     False
72      1489     3898      True
96      2845    52867      True

[120 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9433962264150944,
 'test_loss': 0.08295559883117676,
 'test_prec': 0.9615384615384616,
 'test_recall': 0.9259259259259259}
--------------------------------------------------------------------------------

Test : 140
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9629629629629629,
 'test_loss': 0.05113682895898819,
 'test_prec': 0.9629629629629629,
 'test_recall': 0.9629629629629629}
--------------------------------------------------------------------------------
{'test_loss': 0.05113682895898819, 'test_prec': 0.9629629629629629, 'test_recall': 0.9629629629629629, 'test_f1': 0.9629629629629629, 'positive_rate': 0.4357142857142857, 'labeled_instances': 140, 'iteration_time': 246.24648571014404}
-- Random test --

     a.index  b.index  matching
173     1736    10938      True
132     3358    39320      True
197     1263    28025     False
9       2477     1222     False
104     5682    35056     False
..       ...      ...       ...
285      969    41979     False
86      6857    39318      True
271     4326    23361      True
146     3312    34336     False
272     4678    41114     False

[140 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9259259259259259,
 'test_loss': 0.15782061219215393,
 'test_prec': 0.9259259259259259,
 'test_recall': 0.9259259259259259}
--------------------------------------------------------------------------------

Test : 160
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9454545454545454,
 'test_loss': 0.09804627299308777,
 'test_prec': 0.9285714285714286,
 'test_recall': 0.9629629629629629}
--------------------------------------------------------------------------------
{'test_loss': 0.09804627299308777, 'test_prec': 0.9285714285714286, 'test_recall': 0.9629629629629629, 'test_f1': 0.9454545454545454, 'positive_rate': 0.44375, 'labeled_instances': 160, 'iteration_time': 251.76689553260803}
-- Random test --

     a.index  b.index  matching
173     1736    10938      True
132     3358    39320      True
197     1263    28025     False
9       2477     1222     False
104     5682    35056     False
..       ...      ...       ...
309     6876    13612     False
291      368    19176     False
177     3449     7363     False
280     6011    47246     False
154     5080     9487     False

[160 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.923076923076923,
 'test_loss': 0.12094759196043015,
 'test_prec': 0.96,
 'test_recall': 0.8888888888888888}
--------------------------------------------------------------------------------

Test : 180
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9454545454545454,
 'test_loss': 0.11069808900356293,
 'test_prec': 0.9285714285714286,
 'test_recall': 0.9629629629629629}
--------------------------------------------------------------------------------
{'test_loss': 0.11069808900356293, 'test_prec': 0.9285714285714286, 'test_recall': 0.9629629629629629, 'test_f1': 0.9454545454545454, 'positive_rate': 0.42777777777777776, 'labeled_instances': 180, 'iteration_time': 239.0865020751953}
-- Random test --

     a.index  b.index  matching
173     1736    10938      True
132     3358    39320      True
197     1263    28025     False
9       2477     1222     False
104     5682    35056     False
..       ...      ...       ...
181     1735    10926      True
133     1022     9526     False
219     1345    42034     False
248     5073    34877     False
296     5122    34113      True

[180 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.92,
 'test_loss': 0.15369458496570587,
 'test_prec': 1.0,
 'test_recall': 0.8518518518518519}
--------------------------------------------------------------------------------

Test : 200
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 28 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9473684210526316,
 'test_loss': 0.10296428948640823,
 'test_prec': 0.9,
 'test_recall': 1.0}
--------------------------------------------------------------------------------
{'test_loss': 0.10296428948640823, 'test_prec': 0.9, 'test_recall': 1.0, 'test_f1': 0.9473684210526316, 'positive_rate': 0.385, 'labeled_instances': 200, 'iteration_time': 239.44801330566406}
-- Random test --

     a.index  b.index  matching
173     1736    10938      True
132     3358    39320      True
197     1263    28025     False
9       2477     1222     False
104     5682    35056     False
..       ...      ...       ...
238     3104    22995      True
178     2490     4511      True
253     3507    23084      True
41       801    29543     False
89      5707    37649     False

[200 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 124 M 
---------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
498.586   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9090909090909091,
 'test_loss': 0.16428396105766296,
 'test_prec': 0.8928571428571429,
 'test_recall': 0.9259259259259259}
--------------------------------------------------------------------------------

Test : 250
-- Full test test --

Positive rate: 0.24299065420560748
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9818181818181818,
 'test_loss': 0.06976588070392609,
 'test_prec': 0.9642857142857143,
 'test_recall': 1.0}
--------------------------------------------------------------------------------
Could not create dir out, File exists
End of job!
