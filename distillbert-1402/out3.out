We are running from this directory: /cluster/work/oyvinsam
The name of the job is: alt-3
The job ID is 29538
The job was run on these nodes: idun-06-01
Number of nodes: 1
We are using 1 cores
We are using 1 cores per node
Total of 1 cores
Mon Mar 15 19:10:49 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.27.04    Driver Version: 460.27.04    CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-PCIE...  Off  | 00000000:C2:00.0 Off |                    0 |
| N/A   33C    P0    34W / 250W |      0MiB / 32510MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
fatal: destination path 'experiment-data' already exists and is not an empty directory.
Launch Python
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
Could not create dir out, File exists
[50, 75, 100, 120, 140, 160, 180, 200, 250, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 2000]
    ########### 



New Dataset: <function deepmatcher_textual_abt_buy at 0x145e718819d0>

Test : 50
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.3429989814758301,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------
{'test_loss': 0.3429989814758301, 'test_prec': 0.0, 'test_recall': 0.0, 'test_f1': 0.0, 'positive_rate': 0.18, 'labeled_instances': [50, 75, 100, 120, 140, 160, 180, 200, 250, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 2000], 'iteration_time': 551.0522458553314}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
1586      612      616      True
4694      473      568     False
3095      764      648     False
199       852      821     False
3827      906      245     False
624       422      155     False
1393     1056       46     False
1454      631      716     False
3634       44      740     False
3323      661      671     False
3103      425      242     False
3787      636      758     False
3728      451      506     False
101      1076      526     False
2173      655      503     False
5065      476      629     False
576       194       81      True
3915      459      384     False
1315      715      567     False
132        55      102     False
4083      779      661     False
3066      489      736     False
1046      607      881     False
1954      785      121     False
808       496      561     False
1872      579      714     False
2794      257      194     False
4756      550      709     False
1779      482      415     False
1566      535      302     False
4472      912     1005     False
1370      337      183     False
3145      118      617     False
3783      617      988     False
1194      481      846     False
3892      901      961     False
907       921     1008     False
2063      665      641     False
2809      469      585     False
599       445      414     False
1477      383      483     False
5417      172      358     False
4153      906      294     False
5597      857      607     False
2522      402      391     False
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.3408482074737549,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 75
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.3364833891391754,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------
{'test_loss': 0.3364833891391754, 'test_prec': 0.0, 'test_recall': 0.0, 'test_f1': 0.0, 'positive_rate': 0.17333333333333334, 'labeled_instances': [50, 75, 100, 120, 140, 160, 180, 200, 250, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 2000], 'iteration_time': 364.83955359458923}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
805       692      789     False
1084      502      553      True
896      1037      949     False
5539      176      688     False
4839      168      245     False

[75 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0,
 'test_loss': 0.3760344982147217,
 'test_prec': 0.0,
 'test_recall': 0.0}
--------------------------------------------------------------------------------

Test : 100
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.03636363636363636,
 'test_loss': 0.3420516550540924,
 'test_prec': 0.2857142857142857,
 'test_recall': 0.019417475728155338}
--------------------------------------------------------------------------------
{'test_loss': 0.3420516550540924, 'test_prec': 0.2857142857142857, 'test_recall': 0.019417475728155338, 'test_f1': 0.03636363636363636, 'positive_rate': 0.19, 'labeled_instances': [50, 75, 100, 120, 140, 160, 180, 200, 250, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 2000], 'iteration_time': 431.2459065914154}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
3286      708      742     False
2022      902      631     False
5072      443      585     False
4705      940      574     False
755      1019      172     False

[100 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.009433962264150943,
 'test_loss': 0.4020894765853882,
 'test_prec': 0.16666666666666666,
 'test_recall': 0.0048543689320388345}
--------------------------------------------------------------------------------

Test : 120
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.05172413793103449,
 'test_loss': 0.37369996309280396,
 'test_prec': 0.23076923076923078,
 'test_recall': 0.02912621359223301}
--------------------------------------------------------------------------------
{'test_loss': 0.37369996309280396, 'test_prec': 0.23076923076923078, 'test_recall': 0.02912621359223301, 'test_f1': 0.05172413793103449, 'positive_rate': 0.225, 'labeled_instances': [50, 75, 100, 120, 140, 160, 180, 200, 250, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 2000], 'iteration_time': 362.4548580646515}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
3237      750      405     False
3262      570      667     False
5379       64      307     False
911       532      762     False
1412      184      539     False

[120 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.026785714285714284,
 'test_loss': 0.4962114691734314,
 'test_prec': 0.16666666666666666,
 'test_recall': 0.014563106796116505}
--------------------------------------------------------------------------------

Test : 140
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.22121212121212122,
 'test_loss': 0.7034619450569153,
 'test_prec': 0.16079295154185022,
 'test_recall': 0.35436893203883496}
--------------------------------------------------------------------------------
{'test_loss': 0.7034619450569153, 'test_prec': 0.16079295154185022, 'test_recall': 0.35436893203883496, 'test_f1': 0.22121212121212122, 'positive_rate': 0.2857142857142857, 'labeled_instances': [50, 75, 100, 120, 140, 160, 180, 200, 250, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 2000], 'iteration_time': 415.9786913394928}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
4192      660      621     False
5586      545      716     False
14        519      399     False
2402      578     1061     False
3768      903      399     False

[140 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.027397260273972605,
 'test_loss': 0.44796791672706604,
 'test_prec': 0.23076923076923078,
 'test_recall': 0.014563106796116505}
--------------------------------------------------------------------------------

Test : 160
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.25817555938037867,
 'test_loss': 0.5368531942367554,
 'test_prec': 0.2,
 'test_recall': 0.3640776699029126}
--------------------------------------------------------------------------------
{'test_loss': 0.5368531942367554, 'test_prec': 0.2, 'test_recall': 0.3640776699029126, 'test_f1': 0.25817555938037867, 'positive_rate': 0.31875, 'labeled_instances': [50, 75, 100, 120, 140, 160, 180, 200, 250, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 2000], 'iteration_time': 355.720903635025}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
865       897      622     False
79        741     1077     False
5429       95       83     False
181       534      634     False
2932     1038      716     False

[160 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.0398406374501992,
 'test_loss': 0.5190655589103699,
 'test_prec': 0.1111111111111111,
 'test_recall': 0.024271844660194174}
--------------------------------------------------------------------------------

Test : 180
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.2058823529411765,
 'test_loss': 0.484580397605896,
 'test_prec': 0.16568047337278108,
 'test_recall': 0.27184466019417475}
--------------------------------------------------------------------------------
{'test_loss': 0.484580397605896, 'test_prec': 0.16568047337278108, 'test_recall': 0.27184466019417475, 'test_f1': 0.2058823529411765, 'positive_rate': 0.32222222222222224, 'labeled_instances': [50, 75, 100, 120, 140, 160, 180, 200, 250, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 2000], 'iteration_time': 306.63002848625183}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
4954      953      187     False
4596      901      510     False
2638      584      660     False
5275      136      234     False
915       892     1061     False

[180 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.017857142857142856,
 'test_loss': 0.5379369854927063,
 'test_prec': 0.1111111111111111,
 'test_recall': 0.009708737864077669}
--------------------------------------------------------------------------------

Test : 200
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.2361963190184049,
 'test_loss': 0.6559662818908691,
 'test_prec': 0.1726457399103139,
 'test_recall': 0.3737864077669903}
--------------------------------------------------------------------------------
{'test_loss': 0.6559662818908691, 'test_prec': 0.1726457399103139, 'test_recall': 0.3737864077669903, 'test_f1': 0.2361963190184049, 'positive_rate': 0.34, 'labeled_instances': [50, 75, 100, 120, 140, 160, 180, 200, 250, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 2000], 'iteration_time': 354.8103663921356}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
2607     1014      736     False
1988      869      987     False
2603      543      716     False
3143      716      800     False
1038      399       72     False

[200 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.025974025974025976,
 'test_loss': 0.5585103631019592,
 'test_prec': 0.12,
 'test_recall': 0.014563106796116505}
--------------------------------------------------------------------------------

Test : 250
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.4752066115702479,
 'test_loss': 0.37372392416000366,
 'test_prec': 0.4136690647482014,
 'test_recall': 0.558252427184466}
--------------------------------------------------------------------------------
{'test_loss': 0.37372392416000366, 'test_prec': 0.4136690647482014, 'test_recall': 0.558252427184466, 'test_f1': 0.4752066115702479, 'positive_rate': 0.368, 'labeled_instances': [50, 75, 100, 120, 140, 160, 180, 200, 250, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 2000], 'iteration_time': 230.90991258621216}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
4578      180      627     False
4797      471      476     False
2357     1039       98     False
5350      864      504     False
4584     1010      528     False

[250 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.10071942446043165,
 'test_loss': 0.5481802821159363,
 'test_prec': 0.19444444444444445,
 'test_recall': 0.06796116504854369}
--------------------------------------------------------------------------------

Test : 300
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.3100511073253833,
 'test_loss': 0.4973677098751068,
 'test_prec': 0.2388451443569554,
 'test_recall': 0.441747572815534}
--------------------------------------------------------------------------------
{'test_loss': 0.4973677098751068, 'test_prec': 0.2388451443569554, 'test_recall': 0.441747572815534, 'test_f1': 0.3100511073253833, 'positive_rate': 0.38666666666666666, 'labeled_instances': [50, 75, 100, 120, 140, 160, 180, 200, 250, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 2000], 'iteration_time': 221.15201115608215}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
1302      658      621     False
3866      649      663     False
932       489      629     False
1095      952      428     False
2018      194      480     False

[300 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.07692307692307693,
 'test_loss': 0.5607759356498718,
 'test_prec': 0.32142857142857145,
 'test_recall': 0.043689320388349516}
--------------------------------------------------------------------------------

Test : 400
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6707818930041152,
 'test_loss': 0.24456757307052612,
 'test_prec': 0.5821428571428572,
 'test_recall': 0.7912621359223301}
--------------------------------------------------------------------------------
{'test_loss': 0.24456757307052612, 'test_prec': 0.5821428571428572, 'test_recall': 0.7912621359223301, 'test_f1': 0.6707818930041152, 'positive_rate': 0.41, 'labeled_instances': [50, 75, 100, 120, 140, 160, 180, 200, 250, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 2000], 'iteration_time': 222.57259106636047}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
1745      780      484     False
1488      842      816     False
5367       14      302     False
5083      115       72     False
4141      915     1068     False

[400 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.11522633744855967,
 'test_loss': 0.572706401348114,
 'test_prec': 0.3783783783783784,
 'test_recall': 0.06796116504854369}
--------------------------------------------------------------------------------

Test : 500
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6773455377574371,
 'test_loss': 0.22521698474884033,
 'test_prec': 0.6406926406926406,
 'test_recall': 0.7184466019417476}
--------------------------------------------------------------------------------
{'test_loss': 0.22521698474884033, 'test_prec': 0.6406926406926406, 'test_recall': 0.7184466019417476, 'test_f1': 0.6773455377574371, 'positive_rate': 0.426, 'labeled_instances': [50, 75, 100, 120, 140, 160, 180, 200, 250, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 2000], 'iteration_time': 230.0431945323944}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
5184      444     1000     False
2067      883      727     False
1197      667      100     False
1074      847      686     False
3872      484      475     False

[500 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.3127035830618893,
 'test_loss': 0.4147319793701172,
 'test_prec': 0.4752475247524752,
 'test_recall': 0.23300970873786409}
--------------------------------------------------------------------------------

Test : 600
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7172995780590717,
 'test_loss': 0.2269677072763443,
 'test_prec': 0.6343283582089553,
 'test_recall': 0.8252427184466019}
--------------------------------------------------------------------------------
{'test_loss': 0.2269677072763443, 'test_prec': 0.6343283582089553, 'test_recall': 0.8252427184466019, 'test_f1': 0.7172995780590717, 'positive_rate': 0.42833333333333334, 'labeled_instances': [50, 75, 100, 120, 140, 160, 180, 200, 250, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 2000], 'iteration_time': 233.44101548194885}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
5339      858      563     False
367       875     1060     False
5540      650      694     False
4561      932      977     False
5687      473      650     False

[600 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5819209039548022,
 'test_loss': 0.29147881269454956,
 'test_prec': 0.6959459459459459,
 'test_recall': 0.5}
--------------------------------------------------------------------------------

Test : 700
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7268722466960351,
 'test_loss': 0.22500495612621307,
 'test_prec': 0.6653225806451613,
 'test_recall': 0.8009708737864077}
--------------------------------------------------------------------------------
{'test_loss': 0.22500495612621307, 'test_prec': 0.6653225806451613, 'test_recall': 0.8009708737864077, 'test_f1': 0.7268722466960351, 'positive_rate': 0.41, 'labeled_instances': [50, 75, 100, 120, 140, 160, 180, 200, 250, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 2000], 'iteration_time': 239.00198936462402}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
4640      941      966     False
106       280      633     False
4831      962      540     False
2272      693      772     False
4335      476      630     False

[700 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6333333333333333,
 'test_loss': 0.24161414802074432,
 'test_prec': 0.7402597402597403,
 'test_recall': 0.5533980582524272}
--------------------------------------------------------------------------------

Test : 800
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7521739130434784,
 'test_loss': 0.22742041945457458,
 'test_prec': 0.6811023622047244,
 'test_recall': 0.8398058252427184}
--------------------------------------------------------------------------------
{'test_loss': 0.22742041945457458, 'test_prec': 0.6811023622047244, 'test_recall': 0.8398058252427184, 'test_f1': 0.7521739130434784, 'positive_rate': 0.37625, 'labeled_instances': [50, 75, 100, 120, 140, 160, 180, 200, 250, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 2000], 'iteration_time': 243.32629299163818}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
5062      774      807      True
711       511      595     False
811       455      980     False
3429      547      595     False
4649      230      913     False

[800 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6333333333333333,
 'test_loss': 0.2697458267211914,
 'test_prec': 0.7402597402597403,
 'test_recall': 0.5533980582524272}
--------------------------------------------------------------------------------

Test : 900
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7319148936170212,
 'test_loss': 0.24558578431606293,
 'test_prec': 0.6515151515151515,
 'test_recall': 0.8349514563106796}
--------------------------------------------------------------------------------
{'test_loss': 0.24558578431606293, 'test_prec': 0.6515151515151515, 'test_recall': 0.8349514563106796, 'test_f1': 0.7319148936170212, 'positive_rate': 0.3511111111111111, 'labeled_instances': [50, 75, 100, 120, 140, 160, 180, 200, 250, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 2000], 'iteration_time': 254.64414954185486}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
3260      529      879     False
30        919     1004     False
3439      885      846     False
1951      946      152     False
3481      843      676     False

[900 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.3926380368098159,
 'test_loss': 0.3905922472476959,
 'test_prec': 0.5333333333333333,
 'test_recall': 0.3106796116504854}
--------------------------------------------------------------------------------

Test : 1000
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7308533916849015,
 'test_loss': 0.25585323572158813,
 'test_prec': 0.6653386454183267,
 'test_recall': 0.8106796116504854}
--------------------------------------------------------------------------------
{'test_loss': 0.25585323572158813, 'test_prec': 0.6653386454183267, 'test_recall': 0.8106796116504854, 'test_f1': 0.7308533916849015, 'positive_rate': 0.339, 'labeled_instances': [50, 75, 100, 120, 140, 160, 180, 200, 250, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 2000], 'iteration_time': 286.76414799690247}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
4414     1069      518      True
44        637      429     False
5709     1001      991     False
1652      267      347     False
746       615      641     False

[1000 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5063291139240507,
 'test_loss': 0.33932968974113464,
 'test_prec': 0.7272727272727273,
 'test_recall': 0.3883495145631068}
--------------------------------------------------------------------------------

Test : 1100
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7380410022779044,
 'test_loss': 0.23966796696186066,
 'test_prec': 0.6952789699570815,
 'test_recall': 0.7864077669902912}
--------------------------------------------------------------------------------
{'test_loss': 0.23966796696186066, 'test_prec': 0.6952789699570815, 'test_recall': 0.7864077669902912, 'test_f1': 0.7380410022779044, 'positive_rate': 0.31727272727272726, 'labeled_instances': [50, 75, 100, 120, 140, 160, 180, 200, 250, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 2000], 'iteration_time': 263.4073898792267}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
4147      484      419     False
2232      896      622     False
1919      722      800     False
3245      171       45      True
252       900      629     False

[1100 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6189111747851003,
 'test_loss': 0.31214454770088196,
 'test_prec': 0.7552447552447552,
 'test_recall': 0.5242718446601942}
--------------------------------------------------------------------------------

Test : 1200
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7437641723356009,
 'test_loss': 0.22284384071826935,
 'test_prec': 0.6978723404255319,
 'test_recall': 0.7961165048543689}
--------------------------------------------------------------------------------
{'test_loss': 0.22284384071826935, 'test_prec': 0.6978723404255319, 'test_recall': 0.7961165048543689, 'test_f1': 0.7437641723356009, 'positive_rate': 0.30416666666666664, 'labeled_instances': [50, 75, 100, 120, 140, 160, 180, 200, 250, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 2000], 'iteration_time': 270.57827281951904}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
4163      970      402     False
5492      325      596     False
670       540      665     False
3574      659      113     False
3786      885      475     False

[1200 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.689295039164491,
 'test_loss': 0.24016253650188446,
 'test_prec': 0.7457627118644068,
 'test_recall': 0.6407766990291263}
--------------------------------------------------------------------------------

Test : 1300
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7586206896551724,
 'test_loss': 0.22082673013210297,
 'test_prec': 0.7205240174672489,
 'test_recall': 0.8009708737864077}
--------------------------------------------------------------------------------
{'test_loss': 0.22082673013210297, 'test_prec': 0.7205240174672489, 'test_recall': 0.8009708737864077, 'test_f1': 0.7586206896551724, 'positive_rate': 0.30153846153846153, 'labeled_instances': [50, 75, 100, 120, 140, 160, 180, 200, 250, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 2000], 'iteration_time': 274.2046444416046}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
3209      570      971     False
1620       73      870     False
957       528      835     False
3919      345      662     False
2536      482      907     False

[1300 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6759776536312849,
 'test_loss': 0.2724989652633667,
 'test_prec': 0.7960526315789473,
 'test_recall': 0.587378640776699}
--------------------------------------------------------------------------------

Test : 1400
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7838479809976248,
 'test_loss': 0.20399335026741028,
 'test_prec': 0.7674418604651163,
 'test_recall': 0.8009708737864077}
--------------------------------------------------------------------------------
{'test_loss': 0.20399335026741028, 'test_prec': 0.7674418604651163, 'test_recall': 0.8009708737864077, 'test_f1': 0.7838479809976248, 'positive_rate': 0.2892857142857143, 'labeled_instances': [50, 75, 100, 120, 140, 160, 180, 200, 250, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 2000], 'iteration_time': 283.25312757492065}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
4267      491      574     False
120       615      637     False
2671      951      500     False
3612      174      182      True
5032      531      313     False

[1400 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6826666666666665,
 'test_loss': 0.22747570276260376,
 'test_prec': 0.757396449704142,
 'test_recall': 0.6213592233009708}
--------------------------------------------------------------------------------

Test : 1500
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7885985748218527,
 'test_loss': 0.1867576390504837,
 'test_prec': 0.772093023255814,
 'test_recall': 0.8058252427184466}
--------------------------------------------------------------------------------
{'test_loss': 0.1867576390504837, 'test_prec': 0.772093023255814, 'test_recall': 0.8058252427184466, 'test_f1': 0.7885985748218527, 'positive_rate': 0.278, 'labeled_instances': [50, 75, 100, 120, 140, 160, 180, 200, 250, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 2000], 'iteration_time': 290.0748257637024}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
1694      699      774     False
5466      966     1068      True
4382      625     1064     False
3253      550      763     False
841       466      580     False

[1500 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7046632124352331,
 'test_loss': 0.22467923164367676,
 'test_prec': 0.7555555555555555,
 'test_recall': 0.6601941747572816}
--------------------------------------------------------------------------------

Test : 2000
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7877358490566038,
 'test_loss': 0.19562114775180817,
 'test_prec': 0.7660550458715596,
 'test_recall': 0.8106796116504854}
--------------------------------------------------------------------------------
{'test_loss': 0.19562114775180817, 'test_prec': 0.7660550458715596, 'test_recall': 0.8106796116504854, 'test_f1': 0.7877358490566038, 'positive_rate': 0.2355, 'labeled_instances': [50, 75, 100, 120, 140, 160, 180, 200, 250, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 2000], 'iteration_time': 315.1360342502594}
-- Random test --

      a.index  b.index  matching
763       843      821     False
3316      544      692     False
5454      725      687      True
5537      459      464     False
4943      515      547     False
...       ...      ...       ...
3799      510      924     False
4741      438      751     False
618       615      633     False
4913      916     1004     False
4072      905      727     False

[2000 rows x 3 columns]
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7002801120448179,
 'test_loss': 0.2611634135246277,
 'test_prec': 0.8278145695364238,
 'test_recall': 0.6067961165048543}
--------------------------------------------------------------------------------
-- Full test test --

Positive rate: 0.10726101340762667
Traceback (most recent call last):
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/eb/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8478802992518701,
 'test_loss': 0.1729310154914856,
 'test_prec': 0.8717948717948718,
 'test_recall': 0.8252427184466019}
--------------------------------------------------------------------------------
Could not create dir out, File exists
    ########### 



New Dataset: <function deepmatcher_structured_itunes_amazon at 0x145e71881700>

Test : 50
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7058823529411765,
 'test_loss': 0.36193984746932983,
 'test_prec': 0.75,
 'test_recall': 0.6666666666666666}
--------------------------------------------------------------------------------
{'test_loss': 0.36193984746932983, 'test_prec': 0.75, 'test_recall': 0.6666666666666666, 'test_f1': 0.7058823529411765, 'positive_rate': 0.36, 'labeled_instances': [50, 75, 100, 120, 140, 160, 180, 200, 250, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 2000], 'iteration_time': 210.02607679367065}
-- Random test --

     a.index  b.index  matching
173     1736    10938      True
132     3358    39320      True
197     1263    28025     False
9       2477     1222     False
104     5682    35056     False
119     3378     7377     False
250      311    22308     False
158     3255     4532     False
226     2962    22498     False
310     2394    29834      True
196     3414    34350     False
90      5806     6499      True
277     4743    41115     False
84       254    49104      True
185     6724    17069      True
268     3870    23901      True
126     5852    32665     False
78      1278    34912     False
25       303    22290     False
5       1303    34060     False
204     1759    27480     False
55      2841    52852     False
46      2749    17161      True
304     5161    34090     False
298     1069    11277      True
114     1579    41593     False
57      1183    34915     False
77      3093    22994      True
195     3450     7383     False
254     1570    27494     False
108     2729    17190     False
208     1784    11758     False
63      1159    28024     False
209     4733    31618     False
247     3499    54794     False
172     3450    34292     False
290     3312    34309     False
33      2694    17169     False
143     3327    34307     False
164     1314    34035     False
302     1263    34898     False
42      6234    13713      True
256     2375     3581      True
316     6282    47824     False
45      1625    27515     False
301     4587    26140      True
82      4761     6229     False
94      4047    37547     False
16      4236    27814     False
75      2987    37085     False
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.5957446808510639,
 'test_loss': 0.4081583619117737,
 'test_prec': 0.7,
 'test_recall': 0.5185185185185185}
--------------------------------------------------------------------------------

Test : 75
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.72,
 'test_loss': 0.40570151805877686,
 'test_prec': 0.782608695652174,
 'test_recall': 0.6666666666666666}
--------------------------------------------------------------------------------
{'test_loss': 0.40570151805877686, 'test_prec': 0.782608695652174, 'test_recall': 0.6666666666666666, 'test_f1': 0.72, 'positive_rate': 0.38666666666666666, 'labeled_instances': [50, 75, 100, 120, 140, 160, 180, 200, 250, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 2000], 'iteration_time': 199.0291886329651}
-- Random test --

     a.index  b.index  matching
173     1736    10938      True
132     3358    39320      True
197     1263    28025     False
9       2477     1222     False
104     5682    35056     False
..       ...      ...       ...
73      5079    40453     False
101     1264    28000     False
137     1277    28012     False
281     6851    39325     False
294     3527    54789     False

[75 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.48648648648648646,
 'test_loss': 0.3855054974555969,
 'test_prec': 0.9,
 'test_recall': 0.3333333333333333}
--------------------------------------------------------------------------------

Test : 100
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8571428571428572,
 'test_loss': 0.18726123869419098,
 'test_prec': 0.8275862068965517,
 'test_recall': 0.8888888888888888}
--------------------------------------------------------------------------------
{'test_loss': 0.18726123869419098, 'test_prec': 0.8275862068965517, 'test_recall': 0.8888888888888888, 'test_f1': 0.8571428571428572, 'positive_rate': 0.41, 'labeled_instances': [50, 75, 100, 120, 140, 160, 180, 200, 250, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 2000], 'iteration_time': 202.18488192558289}
-- Random test --

     a.index  b.index  matching
173     1736    10938      True
132     3358    39320      True
197     1263    28025     False
9       2477     1222     False
104     5682    35056     False
..       ...      ...       ...
167     6855     7373     False
145     1263    31287     False
206     1175    34891     False
81      6624      800     False
147     1542    41566     False

[100 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.711864406779661,
 'test_loss': 0.35990390181541443,
 'test_prec': 0.65625,
 'test_recall': 0.7777777777777778}
--------------------------------------------------------------------------------

Test : 120
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8888888888888888,
 'test_loss': 0.1653287559747696,
 'test_prec': 0.8888888888888888,
 'test_recall': 0.8888888888888888}
--------------------------------------------------------------------------------
{'test_loss': 0.1653287559747696, 'test_prec': 0.8888888888888888, 'test_recall': 0.8888888888888888, 'test_f1': 0.8888888888888888, 'positive_rate': 0.425, 'labeled_instances': [50, 75, 100, 120, 140, 160, 180, 200, 250, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 2000], 'iteration_time': 206.7324607372284}
-- Random test --

     a.index  b.index  matching
173     1736    10938      True
132     3358    39320      True
197     1263    28025     False
9       2477     1222     False
104     5682    35056     False
..       ...      ...       ...
79      1343     6231     False
124     2020    28341     False
184     3564    19787     False
72      1489     3898      True
96      2845    52867      True

[120 rows x 3 columns]
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.6956521739130435,
 'test_loss': 0.2785075902938843,
 'test_prec': 0.8421052631578947,
 'test_recall': 0.5925925925925926}
--------------------------------------------------------------------------------

Test : 140
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.7346938775510203,
 'test_loss': 0.2693679630756378,
 'test_prec': 0.8181818181818182,
 'test_recall': 0.6666666666666666}
--------------------------------------------------------------------------------
{'test_loss': 0.2693679630756378, 'test_prec': 0.8181818181818182, 'test_recall': 0.6666666666666666, 'test_f1': 0.7346938775510203, 'positive_rate': 0.4357142857142857, 'labeled_instances': [50, 75, 100, 120, 140, 160, 180, 200, 250, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 2000], 'iteration_time': 212.15039205551147}
-- Random test --

     a.index  b.index  matching
173     1736    10938      True
132     3358    39320      True
197     1263    28025     False
9       2477     1222     False
104     5682    35056     False
..       ...      ...       ...
285      969    41979     False
86      6857    39318      True
271     4326    23361      True
146     3312    34336     False
272     4678    41114     False

[140 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8750000000000001,
 'test_loss': 0.1593988984823227,
 'test_prec': 1.0,
 'test_recall': 0.7777777777777778}
--------------------------------------------------------------------------------

Test : 160
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9259259259259259,
 'test_loss': 0.17313909530639648,
 'test_prec': 0.9259259259259259,
 'test_recall': 0.9259259259259259}
--------------------------------------------------------------------------------
{'test_loss': 0.17313909530639648, 'test_prec': 0.9259259259259259, 'test_recall': 0.9259259259259259, 'test_f1': 0.9259259259259259, 'positive_rate': 0.44375, 'labeled_instances': [50, 75, 100, 120, 140, 160, 180, 200, 250, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 2000], 'iteration_time': 210.9649522304535}
-- Random test --

     a.index  b.index  matching
173     1736    10938      True
132     3358    39320      True
197     1263    28025     False
9       2477     1222     False
104     5682    35056     False
..       ...      ...       ...
309     6876    13612     False
291      368    19176     False
177     3449     7363     False
280     6011    47246     False
154     5080     9487     False

[160 rows x 3 columns]
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.8888888888888888,
 'test_loss': 0.14752796292304993,
 'test_prec': 0.8888888888888888,
 'test_recall': 0.8888888888888888}
--------------------------------------------------------------------------------

Test : 180
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9433962264150944,
 'test_loss': 0.12570689618587494,
 'test_prec': 0.9615384615384616,
 'test_recall': 0.9259259259259259}
--------------------------------------------------------------------------------
{'test_loss': 0.12570689618587494, 'test_prec': 0.9615384615384616, 'test_recall': 0.9259259259259259, 'test_f1': 0.9433962264150944, 'positive_rate': 0.42777777777777776, 'labeled_instances': [50, 75, 100, 120, 140, 160, 180, 200, 250, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 2000], 'iteration_time': 217.94568848609924}
-- Random test --

     a.index  b.index  matching
173     1736    10938      True
132     3358    39320      True
197     1263    28025     False
9       2477     1222     False
104     5682    35056     False
..       ...      ...       ...
181     1735    10926      True
133     1022     9526     False
219     1345    42034     False
248     5073    34877     False
296     5122    34113      True

[180 rows x 3 columns]
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9454545454545454,
 'test_loss': 0.1125124916434288,
 'test_prec': 0.9285714285714286,
 'test_recall': 0.9629629629629629}
--------------------------------------------------------------------------------

Test : 200
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9259259259259259,
 'test_loss': 0.1630154252052307,
 'test_prec': 0.9259259259259259,
 'test_recall': 0.9259259259259259}
--------------------------------------------------------------------------------
{'test_loss': 0.1630154252052307, 'test_prec': 0.9259259259259259, 'test_recall': 0.9259259259259259, 'test_f1': 0.9259259259259259, 'positive_rate': 0.385, 'labeled_instances': [50, 75, 100, 120, 140, 160, 180, 200, 250, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 2000], 'iteration_time': 220.3218240737915}
-- Random test --

     a.index  b.index  matching
173     1736    10938      True
132     3358    39320      True
197     1263    28025     False
9       2477     1222     False
104     5682    35056     False
..       ...      ...       ...
238     3104    22995      True
178     2490     4511      True
253     3507    23084      True
41       801    29543     False
89      5707    37649     False

[200 rows x 3 columns]
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
Using native 16bit precision.
Set SLURM handle signals.

  | Name  | Type   | Params
---------------------------------
0 | model | _Model | 66.4 M
---------------------------------
66.4 M    Trainable params
0         Non-trainable params
66.4 M    Total params
265.455   Total estimated model params size (MB)
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9454545454545454,
 'test_loss': 0.10643872618675232,
 'test_prec': 0.9285714285714286,
 'test_recall': 0.9629629629629629}
--------------------------------------------------------------------------------

Test : 250
-- Full test test --

Positive rate: 0.24299065420560748
/cluster/work/oyvinsam/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test_f1': 0.9285714285714286,
 'test_loss': 0.13062147796154022,
 'test_prec': 0.896551724137931,
 'test_recall': 0.9629629629629629}
--------------------------------------------------------------------------------
Could not create dir out, File exists
End of job!
